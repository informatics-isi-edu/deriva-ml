{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ffee41-4986-4196-b35d-b38b6e10490a",
   "metadata": {},
   "source": [
    "DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library."
   ]
  },
  {
   "cell_type": "code",
   "id": "ff605747-195b-40a1-b915-0e799f8d0748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T07:38:59.116257Z",
     "start_time": "2025-01-09T07:38:59.099222Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9493a5ef-86b9-490b-a1d5-f461fdcd68ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T07:42:38.544410Z",
     "start_time": "2025-01-09T07:42:38.389772Z"
    }
   },
   "source": [
    "import builtins\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from deriva_ml import DatasetBag, ExecutionConfiguration, Workflow, MLVocab\n",
    "from deriva_ml.demo_catalog import create_demo_catalog, DemoML\n",
    "import itertools\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DerivaML' from partially initialized module 'deriva_ml.deriva_ml_base' (most likely due to a circular import) (/Users/carl/Repos/Projects/deriva-ml/src/deriva_ml/deriva_ml_base.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbuiltins\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mderiva\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mglobus_auth_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GlobusNativeLogin\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mderiva_ml\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DatasetBag, ExecutionConfiguration, Workflow, MLVocab\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mderiva_ml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdemo_catalog\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_demo_catalog, DemoML\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n",
      "File \u001B[0;32m~/Repos/Projects/deriva-ml/src/deriva_ml/__init__.py:16\u001B[0m\n\u001B[1;32m      1\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDerivaML\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDerivaMLException\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExecMetadataVocab\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     14\u001B[0m ]\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mderiva_ml_base\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DerivaML\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexecution_configuration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExecutionConfiguration, Workflow\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_bag\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DatasetBag\n",
      "File \u001B[0;32m~/Repos/Projects/deriva-ml/src/deriva_ml/deriva_ml_base.py:19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mderiva_definitions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MLVocab, ExecMetadataVocab\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexecution_configuration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExecutionConfiguration\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mderiva_ml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexecution\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mschema_setup\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_annotations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m generate_dataset_annotations\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mupload\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m asset_dir\n",
      "File \u001B[0;32m~/Repos/Projects/deriva-ml/src/deriva_ml/execution.py:6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mderiva\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m format_exception\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mderiva\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mermrest_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Table\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mderiva_ml_base\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DerivaML, FeatureRecord\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mderiva_definitions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RID, Status, FileUploadState, UploadState, MLVocab, DerivaMLException, ExecMetadataVocab\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexecution_configuration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExecutionConfiguration\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'DerivaML' from partially initialized module 'deriva_ml.deriva_ml_base' (most likely due to a circular import) (/Users/carl/Repos/Projects/deriva-ml/src/deriva_ml/deriva_ml_base.py)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ba06990f-6dc5-4805-9e82-0881a524bfef",
   "metadata": {},
   "source": [
    "Set the details for the catalog we want and authenticate to the server if needed."
   ]
  },
  {
   "cell_type": "code",
   "id": "9ee79ab7-a3f7-4c69-9c80-336871c13ec2",
   "metadata": {},
   "source": [
    "hostname = 'dev.eye-ai.org'\n",
    "domain_schema = 'demo-schema'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=hostname)\n",
    "if gnl.is_logged_in([hostname]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a23e5177-106b-48b6-b5e0-a126d35f4084",
   "metadata": {},
   "source": [
    "Create a test catalog and get an instance of the DerivaML class."
   ]
  },
  {
   "cell_type": "code",
   "id": "e9bddcf0-27ea-40b3-a388-b77635586fad",
   "metadata": {},
   "source": [
    "test_catalog = create_demo_catalog(hostname, domain_schema, create_features=True, create_datasets=True)\n",
    "ml_instance = DemoML(hostname, test_catalog.catalog_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b151033-6eb5-4fbb-a8dd-8d9b2154299a",
   "metadata": {},
   "source": [
    "display(\n",
    "    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Subject\")],\n",
    "    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Image\")]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_columns = ['RCT', 'RMT', 'RCB', 'RMB']\n",
    "datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=system_columns)\n",
    "training_dataset_rid = [ds['RID'] for ds in ml_instance.find_datasets() if 'Training' in ds['Dataset_Type']][0]\n",
    "\n",
    "display(\n",
    "    Markdown(f'Training Dataset: {training_dataset_rid}'),\n",
    "    Markdown('## Datasets'),\n",
    "    datasets)"
   ],
   "id": "29a0bd7230799257",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A feature is a set of values that are attached to a table in the DerivaML catalog. Instances of features are distingushed from one another by the ID of the execution that produced the feature value. The execution could be the result of a program, or it could be a manual process by which a person defines a set of values\n",
    "\n",
    "To create a new feature, we need to know the name of the feature, the table to which it is attached, and the set of values that make up the feature.  The values could be terms from a controlled vocabulary, a set of one or more file based assets, or other values, such as integers, or strings. However, use of strings outside of controlled vocabularies is discouraged."
   ],
   "id": "353d51c9-b8a6-4b75-a0da-ffa2db134169"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ml_instance.add_term(MLVocab.workflow_type, \"Manual Workflow\", description=\"A Workflow that uses Deriva ML API\")\n",
    "ml_instance.add_term(MLVocab.execution_asset_type, \"API_Model\", description=\"Model for our API workflow\")\n",
    "\n",
    "api_workflow = Workflow(\n",
    "    name=\"Manual Workflow\",\n",
    "    url=\"https://github.com/informatics-isi-edu/deriva-ml/blob/main/pyproject.toml\",\n",
    "    workflow_type=\"Manual Workflow\",\n",
    "    description=\"A manual operation\"\n",
    ")\n",
    "\n",
    "manual_execution = ml_instance.create_execution(ExecutionConfiguration( description=\"Sample Execution\", workflow=api_workflow))\n",
    "\n",
    "# Now lets create model configuration for our program.\n",
    "model_file = manual_execution.execution_assets_path('API_Model') / 'modelfile.txt'\n",
    "with builtins.open(model_file, \"w\") as fp:\n",
    "    fp.write(f\"My model\")\n",
    "\n",
    "# Now upload the file and retrieve the RID of the new asset from the returned results.\n",
    "uploaded_assets = manual_execution.upload_execution_outputs()\n",
    "training_model_rid = uploaded_assets['API_Model/modelfile.txt'].result['RID']"
   ],
   "id": "1d726b44-c60f-435a-9966-cfe3fc3da2e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now create a dataset with our new assets.",
   "id": "cfce553e81530e79"
  },
  {
   "cell_type": "markdown",
   "id": "83d2bd27-da2d-4918-9c8a-378c95addfcc",
   "metadata": {},
   "source": [
    "Now we can add some features to our images.  To streamline the creation of new feature, we create a class that is specific to the arguments required to create it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92416df1-e3f9-4097-bc19-b24712dc7242",
   "metadata": {},
   "source": [
    "Now using TestFeatureClass, we can create some instances of the feature and add it.  We must have a exeuction_rid in order to define the feature."
   ]
  },
  {
   "cell_type": "code",
   "id": "cdcc8f5c-874b-4bf9-89ef-e1ea90b9f91f",
   "metadata": {},
   "source": [
    "ml_instance.add_term(MLVocab.workflow_type, \"API Workflow\", description=\"A Workflow that uses Deriva ML API\")\n",
    "ml_instance.add_term(MLVocab.execution_asset_type, \"API_Model\", description=\"Model for our API workflow\")\n",
    "\n",
    "api_workflow = Workflow(\n",
    "    name=\"API Workflow\",\n",
    "    url=\"https://github.com/informatics-isi-edu/deriva-ml/blob/main/pyproject.toml\",\n",
    "    workflow_type=\"API Workflow\",\n",
    "    description=\"A workflow that uses Deriva ML\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=[training_dataset_rid],\n",
    "    assets = [training_model_rid],\n",
    "    description=\"Sample Execution\",\n",
    "    workflow=api_workflow\n",
    ")\n",
    "\n",
    "ml_execution = ml_instance.create_execution(config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with MLExecute(ml_execution):\n",
    "    # Get the input datasets:\n",
    "    training_dataset = DatasetBag(ml_execution.bag_paths[0])  # Input dataset\n",
    "    image_rids = training_dataset.get_table_as_dataframe('Image')['RID']\n",
    "\n",
    "    # Get input files\n",
    "    with open(ml_execution.asset_paths[0], 'rt') as model_file:\n",
    "        training_model = model_file.read()\n",
    "        print(f'Got model file: {training_model}')\n",
    "\n",
    "    # Put your ML code here....\n",
    "    pass\n",
    "\n",
    "    # Write a new model\n",
    "    model_file = manual_execution.execution_assets_path('API_Model') / 'modelfile.txt'\n",
    "    with open(model_file) as f:\n",
    "        f.write(\"Hello there a new model;\\n\")\n",
    "\n",
    "    # Create some new feature values.\n",
    "    bb_csv_path, bb_asset_paths = ml_execution.feature_paths('Image', 'BoundingBox')\n",
    "    bounding_box_files = [bb_asset_paths['BoundingBox'] / f\"box{i}.txt\" for i in range(10)]\n",
    "    for i in range(10):\n",
    "        bounding_box_files.append(fn := bb_asset_paths['BoundingBox'] / f\"box{i}.txt\")\n",
    "        with builtins.open(fn, \"w\") as fp:\n",
    "            fp.write(f\"Hi there {i}\")\n",
    "\n",
    "    ImageBoundingboxFeature = ml_instance.feature_record_class(\"Image\", \"BoundingBox\")\n",
    "    image_bounding_box_feature_list = [ImageBoundingboxFeature(Image=image_rid,\n",
    "                                                               Execution=ml_execution.execution_rid,\n",
    "                                                               BoundingBox=asset_rid)\n",
    "                                       for image_rid, asset_rid in zip(image_rids, itertools.cycle(bounding_box_files))]\n",
    "\n",
    "    ml_execution.write_feature_file(image_bounding_box_feature_list)\n",
    "\n",
    "upload_status = ml_execution.upload_execution_outputs()"
   ],
   "id": "c8860e47d5f72069",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "e = (list(ml_instance.pathBuilder.deriva_ml.Execution.entities().fetch()))[0]",
   "id": "bca63c2d15cce655",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame(ml_instance.list_feature_values(\"Image\", \"Feature1\")])",
   "id": "240cb784-0ffc-4fc5-aa8d-fb2ee9267355",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd670182dfb20afd",
   "metadata": {},
   "source": [
    "test_catalog.delete_ermrest_catalog(really=True)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
