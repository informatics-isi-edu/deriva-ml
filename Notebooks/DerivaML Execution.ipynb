{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ffee41-4986-4196-b35d-b38b6e10490a",
   "metadata": {},
   "source": [
    "DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library."
   ]
  },
  {
   "cell_type": "code",
   "id": "ff605747-195b-40a1-b915-0e799f8d0748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T04:58:58.826171Z",
     "start_time": "2025-01-09T04:58:58.798247Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9493a5ef-86b9-490b-a1d5-f461fdcd68ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T05:32:11.169253Z",
     "start_time": "2025-01-09T05:32:10.826863Z"
    }
   },
   "source": [
    "import builtins\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from deriva_ml.dataset_bag import DatasetBag\n",
    "from deriva_ml.demo_catalog import create_demo_catalog, DemoML\n",
    "from deriva_ml import ExecutionConfiguration, Workflow, Execution, MLVocab\n",
    "import itertools\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tempfile"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "ba06990f-6dc5-4805-9e82-0881a524bfef",
   "metadata": {},
   "source": [
    "Set the details for the catalog we want and authenticate to the server if needed."
   ]
  },
  {
   "cell_type": "code",
   "id": "9ee79ab7-a3f7-4c69-9c80-336871c13ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T04:59:01.557925Z",
     "start_time": "2025-01-09T04:59:01.504065Z"
    }
   },
   "source": [
    "hostname = 'dev.eye-ai.org'\n",
    "domain_schema = 'demo-schema'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=hostname)\n",
    "if gnl.is_logged_in([hostname]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "a23e5177-106b-48b6-b5e0-a126d35f4084",
   "metadata": {},
   "source": [
    "Create a test catalog and get an instance of the DerivaML class."
   ]
  },
  {
   "cell_type": "code",
   "id": "e9bddcf0-27ea-40b3-a388-b77635586fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T05:12:53.383386Z",
     "start_time": "2025-01-09T05:12:14.031856Z"
    }
   },
   "source": [
    "test_catalog = create_demo_catalog(hostname, domain_schema, create_features=True, create_datasets=True)\n",
    "ml_instance = DemoML(hostname, test_catalog.catalog_id)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9b151033-6eb5-4fbb-a8dd-8d9b2154299a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T05:15:08.192170Z",
     "start_time": "2025-01-09T05:15:08.170599Z"
    }
   },
   "source": [
    "display(\n",
    "    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Subject\")],\n",
    "    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Image\")]\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Subject:Health']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Image:BoundingBox', 'Image:Quality']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T05:15:14.492392Z",
     "start_time": "2025-01-09T05:15:13.665509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_columns = ['RCT', 'RMT', 'RCB', 'RMB']\n",
    "datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=system_columns)\n",
    "training_dataset = [ds['RID'] for ds in ml_instance.find_datasets() if 'Training' in ds['Dataset_Type']][0]\n",
    "\n",
    "display(\n",
    "    Markdown(f'Training Dataset: {training_dataset}'),\n",
    "    Markdown('## Datasets'),\n",
    "    datasets)"
   ],
   "id": "29a0bd7230799257",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Training Dataset: 3R6"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Datasets"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   RID Version                            Description          Dataset_Type\n",
       "0  3QY    None  A nested dataset for machine learning  [Partitioned, Image]\n",
       "1  3R6    None          An image dataset for training            [Training]\n",
       "2  3RC    None            A image dataset for testing             [Testing]\n",
       "3  3RJ    None         A image dataset for validation          [Validation]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Version</th>\n",
       "      <th>Description</th>\n",
       "      <th>Dataset_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3QY</td>\n",
       "      <td>None</td>\n",
       "      <td>A nested dataset for machine learning</td>\n",
       "      <td>[Partitioned, Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3R6</td>\n",
       "      <td>None</td>\n",
       "      <td>An image dataset for training</td>\n",
       "      <td>[Training]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3RC</td>\n",
       "      <td>None</td>\n",
       "      <td>A image dataset for testing</td>\n",
       "      <td>[Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3RJ</td>\n",
       "      <td>None</td>\n",
       "      <td>A image dataset for validation</td>\n",
       "      <td>[Validation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A feature is a set of values that are attached to a table in the DerivaML catalog. Instances of features are distingushed from one another by the ID of the execution that produced the feature value. The execution could be the result of a program, or it could be a manual process by which a person defines a set of values\n",
    "\n",
    "To create a new feature, we need to know the name of the feature, the table to which it is attached, and the set of values that make up the feature.  The values could be terms from a controlled vocabulary, a set of one or more file based assets, or other values, such as integers, or strings. However, use of strings outside of controlled vocabularies is discouraged."
   ],
   "id": "353d51c9-b8a6-4b75-a0da-ffa2db134169"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T05:38:29.722217Z",
     "start_time": "2025-01-09T05:38:27.430559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ml_instance.add_term(MLVocab.workflow_type, \"Manual Workflow\", description=\"A Workflow that uses Deriva ML API\")\n",
    "ml_instance.add_term(MLVocab.execution_asset_type, \"API_Model\", description=\"Model for our API workflow\")\n",
    "\n",
    "api_workflow = Workflow(\n",
    "    name=\"API Workflow\",\n",
    "    url=\"https://github.com/informatics-isi-edu/deriva-ml/blob/main/pyproject.toml\",\n",
    "    workflow_type=\"Manual Workflow\",\n",
    "    description=\"A manual operation\"\n",
    ")\n",
    "\n",
    "manual_execution = ml_instance.create_execution(ExecutionConfiguration( description=\"Sample Execution\", workflow=api_workflow))\n",
    "\n",
    "# Now lets create model configuration for our program.\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    model_file = Path(temp_dir)  / 'modelfile.txt'\n",
    "    with builtins.open(model_file, \"w\") as fp:\n",
    "            fp.write(f\"My model\")\n",
    "    training_model = manual_execution.upload_execution_asset(model_file, 'API_Model')"
   ],
   "id": "1d726b44-c60f-435a-9966-cfe3fc3da2e9",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Execution' object has no attribute 'upload_execution_asset'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m builtins\u001B[38;5;241m.\u001B[39mopen(model_file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fp:\n\u001B[1;32m     17\u001B[0m         fp\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMy model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 18\u001B[0m training_model \u001B[38;5;241m=\u001B[39m \u001B[43mmanual_execution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupload_execution_asset\u001B[49m(model_file, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAPI_Model\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Execution' object has no attribute 'upload_execution_asset'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now create a dataset with our new assets.",
   "id": "cfce553e81530e79"
  },
  {
   "cell_type": "markdown",
   "id": "83d2bd27-da2d-4918-9c8a-378c95addfcc",
   "metadata": {},
   "source": [
    "Now we can add some features to our images.  To streamline the creation of new feature, we create a class that is specific to the arguments required to create it."
   ]
  },
  {
   "cell_type": "code",
   "id": "7f6b68c6-4bc0-4837-a2b6-729d116a8702",
   "metadata": {},
   "source": [
    "TestFeatureClass = ml_instance.feature_record_class(\"Image\", \"Feature1\")\n",
    "TestFeatureClass.model_fields"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92416df1-e3f9-4097-bc19-b24712dc7242",
   "metadata": {},
   "source": [
    "Now using TestFeatureClass, we can create some instances of the feature and add it.  We must have a exeuction_rid in order to define the feature."
   ]
  },
  {
   "cell_type": "code",
   "id": "cdcc8f5c-874b-4bf9-89ef-e1ea90b9f91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T05:32:26.800962Z",
     "start_time": "2025-01-09T05:32:26.183483Z"
    }
   },
   "source": [
    "ml_instance.add_term(MLVocab.workflow_type, \"API Workflow\", description=\"A Workflow that uses Deriva ML API\")\n",
    "ml_instance.add_term(MLVocab.execution_asset_type, \"API_Model\", description=\"Model for our API workflow\")\n",
    "\n",
    "api_workflow = Workflow(\n",
    "    name=\"API Workflow\",\n",
    "    url=\"https://github.com/informatics-isi-edu/deriva-ml/blob/main/pyproject.toml\",\n",
    "    workflow_type=\"API Workflow\",\n",
    "    description=\"A workflow that uses Deriva ML\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=[training_dataset],\n",
    "    assets = [training_model],\n",
    "    description=\"Sample Execution\",\n",
    "    workflow=api_workflow\n",
    ")\n",
    "\n",
    "ml_execution = ml_instance.create_execution(config)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 13\u001B[0m\n\u001B[1;32m      2\u001B[0m ml_instance\u001B[38;5;241m.\u001B[39madd_term(MLVocab\u001B[38;5;241m.\u001B[39mexecution_asset_type, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI_Model\u001B[39m\u001B[38;5;124m\"\u001B[39m, description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel for our API workflow\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m api_workflow \u001B[38;5;241m=\u001B[39m Workflow(\n\u001B[1;32m      5\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI Workflow\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      6\u001B[0m     url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://github.com/informatics-isi-edu/deriva-ml/blob/main/pyproject.toml\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     workflow_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI Workflow\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      8\u001B[0m     description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA workflow that uses Deriva ML\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m )\n\u001B[1;32m     11\u001B[0m config \u001B[38;5;241m=\u001B[39m ExecutionConfiguration(\n\u001B[1;32m     12\u001B[0m     datasets\u001B[38;5;241m=\u001B[39m[training_dataset],\n\u001B[0;32m---> 13\u001B[0m     assets \u001B[38;5;241m=\u001B[39m [\u001B[43mtraining_model\u001B[49m],\n\u001B[1;32m     14\u001B[0m     description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSample Execution\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     15\u001B[0m     workflow\u001B[38;5;241m=\u001B[39mapi_workflow\n\u001B[1;32m     16\u001B[0m )\n\u001B[1;32m     18\u001B[0m ml_execution \u001B[38;5;241m=\u001B[39m ml_instance\u001B[38;5;241m.\u001B[39mcreate_execution(config)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'training_model' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with MLExecute(ml_execution):\n",
    "    # Get the input datasets:\n",
    "    dataset = DatasetBag(ml_execution.bag_paths[0])  # Input dataset\n",
    "\n",
    "    # Get input files\n",
    "    with open(ml_execution.asset_paths[0], 'rt') as model_file:\n",
    "        model = model_file.read()\n",
    "        print(f'Got model file: {model}')\n",
    "\n",
    "    # Put your ML code here....\n",
    "    pass\n",
    "\n",
    "    # Write model\n",
    "    # Write asset.\n",
    "    with open(ml_execution.model_dir) as model_file:\n",
    "        output_dir = ml_instance.execution_assets_path / \"Fun Files\"\n",
    "        with open(output_dir / \"test.txt\", \"w+\") as f:\n",
    "            f.write(\"Hello there a new model;\\n\")\n",
    "\n",
    "    # Create some new feature values.\n",
    "    bb_csv_path, bb_asset_paths = ml_execution.feature_paths('Image', 'BoundingBox')\n",
    "    bounding_box_files = [bb_asset_paths['BoundingBox'] / f\"box{i}.txt\" for i in range(10)]\n",
    "    for i in range(10):\n",
    "        bounding_box_files.append(fn := bb_asset_paths['BoundingBox'] / f\"box{i}.txt\")\n",
    "        with builtins.open(fn, \"w\") as fp:\n",
    "            fp.write(f\"Hi there {i}\")\n",
    "\n",
    "    image_bounding_box_feature_list = [ImageBoundingboxFeature(Image=image_rid,\n",
    "                                                               Execution=ml_execution.execution_rid,\n",
    "                                                               BoundingBox=asset_rid)\n",
    "                                       for image_rid, asset_rid in zip(image_rids, itertools.cycle(bounding_box_files))]\n",
    "\n",
    "    configuration_record.write_feature_file(image_bounding_box_feature_list)"
   ],
   "id": "c8860e47d5f72069",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "upload_status = ml_instance.upload_execution(configuration=ml_execution)\n",
    "e = (list(ml_instance.pathBuilder.deriva_ml.Execution.entities().fetch()))[0]"
   ],
   "id": "bca63c2d15cce655",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "pd.DataFrame(ml_instance.list_feature_values(\"Image\", \"Feature1\")])"
   ],
   "id": "240cb784-0ffc-4fc5-aa8d-fb2ee9267355",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd670182dfb20afd",
   "metadata": {},
   "source": [
    "test_catalog.delete_ermrest_catalog(really=True)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
