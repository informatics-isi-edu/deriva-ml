{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# DerivaML Dataset\n",
    "\n",
    "DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Set up DerivaML  for test case"
   ]
  },
  {
   "cell_type": "code",
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:04:01.740429Z",
     "start_time": "2025-04-21T22:04:01.645913Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:04:23.587064Z",
     "start_time": "2025-04-21T22:04:20.310743Z"
    }
   },
   "source": [
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from deriva_ml.demo_catalog import create_demo_catalog, DemoML\n",
    "from deriva_ml import MLVocab, ExecutionConfiguration, Workflow, DerivaSystemColumns, VersionPart, DatasetSpec\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, HTML, JSON"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Set the details for the catalog we want and authenticate to the server if needed."
   ]
  },
  {
   "cell_type": "code",
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:04:29.340516Z",
     "start_time": "2025-04-21T22:04:28.345392Z"
    }
   },
   "source": [
    "hostname = 'dev.eye-ai.org'\n",
    "domain_schema = 'demo-schema'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=hostname)\n",
    "if gnl.is_logged_in([hostname]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Create a test catalog and get an instance of the DemoML class."
   ]
  },
  {
   "cell_type": "code",
   "id": "7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:07:15.269818Z",
     "start_time": "2025-04-21T22:06:55.476942Z"
    }
   },
   "source": [
    "test_catalog = create_demo_catalog(hostname, domain_schema)\n",
    "ml_instance = DemoML(hostname, test_catalog.catalog_id)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 15:07:10,192 - deriva_ml.WARNING - File /Users/carl/Repos/Projects/deriva-ml/docs/Notebooks/DerivaML Dataset.ipynb has been modified since last commit. Consider commiting before executing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Execution RID: https://dev.eye-ai.org/id/1941/3N4@336-M8PY-6MVG"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 15:07:14,148 - deriva.transfer.upload.deriva_upload.WARNING - The following 8 file(s) were skipped because they did not satisfy the matching criteria of the configuration:\n",
      "\n",
      "/Users/carl/deriva-ml/DerivaML_working/deriva-ml/execution/3N4/asset/demo-ml/Image/3MR/test_3MR.txt\n",
      "/Users/carl/deriva-ml/DerivaML_working/deriva-ml/execution/3N4/asset/demo-ml/Image/3MT/test_3MT.txt\n",
      "/Users/carl/deriva-ml/DerivaML_working/deriva-ml/execution/3N4/asset/demo-ml/Image/3MW/test_3MW.txt\n",
      "/Users/carl/deriva-ml/DerivaML_working/deriva-ml/execution/3N4/asset/demo-ml/Image/3MY/test_3MY.txt\n",
      "/Users/carl/deriva-ml/DerivaML_working/deriva-ml/execution/3N4/asset/deriva-ml/Execution_Metadata/Execution_Config/configuration.json\n",
      "/Users/carl/deriva-ml/DerivaML_working/deriva-ml/execution/3N4/asset/deriva-ml/Execution_Metadata/None/configuration.json\n",
      "/Users/carl/deriva-ml/DerivaML_working/deriva-ml/execution/3N4/asset/deriva-ml/Execution_Metadata/None/environment_snapshot_20250407_175912.txt\n",
      "/Users/carl/deriva-ml/DerivaML_working/deriva-ml/execution/3N4/asset/deriva-ml/Execution_Metadata/Runtime_Env/environment_snapshot_20250407_114742.txt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Configure DerivaML Datasets\n",
    "\n",
    "In Deriva-ML a dataset is used to aggregate instances of entities.  However, before we can create any datasets, we must configure \n",
    "Deriva-ML for the specifics of the datasets.  The first stp is we need to tell Deriva-ML what types of use defined objects can be associated with a dataset.  \n",
    "\n",
    "Note that out of the box, Deriva-ML is configured to allow datasets to contained dataset (i.e. nested datasets), so we don't need to do anything for that specific configuration."
   ]
  },
  {
   "cell_type": "code",
   "id": "9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:08:40.780496Z",
     "start_time": "2025-04-21T22:08:39.170785Z"
    }
   },
   "source": [
    "print(f\"Current dataset_table element types: {[a.name for a in ml_instance.list_dataset_element_types()]}\")\n",
    "ml_instance.add_dataset_element_type(\"Subject\")\n",
    "ml_instance.add_dataset_element_type(\"Image\")\n",
    "print(f\"New dataset_table element types {[a.name for a in ml_instance.list_dataset_element_types()]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dataset_table element types: ['Dataset']\n",
      "New dataset_table element types ['Dataset', 'Subject', 'Image']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now that we have configured our datasets, we need to identify the dataset types so we can distinguish between them."
   ]
  },
  {
   "cell_type": "code",
   "id": "11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:09:59.070741Z",
     "start_time": "2025-04-21T22:09:58.064820Z"
    }
   },
   "source": [
    "# Create a new dataset_table\n",
    "ml_instance.add_term(MLVocab.dataset_type, \"DemoSet\", description=\"A test dataset_table\")\n",
    "ml_instance.add_term(MLVocab.dataset_type, 'Partitioned', description=\"A partitioned dataset_table for ML training.\")\n",
    "ml_instance.add_term(MLVocab.dataset_type, \"Subject\", description=\"A test dataset_table\")\n",
    "ml_instance.add_term(MLVocab.dataset_type, \"Image\", description=\"A test dataset_table\")\n",
    "ml_instance.add_term(MLVocab.dataset_type, \"Training\", description=\"Training dataset_table\")\n",
    "ml_instance.add_term(MLVocab.dataset_type, \"Testing\", description=\"Training dataset_table\")\n",
    "ml_instance.add_term(MLVocab.dataset_type, \"Validation\", description=\"Validation dataset_table\")\n",
    "\n",
    "ml_instance.list_vocabulary_terms(MLVocab.dataset_type)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VocabularyTerm(name='DemoSet', synonyms=[], id='ml-test:3V0', uri='/id/3V0', description='A test dataset_table', rid='3V0'),\n",
       " VocabularyTerm(name='Partitioned', synonyms=[], id='ml-test:3V2', uri='/id/3V2', description='A partitioned dataset_table for ML training.', rid='3V2'),\n",
       " VocabularyTerm(name='Subject', synonyms=[], id='ml-test:3V4', uri='/id/3V4', description='A test dataset_table', rid='3V4'),\n",
       " VocabularyTerm(name='Image', synonyms=[], id='ml-test:3V6', uri='/id/3V6', description='A test dataset_table', rid='3V6'),\n",
       " VocabularyTerm(name='Training', synonyms=[], id='ml-test:3V8', uri='/id/3V8', description='Training dataset_table', rid='3V8'),\n",
       " VocabularyTerm(name='Testing', synonyms=[], id='ml-test:3VA', uri='/id/3VA', description='Training dataset_table', rid='3VA'),\n",
       " VocabularyTerm(name='Validation', synonyms=[], id='ml-test:3VC', uri='/id/3VC', description='Validation dataset_table', rid='3VC')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Now create datasets and populate with elements from the test catalogs."
   ]
  },
  {
   "cell_type": "code",
   "id": "13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:10:06.879866Z",
     "start_time": "2025-04-21T22:10:05.595418Z"
    }
   },
   "source": [
    "ml_instance.add_term(MLVocab.workflow_type, \"Create Dataset Notebook\", description=\"A Workflow that creates a new dataset_table\")\n",
    "\n",
    "# Now lets create model configuration for our program.\n",
    "api_workflow = Workflow(\n",
    "    name=\"API Workflow\",\n",
    "    url=\"https://github.com/informatics-isi-edu/deriva-ml/blob/main/docs/Notebooks/DerivaML%20Dataset.ipynb\",\n",
    "    workflow_type=\"Create Dataset Notebook\"\n",
    ")\n",
    "\n",
    "dataset_execution = ml_instance.create_execution(\n",
    "    ExecutionConfiguration(\n",
    "        workflow=api_workflow,\n",
    "        description=\"Our Sample Workflow instance\")\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 15:10:06,254 - deriva_ml.INFO - Downloading assets ...\n",
      "2025-04-21 15:10:06,777 - deriva_ml.INFO - Initialize status finished.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:10:29.865295Z",
     "start_time": "2025-04-21T22:10:28.695323Z"
    }
   },
   "source": [
    "subject_dataset = dataset_execution.create_dataset(['DemoSet', 'Subject'], description=\"A subject dataset_table\")\n",
    "image_dataset = dataset_execution.create_dataset(['DemoSet', 'Image'], description=\"A image training dataset_table\")\n",
    "datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns)\n",
    "display(\n",
    "    Markdown('## Datasets'),\n",
    "    datasets)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Datasets"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                      Description  Deleted Version MLVocab.dataset_type\n",
       "0         A subject dataset_table    False     3VW   [DemoSet, Subject]\n",
       "1  A image training dataset_table    False     3W6     [DemoSet, Image]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Version</th>\n",
       "      <th>MLVocab.dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subject dataset_table</td>\n",
       "      <td>False</td>\n",
       "      <td>3VW</td>\n",
       "      <td>[DemoSet, Subject]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A image training dataset_table</td>\n",
       "      <td>False</td>\n",
       "      <td>3W6</td>\n",
       "      <td>[DemoSet, Image]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "And now that we have defined some datasets, we can add elements of the appropriate type to them.  We can see what is in our new datasets by listing the dataset members."
   ]
  },
  {
   "cell_type": "code",
   "id": "16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:10:39.182493Z",
     "start_time": "2025-04-21T22:10:35.153964Z"
    }
   },
   "source": [
    "# Get list of subjects and images from the catalog using the DataPath API.\n",
    "dp = ml_instance.domain_path  # Each call returns a new path instance, so only call once...\n",
    "subject_rids = [i['RID'] for i in dp.tables['Subject'].entities().fetch()]\n",
    "image_rids = [i['RID'] for i in dp.tables['Image'].entities().fetch()]\n",
    "\n",
    "ml_instance.add_dataset_members(dataset_rid=subject_dataset, members=subject_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=image_dataset, members=image_rids)\n",
    "\n",
    "# List the contents of our datasets, and let's not include columns like modify time.\n",
    "display(\n",
    "    Markdown('## Subject Dataset'),\n",
    "    pd.DataFrame(ml_instance.list_dataset_members(subject_dataset)['Subject']).drop(columns=DerivaSystemColumns),\n",
    "    Markdown('## Image Dataset'),\n",
    "    pd.DataFrame(ml_instance.list_dataset_members(image_dataset)['Image']).drop(columns=DerivaSystemColumns))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Subject Dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "     Name\n",
       "0  Thing1\n",
       "1  Thing2\n",
       "2  Thing3\n",
       "3  Thing4"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thing4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Image Dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                                                 URL      Filename  \\\n",
       "0  /hatrac/Image/ee9cdc79ca499e1b5a857d42f54867c6...  test_3MW.txt   \n",
       "1  /hatrac/Image/6eba4bbbffbb894c398a9ad38cebb779...  test_3MY.txt   \n",
       "2  /hatrac/Image/f3237139bbefa53ce0bc5d6f895907bb...  test_3MT.txt   \n",
       "3  /hatrac/Image/5f25ababc08a134b7bfd26ce9876ad3e...  test_3MR.txt   \n",
       "\n",
       "  Description  Length                               MD5 Subject  \n",
       "0        None      31  ee9cdc79ca499e1b5a857d42f54867c6     3MW  \n",
       "1        None      31  6eba4bbbffbb894c398a9ad38cebb779     3MY  \n",
       "2        None      31  f3237139bbefa53ce0bc5d6f895907bb     3MT  \n",
       "3        None      31  5f25ababc08a134b7bfd26ce9876ad3e     3MR  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Description</th>\n",
       "      <th>Length</th>\n",
       "      <th>MD5</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/hatrac/Image/ee9cdc79ca499e1b5a857d42f54867c6...</td>\n",
       "      <td>test_3MW.txt</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>ee9cdc79ca499e1b5a857d42f54867c6</td>\n",
       "      <td>3MW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/hatrac/Image/6eba4bbbffbb894c398a9ad38cebb779...</td>\n",
       "      <td>test_3MY.txt</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>6eba4bbbffbb894c398a9ad38cebb779</td>\n",
       "      <td>3MY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/hatrac/Image/f3237139bbefa53ce0bc5d6f895907bb...</td>\n",
       "      <td>test_3MT.txt</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>f3237139bbefa53ce0bc5d6f895907bb</td>\n",
       "      <td>3MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/hatrac/Image/5f25ababc08a134b7bfd26ce9876ad3e...</td>\n",
       "      <td>test_3MR.txt</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>5f25ababc08a134b7bfd26ce9876ad3e</td>\n",
       "      <td>3MR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Create partitioned dataset\n",
    "\n",
    "Now let's create some subsets of the original dataset based on subject level metadata. We are going to create the subsets based on the metadata values of the subjects. We will download the subject dataset and look at its metadata to figure out how to partition the original data. Since we are not going to look at the images, we use the materialize=False option to save some time."
   ]
  },
  {
   "cell_type": "code",
   "id": "18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:10:55.939064Z",
     "start_time": "2025-04-21T22:10:47.147670Z"
    }
   },
   "source": [
    "dataset_bag = ml_instance.download_dataset_bag(DatasetSpec(rid=subject_dataset, version=ml_instance.dataset_version(subject_dataset), materialize=False))\n",
    "print(f\"Bag materialized\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 15:10:48,108 - deriva_ml.INFO - Creating new MINID for dataset 3VM\n",
      "2025-04-21 15:10:48,583 - deriva_ml.INFO - Downloading dataset minid for catalog: 3VM@0.2.0\n",
      "2025-04-21 15:10:48,698 - deriva.transfer.download.deriva_export.INFO - Processing export config file: /var/folders/0k/27qzm97x3t7g3j1m6ksf_9f40000gn/T/tmp1j4nhuf6/download_spec.json\n",
      "2025-04-21 15:10:48,699 - deriva.transfer.download.deriva_export.INFO - Requesting bdbag export at: https://dev.eye-ai.org/deriva/export/bdbag\n",
      "2025-04-21 15:10:54,376 - deriva.transfer.download.deriva_export.INFO - Export successful. Service responded with URL list: ['https://identifiers.fair-research.org/hdl:20.500.12582/eTzt1YQ2xJJD', 'https://dev.eye-ai.org/deriva/export/bdbag/b1b5ab1f-a508-494a-b610-12895f341b92']\n",
      "2025-04-21 15:10:55,887 - deriva_ml.INFO - Loading /Users/carl/deriva-ml/cache/3VM_01f0f4140c278ca3d2f1564e0fb8d21a9d1cde0be675e45443daab46d8884eee/Dataset_3VM\n",
      "2025-04-21 15:10:55,936 - deriva_ml.INFO - Creating new database for dataset: 3VM in /Users/carl/deriva-ml/DemoML_working/3VM@336-M937-SCHM.db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag materialized\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "The domain model has two objects: Subject and Images where an Image is associated with a subject, but a subject can have multiple images associated with it.  Let's look at the subjects and partition into test and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "id": "20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:11:31.907197Z",
     "start_time": "2025-04-21T22:11:31.870301Z"
    }
   },
   "source": [
    "# Get information about the subjects.....\n",
    "subject_df = dataset_bag.get_table_as_dataframe('Subject')[['RID', 'Name']]\n",
    "image_df = dataset_bag.get_table_as_dataframe('Image')[['RID', 'Subject', 'URL']]\n",
    "metadata_df = subject_df.join(image_df, lsuffix=\"_subject\", rsuffix=\"_image\")\n",
    "display(metadata_df)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  RID_subject    Name RID_image Subject  \\\n",
       "0         3MR  Thing1       3N6     3MW   \n",
       "1         3MT  Thing2       3N8     3MY   \n",
       "2         3MW  Thing3       3NA     3MT   \n",
       "3         3MY  Thing4       3NC     3MR   \n",
       "\n",
       "                                                 URL  \n",
       "0  /hatrac/Image/ee9cdc79ca499e1b5a857d42f54867c6...  \n",
       "1  /hatrac/Image/6eba4bbbffbb894c398a9ad38cebb779...  \n",
       "2  /hatrac/Image/f3237139bbefa53ce0bc5d6f895907bb...  \n",
       "3  /hatrac/Image/5f25ababc08a134b7bfd26ce9876ad3e...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID_subject</th>\n",
       "      <th>Name</th>\n",
       "      <th>RID_image</th>\n",
       "      <th>Subject</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3MR</td>\n",
       "      <td>Thing1</td>\n",
       "      <td>3N6</td>\n",
       "      <td>3MW</td>\n",
       "      <td>/hatrac/Image/ee9cdc79ca499e1b5a857d42f54867c6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3MT</td>\n",
       "      <td>Thing2</td>\n",
       "      <td>3N8</td>\n",
       "      <td>3MY</td>\n",
       "      <td>/hatrac/Image/6eba4bbbffbb894c398a9ad38cebb779...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3MW</td>\n",
       "      <td>Thing3</td>\n",
       "      <td>3NA</td>\n",
       "      <td>3MT</td>\n",
       "      <td>/hatrac/Image/f3237139bbefa53ce0bc5d6f895907bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3MY</td>\n",
       "      <td>Thing4</td>\n",
       "      <td>3NC</td>\n",
       "      <td>3MR</td>\n",
       "      <td>/hatrac/Image/5f25ababc08a134b7bfd26ce9876ad3e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "For ths example, lets partition the data based on the name of the subject.  Of course in real examples, we would do a more complex analysis in deciding\n",
    "what subset goes into each data set."
   ]
  },
  {
   "cell_type": "code",
   "id": "22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:11:34.571272Z",
     "start_time": "2025-04-21T22:11:34.541727Z"
    }
   },
   "source": [
    "def thing_number(name: pd.Series) -> pd.Series:\n",
    "    return name.map(lambda n: int(n.replace('Thing','')))\n",
    "\n",
    "training_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 0]['RID_image'].tolist()\n",
    "testing_rids =  metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 1]['RID_image'].tolist()\n",
    "validation_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 2]['RID_image'].tolist()\n",
    "\n",
    "print(f'Training images: {training_rids}')\n",
    "print(f'Testing images: {testing_rids}')\n",
    "print(f'Validation images: {validation_rids}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: ['3NA']\n",
      "Testing images: ['3N6', '3NC']\n",
      "Validation images: ['3N8']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Now that we know what we want in each dataset, lets create datasets for each of our partitioned elements along with a nested dataset to track the entire collection."
   ]
  },
  {
   "cell_type": "code",
   "id": "24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:11:40.809636Z",
     "start_time": "2025-04-21T22:11:38.689355Z"
    }
   },
   "source": [
    "nested_dataset = dataset_execution.create_dataset(['Partitioned', 'Image'], description='A nested dataset_table for machine learning')\n",
    "training_dataset = dataset_execution.create_dataset('Training', description='An image dataset_table for training')\n",
    "testing_dataset = dataset_execution.create_dataset('Testing', description='A image dataset_table for testing')\n",
    "validation_dataset = dataset_execution.create_dataset('Validation', description='A image dataset_table for validation')\n",
    "pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                   Description  Deleted Version  \\\n",
       "0                      A subject dataset_table    False     3WG   \n",
       "1               A image training dataset_table    False     3WT   \n",
       "2  A nested dataset_table for machine learning    False     3X4   \n",
       "3          An image dataset_table for training    False     3XC   \n",
       "4            A image dataset_table for testing    False     3XM   \n",
       "5         A image dataset_table for validation    False     3XW   \n",
       "\n",
       "   MLVocab.dataset_type  \n",
       "0    [DemoSet, Subject]  \n",
       "1      [DemoSet, Image]  \n",
       "2  [Partitioned, Image]  \n",
       "3            [Training]  \n",
       "4             [Testing]  \n",
       "5          [Validation]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Version</th>\n",
       "      <th>MLVocab.dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subject dataset_table</td>\n",
       "      <td>False</td>\n",
       "      <td>3WG</td>\n",
       "      <td>[DemoSet, Subject]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A image training dataset_table</td>\n",
       "      <td>False</td>\n",
       "      <td>3WT</td>\n",
       "      <td>[DemoSet, Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A nested dataset_table for machine learning</td>\n",
       "      <td>False</td>\n",
       "      <td>3X4</td>\n",
       "      <td>[Partitioned, Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An image dataset_table for training</td>\n",
       "      <td>False</td>\n",
       "      <td>3XC</td>\n",
       "      <td>[Training]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A image dataset_table for testing</td>\n",
       "      <td>False</td>\n",
       "      <td>3XM</td>\n",
       "      <td>[Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A image dataset_table for validation</td>\n",
       "      <td>False</td>\n",
       "      <td>3XW</td>\n",
       "      <td>[Validation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "And then fill the datasets with the appropriate members."
   ]
  },
  {
   "cell_type": "code",
   "id": "26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:11:55.210364Z",
     "start_time": "2025-04-21T22:11:43.968020Z"
    }
   },
   "source": [
    "ml_instance.add_dataset_members(dataset_rid=nested_dataset, members=[training_dataset, testing_dataset, validation_dataset])\n",
    "ml_instance.add_dataset_members(dataset_rid=training_dataset, members=training_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=testing_dataset, members=testing_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=validation_dataset, members=validation_rids)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Ok, lets see what we have now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "As our very last step, lets get a PID that will allow us to share and cite the dataset that we just created"
   ]
  },
  {
   "cell_type": "code",
   "id": "29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:12:12.990753Z",
     "start_time": "2025-04-21T22:12:11.747072Z"
    }
   },
   "source": [
    "display(\n",
    "    Markdown('## Nested Dataset'),\n",
    "    pd.DataFrame(ml_instance.list_dataset_members(nested_dataset)['Dataset']).drop(columns=DerivaSystemColumns),\n",
    "    Markdown('## Training Dataset'),\n",
    "    pd.DataFrame(ml_instance.list_dataset_members(training_dataset)['Image']).drop(columns=DerivaSystemColumns),\n",
    "    Markdown('## Testing Dataset'),\n",
    "    pd.DataFrame(ml_instance.list_dataset_members(testing_dataset)['Image']).drop(columns=DerivaSystemColumns),\n",
    "    Markdown('## Validation Dataset'),\n",
    "    pd.DataFrame(ml_instance.list_dataset_members(validation_dataset)['Image']).drop(columns=DerivaSystemColumns),)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Nested Dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                            Description  Deleted Version\n",
       "0   An image dataset_table for training    False     3ZA\n",
       "1     A image dataset_table for testing    False     3Z8\n",
       "2  A image dataset_table for validation    False     3Z4"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An image dataset_table for training</td>\n",
       "      <td>False</td>\n",
       "      <td>3ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A image dataset_table for testing</td>\n",
       "      <td>False</td>\n",
       "      <td>3Z8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A image dataset_table for validation</td>\n",
       "      <td>False</td>\n",
       "      <td>3Z4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Training Dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                                                 URL      Filename  \\\n",
       "0  /hatrac/Image/f3237139bbefa53ce0bc5d6f895907bb...  test_3MT.txt   \n",
       "\n",
       "  Description  Length                               MD5 Subject  \n",
       "0        None      31  f3237139bbefa53ce0bc5d6f895907bb     3MT  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Description</th>\n",
       "      <th>Length</th>\n",
       "      <th>MD5</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/hatrac/Image/f3237139bbefa53ce0bc5d6f895907bb...</td>\n",
       "      <td>test_3MT.txt</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>f3237139bbefa53ce0bc5d6f895907bb</td>\n",
       "      <td>3MT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Testing Dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                                                 URL      Filename  \\\n",
       "0  /hatrac/Image/ee9cdc79ca499e1b5a857d42f54867c6...  test_3MW.txt   \n",
       "1  /hatrac/Image/5f25ababc08a134b7bfd26ce9876ad3e...  test_3MR.txt   \n",
       "\n",
       "  Description  Length                               MD5 Subject  \n",
       "0        None      31  ee9cdc79ca499e1b5a857d42f54867c6     3MW  \n",
       "1        None      31  5f25ababc08a134b7bfd26ce9876ad3e     3MR  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Description</th>\n",
       "      <th>Length</th>\n",
       "      <th>MD5</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/hatrac/Image/ee9cdc79ca499e1b5a857d42f54867c6...</td>\n",
       "      <td>test_3MW.txt</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>ee9cdc79ca499e1b5a857d42f54867c6</td>\n",
       "      <td>3MW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/hatrac/Image/5f25ababc08a134b7bfd26ce9876ad3e...</td>\n",
       "      <td>test_3MR.txt</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>5f25ababc08a134b7bfd26ce9876ad3e</td>\n",
       "      <td>3MR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Validation Dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                                                 URL      Filename  \\\n",
       "0  /hatrac/Image/6eba4bbbffbb894c398a9ad38cebb779...  test_3MY.txt   \n",
       "\n",
       "  Description  Length                               MD5 Subject  \n",
       "0        None      31  6eba4bbbffbb894c398a9ad38cebb779     3MY  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Description</th>\n",
       "      <th>Length</th>\n",
       "      <th>MD5</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/hatrac/Image/6eba4bbbffbb894c398a9ad38cebb779...</td>\n",
       "      <td>test_3MY.txt</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>6eba4bbbffbb894c398a9ad38cebb779</td>\n",
       "      <td>3MY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:12:18.148413Z",
     "start_time": "2025-04-21T22:12:17.826051Z"
    }
   },
   "source": [
    "print(f'Dataset parents: {ml_instance.list_dataset_parents(training_dataset)}')\n",
    "print(f'Dataset children: {ml_instance.list_dataset_children(nested_dataset)}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parents: ['3WW']\n",
      "Dataset children: ['3XE', '3X6', '3XP']\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:12:20.129722Z",
     "start_time": "2025-04-21T22:12:19.986019Z"
    }
   },
   "source": [
    "dataset_citation = ml_instance.cite(nested_dataset)\n",
    "display(\n",
    "    HTML(f'Nested dataset_table citation: <a href={dataset_citation}>{dataset_citation}</a>')\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Nested dataset_table citation: <a href=https://dev.eye-ai.org/id/1941/3WW@336-M97X-1PR4>https://dev.eye-ai.org/id/1941/3WW@336-M97X-1PR4</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:12:23.264599Z",
     "start_time": "2025-04-21T22:12:22.080859Z"
    }
   },
   "source": [
    "display(\n",
    "     Markdown('## Nested Dataset -- Recursive Listing'),\n",
    "    JSON(ml_instance.list_dataset_members(nested_dataset, recurse=True))\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Nested Dataset -- Recursive Listing"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ],
      "application/json": {
       "Dataset": [
        {
         "RID": "3X6",
         "RCT": "2025-04-21T22:11:39.353625+00:00",
         "RMT": "2025-04-21T22:11:55.175298+00:00",
         "RCB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "RMB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "Description": "An image dataset_table for training",
         "Deleted": false,
         "Version": "3ZA"
        },
        {
         "RID": "3XE",
         "RCT": "2025-04-21T22:11:39.761087+00:00",
         "RMT": "2025-04-21T22:11:55.175298+00:00",
         "RCB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "RMB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "Description": "A image dataset_table for testing",
         "Deleted": false,
         "Version": "3Z8"
        },
        {
         "RID": "3XP",
         "RCT": "2025-04-21T22:11:40.17409+00:00",
         "RMT": "2025-04-21T22:11:55.175298+00:00",
         "RCB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "RMB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "Description": "A image dataset_table for validation",
         "Deleted": false,
         "Version": "3Z4"
        }
       ],
       "Subject": [],
       "Image": [
        {
         "RID": "3NA",
         "RCT": "2025-04-21T22:07:13.363705+00:00",
         "RMT": "2025-04-21T22:07:13.363705+00:00",
         "RCB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "RMB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "URL": "/hatrac/Image/f3237139bbefa53ce0bc5d6f895907bb.test_3MT.txt:RpA_saT0smPN7c33cIENWL6VbYV._6c5",
         "Filename": "test_3MT.txt",
         "Description": null,
         "Length": 31,
         "MD5": "f3237139bbefa53ce0bc5d6f895907bb",
         "Subject": "3MT"
        },
        {
         "RID": "3N6",
         "RCT": "2025-04-21T22:07:12.866799+00:00",
         "RMT": "2025-04-21T22:07:12.866799+00:00",
         "RCB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "RMB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "URL": "/hatrac/Image/ee9cdc79ca499e1b5a857d42f54867c6.test_3MW.txt:sdv_b2nCpXDa0yFNkk0_Zv3PU4umKLZK",
         "Filename": "test_3MW.txt",
         "Description": null,
         "Length": 31,
         "MD5": "ee9cdc79ca499e1b5a857d42f54867c6",
         "Subject": "3MW"
        },
        {
         "RID": "3NC",
         "RCT": "2025-04-21T22:07:13.586507+00:00",
         "RMT": "2025-04-21T22:07:13.586507+00:00",
         "RCB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "RMB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "URL": "/hatrac/Image/5f25ababc08a134b7bfd26ce9876ad3e.test_3MR.txt:anKr9ghPcQNlDU.qt9nhVFK7KfcxAqO_",
         "Filename": "test_3MR.txt",
         "Description": null,
         "Length": 31,
         "MD5": "5f25ababc08a134b7bfd26ce9876ad3e",
         "Subject": "3MR"
        },
        {
         "RID": "3N8",
         "RCT": "2025-04-21T22:07:13.152097+00:00",
         "RMT": "2025-04-21T22:07:13.152097+00:00",
         "RCB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "RMB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
         "URL": "/hatrac/Image/6eba4bbbffbb894c398a9ad38cebb779.test_3MY.txt:DAdaS9ecebzrmiPm5Fh8Ez5ZfOnXiBXK",
         "Filename": "test_3MY.txt",
         "Description": null,
         "Length": 31,
         "MD5": "6eba4bbbffbb894c398a9ad38cebb779",
         "Subject": "3MY"
        }
       ]
      }
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Dataset Versions\n",
    "Datasets have a version number which can be retrieved or incremented.  We follow the equivalent of semantic versioning, but for data rather than code.  Note that datasets are also versioned by virtue of the fact that the dataset RID can include a catalog snapshot ID as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Current dataset_table version for training_dataset: {ml_instance.dataset_version(training_dataset)}')\n",
    "next_version = ml_instance.increment_dataset_version(training_dataset, VersionPart.minor)\n",
    "print(f'Next dataset_table version for training_dataset: {next_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(f'<a href={ml_instance.chaise_url(\"Dataset\")}>Browse Datasets</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "id": "36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T22:12:29.725147Z",
     "start_time": "2025-04-21T22:12:29.588023Z"
    }
   },
   "source": [
    "test_catalog.delete_ermrest_catalog(really=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [204]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
