{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ffee41-4986-4196-b35d-b38b6e10490a",
   "metadata": {},
   "source": [
    "# DerivaML Features Example\n",
    "\n",
    "DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library.\n",
    "\n",
    "\n",
    "In DerivaML, \"features\" are the way we attach values to objects in the catalog. A feature could be a computed value that serves as input to a ML model, or it could be a label, that is the result of running a model.  A feature can be a controlled vocabulary term, an asset, or a value.\n",
    "\n",
    "Each feature in the catalog is distinguished by the name of the feature, the identity of the object that the feature is being attached to, and the execution RID of the process that generated the feature value\n",
    "\n",
    "## Set up Deriva for test case"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff605747-195b-40a1-b915-0e799f8d0748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:34:19.025886Z",
     "start_time": "2024-10-18T05:34:19.001003Z"
    }
   },
   "source": [
    "from fontTools.misc.bezierTools import namedtuple\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9493a5ef-86b9-490b-a1d5-f461fdcd68ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:34:22.392683Z",
     "start_time": "2024-10-18T05:34:20.998858Z"
    }
   },
   "source": [
    "import builtins\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from deriva_ml.deriva_ml_base import ColumnDefinition, BuiltinTypes\n",
    "from deriva_ml.schema_setup.test_catalog import create_test_catalog, DemoML\n",
    "from deriva_ml.execution_configuration import ExecutionConfiguration, Workflow, Execution, WorkflowTerm, Term\n",
    "from IPython.display import display, Markdown\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set the details for the catalog we want and authenticate to the server if needed.",
   "id": "6a3738109c9344d1"
  },
  {
   "cell_type": "code",
   "id": "9ee79ab7-a3f7-4c69-9c80-336871c13ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:34:23.430452Z",
     "start_time": "2024-10-18T05:34:23.373057Z"
    }
   },
   "source": [
    "hostname = 'dev.eye-ai.org'\n",
    "domain_schema = 'demo-schema'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=hostname)\n",
    "if gnl.is_logged_in([hostname]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a test catalog and get an instance of the DerivaML class.",
   "id": "a23e5177-106b-48b6-b5e0-a126d35f4084"
  },
  {
   "cell_type": "code",
   "id": "e9bddcf0-27ea-40b3-a388-b77635586fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:34:47.812500Z",
     "start_time": "2024-10-18T05:34:26.440942Z"
    }
   },
   "source": [
    "test_catalog = create_test_catalog(hostname, domain_schema)\n",
    "ml_instance = DemoML(hostname, test_catalog.catalog_id)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 22:34:47,494 - INFO - Creating client of type <class 'globus_sdk.services.auth.client.native_client.NativeAppAuthClient'> for service \"auth\"\n",
      "2024-10-17 22:34:47,495 - INFO - Finished initializing AuthLoginClient. client_id='8ef15ba9-2b4a-469c-a163-7fd910c9d111', type(authorizer)=<class 'globus_sdk.authorizers.base.NullAuthorizer'>\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "353d51c9-b8a6-4b75-a0da-ffa2db134169",
   "metadata": {},
   "source": [
    "A feature is a set of values that are attached to a table in the DerivaML catalog. Instances of features are distingushed from one another by the ID of the execution that produced the feature value. The execution could be the result of a program, or it could be a manual process by which a person defines a set of values\n",
    "\n",
    "To create a new feature, we need to know the name of the feature, the table to which it is attached, and the set of values that make up the feature.  The values could be terms from a controlled vocabulary, a set of one or more file based assets, or other values, such as integers, or strings. However, use of strings outside of controlled vocabularies is discouraged."
   ]
  },
  {
   "cell_type": "code",
   "id": "1d726b44-c60f-435a-9966-cfe3fc3da2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:30:49.659440Z",
     "start_time": "2024-10-17T21:30:44.436244Z"
    }
   },
   "source": [
    "# Prerequests for our feature, which will include a CV term and asset.\n",
    "\n",
    "# Create a vocabulary and add a term to it to use in our features.\n",
    "ml_instance.create_vocabulary(\"SubjectHealth\", \"A vocab\")\n",
    "ml_instance.add_term(\"SubjectHealth\", \"Sick\", description=\"The subject self reports that they are sick\")\n",
    "ml_instance.add_term(\"SubjectHealth\", \"Well\", description=\"The subject self reports that they feel well\")\n",
    "\n",
    "ml_instance.create_vocabulary(\"ImageQuality\", \"Controlled vocabulary for image quality\")\n",
    "ml_instance.add_term(\"ImageQuality\", \"Good\", description=\"The image is good\")\n",
    "ml_instance.add_term(\"ImageQuality\", \"Bad\", description=\"The image is bad\")\n",
    "\n",
    "box_asset = ml_instance.create_asset(\"BoundingBox\", comment=\"A file that contains a cropped version of a image\")\n",
    "\n",
    "# Now lets create and upload a simple asset.\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    assetdir = Path(tmpdirname) / \"BoundingBox\"\n",
    "    assetdir.mkdir(parents=True, exist_ok=True)\n",
    "    for i in range(10):\n",
    "        with builtins.open(assetdir / f\"box{i}.txt\", \"w\") as fp:\n",
    "            fp.write(f\"Hi there {i}\")\n",
    "    ml_instance.upload_assets(assetdir)  # Upload all of the images in the directory to the asset table"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "8dcaabf3e33a1f9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T23:39:35.175020Z",
     "start_time": "2024-10-17T23:39:34.515571Z"
    }
   },
   "source": [
    "# We are going to have three values in our feature, a controlled vocabulary term from the vocabulary FeatureValue, a file asset and \n",
    "# an integer value which we will call \"TestCol\"\n",
    "ml_instance.create_feature(\"Health\", \"Subject\",\n",
    "                                        terms=[\"SubjectHealth\"],\n",
    "                                        metadata=[ColumnDefinition(name='Scale', type=BuiltinTypes.int2)])\n",
    "\n",
    "ml_instance.create_feature(\"BoundingBox\", \"Image\", assets=[box_asset])\n",
    "ml_instance.create_feature(\"Quality\", \"Image\", terms=[\"ImageQuality\"])"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table Execution_Subject_Health already exists.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# We are going to have three values in our feature, a controlled vocabulary term from the vocabulary FeatureValue, a file asset and \u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# an integer value which we will call \"TestCol\"\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mml_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_feature\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHealth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSubject\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mterms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSubjectHealth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mColumnDefinition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mScale\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBuiltinTypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m ml_instance\u001B[38;5;241m.\u001B[39mcreate_feature(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBoundingBox\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage\u001B[39m\u001B[38;5;124m\"\u001B[39m, assets\u001B[38;5;241m=\u001B[39m[box_asset])\n\u001B[1;32m      8\u001B[0m ml_instance\u001B[38;5;241m.\u001B[39mcreate_feature(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuality\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage\u001B[39m\u001B[38;5;124m\"\u001B[39m, terms\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImageQuality\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/Repos/Projects/deriva-ml/deriva_ml/deriva_ml_base.py:548\u001B[0m, in \u001B[0;36mDerivaML.create_feature\u001B[0;34m(self, feature_name, table, terms, assets, metadata, comment)\u001B[0m\n\u001B[1;32m    546\u001B[0m atable_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExecution_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtable\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfeature_name_term\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    547\u001B[0m \u001B[38;5;66;03m# Now create the association table that implements the feature.\u001B[39;00m\n\u001B[0;32m--> 548\u001B[0m atable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschemas\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdomain_schema\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefine_association\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtable_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43matable_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43massociates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mexecution\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_name_table\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mnormalize_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchain\u001B[49m\u001B[43m(\u001B[49m\u001B[43massets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mterms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    556\u001B[0m atable\u001B[38;5;241m.\u001B[39mcolumns[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFeature_Name\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39malter(default\u001B[38;5;241m=\u001B[39mfeature_name_term\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m    557\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_record_class(table, feature_name)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/deriva/core/ermrest_model.py:687\u001B[0m, in \u001B[0;36mSchema.create_table\u001B[0;34m(self, table_def)\u001B[0m\n\u001B[1;32m    685\u001B[0m tname \u001B[38;5;241m=\u001B[39m table_def[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtable_name\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    686\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tname \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtables:\n\u001B[0;32m--> 687\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTable \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m already exists.\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m tname)\n\u001B[1;32m    688\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcatalog\u001B[38;5;241m.\u001B[39mpost(\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m/table\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muri_path,\n\u001B[1;32m    690\u001B[0m     json\u001B[38;5;241m=\u001B[39mtable_def,\n\u001B[1;32m    691\u001B[0m )\n\u001B[1;32m    692\u001B[0m r\u001B[38;5;241m.\u001B[39mraise_for_status()\n",
      "\u001B[0;31mValueError\u001B[0m: Table Execution_Subject_Health already exists."
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T21:31:41.025989Z",
     "start_time": "2024-10-17T21:31:41.002750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "display([f.name for f in ml_instance.find_features(\"Subject\")])\n",
    "display([f.name for f in ml_instance.find_features(\"Image\")])"
   ],
   "id": "50fc85db-8173-463d-830e-7dfd7eba08f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Execution_Subject_Health']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Execution_Image_BoundingBox', 'Execution_Image_Quality']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "83d2bd27-da2d-4918-9c8a-378c95addfcc",
   "metadata": {},
   "source": [
    "Now we can add some features to our images.  To streamline the creation of new feature, we create a class that is specific to the arguments required to create it."
   ]
  },
  {
   "cell_type": "code",
   "id": "7f6b68c6-4bc0-4837-a2b6-729d116a8702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T23:26:28.329820Z",
     "start_time": "2024-10-17T23:26:28.297550Z"
    }
   },
   "source": [
    "ImageQualityFeature = ml_instance.feature_record_class(\"Image\", \"Quality\")\n",
    "ImageBoundingboxFeature = ml_instance.feature_record_class(\"Image\", \"Quality\")\n",
    "SubjectWellnessFeature= ml_instance.feature_record_class(\"Subject\", \"Health\")\n",
    "\n",
    "display(Markdown('### SubjectWellnessFeature'))\n",
    "display(SubjectWellnessFeature.model_fields)\n",
    "display(Markdown('### ImageQualityFeature'))\n",
    "display(ImageQualityFeature.model_fields)\n",
    "display(Markdown('### ImageBoundingboxFeature'))\n",
    "display(ImageBoundingboxFeature.model_fields)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### SubjectWellnessFeature"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Execution': FieldInfo(annotation=str, required=True),\n",
       " 'Subject': FieldInfo(annotation=str, required=True),\n",
       " 'Feature_Name': FieldInfo(annotation=str, required=False, default='Health'),\n",
       " 'SubjectHealth': FieldInfo(annotation=str, required=True),\n",
       " 'Scale': FieldInfo(annotation=int, required=True)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### ImageQualityFeature"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Execution': FieldInfo(annotation=str, required=True),\n",
       " 'Image': FieldInfo(annotation=str, required=True),\n",
       " 'Feature_Name': FieldInfo(annotation=str, required=False, default='Quality'),\n",
       " 'ImageQuality': FieldInfo(annotation=str, required=True)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### ImageBoundingboxFeature"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Execution': FieldInfo(annotation=str, required=True),\n",
       " 'Image': FieldInfo(annotation=str, required=True),\n",
       " 'Feature_Name': FieldInfo(annotation=str, required=False, default='Quality'),\n",
       " 'ImageQuality': FieldInfo(annotation=str, required=True)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "id": "92416df1-e3f9-4097-bc19-b24712dc7242",
   "metadata": {},
   "source": [
    "Now using TestFeatureClass, we can create some instances of the feature and add it.  We must have a exeuction_rid in order to define the feature."
   ]
  },
  {
   "cell_type": "code",
   "id": "cdcc8f5c-874b-4bf9-89ef-e1ea90b9f91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T23:26:40.804125Z",
     "start_time": "2024-10-17T23:26:36.789082Z"
    }
   },
   "source": [
    "api_workflow = Workflow(\n",
    "    name=\"API Workflow\", \n",
    "    url=\"https://github.com/informatics-isi-edu/deriva-ml/blob/main/pyproject.toml\",\n",
    "    workflow_type=\"API Workflow\"\n",
    ")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "    execution=Execution(description=\"Sample Execution\"), \n",
    "    workflow=api_workflow, \n",
    "    workflow_terms=[WorkflowTerm(term=Term.workflow, name=\"API Driven Workflow\", description=\"A workflow that only uses feature API\")],\n",
    "    description=\"Our Sample Workflow instance\")\n",
    "configuration_record = ml_instance.initialize_execution(config)\n",
    "execution_rid = configuration_record.execution_rid"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "4d8204f2-1411-45ed-b093-1d50751862ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T23:38:38.254893Z",
     "start_time": "2024-10-17T23:38:32.786191Z"
    }
   },
   "source": [
    "# Get some images to attach the feature value to.\n",
    "subject_rids = [i['RID'] for i in ml_instance.domain_path.tables['Subject'].entities().fetch()]\n",
    "image_rids = [i['RID'] for i in ml_instance.domain_path.tables['Image'].entities().fetch()]\n",
    "asset_rids = [i['RID'] for i in ml_instance.domain_path.tables['BoundingBox'].entities().fetch()]\n",
    "# Now create a list of features using the feature creation class returned by create_feature.\n",
    "subject_feature_list = [SubjectWellnessFeature(\n",
    "    Subject=subject_rid,\n",
    "    Execution=execution_rid,\n",
    "    SubjectHealth= [\"Well\", \"Sick\"][random.randint(0,1)],\n",
    "    Scale=random.randint(1, 10)) for subject_rid in subject_rids]\n",
    "\n",
    "image_quality_feature_list = [ImageQualityFeature(\n",
    "    Image=image_rid,\n",
    "    Execution=execution_rid,\n",
    "    ImageQuality= [\"Good\", \"Bad\"][random.randint(0,1)])\n",
    "        for image_rid in image_rids]\n",
    "\n",
    "image_boundingbox_feature_list = [ImageBoundingboxFeature(\n",
    "    Image=image_rid,\n",
    "    Execution=execution_rid,\n",
    "    box_asset=asset_rid)\n",
    "        for image_rid, asset_rid in zip(image_rids, itertools.cycle(asset_rids))]\n",
    "\n",
    "#ml_instance.add_features(subject_feature_list)\n",
    "#ml_instance.add_features(image_feature_list)"
   ],
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ImageFeatureQuality\nImageQuality\n  Field required [type=missing, input_value={'Image': '30R', 'Executi...JE', 'box_asset': '38E'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 18\u001B[0m\n\u001B[1;32m      6\u001B[0m subject_feature_list \u001B[38;5;241m=\u001B[39m [SubjectWellnessFeature(\n\u001B[1;32m      7\u001B[0m     Subject\u001B[38;5;241m=\u001B[39msubject_rid,\n\u001B[1;32m      8\u001B[0m     Execution\u001B[38;5;241m=\u001B[39mexecution_rid,\n\u001B[1;32m      9\u001B[0m     SubjectHealth\u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWell\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSick\u001B[39m\u001B[38;5;124m\"\u001B[39m][random\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m)],\n\u001B[1;32m     10\u001B[0m     Scale\u001B[38;5;241m=\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m10\u001B[39m)) \u001B[38;5;28;01mfor\u001B[39;00m subject_rid \u001B[38;5;129;01min\u001B[39;00m subject_rids]\n\u001B[1;32m     12\u001B[0m image_quality_feature_list \u001B[38;5;241m=\u001B[39m [ImageQualityFeature(\n\u001B[1;32m     13\u001B[0m     Image\u001B[38;5;241m=\u001B[39mimage_rid,\n\u001B[1;32m     14\u001B[0m     Execution\u001B[38;5;241m=\u001B[39mexecution_rid,\n\u001B[1;32m     15\u001B[0m     ImageQuality\u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGood\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBad\u001B[39m\u001B[38;5;124m\"\u001B[39m][random\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m)])\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m image_rid \u001B[38;5;129;01min\u001B[39;00m image_rids]\n\u001B[0;32m---> 18\u001B[0m image_boundingbox_feature_list \u001B[38;5;241m=\u001B[39m [\u001B[43mImageBoundingboxFeature\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mImage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage_rid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mExecution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexecution_rid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbox_asset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43masset_rid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m image_rid, asset_rid \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(image_rids, itertools\u001B[38;5;241m.\u001B[39mcycle(asset_rids))]\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m#ml_instance.add_features(subject_feature_list)\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m#ml_instance.add_features(image_feature_list)\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/pydantic/main.py:193\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[0;34m(self, **data)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[1;32m    192\u001B[0m __tracebackhide__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 193\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__pydantic_validator__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mself_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValidationError\u001B[0m: 1 validation error for ImageFeatureQuality\nImageQuality\n  Field required [type=missing, input_value={'Image': '30R', 'Executi...JE', 'box_asset': '38E'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "240cb784-0ffc-4fc5-aa8d-fb2ee9267355",
   "metadata": {},
   "source": [
    "def strip_system(d):\n",
    "    return {k:v for k,v in d.items() if k not in ['RCT', 'RMT', 'RCB', 'RMB']}\n",
    "    \n",
    "pd.DataFrame([strip_system(i) for i in ml_instance.list_feature(\"Image\", \"Feature1\")])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e76bbdf-2441-4444-be7f-e55399bcc32a",
   "metadata": {},
   "source": [
    "test_catalog.delete_ermrest_catalog(really=True)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deriva-kernal",
   "language": "python",
   "name": "deriva-kernal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
