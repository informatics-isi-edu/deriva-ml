{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ffee41-4986-4196-b35d-b38b6e10490a",
   "metadata": {},
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DerivaML Dataset Example.\n",
    "\n",
    "DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library."
   ],
   "id": "a5ff6e4c93a70770"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up DerivaML  for test case",
   "id": "db30e3e5ccd3ad77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "29f3e870d1fea4f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from deriva_ml.schema_setup.test_catalog import create_test_catalog, DemoML"
   ],
   "id": "1d18222d50d0ef7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set the details for the catalog we want and authenticate to the server if needed.",
   "id": "eb169235902c77be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hostname = 'dev.eye-ai.org'\n",
    "domain_schema = 'demo-schema'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=hostname)\n",
    "if gnl.is_logged_in([hostname]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")\n"
   ],
   "id": "677df6f200423a9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a test catalog and get an instance of the DemoML class.",
   "id": "cc01e85a63c60536"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_catalog = create_test_catalog(hostname, domain_schema)\n",
    "ml_instance = DemoML(hostname, test_catalog.catalog_id)"
   ],
   "id": "a843170d141c8a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Current dataset element types: {[a.name for a in ml_instance.list_dataset_element_types()]}\")\n",
    "ml_instance.add_dataset_element_type(\"Subject\")\n",
    "ml_instance.add_dataset_element_type(\"Image\")\n",
    "print(f\"New dataset element types {[a.name for a in ml_instance.list_dataset_element_types()]}\")"
   ],
   "id": "21e3d412920ac963",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Configure DerivaML Datasets\n",
    "\n",
    "Create vocabulary terms for the dataset types"
   ],
   "id": "48c7854af033245"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a new dataset\n",
    "ml_instance.add_term(\"Dataset_Type\", \"DemoSet\", description=\"A test dataset\")\n",
    "ml_instance.add_term('Dataset_Type', 'Partitioned', description=\"A partitioned dataset for ML training.\")\n",
    "ml_instance.add_term(\"Dataset_Type\", \"Subject\", description=\"A test dataset\")\n",
    "ml_instance.add_term(\"Dataset_Type\", \"Image\", description=\"A test dataset\")\n",
    "ml_instance.add_term(\"Dataset_Type\", \"Training\", description=\"Training dataset\")\n",
    "ml_instance.add_term(\"Dataset_Type\", \"Testing\", description=\"Training dataset\")\n",
    "ml_instance.add_term(\"Dataset_Type\", \"Validation\", description=\"Validation dataset\")"
   ],
   "id": "c8582937bce0b86b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now create datasets and populate with elements from the test catalogs.",
   "id": "1f902cd9561842c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_columns = ['RCT', 'RMT', 'RCB', 'RMB']\n",
    "\n",
    "subject_dataset = ml_instance.create_dataset(['DemoSet', 'Subject'], description=\"A subject dataset\")\n",
    "image_dataset = ml_instance.create_dataset(['DemoSet', 'Image'], description=\"A image training dataset\")\n",
    "datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=system_columns)\n",
    "display(datasets)"
   ],
   "id": "10567931cbd3c322",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dp = ml_instance.domain_path  # Each call returns a new path instance, so only call once...\n",
    "subject_rids = [i['RID'] for i in dp.tables['Subject'].entities().fetch()]\n",
    "image_rids = [i['RID'] for i in dp.tables['Image'].entities().fetch()]\n",
    "\n",
    "ml_instance.add_dataset_members(dataset_rid=subject_dataset, members=subject_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=image_dataset, members=image_rids)\n",
    "\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(subject_dataset)['Subject']).drop(columns=system_columns))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(image_dataset)['Image']).drop(columns=system_columns))"
   ],
   "id": "16bb5b8b8b2a5288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create partitioned dataset\n",
    "\n",
    "Now lets create some subsets of the origional dataset based on subject level metadata. We are going to create the subsets based on the metadata values of the subjects.  SO we will download the subject dataset and look at its metadata to figure out whow to partition the origional data. Since we are not going to look at the images, we use dowload_dataset_bag, rather than materialize_bag."
   ],
   "id": "2ac02c487e8a3be3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bag_path, bag_rid = ml_instance.download_dataset_bag(subject_dataset)\n",
    "ml_instance.materialize_bdbag(subject_dataset)\n",
    "print(f\"Bag materialized to {bag_path}\")"
   ],
   "id": "5f8f12b942310485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The domain model has two object: Subject and Images where an Image is associated with a subject, but a subject can have multiple images associated with it.  Lets look at the subjects and partition into test and training datasets.",
   "id": "aefa71000a8888b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Bag path is: {bag_path}\")\n",
    "os.chdir(bag_path / 'data/Subject')\n",
    "%ls \n",
    "\n",
    "# Get information about the subjects.....        \n",
    "subject_df = pd.read_csv('Subject.csv', usecols=['RID', 'Name'])\n",
    "image_df = pd.read_csv('Image/Image.csv', usecols=['RID', 'Subject', 'URL'])\n",
    "metadata_df = subject_df.join(image_df, lsuffix=\"_subject\", rsuffix=\"_image\")\n",
    "display(metadata_df)"
   ],
   "id": "405cebbc9d686f9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def thing_number(name: pd.Series) -> pd.Series:\n",
    "    return name.map(lambda n: int(n.replace('Thing','')))\n",
    "\n",
    "training_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 0]['RID_image'].tolist()\n",
    "testing_rids =  metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 1]['RID_image'].tolist()\n",
    "validation_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 2]['RID_image'].tolist()\n",
    "print(f'Training images: {training_rids}')\n",
    "print(f'Testing images: {testing_rids}')\n",
    "print(f'Validation images: {validation_rids}')\n"
   ],
   "id": "fac3a1b3d7db6556",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1fcf179738fad9f2",
   "metadata": {},
   "source": [
    "nested_dataset = ml_instance.create_dataset(['Partitioned', 'Image'], description='A nested dataset for machine learning')\n",
    "training_dataset = ml_instance.create_dataset('Training', description='An image dataset for training')\n",
    "testing_dataset = ml_instance.create_dataset('Testing', description='A image dataset for testing')\n",
    "validation_dataset = ml_instance.create_dataset('Validation', description='A image dataset for validation')\n",
    "pd.DataFrame(ml_instance.find_datasets()).drop(columns=system_columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "ml_instance.add_dataset_members(dataset_rid=nested_dataset, members=[training_dataset, testing_dataset, validation_dataset])\n",
    "ml_instance.add_dataset_members(dataset_rid=training_dataset, members=training_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=testing_dataset, members=testing_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=validation_dataset, members=validation_rids)\n"
   ],
   "id": "6e76bbdf-2441-4444-be7f-e55399bcc32a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ok, lets see what we have now.",
   "id": "9d67f5a8334cde9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "display(pd.DataFrame(ml_instance.list_dataset_members(nested_dataset)['Dataset']).drop(columns=system_columns))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(training_dataset)['Image']).drop(columns=system_columns))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(testing_dataset)['Image']).drop(columns=system_columns))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(validation_dataset)['Image']).drop(columns=system_columns))"
   ],
   "id": "93af8b022d6c7edf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ml_instance.cite(nested_dataset)",
   "id": "636459f674713ec9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_catalog.delete_ermrest_catalog(really=True)",
   "id": "2b47915187993a22",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
