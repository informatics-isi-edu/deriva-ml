{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ffee41-4986-4196-b35d-b38b6e10490a",
   "metadata": {},
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DerivaML Dataset Example.\n",
    "\n",
    "DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library."
   ],
   "id": "a5ff6e4c93a70770"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up DerivaML  for test case",
   "id": "db30e3e5ccd3ad77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "beafab2f33e6207b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:07:38.131404Z",
     "start_time": "2024-11-19T19:07:36.368845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dash.testing.errors import DashTestingError\n",
    "\n",
    "from schema_setup.create_schema import define_table_dataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "29f3e870d1fea4f8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:17:18.548047Z",
     "start_time": "2024-11-19T19:17:18.526187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from deriva_ml.schema_setup.test_catalog import create_test_catalog, DemoML\n",
    "from deriva_ml.deriva_ml_base import MLVocab as vt\n",
    "from deriva_ml.dataset_bag import DatasetBag\n",
    "from IPython.display import display, Markdown"
   ],
   "id": "1d18222d50d0ef7c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set the details for the catalog we want and authenticate to the server if needed.",
   "id": "eb169235902c77be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:07:38.470927Z",
     "start_time": "2024-11-19T19:07:38.232351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hostname = 'dev.eye-ai.org'\n",
    "domain_schema = 'demo-schema'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=hostname)\n",
    "if gnl.is_logged_in([hostname]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")\n"
   ],
   "id": "677df6f200423a9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a test catalog and get an instance of the DemoML class.",
   "id": "cc01e85a63c60536"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "49964b240ff9ee88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:07:58.021469Z",
     "start_time": "2024-11-19T19:07:38.483029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_catalog = create_test_catalog(hostname, domain_schema)\n",
    "ml_instance = DemoML(hostname, test_catalog.catalog_id)"
   ],
   "id": "a843170d141c8a8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Configure DerivaML Datasets\n",
    "\n",
    "In Deriva-ML a dataset is used to aggregate instances of entities.  However, before we can create any datasets, we must configure \n",
    "Deriva-ML for the specifics of the datasets.  The first stp is we need to tell Deriva-ML what types of use defined objects can be associated with a dataset.  \n",
    "\n",
    "Note that out of the box, Deriva-ML is configured to allow datasets to contained dataset (i.e. nested datasets), so we don't need to do anything for that specific configuration."
   ],
   "id": "48c7854af033245"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:07:59.606258Z",
     "start_time": "2024-11-19T19:07:58.031093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Current dataset element types: {[a.name for a in ml_instance.list_dataset_element_types()]}\")\n",
    "ml_instance.add_dataset_element_type(\"Subject\")\n",
    "ml_instance.add_dataset_element_type(\"Image\")\n",
    "print(f\"New dataset element types {[a.name for a in ml_instance.list_dataset_element_types()]}\")"
   ],
   "id": "21e3d412920ac963",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dataset element types: ['Dataset']\n",
      "New dataset element types ['Dataset', 'Subject', 'Image']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have configured our datasets, we need to identify the dataset types so we can distiguish between them.",
   "id": "874f49d81439e0c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:08:00.505274Z",
     "start_time": "2024-11-19T19:07:59.614903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a new dataset\n",
    "ml_instance.add_term(vt.dataset_type, \"DemoSet\", description=\"A test dataset\")\n",
    "ml_instance.add_term(vt.dataset_type, 'Partitioned', description=\"A partitioned dataset for ML training.\")\n",
    "ml_instance.add_term(vt.dataset_type, \"Subject\", description=\"A test dataset\")\n",
    "ml_instance.add_term(vt.dataset_type, \"Image\", description=\"A test dataset\")\n",
    "ml_instance.add_term(vt.dataset_type, \"Training\", description=\"Training dataset\")\n",
    "ml_instance.add_term(vt.dataset_type, \"Testing\", description=\"Training dataset\")\n",
    "ml_instance.add_term(vt.dataset_type, \"Validation\", description=\"Validation dataset\")\n",
    "\n",
    "ml_instance.list_vocabulary_terms(vt.dataset_type)"
   ],
   "id": "6908fba1443aee13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VocabularyTerm(name='DemoSet', synonyms=[], id='ml-test:36R', uri='/id/36R', description='A test dataset', rid='36R'),\n",
       " VocabularyTerm(name='Partitioned', synonyms=[], id='ml-test:36T', uri='/id/36T', description='A partitioned dataset for ML training.', rid='36T'),\n",
       " VocabularyTerm(name='Subject', synonyms=[], id='ml-test:36W', uri='/id/36W', description='A test dataset', rid='36W'),\n",
       " VocabularyTerm(name='Image', synonyms=[], id='ml-test:36Y', uri='/id/36Y', description='A test dataset', rid='36Y'),\n",
       " VocabularyTerm(name='Training', synonyms=[], id='ml-test:370', uri='/id/370', description='Training dataset', rid='370'),\n",
       " VocabularyTerm(name='Testing', synonyms=[], id='ml-test:372', uri='/id/372', description='Training dataset', rid='372'),\n",
       " VocabularyTerm(name='Validation', synonyms=[], id='ml-test:374', uri='/id/374', description='Validation dataset', rid='374')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now create datasets and populate with elements from the test catalogs.",
   "id": "1f902cd9561842c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:08:01.529020Z",
     "start_time": "2024-11-19T19:08:00.514452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_columns = ['RCT', 'RMT', 'RCB', 'RMB']\n",
    "\n",
    "subject_dataset = ml_instance.create_dataset(['DemoSet', 'Subject'], description=\"A subject dataset\")\n",
    "image_dataset = ml_instance.create_dataset(['DemoSet', 'Image'], description=\"A image training dataset\")\n",
    "datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=system_columns)\n",
    "display(datasets)"
   ],
   "id": "10567931cbd3c322",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   RID               Description        Dataset_Type\n",
       "0  376         A subject dataset  [DemoSet, Subject]\n",
       "1  37C  A image training dataset    [DemoSet, Image]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Dataset_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>376</td>\n",
       "      <td>A subject dataset</td>\n",
       "      <td>[DemoSet, Subject]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37C</td>\n",
       "      <td>A image training dataset</td>\n",
       "      <td>[DemoSet, Image]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And now that we have defined some datasets, we can add elements of the approproate type to them.  We can see what is in our new datasets by listing the dataset members.",
   "id": "6474d1edb488097f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:08:07.126842Z",
     "start_time": "2024-11-19T19:08:01.552150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dp = ml_instance.domain_path  # Each call returns a new path instance, so only call once...\n",
    "subject_rids = [i['RID'] for i in dp.tables['Subject'].entities().fetch()]\n",
    "image_rids = [i['RID'] for i in dp.tables['Image'].entities().fetch()]\n",
    "\n",
    "ml_instance.add_dataset_members(dataset_rid=subject_dataset, members=subject_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=image_dataset, members=image_rids)\n",
    "\n",
    "# List the contents of our datasets, and lets not include columns like modify time.\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(subject_dataset)['Subject']).drop(columns=system_columns))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(image_dataset)['Image']).drop(columns=system_columns))"
   ],
   "id": "16bb5b8b8b2a5288",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    RID     Name\n",
       "0   2ZG   Thing1\n",
       "1   2ZJ   Thing2\n",
       "2   2ZM   Thing3\n",
       "3   2ZP   Thing4\n",
       "4   2ZR   Thing5\n",
       "5   2ZT   Thing6\n",
       "6   2ZW   Thing7\n",
       "7   2ZY   Thing8\n",
       "8   300   Thing9\n",
       "9   302  Thing10\n",
       "10  304  Thing11\n",
       "11  306  Thing12\n",
       "12  308  Thing13\n",
       "13  30A  Thing14\n",
       "14  30C  Thing15\n",
       "15  30E  Thing16\n",
       "16  30G  Thing17\n",
       "17  30J  Thing18\n",
       "18  30M  Thing19\n",
       "19  30P  Thing20"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ZG</td>\n",
       "      <td>Thing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ZJ</td>\n",
       "      <td>Thing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ZM</td>\n",
       "      <td>Thing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2ZP</td>\n",
       "      <td>Thing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ZR</td>\n",
       "      <td>Thing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2ZT</td>\n",
       "      <td>Thing6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2ZW</td>\n",
       "      <td>Thing7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2ZY</td>\n",
       "      <td>Thing8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>Thing9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>302</td>\n",
       "      <td>Thing10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>304</td>\n",
       "      <td>Thing11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>306</td>\n",
       "      <td>Thing12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>308</td>\n",
       "      <td>Thing13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30A</td>\n",
       "      <td>Thing14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30C</td>\n",
       "      <td>Thing15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30E</td>\n",
       "      <td>Thing16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30G</td>\n",
       "      <td>Thing17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30J</td>\n",
       "      <td>Thing18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30M</td>\n",
       "      <td>Thing19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30P</td>\n",
       "      <td>Thing20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "    RID                                                URL      Filename  \\\n",
       "0   30R  /hatrac/Image/a87499a167e6961d6c81f62f47e852b7...  test_2ZG.txt   \n",
       "1   30T  /hatrac/Image/b33e3f78223b87143f542530abd86d1e...  test_2ZJ.txt   \n",
       "2   30W  /hatrac/Image/0f17ea53ddc22ec6befe44abd89cb7d9...  test_2ZM.txt   \n",
       "3   30Y  /hatrac/Image/9292500baae06aec4f50142755790b15...  test_2ZP.txt   \n",
       "4   310  /hatrac/Image/a99fae2c67ab1b255dea81a68a7ecfb3...  test_2ZR.txt   \n",
       "5   312  /hatrac/Image/9090f2cbd9a50959c3cf6b8206bd7cf3...  test_2ZT.txt   \n",
       "6   314  /hatrac/Image/3ad4f00c4edc023765dd1998ad16778a...  test_2ZW.txt   \n",
       "7   316  /hatrac/Image/2d0e4bf553a29e3772738c2747278413...  test_2ZY.txt   \n",
       "8   318  /hatrac/Image/3b0a8644673cdaed8d2efeb9e4a11622...  test_300.txt   \n",
       "9   31A  /hatrac/Image/1f41e1780620502a64c20c917dfc0c6e...  test_302.txt   \n",
       "10  31C  /hatrac/Image/caaa64c5154aacd07ab043d58a5cd93e...  test_304.txt   \n",
       "11  31E  /hatrac/Image/160353b7bbbf872e388d0fdc87d8ba33...  test_306.txt   \n",
       "12  31G  /hatrac/Image/090e39a50aef41105e6c38eb34917b77...  test_308.txt   \n",
       "13  31J  /hatrac/Image/b78a28ae8a3c05228477066e3baa3999...  test_30A.txt   \n",
       "14  31M  /hatrac/Image/89fa722ff6129dd094e7676987a2cf96...  test_30C.txt   \n",
       "15  31P  /hatrac/Image/fff6a11bb5f109479b1da774f508af80...  test_30E.txt   \n",
       "16  31R  /hatrac/Image/ac7c5da130697de17532ab3dee828e33...  test_30G.txt   \n",
       "17  31T  /hatrac/Image/c207dc85b82a2fff32f0534a06ef31a4...  test_30J.txt   \n",
       "18  31W  /hatrac/Image/f4401cb7cb4eb293087e461242a8d184...  test_30M.txt   \n",
       "19  31Y  /hatrac/Image/35180b54ec8101120eb242f35ec60a92...  test_30P.txt   \n",
       "\n",
       "     Description  Length                               MD5  Name Subject  \n",
       "0   A test image      31  a87499a167e6961d6c81f62f47e852b7  None     2ZG  \n",
       "1   A test image      31  b33e3f78223b87143f542530abd86d1e  None     2ZJ  \n",
       "2   A test image      30  0f17ea53ddc22ec6befe44abd89cb7d9  None     2ZM  \n",
       "3   A test image      31  9292500baae06aec4f50142755790b15  None     2ZP  \n",
       "4   A test image      31  a99fae2c67ab1b255dea81a68a7ecfb3  None     2ZR  \n",
       "5   A test image      32  9090f2cbd9a50959c3cf6b8206bd7cf3  None     2ZT  \n",
       "6   A test image      32  3ad4f00c4edc023765dd1998ad16778a  None     2ZW  \n",
       "7   A test image      32  2d0e4bf553a29e3772738c2747278413  None     2ZY  \n",
       "8   A test image      32  3b0a8644673cdaed8d2efeb9e4a11622  None     300  \n",
       "9   A test image      31  1f41e1780620502a64c20c917dfc0c6e  None     302  \n",
       "10  A test image      31  caaa64c5154aacd07ab043d58a5cd93e  None     304  \n",
       "11  A test image      31  160353b7bbbf872e388d0fdc87d8ba33  None     306  \n",
       "12  A test image      31  090e39a50aef41105e6c38eb34917b77  None     308  \n",
       "13  A test image      31  b78a28ae8a3c05228477066e3baa3999  None     30A  \n",
       "14  A test image      31  89fa722ff6129dd094e7676987a2cf96  None     30C  \n",
       "15  A test image      32  fff6a11bb5f109479b1da774f508af80  None     30E  \n",
       "16  A test image      31  ac7c5da130697de17532ab3dee828e33  None     30G  \n",
       "17  A test image      32  c207dc85b82a2fff32f0534a06ef31a4  None     30J  \n",
       "18  A test image      31  f4401cb7cb4eb293087e461242a8d184  None     30M  \n",
       "19  A test image      31  35180b54ec8101120eb242f35ec60a92  None     30P  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Description</th>\n",
       "      <th>Length</th>\n",
       "      <th>MD5</th>\n",
       "      <th>Name</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30R</td>\n",
       "      <td>/hatrac/Image/a87499a167e6961d6c81f62f47e852b7...</td>\n",
       "      <td>test_2ZG.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>a87499a167e6961d6c81f62f47e852b7</td>\n",
       "      <td>None</td>\n",
       "      <td>2ZG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30T</td>\n",
       "      <td>/hatrac/Image/b33e3f78223b87143f542530abd86d1e...</td>\n",
       "      <td>test_2ZJ.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>b33e3f78223b87143f542530abd86d1e</td>\n",
       "      <td>None</td>\n",
       "      <td>2ZJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30W</td>\n",
       "      <td>/hatrac/Image/0f17ea53ddc22ec6befe44abd89cb7d9...</td>\n",
       "      <td>test_2ZM.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>30</td>\n",
       "      <td>0f17ea53ddc22ec6befe44abd89cb7d9</td>\n",
       "      <td>None</td>\n",
       "      <td>2ZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30Y</td>\n",
       "      <td>/hatrac/Image/9292500baae06aec4f50142755790b15...</td>\n",
       "      <td>test_2ZP.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>9292500baae06aec4f50142755790b15</td>\n",
       "      <td>None</td>\n",
       "      <td>2ZP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310</td>\n",
       "      <td>/hatrac/Image/a99fae2c67ab1b255dea81a68a7ecfb3...</td>\n",
       "      <td>test_2ZR.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>a99fae2c67ab1b255dea81a68a7ecfb3</td>\n",
       "      <td>None</td>\n",
       "      <td>2ZR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>312</td>\n",
       "      <td>/hatrac/Image/9090f2cbd9a50959c3cf6b8206bd7cf3...</td>\n",
       "      <td>test_2ZT.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>32</td>\n",
       "      <td>9090f2cbd9a50959c3cf6b8206bd7cf3</td>\n",
       "      <td>None</td>\n",
       "      <td>2ZT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>314</td>\n",
       "      <td>/hatrac/Image/3ad4f00c4edc023765dd1998ad16778a...</td>\n",
       "      <td>test_2ZW.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>32</td>\n",
       "      <td>3ad4f00c4edc023765dd1998ad16778a</td>\n",
       "      <td>None</td>\n",
       "      <td>2ZW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>316</td>\n",
       "      <td>/hatrac/Image/2d0e4bf553a29e3772738c2747278413...</td>\n",
       "      <td>test_2ZY.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>32</td>\n",
       "      <td>2d0e4bf553a29e3772738c2747278413</td>\n",
       "      <td>None</td>\n",
       "      <td>2ZY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>318</td>\n",
       "      <td>/hatrac/Image/3b0a8644673cdaed8d2efeb9e4a11622...</td>\n",
       "      <td>test_300.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>32</td>\n",
       "      <td>3b0a8644673cdaed8d2efeb9e4a11622</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31A</td>\n",
       "      <td>/hatrac/Image/1f41e1780620502a64c20c917dfc0c6e...</td>\n",
       "      <td>test_302.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>1f41e1780620502a64c20c917dfc0c6e</td>\n",
       "      <td>None</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31C</td>\n",
       "      <td>/hatrac/Image/caaa64c5154aacd07ab043d58a5cd93e...</td>\n",
       "      <td>test_304.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>caaa64c5154aacd07ab043d58a5cd93e</td>\n",
       "      <td>None</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31E</td>\n",
       "      <td>/hatrac/Image/160353b7bbbf872e388d0fdc87d8ba33...</td>\n",
       "      <td>test_306.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>160353b7bbbf872e388d0fdc87d8ba33</td>\n",
       "      <td>None</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31G</td>\n",
       "      <td>/hatrac/Image/090e39a50aef41105e6c38eb34917b77...</td>\n",
       "      <td>test_308.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>090e39a50aef41105e6c38eb34917b77</td>\n",
       "      <td>None</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31J</td>\n",
       "      <td>/hatrac/Image/b78a28ae8a3c05228477066e3baa3999...</td>\n",
       "      <td>test_30A.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>b78a28ae8a3c05228477066e3baa3999</td>\n",
       "      <td>None</td>\n",
       "      <td>30A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31M</td>\n",
       "      <td>/hatrac/Image/89fa722ff6129dd094e7676987a2cf96...</td>\n",
       "      <td>test_30C.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>89fa722ff6129dd094e7676987a2cf96</td>\n",
       "      <td>None</td>\n",
       "      <td>30C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31P</td>\n",
       "      <td>/hatrac/Image/fff6a11bb5f109479b1da774f508af80...</td>\n",
       "      <td>test_30E.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>32</td>\n",
       "      <td>fff6a11bb5f109479b1da774f508af80</td>\n",
       "      <td>None</td>\n",
       "      <td>30E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31R</td>\n",
       "      <td>/hatrac/Image/ac7c5da130697de17532ab3dee828e33...</td>\n",
       "      <td>test_30G.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>ac7c5da130697de17532ab3dee828e33</td>\n",
       "      <td>None</td>\n",
       "      <td>30G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31T</td>\n",
       "      <td>/hatrac/Image/c207dc85b82a2fff32f0534a06ef31a4...</td>\n",
       "      <td>test_30J.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>32</td>\n",
       "      <td>c207dc85b82a2fff32f0534a06ef31a4</td>\n",
       "      <td>None</td>\n",
       "      <td>30J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31W</td>\n",
       "      <td>/hatrac/Image/f4401cb7cb4eb293087e461242a8d184...</td>\n",
       "      <td>test_30M.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>f4401cb7cb4eb293087e461242a8d184</td>\n",
       "      <td>None</td>\n",
       "      <td>30M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31Y</td>\n",
       "      <td>/hatrac/Image/35180b54ec8101120eb242f35ec60a92...</td>\n",
       "      <td>test_30P.txt</td>\n",
       "      <td>A test image</td>\n",
       "      <td>31</td>\n",
       "      <td>35180b54ec8101120eb242f35ec60a92</td>\n",
       "      <td>None</td>\n",
       "      <td>30P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create partitioned dataset\n",
    "\n",
    "Now lets create some subsets of the origional dataset based on subject level metadata. We are going to create the subsets based on the metadata values of the subjects.  SO we will download the subject dataset and look at its metadata to figure out whow to partition the origional data. Since we are not going to look at the images, we use dowload_dataset_bag, rather than materialize_bag."
   ],
   "id": "2ac02c487e8a3be3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:17:30.989861Z",
     "start_time": "2024-11-19T19:17:28.479057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bag_path, bag_rid = ml_instance.download_dataset_bag(subject_dataset)\n",
    "ml_instance.materialize_dataset_bag(subject_dataset)\n",
    "dataset_bag = DatasetBag(bag_path)\n",
    "print(f\"Bag materialized to {bag_path}\")"
   ],
   "id": "5f8f12b942310485",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag materialized to /private/var/folders/0k/27qzm97x3t7g3j1m6ksf_9f40000gn/T/tmp8bj35v2v/376_6b3147ffdea444aa8fc6c821be2652c0815bdd4b51b10c887a842c9a6e0cb272/Dataset_376\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The domain model has two object: Subject and Images where an Image is associated with a subject, but a subject can have multiple images associated with it.  Lets look at the subjects and partition into test and training datasets.",
   "id": "aefa71000a8888b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T19:20:29.490049Z",
     "start_time": "2024-11-19T19:20:29.469689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get information about the subjects.....\n",
    "subject_df = dataset_bag.get_table_as_dataframe('Subject')[['RID', 'Name']]\n",
    "image_df = dataset_bag.get_table_as_dataframe('Image')[['RID', 'Subject', 'URL']]\n",
    "metadata_df = subject_df.join(image_df, lsuffix=\"_subject\", rsuffix=\"_image\")\n",
    "display(metadata_df)"
   ],
   "id": "405cebbc9d686f9b",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'[' was never closed (1984327912.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[16], line 3\u001B[0;36m\u001B[0m\n\u001B[0;31m    image_df = dataset_bag.get_table_as_dataframe('Image')[['RID', 'Subject', 'URL']\u001B[0m\n\u001B[0m                                                          ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m '[' was never closed\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For ths example, lets partition the data based on the name of the subject.  Of course in real examples, we would do a more complex analysis in deciding\n",
    "what subset goes into each data set."
   ],
   "id": "a251643b1b7389b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def thing_number(name: pd.Series) -> pd.Series:\n",
    "    return name.map(lambda n: int(n.replace('Thing','')))\n",
    "\n",
    "training_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 0]['RID_image'].tolist()\n",
    "testing_rids =  metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 1]['RID_image'].tolist()\n",
    "validation_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 2]['RID_image'].tolist()\n",
    "\n",
    "print(f'Training images: {training_rids}')\n",
    "print(f'Testing images: {testing_rids}')\n",
    "print(f'Validation images: {validation_rids}')\n"
   ],
   "id": "fac3a1b3d7db6556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we know what we want in each dataset, lets create datasets for each of our partitioned elements along with a nested dataset to track the entire collection.",
   "id": "27e66ce59b0fb193"
  },
  {
   "cell_type": "code",
   "id": "1fcf179738fad9f2",
   "metadata": {},
   "source": [
    "nested_dataset = ml_instance.create_dataset(['Partitioned', 'Image'], description='A nested dataset for machine learning')\n",
    "training_dataset = ml_instance.create_dataset('Training', description='An image dataset for training')\n",
    "testing_dataset = ml_instance.create_dataset('Testing', description='A image dataset for testing')\n",
    "validation_dataset = ml_instance.create_dataset('Validation', description='A image dataset for validation')\n",
    "pd.DataFrame(ml_instance.find_datasets()).drop(columns=system_columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And then fill the datasets with the appropriate members.",
   "id": "ac71fa8b087340ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "ml_instance.add_dataset_members(dataset_rid=nested_dataset, members=[training_dataset, testing_dataset, validation_dataset])\n",
    "ml_instance.add_dataset_members(dataset_rid=training_dataset, members=training_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=testing_dataset, members=testing_rids)\n",
    "ml_instance.add_dataset_members(dataset_rid=validation_dataset, members=validation_rids)\n"
   ],
   "id": "6e76bbdf-2441-4444-be7f-e55399bcc32a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ok, lets see what we have now.",
   "id": "9d67f5a8334cde9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "display(Markdown('## Nested Dataset'))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(nested_dataset)['Dataset']).drop(columns=system_columns))\n",
    "display(Markdown('## Training Dataset'))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(training_dataset)['Image']).drop(columns=system_columns))\n",
    "display(Markdown('## Testing Dataset'))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(testing_dataset)['Image']).drop(columns=system_columns))\n",
    "display(Markdown('## Validation Dataset'))\n",
    "display(pd.DataFrame(ml_instance.list_dataset_members(validation_dataset)['Image']).drop(columns=system_columns))"
   ],
   "id": "93af8b022d6c7edf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As our very last step, lets get a PID that will allow us to share and and cite the dataset that we just created",
   "id": "fc6b8ddd57688870"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ml_instance.cite(nested_dataset)",
   "id": "636459f674713ec9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_catalog.delete_ermrest_catalog(really=True)",
   "id": "2b47915187993a22",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
