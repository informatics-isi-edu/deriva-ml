{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to DerivaML","text":"<p>DerivaML is a library designed to improve the reproducibility of machine learning experiments.  Using DerivaML facilitates the ability to create data that is continously Findable, Accessable, Interoperable, and Reusable (FAIR).  </p> <p>More details about the principles of continous FAIRness can be found here.</p> <p>Dempsey, William, Ian Foster, Scott Fraser, and Carl Kesselman.  Sharing begins at home: how continuous and ubiquitous FAIRness can enhance research productivity and data reuse.  Harvard data science review 4, no. 3 (2022). PDF</p> <p>An overview of the design and operational aspects of DerivaML can be found in this paper.</p> <p>[Li, Zhiwei, Carl Kesselman, Mike D\u2019Arcy, Michael Pazzani, and Benjamin Yizing Xu.  Deriva-ML: A Continuous FAIRness Approach to Reproducible Machine Learning Models. In 2024 IEEE 20th International Conference on e-Science (e-Science), pp. 1-10. IEEE, 2024. PDF</p> <p>The data model design in Deriva Catalog:</p> <p></p>"},{"location":"architecture/","title":"DerivaML System Architecture","text":"<p>This document describes the architecture of the DerivaML ecosystem, including all components and their relationships.</p>"},{"location":"architecture/#system-overview","title":"System Overview","text":"<p>DerivaML is a comprehensive platform for reproducible machine learning workflows. It combines scientific data management (Deriva), ML workflow orchestration (deriva-ml), AI-assisted development (MCP server + Claude Code), and configuration management (Hydra-zen) into a unified system that captures complete provenance for all experiments.</p> <pre><code>flowchart TB\n    subgraph \"User Interface Layer\"\n        CC[Claude Code&lt;br/&gt;AI Assistant]\n        CLI[deriva-ml-run&lt;br/&gt;CLI]\n        NB[Jupyter&lt;br/&gt;Notebooks]\n        CH[Chaise&lt;br/&gt;Web UI]\n    end\n\n    subgraph \"AI Integration Layer\"\n        MCP[deriva-ml-mcp&lt;br/&gt;MCP Server]\n    end\n\n    subgraph \"Workflow Layer\"\n        DML[deriva-ml&lt;br/&gt;Python Library]\n        HZ[Hydra-zen&lt;br/&gt;Configuration]\n    end\n\n    subgraph \"Data Access Layer\"\n        DPY[deriva-py&lt;br/&gt;Python Client]\n    end\n\n    subgraph \"Storage Layer\"\n        subgraph \"Deriva Catalog\"\n            PG[(PostgreSQL&lt;br/&gt;Database)]\n            ER[ERMrest&lt;br/&gt;REST API]\n            HT[Hatrac&lt;br/&gt;File Store]\n        end\n    end\n\n    CC --&gt; MCP\n    MCP --&gt; DML\n    CLI --&gt; HZ\n    CLI --&gt; DML\n    NB --&gt; DML\n    CH --&gt; ER\n    DML --&gt; DPY\n    HZ --&gt; DML\n    DPY --&gt; ER\n    DPY --&gt; HT\n    ER --&gt; PG\n</code></pre>"},{"location":"architecture/#component-descriptions","title":"Component Descriptions","text":""},{"location":"architecture/#storage-layer-deriva-catalog","title":"Storage Layer: Deriva Catalog","text":"<p>The Deriva catalog provides the persistent storage foundation:</p> <ul> <li>PostgreSQL Database: Stores all structured data including datasets, executions, features, and vocabularies</li> <li>ERMrest: Entity-Relationship Mapping REST API that provides a RESTful interface to the database with fine-grained access control</li> <li>Hatrac: Object storage service for large files (images, model weights, prediction outputs)</li> <li>Chaise: Web-based user interface for browsing and editing catalog data</li> </ul>"},{"location":"architecture/#data-access-layer-deriva-py","title":"Data Access Layer: deriva-py","text":"<p>The <code>deriva-py</code> library provides Python bindings for Deriva services:</p> <ul> <li>ERMrest client for database operations (CRUD, queries, schema management)</li> <li>Hatrac client for file upload/download</li> <li>Authentication via Globus</li> <li>BDBag support for reproducible data packaging</li> </ul>"},{"location":"architecture/#workflow-layer-deriva-ml","title":"Workflow Layer: deriva-ml","text":"<p>The <code>deriva-ml</code> library provides ML-specific abstractions:</p> <ul> <li>DerivaML: Main class connecting to catalogs and orchestrating workflows</li> <li>Execution: Tracks individual experiment runs with inputs, outputs, and status</li> <li>Dataset: Versioned collections of data with semantic versioning</li> <li>Workflow: Reusable workflow definitions linked to source code</li> <li>Feature: Maps vocabulary terms to domain records (labels, annotations)</li> <li>Asset: Files with metadata (images, model weights, predictions)</li> </ul>"},{"location":"architecture/#configuration-layer-hydra-zen","title":"Configuration Layer: Hydra-zen","text":"<p>Hydra-zen provides Python-first configuration management:</p> <ul> <li>Configuration as code (no YAML files)</li> <li>Runtime composition and overrides</li> <li>Multirun support for hyperparameter sweeps</li> <li>Automatic config tracking for reproducibility</li> </ul>"},{"location":"architecture/#ai-integration-layer-deriva-ml-mcp","title":"AI Integration Layer: deriva-ml-mcp","text":"<p>The MCP (Model Context Protocol) server exposes DerivaML operations to AI assistants:</p> <ul> <li>60+ tools for catalog operations</li> <li>Resources for read-only access to schema and data</li> <li>Prompts for guided workflows</li> <li>Secure credential handling (never exposed to AI)</li> </ul>"},{"location":"architecture/#user-interface-layer","title":"User Interface Layer","text":"<p>Multiple interfaces for different use cases:</p> <ul> <li>Claude Code: AI-powered development assistant using MCP tools</li> <li>deriva-ml-run: Command-line interface for running experiments</li> <li>Jupyter Notebooks: Interactive analysis with <code>run_notebook()</code> API</li> <li>Chaise: Web UI for browsing and editing data</li> </ul>"},{"location":"architecture/#data-model","title":"Data Model","text":"<p>The core entities and their relationships:</p> <pre><code>erDiagram\n    Workflow ||--o{ Execution : \"has many\"\n    Execution ||--o{ Dataset : \"uses (input)\"\n    Execution ||--o{ Dataset : \"produces (output)\"\n    Execution ||--o{ Asset : \"uses (input)\"\n    Execution ||--o{ Asset : \"produces (output)\"\n    Dataset ||--o{ Dataset_Version : \"has versions\"\n    Dataset ||--o{ Dataset : \"contains (nested)\"\n    Dataset }o--o{ Domain_Record : \"contains members\"\n    Feature ||--o{ Feature_Value : \"has values\"\n    Feature_Value }o--|| Domain_Record : \"labels\"\n    Feature_Value }o--|| Vocabulary_Term : \"uses term\"\n    Workflow }o--|| Workflow_Type : \"has type\"\n    Dataset }o--o{ Dataset_Type : \"has types\"\n\n    Workflow {\n        RID rid PK\n        string name\n        string url\n        string checksum\n        string workflow_type FK\n    }\n\n    Execution {\n        RID rid PK\n        string workflow FK\n        string status\n        string description\n        timestamp start_time\n        timestamp end_time\n    }\n\n    Dataset {\n        RID rid PK\n        string description\n        string version FK\n        boolean deleted\n    }\n\n    Dataset_Version {\n        RID rid PK\n        RID dataset FK\n        string version\n        string snapshot\n        string minid\n    }\n\n    Asset {\n        RID rid PK\n        string filename\n        string url\n        string md5\n        int length\n    }\n\n    Feature {\n        RID rid PK\n        string name\n        string target_table\n        string vocabulary\n    }\n\n    Feature_Value {\n        RID rid PK\n        RID feature FK\n        RID target FK\n        string term FK\n    }\n</code></pre>"},{"location":"architecture/#workflow-running-an-experiment","title":"Workflow: Running an Experiment","text":"<p>The typical flow for running an ML experiment:</p> <pre><code>sequenceDiagram\n    participant User\n    participant CLI as deriva-ml-run\n    participant Hydra as Hydra-zen\n    participant DML as deriva-ml\n    participant Catalog as Deriva Catalog\n\n    User-&gt;&gt;CLI: deriva-ml-run +experiment=cifar10_quick\n    CLI-&gt;&gt;Hydra: Load and compose configs\n    Hydra-&gt;&gt;CLI: Resolved configuration\n    CLI-&gt;&gt;DML: run_model(config)\n\n    DML-&gt;&gt;Catalog: Create Workflow record\n    DML-&gt;&gt;Catalog: Create Execution record\n    DML-&gt;&gt;Catalog: Link input Datasets\n\n    DML-&gt;&gt;Catalog: Download Dataset (BDBag)\n    Catalog--&gt;&gt;DML: Dataset files\n\n    Note over DML: Execute model code\n\n    DML-&gt;&gt;Catalog: Upload output files (Hatrac)\n    DML-&gt;&gt;Catalog: Create Asset records\n    DML-&gt;&gt;Catalog: Record Feature values\n    DML-&gt;&gt;Catalog: Update Execution status\n\n    DML--&gt;&gt;CLI: Execution complete\n    CLI--&gt;&gt;User: Results summary\n</code></pre>"},{"location":"architecture/#workflow-ai-assisted-development","title":"Workflow: AI-Assisted Development","text":"<p>Using Claude Code with the MCP server:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Claude as Claude Code\n    participant MCP as deriva-ml-mcp\n    participant DML as deriva-ml\n    participant Catalog as Deriva Catalog\n\n    User-&gt;&gt;Claude: \"List my datasets\"\n    Claude-&gt;&gt;MCP: connect_catalog(host, catalog_id)\n    MCP-&gt;&gt;DML: DerivaML(host, catalog_id)\n    DML-&gt;&gt;Catalog: Authenticate (Globus)\n    Catalog--&gt;&gt;DML: Session established\n    DML--&gt;&gt;MCP: Connected\n    MCP--&gt;&gt;Claude: Connection confirmed\n\n    Claude-&gt;&gt;MCP: find_datasets()\n    MCP-&gt;&gt;DML: ml.find_datasets()\n    DML-&gt;&gt;Catalog: Query Dataset table\n    Catalog--&gt;&gt;DML: Dataset records\n    DML--&gt;&gt;MCP: Dataset list\n    MCP--&gt;&gt;Claude: JSON results\n\n    Claude--&gt;&gt;User: \"You have 13 datasets...\"\n</code></pre>"},{"location":"architecture/#dataset-versioning-and-bdbags","title":"Dataset Versioning and BDBags","text":"<p>Datasets support semantic versioning for reproducibility:</p> <pre><code>flowchart LR\n    subgraph \"Catalog State\"\n        D[Dataset&lt;br/&gt;RID: ABC]\n        V1[Version 0.1.0&lt;br/&gt;Snapshot: T1]\n        V2[Version 0.2.0&lt;br/&gt;Snapshot: T2]\n        V3[Version 1.0.0&lt;br/&gt;Snapshot: T3]\n    end\n\n    subgraph \"BDBag Export\"\n        B1[BDBag v0.1.0]\n        B2[BDBag v0.2.0]\n        B3[BDBag v1.0.0]\n    end\n\n    subgraph \"External Storage\"\n        S3[S3 Bucket]\n        MINID[MINID Registry]\n    end\n\n    D --&gt; V1\n    D --&gt; V2\n    D --&gt; V3\n\n    V1 -.-&gt; B1\n    V2 -.-&gt; B2\n    V3 -.-&gt; B3\n\n    B3 --&gt; S3\n    S3 --&gt; MINID\n</code></pre> <p>Version semantics: - Major: Breaking changes to dataset structure - Minor: New data added (members, types, features) - Patch: Metadata corrections</p> <p>BDBag features: - Self-describing archive format - Cryptographic checksums for integrity - Remote file references for large assets - MINID registration for permanent identifiers</p>"},{"location":"architecture/#provenance-chain","title":"Provenance Chain","text":"<p>Complete provenance tracking from code to results:</p> <pre><code>flowchart TB\n    subgraph \"Code Provenance\"\n        GH[GitHub Repository]\n        COMMIT[Git Commit SHA]\n        URL[Blob URL]\n    end\n\n    subgraph \"Workflow Record\"\n        WF[Workflow]\n        WT[Workflow Type]\n    end\n\n    subgraph \"Execution Record\"\n        EX[Execution]\n        CFG[Config Choices]\n        PARAMS[Parameters]\n    end\n\n    subgraph \"Input Provenance\"\n        DS_IN[Input Datasets]\n        AS_IN[Input Assets]\n        VER[Dataset Versions]\n    end\n\n    subgraph \"Output Provenance\"\n        DS_OUT[Output Datasets]\n        AS_OUT[Output Assets]\n        FV[Feature Values]\n    end\n\n    GH --&gt; COMMIT\n    COMMIT --&gt; URL\n    URL --&gt; WF\n    WT --&gt; WF\n    WF --&gt; EX\n    CFG --&gt; EX\n    PARAMS --&gt; EX\n    DS_IN --&gt; EX\n    AS_IN --&gt; EX\n    VER --&gt; DS_IN\n    EX --&gt; DS_OUT\n    EX --&gt; AS_OUT\n    EX --&gt; FV\n</code></pre>"},{"location":"architecture/#configuration-system","title":"Configuration System","text":"<p>Hydra-zen configuration hierarchy:</p> <pre><code>flowchart TB\n    subgraph \"Config Modules (src/configs/)\"\n        DERIVA[deriva.py&lt;br/&gt;Connection configs]\n        DATASETS[datasets.py&lt;br/&gt;Dataset specs]\n        ASSETS[assets.py&lt;br/&gt;Asset RIDs]\n        MODEL[cifar10_cnn.py&lt;br/&gt;Model configs]\n        EXP[experiments.py&lt;br/&gt;Experiment presets]\n        MULTI[multiruns.py&lt;br/&gt;Sweep configs]\n    end\n\n    subgraph \"Hydra Store\"\n        STORE[hydra-zen store]\n    end\n\n    subgraph \"Runtime\"\n        CLI[CLI Overrides]\n        COMPOSED[Composed Config]\n        MODEL_FN[Model Function]\n    end\n\n    DERIVA --&gt; STORE\n    DATASETS --&gt; STORE\n    ASSETS --&gt; STORE\n    MODEL --&gt; STORE\n    EXP --&gt; STORE\n    MULTI --&gt; STORE\n\n    STORE --&gt; COMPOSED\n    CLI --&gt; COMPOSED\n    COMPOSED --&gt; MODEL_FN\n</code></pre> <p>Configuration groups: - <code>deriva_ml</code>: Connection settings (hostname, catalog_id) - <code>datasets</code>: Dataset specifications with RID and version - <code>assets</code>: Asset RID lists for pre-trained weights, etc. - <code>model_config</code>: Model hyperparameters - <code>experiment</code>: Preset combinations of all settings - <code>multirun</code>: Parameter sweep definitions</p>"},{"location":"architecture/#schema-organization","title":"Schema Organization","text":"<p>The catalog uses multiple schemas for organization:</p> <pre><code>flowchart TB\n    subgraph \"deriva-ml Schema\"\n        DS[Dataset]\n        DV[Dataset_Version]\n        EX[Execution]\n        WF[Workflow]\n        FT[Feature]\n        FV[Feature_Value]\n    end\n\n    subgraph \"Domain Schema (e.g., cifar10)\"\n        IMG[Image]\n        IC[Image_Class&lt;br/&gt;Vocabulary]\n        ICF[Image_Classification&lt;br/&gt;Feature]\n    end\n\n    subgraph \"Association Tables\"\n        DE[Dataset_Execution]\n        DD[Dataset_Dataset]\n        DI[Dataset_Image]\n        EA[Execution_Asset]\n    end\n\n    DS --&gt; DE\n    EX --&gt; DE\n    DS --&gt; DD\n    DS --&gt; DI\n    IMG --&gt; DI\n    EX --&gt; EA\n\n    FT --&gt; FV\n    IC --&gt; FV\n    IMG --&gt; FV\n</code></pre>"},{"location":"architecture/#security-model","title":"Security Model","text":"<p>Authentication and authorization flow:</p> <pre><code>flowchart LR\n    subgraph \"Client\"\n        USER[User]\n        APP[Application]\n        CRED[Local Credentials]\n    end\n\n    subgraph \"Authentication\"\n        GLOBUS[Globus Auth]\n        TOKEN[Access Token]\n    end\n\n    subgraph \"Deriva Services\"\n        ER[ERMrest]\n        HT[Hatrac]\n        ACL[ACL Policies]\n    end\n\n    USER --&gt; GLOBUS\n    GLOBUS --&gt; TOKEN\n    TOKEN --&gt; CRED\n    APP --&gt; CRED\n    CRED --&gt; ER\n    CRED --&gt; HT\n    ACL --&gt; ER\n    ACL --&gt; HT\n</code></pre> <p>Security features: - Globus authentication with local token caching - Fine-grained ACLs at table, row, and column level - MCP server never exposes credentials to AI - Docker isolation for containerized deployments</p>"},{"location":"architecture/#summary","title":"Summary","text":"<p>The DerivaML ecosystem provides:</p> <ol> <li>Reproducibility: Complete provenance from code to results</li> <li>Versioning: Semantic versioning for datasets with BDBag export</li> <li>Flexibility: Multiple interfaces (CLI, notebooks, AI assistant, web)</li> <li>Scalability: Handles large datasets with remote file references</li> <li>Security: Fine-grained access control with Globus authentication</li> <li>Discoverability: AI-assisted exploration and development</li> </ol>"},{"location":"release-notes/","title":"Release Notes","text":"<p>Version 1.2.0</p> <ul> <li>Dataset versioning with semantic versioning. Note that the current dataset version does NOT have the current catalog values, but rather the values at the time the dataset was created.  To get the current values you must increment the dataset version number.  Please consult online documentation for more information on dataset and versioning.</li> <li>Streamlined create_execution.  Now all datasets are automatically downloaded and instance variable has databag classes. You no longer need to explictly create dataset_bdbag. </li> <li>Significant performance improvement on cached dataset access and initial download</li> <li>Automatic creation of MINID for every dataset download</li> <li>Added method to restore an existing execution from local disk.</li> </ul> <p>Version 1.1.4 - Fixed error when creating DatasetBag on windows platform.</p> <p>Version 1.1.1</p> <ul> <li>Removed restriction on nested datasets so that now any level of nesting can be accomidated.</li> <li>Fixed bug in nested dataset download.</li> <li>Added additional methods to DatasetBag to make it easear to explore datasets.</li> <li>Added <code>datasets</code> instance variable to Execution object which has Dataset objects for all of the datasets listed in the configuration.</li> <li>Added option to DatasetBag init to provide a dataset RID or a path.  If the dataset has already been loaded, or the dataset is nested, this will return the assocated DatasetBag object.</li> </ul>"},{"location":"Notebooks/DerivaML%20Create%20Notes/","title":"DerivaML Create Notes","text":"<p>DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library.</p> In\u00a0[\u00a0]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[\u00a0]: Copied! <pre>import builtins\nfrom demo_catalog import create_demo_catalog, DemoML\nfrom deriva.core.utils.globus_auth_utils import GlobusNativeLogin\nfrom IPython.display import display, Markdown, HTML, IFrame\n</pre> import builtins from demo_catalog import create_demo_catalog, DemoML from deriva.core.utils.globus_auth_utils import GlobusNativeLogin from IPython.display import display, Markdown, HTML, IFrame  <p>Set the details for the catalog we want and authenticate to the server if needed.</p> In\u00a0[\u00a0]: Copied! <pre>hostname = 'dev.eye-ai.org'\ndomain_schema = 'demo-schema'\n\ngnl = GlobusNativeLogin(host=hostname)\nif gnl.is_logged_in([hostname]):\n    print(\"You are already logged in.\")\nelse:\n    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n    print(\"Login Successful\")\n</pre> hostname = 'dev.eye-ai.org' domain_schema = 'demo-schema'  gnl = GlobusNativeLogin(host=hostname) if gnl.is_logged_in([hostname]):     print(\"You are already logged in.\") else:     gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)     print(\"Login Successful\")  In\u00a0[\u00a0]: Copied! <pre>import json\nimport os\nimport ipykernel\nimport requests\n\ndef get_notebook_filename():\n    \"\"\"Returns the current Jupyter Notebook filename.\"\"\"\n    try:\n        # Get the kernel ID\n        kernel_id = ipykernel.connect.get_connection_file().split('-')[1].split('.')[0]\n        print(kernel_id)\n        # Get running notebook servers\n        response = requests.get('http://127.0.0.1:8888/api/sessions', headers={'Authorization': ''})\n        sessions = json.loads(response.text)\n        print(sessions)\n        # Match the kernel ID to find the notebook name\n        for session in sessions:\n            print(session)\n            if session['kernel']['id'] == kernel_id:\n                return session['name']  # Returns the filename\n    except Exception as e:\n        return f\"Error: {e}\"\n\n# Usage\nnotebook_file = get_notebook_filename()\nprint(f\"Current Notebook: {notebook_file}\")\n</pre> import json import os import ipykernel import requests  def get_notebook_filename():     \"\"\"Returns the current Jupyter Notebook filename.\"\"\"     try:         # Get the kernel ID         kernel_id = ipykernel.connect.get_connection_file().split('-')[1].split('.')[0]         print(kernel_id)         # Get running notebook servers         response = requests.get('http://127.0.0.1:8888/api/sessions', headers={'Authorization': ''})         sessions = json.loads(response.text)         print(sessions)         # Match the kernel ID to find the notebook name         for session in sessions:             print(session)             if session['kernel']['id'] == kernel_id:                 return session['name']  # Returns the filename     except Exception as e:         return f\"Error: {e}\"  # Usage notebook_file = get_notebook_filename() print(f\"Current Notebook: {notebook_file}\") In\u00a0[\u00a0]: Copied! <pre>test_catalog = create_demo_catalog(hostname, domain_schema)\nml_instance = DemoML(hostname, test_catalog.catalog_id)\n</pre> test_catalog = create_demo_catalog(hostname, domain_schema) ml_instance = DemoML(hostname, test_catalog.catalog_id) <p>Now using TestFeatureClass, we can create some instances of the feature and add it.  We must have a exeuction_rid in order to define the feature.</p> In\u00a0[\u00a0]: Copied! <pre>display(IFrame(ml_instance.chaise_url('Page'), 500, 500))\n</pre> display(IFrame(ml_instance.chaise_url('Page'), 500, 500))  In\u00a0[\u00a0]: Copied! <pre>ml_instance.chaise_url('Page')\n</pre> ml_instance.chaise_url('Page') In\u00a0[\u00a0]: Copied! <pre>test_catalog.delete_ermrest_catalog(really=True)\n</pre> test_catalog.delete_ermrest_catalog(really=True)"},{"location":"Notebooks/DerivaML%20Dataset/","title":"DerivaML Dataset","text":"In\u00a0[\u00a0]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[\u00a0]: Copied! <pre>from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\nfrom deriva_ml.demo_catalog import create_demo_catalog, DemoML\nfrom deriva_ml import MLVocab, ExecutionConfiguration, Workflow, DerivaSystemColumns, VersionPart, DatasetSpec\nimport pandas as pd\nfrom IPython.display import display, Markdown, HTML, JSON\n</pre> from deriva.core.utils.globus_auth_utils import GlobusNativeLogin from deriva_ml.demo_catalog import create_demo_catalog, DemoML from deriva_ml import MLVocab, ExecutionConfiguration, Workflow, DerivaSystemColumns, VersionPart, DatasetSpec import pandas as pd from IPython.display import display, Markdown, HTML, JSON <p>Set the details for the catalog we want and authenticate to the server if needed.</p> In\u00a0[\u00a0]: parameters Copied! <pre>hostname = 'localhost'\ndomain_schema = 'demo-schema'\n</pre> hostname = 'localhost' domain_schema = 'demo-schema' In\u00a0[\u00a0]: Copied! <pre>gnl = GlobusNativeLogin(host=hostname)\nif gnl.is_logged_in([hostname]):\n    print(\"You are already logged in.\")\nelse:\n    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n    print(\"Login Successful\")\n</pre> gnl = GlobusNativeLogin(host=hostname) if gnl.is_logged_in([hostname]):     print(\"You are already logged in.\") else:     gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)     print(\"Login Successful\")  <p>Create a test catalog and get an instance of the DemoML class.</p> In\u00a0[\u00a0]: Copied! <pre>test_catalog = create_demo_catalog(hostname, domain_schema)\nml_instance = DemoML(hostname, test_catalog.catalog_id, use_minid=False)\n</pre> test_catalog = create_demo_catalog(hostname, domain_schema) ml_instance = DemoML(hostname, test_catalog.catalog_id, use_minid=False) In\u00a0[\u00a0]: Copied! <pre>print(f\"Current dataset_table element types: {[a.name for a in ml_instance.list_dataset_element_types()]}\")\nml_instance.add_dataset_element_type(\"Subject\")\nml_instance.add_dataset_element_type(\"Image\")\nprint(f\"New dataset_table element types {[a.name for a in ml_instance.list_dataset_element_types()]}\")\n</pre> print(f\"Current dataset_table element types: {[a.name for a in ml_instance.list_dataset_element_types()]}\") ml_instance.add_dataset_element_type(\"Subject\") ml_instance.add_dataset_element_type(\"Image\") print(f\"New dataset_table element types {[a.name for a in ml_instance.list_dataset_element_types()]}\") <p>Now that we have configured our datasets, we need to identify the dataset types so we can distinguish between them.</p> In\u00a0[\u00a0]: Copied! <pre># Create a new dataset_table\nml_instance.add_term(MLVocab.dataset_type, \"DemoSet\", description=\"A test dataset_table\")\nml_instance.add_term(MLVocab.dataset_type, 'Partitioned', description=\"A partitioned dataset_table for ML training.\")\nml_instance.add_term(MLVocab.dataset_type, \"Subject\", description=\"A test dataset_table\")\nml_instance.add_term(MLVocab.dataset_type, \"Image\", description=\"A test dataset_table\")\nml_instance.add_term(MLVocab.dataset_type, \"Training\", description=\"Training dataset_table\")\nml_instance.add_term(MLVocab.dataset_type, \"Testing\", description=\"Training dataset_table\")\nml_instance.add_term(MLVocab.dataset_type, \"Validation\", description=\"Validation dataset_table\")\n\nml_instance.list_vocabulary_terms(MLVocab.dataset_type)\n</pre> # Create a new dataset_table ml_instance.add_term(MLVocab.dataset_type, \"DemoSet\", description=\"A test dataset_table\") ml_instance.add_term(MLVocab.dataset_type, 'Partitioned', description=\"A partitioned dataset_table for ML training.\") ml_instance.add_term(MLVocab.dataset_type, \"Subject\", description=\"A test dataset_table\") ml_instance.add_term(MLVocab.dataset_type, \"Image\", description=\"A test dataset_table\") ml_instance.add_term(MLVocab.dataset_type, \"Training\", description=\"Training dataset_table\") ml_instance.add_term(MLVocab.dataset_type, \"Testing\", description=\"Training dataset_table\") ml_instance.add_term(MLVocab.dataset_type, \"Validation\", description=\"Validation dataset_table\")  ml_instance.list_vocabulary_terms(MLVocab.dataset_type) <p>Now create datasets and populate with elements from the test catalogs.</p> In\u00a0[\u00a0]: Copied! <pre>ml_instance.add_term(MLVocab.workflow_type, \"Create Dataset Notebook\", description=\"A Workflow that creates a new dataset_table\")\n\n# Now lets create model configuration for our program.\napi_workflow = Workflow(\n    name=\"API Workflow\",\n    url=\"https://github.com/informatics-isi-edu/deriva-ml/blob/main/docs/Notebooks/DerivaML%20Dataset.ipynb\",\n    workflow_type=\"Create Dataset Notebook\"\n)\n\ndataset_execution = ml_instance.create_execution(\n    ExecutionConfiguration(\n        workflow=api_workflow,\n        description=\"Our Sample Workflow instance\")\n)\n</pre> ml_instance.add_term(MLVocab.workflow_type, \"Create Dataset Notebook\", description=\"A Workflow that creates a new dataset_table\")  # Now lets create model configuration for our program. api_workflow = Workflow(     name=\"API Workflow\",     url=\"https://github.com/informatics-isi-edu/deriva-ml/blob/main/docs/Notebooks/DerivaML%20Dataset.ipynb\",     workflow_type=\"Create Dataset Notebook\" )  dataset_execution = ml_instance.create_execution(     ExecutionConfiguration(         workflow=api_workflow,         description=\"Our Sample Workflow instance\") ) In\u00a0[\u00a0]: Copied! <pre>subject_dataset = dataset_execution.create_dataset(['DemoSet', 'Subject'], description=\"A subject dataset_table\")\nimage_dataset = dataset_execution.create_dataset(['DemoSet', 'Image'], description=\"A image training dataset_table\")\ndatasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns)\ndisplay(\n    Markdown('## Datasets'),\n    datasets)\n</pre> subject_dataset = dataset_execution.create_dataset(['DemoSet', 'Subject'], description=\"A subject dataset_table\") image_dataset = dataset_execution.create_dataset(['DemoSet', 'Image'], description=\"A image training dataset_table\") datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns) display(     Markdown('## Datasets'),     datasets) <p>And now that we have defined some datasets, we can add elements of the appropriate type to them.  We can see what is in our new datasets by listing the dataset members.</p> In\u00a0[\u00a0]: Copied! <pre># Get list of subjects and images from the catalog using the DataPath API.\ndp = ml_instance.domain_path  # Each call returns a new path instance, so only call once...\nsubject_rids = [i['RID'] for i in dp.tables['Subject'].entities().fetch()]\nimage_rids = [i['RID'] for i in dp.tables['Image'].entities().fetch()]\n\nml_instance.add_dataset_members(dataset_rid=subject_dataset, members=subject_rids)\nml_instance.add_dataset_members(dataset_rid=image_dataset, members=image_rids)\n\n# List the contents of our datasets, and let's not include columns like modify time.\ndisplay(\n    Markdown('## Subject Dataset'),\n    pd.DataFrame(ml_instance.list_dataset_members(subject_dataset)['Subject']).drop(columns=DerivaSystemColumns),\n    Markdown('## Image Dataset'),\n    pd.DataFrame(ml_instance.list_dataset_members(image_dataset)['Image']).drop(columns=DerivaSystemColumns))\n</pre> # Get list of subjects and images from the catalog using the DataPath API. dp = ml_instance.domain_path  # Each call returns a new path instance, so only call once... subject_rids = [i['RID'] for i in dp.tables['Subject'].entities().fetch()] image_rids = [i['RID'] for i in dp.tables['Image'].entities().fetch()]  ml_instance.add_dataset_members(dataset_rid=subject_dataset, members=subject_rids) ml_instance.add_dataset_members(dataset_rid=image_dataset, members=image_rids)  # List the contents of our datasets, and let's not include columns like modify time. display(     Markdown('## Subject Dataset'),     pd.DataFrame(ml_instance.list_dataset_members(subject_dataset)['Subject']).drop(columns=DerivaSystemColumns),     Markdown('## Image Dataset'),     pd.DataFrame(ml_instance.list_dataset_members(image_dataset)['Image']).drop(columns=DerivaSystemColumns)) In\u00a0[\u00a0]: Copied! <pre>dataset_bag = ml_instance.download_dataset_bag(DatasetSpec(rid=subject_dataset, version=ml_instance.dataset_version(subject_dataset), materialize=False))\nprint(f\"Bag materialized\")\n</pre> dataset_bag = ml_instance.download_dataset_bag(DatasetSpec(rid=subject_dataset, version=ml_instance.dataset_version(subject_dataset), materialize=False)) print(f\"Bag materialized\") <p>The domain model has two objects: Subject and Images where an Image is associated with a subject, but a subject can have multiple images associated with it.  Let's look at the subjects and partition into test and training datasets.</p> In\u00a0[\u00a0]: Copied! <pre># Get information about the subjects.....\nsubject_df = dataset_bag.get_table_as_dataframe('Subject')[['RID', 'Name']]\nimage_df = dataset_bag.get_table_as_dataframe('Image')[['RID', 'Subject', 'URL']]\nmetadata_df = subject_df.join(image_df, lsuffix=\"_subject\", rsuffix=\"_image\")\ndisplay(metadata_df)\n</pre> # Get information about the subjects..... subject_df = dataset_bag.get_table_as_dataframe('Subject')[['RID', 'Name']] image_df = dataset_bag.get_table_as_dataframe('Image')[['RID', 'Subject', 'URL']] metadata_df = subject_df.join(image_df, lsuffix=\"_subject\", rsuffix=\"_image\") display(metadata_df) <p>For ths example, lets partition the data based on the name of the subject.  Of course in real examples, we would do a more complex analysis in deciding what subset goes into each data set.</p> In\u00a0[\u00a0]: Copied! <pre>def thing_number(name: pd.Series) -&gt; pd.Series:\n    return name.map(lambda n: int(n.replace('Thing','')))\n\ntraining_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 0]['RID_image'].tolist()\ntesting_rids =  metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 1]['RID_image'].tolist()\nvalidation_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 2]['RID_image'].tolist()\n\nprint(f'Training images: {training_rids}')\nprint(f'Testing images: {testing_rids}')\nprint(f'Validation images: {validation_rids}')\n</pre> def thing_number(name: pd.Series) -&gt; pd.Series:     return name.map(lambda n: int(n.replace('Thing','')))  training_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 0]['RID_image'].tolist() testing_rids =  metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 1]['RID_image'].tolist() validation_rids = metadata_df.loc[lambda df: thing_number(df['Name']) % 3 == 2]['RID_image'].tolist()  print(f'Training images: {training_rids}') print(f'Testing images: {testing_rids}') print(f'Validation images: {validation_rids}') <p>Now that we know what we want in each dataset, lets create datasets for each of our partitioned elements along with a nested dataset to track the entire collection.</p> In\u00a0[\u00a0]: Copied! <pre>nested_dataset = dataset_execution.create_dataset(['Partitioned', 'Image'], description='A nested dataset_table for machine learning')\ntraining_dataset = dataset_execution.create_dataset('Training', description='An image dataset_table for training')\ntesting_dataset = dataset_execution.create_dataset('Testing', description='A image dataset_table for testing')\nvalidation_dataset = dataset_execution.create_dataset('Validation', description='A image dataset_table for validation')\npd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns)\n</pre> nested_dataset = dataset_execution.create_dataset(['Partitioned', 'Image'], description='A nested dataset_table for machine learning') training_dataset = dataset_execution.create_dataset('Training', description='An image dataset_table for training') testing_dataset = dataset_execution.create_dataset('Testing', description='A image dataset_table for testing') validation_dataset = dataset_execution.create_dataset('Validation', description='A image dataset_table for validation') pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns) <p>And then fill the datasets with the appropriate members.</p> In\u00a0[\u00a0]: Copied! <pre>ml_instance.add_dataset_members(dataset_rid=nested_dataset, members=[training_dataset, testing_dataset, validation_dataset])\nml_instance.add_dataset_members(dataset_rid=training_dataset, members=training_rids)\nml_instance.add_dataset_members(dataset_rid=testing_dataset, members=testing_rids)\nml_instance.add_dataset_members(dataset_rid=validation_dataset, members=validation_rids)\n</pre> ml_instance.add_dataset_members(dataset_rid=nested_dataset, members=[training_dataset, testing_dataset, validation_dataset]) ml_instance.add_dataset_members(dataset_rid=training_dataset, members=training_rids) ml_instance.add_dataset_members(dataset_rid=testing_dataset, members=testing_rids) ml_instance.add_dataset_members(dataset_rid=validation_dataset, members=validation_rids) <p>Ok, lets see what we have now.</p> <p>As our very last step, lets get a PID that will allow us to share and cite the dataset that we just created</p> In\u00a0[\u00a0]: Copied! <pre>display(\n    Markdown('## Nested Dataset'),\n    pd.DataFrame(ml_instance.list_dataset_members(nested_dataset)['Dataset']).drop(columns=DerivaSystemColumns),\n    Markdown('## Training Dataset'),\n    pd.DataFrame(ml_instance.list_dataset_members(training_dataset)['Image']).drop(columns=DerivaSystemColumns),\n    Markdown('## Testing Dataset'),\n    pd.DataFrame(ml_instance.list_dataset_members(testing_dataset)['Image']).drop(columns=DerivaSystemColumns),\n    Markdown('## Validation Dataset'),\n    pd.DataFrame(ml_instance.list_dataset_members(validation_dataset)['Image']).drop(columns=DerivaSystemColumns),)\n</pre> display(     Markdown('## Nested Dataset'),     pd.DataFrame(ml_instance.list_dataset_members(nested_dataset)['Dataset']).drop(columns=DerivaSystemColumns),     Markdown('## Training Dataset'),     pd.DataFrame(ml_instance.list_dataset_members(training_dataset)['Image']).drop(columns=DerivaSystemColumns),     Markdown('## Testing Dataset'),     pd.DataFrame(ml_instance.list_dataset_members(testing_dataset)['Image']).drop(columns=DerivaSystemColumns),     Markdown('## Validation Dataset'),     pd.DataFrame(ml_instance.list_dataset_members(validation_dataset)['Image']).drop(columns=DerivaSystemColumns),) In\u00a0[\u00a0]: Copied! <pre>print(f'Dataset parents: {ml_instance.list_dataset_parents(training_dataset)}')\nprint(f'Dataset children: {ml_instance.list_dataset_children(nested_dataset)}')\n</pre> print(f'Dataset parents: {ml_instance.list_dataset_parents(training_dataset)}') print(f'Dataset children: {ml_instance.list_dataset_children(nested_dataset)}')  In\u00a0[\u00a0]: Copied! <pre>dataset_citation = ml_instance.cite(nested_dataset)\ndisplay(\n    HTML(f'Nested dataset_table citation: &lt;a href={dataset_citation}&gt;{dataset_citation}&lt;/a&gt;')\n)\n</pre> dataset_citation = ml_instance.cite(nested_dataset) display(     HTML(f'Nested dataset_table citation: {dataset_citation}') ) In\u00a0[\u00a0]: Copied! <pre>display(\n     Markdown('## Nested Dataset -- Recursive Listing'),\n    JSON(ml_instance.list_dataset_members(nested_dataset, recurse=True))\n)\n</pre> display(      Markdown('## Nested Dataset -- Recursive Listing'),     JSON(ml_instance.list_dataset_members(nested_dataset, recurse=True)) ) In\u00a0[\u00a0]: Copied! <pre>print(f'Current dataset_table version for training_dataset: {ml_instance.dataset_version(training_dataset)}')\nnext_version = ml_instance.increment_dataset_version(training_dataset, VersionPart.minor)\nprint(f'Next dataset_table version for training_dataset: {next_version}')\n</pre> print(f'Current dataset_table version for training_dataset: {ml_instance.dataset_version(training_dataset)}') next_version = ml_instance.increment_dataset_version(training_dataset, VersionPart.minor) print(f'Next dataset_table version for training_dataset: {next_version}') In\u00a0[\u00a0]: Copied! <pre>display(HTML(f'&lt;a href={ml_instance.chaise_url(\"Dataset\")}&gt;Browse Datasets&lt;/a&gt;'))\n</pre> display(HTML(f'Browse Datasets')) In\u00a0[\u00a0]: Copied! <pre>test_catalog.delete_ermrest_catalog(really=True)\n</pre> test_catalog.delete_ermrest_catalog(really=True)"},{"location":"Notebooks/DerivaML%20Dataset/#derivaml-dataset","title":"DerivaML Dataset\u00b6","text":"<p>DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library.</p>"},{"location":"Notebooks/DerivaML%20Dataset/#set-up-derivaml-for-test-case","title":"Set up DerivaML  for test case\u00b6","text":""},{"location":"Notebooks/DerivaML%20Dataset/#configure-derivaml-datasets","title":"Configure DerivaML Datasets\u00b6","text":"<p>In Deriva-ML a dataset is used to aggregate instances of entities.  However, before we can create any datasets, we must configure Deriva-ML for the specifics of the datasets.  The first stp is we need to tell Deriva-ML what types of use defined objects can be associated with a dataset.</p> <p>Note that out of the box, Deriva-ML is configured to allow datasets to contained dataset (i.e. nested datasets), so we don't need to do anything for that specific configuration.</p>"},{"location":"Notebooks/DerivaML%20Dataset/#create-partitioned-dataset","title":"Create partitioned dataset\u00b6","text":"<p>Now let's create some subsets of the original dataset based on subject level metadata. We are going to create the subsets based on the metadata values of the subjects. We will download the subject dataset and look at its metadata to figure out how to partition the original data. Since we are not going to look at the images, we use the materialize=False option to save some time.</p>"},{"location":"Notebooks/DerivaML%20Dataset/#dataset-versions","title":"Dataset Versions\u00b6","text":"<p>Datasets have a version number which can be retrieved or incremented.  We follow the equivalent of semantic versioning, but for data rather than code.  Note that datasets are also versioned by virtue of the fact that the dataset RID can include a catalog snapshot ID as well.</p>"},{"location":"Notebooks/DerivaML%20Execution/","title":"DerivaML Execution","text":"In\u00a0[\u00a0]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[\u00a0]: Copied! <pre>import builtins\nfrom deriva.core.utils.globus_auth_utils import GlobusNativeLogin\nfrom deriva_ml import ExecutionConfiguration, MLVocab, DerivaSystemColumns, DatasetSpec\nfrom deriva_ml.demo_catalog import create_demo_catalog, DemoML\nfrom IPython.display import display, Markdown, JSON\nimport itertools\nimport pandas as pd\n</pre> import builtins from deriva.core.utils.globus_auth_utils import GlobusNativeLogin from deriva_ml import ExecutionConfiguration, MLVocab, DerivaSystemColumns, DatasetSpec from deriva_ml.demo_catalog import create_demo_catalog, DemoML from IPython.display import display, Markdown, JSON import itertools import pandas as pd <p>Set the details for the catalog we want and authenticate to the server if needed.</p> In\u00a0[\u00a0]: Copied! <pre>hostname = 'dev.eye-ai.org'\ndomain_schema = 'demo-schema'\n\ngnl = GlobusNativeLogin(host=hostname)\nif gnl.is_logged_in([hostname]):\n    print(\"You are already logged in.\")\nelse:\n    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n    print(\"Login Successful\")\n</pre> hostname = 'dev.eye-ai.org' domain_schema = 'demo-schema'  gnl = GlobusNativeLogin(host=hostname) if gnl.is_logged_in([hostname]):     print(\"You are already logged in.\") else:     gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)     print(\"Login Successful\")  <p>Create a test catalog and get an instance of the DerivaML class.  Use options so that we create some initial datasets and features.  Use the exploration API to find out what features and datasets we have.</p> In\u00a0[\u00a0]: Copied! <pre>test_catalog = create_demo_catalog(hostname, domain_schema, create_features=True, create_datasets=True)\nml_instance = DemoML(hostname, test_catalog.catalog_id)\nprint(f'Creating catalog at {ml_instance.catalog_id}')\n</pre> test_catalog = create_demo_catalog(hostname, domain_schema, create_features=True, create_datasets=True) ml_instance = DemoML(hostname, test_catalog.catalog_id) print(f'Creating catalog at {ml_instance.catalog_id}') In\u00a0[\u00a0]: Copied! <pre>display(\n    Markdown('## Datasets'),\n    pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns),\n\n    Markdown('## Features'),\n    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Subject\")],\n    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Image\")]\n)\n</pre> display(     Markdown('## Datasets'),     pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns),      Markdown('## Features'),     [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Subject\")],     [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Image\")] ) In\u00a0[\u00a0]: Copied! <pre>datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns)\ntraining_dataset_rid = [ds['RID'] for ds in ml_instance.find_datasets() if 'Training' in ds['Dataset_Type']][0]\ntesting_dataset_rid = [ds['RID'] for ds in ml_instance.find_datasets() if 'Testing' in ds['Dataset_Type']][0]\n\ndisplay(\n    Markdown(f'Training Dataset: {training_dataset_rid}'),\n    Markdown('## Datasets'),\n    datasets)\n</pre> datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns) training_dataset_rid = [ds['RID'] for ds in ml_instance.find_datasets() if 'Training' in ds['Dataset_Type']][0] testing_dataset_rid = [ds['RID'] for ds in ml_instance.find_datasets() if 'Testing' in ds['Dataset_Type']][0]  display(     Markdown(f'Training Dataset: {training_dataset_rid}'),     Markdown('## Datasets'),     datasets) In\u00a0[\u00a0]: Copied! <pre>ml_instance.add_term(MLVocab.workflow_type, \"Execution Notebook\", description=\"Notebook for demonstrating executions\")\nml_instance.add_term(MLVocab.asset_type, \"API_Model\", description=\"Model for our API workflow\")\n\napi_workflow = ml_instance.create_workflow(\n    name=\"Execution Notebook Workflow\",\n    workflow_type=\"Execution Notebook\",\n    description=\"Demonstration notebook\"\n)\n\nnotebook_execution = ml_instance.create_execution(ExecutionConfiguration( description=\"Sample Execution\", workflow=api_workflow))\n\n# Now lets create model configuration for our program.\nmodel_file = notebook_execution.asset_file_path(\"Execution_Asset\",'modelfile.txt', asset_types=\"API_Model\")\nwith builtins.open(model_file, \"w\") as fp:\n    fp.write(f\"My model\")\n\n# Now upload the file and retrieve the RID of the new asset from the returned results.\nuploaded_assets = notebook_execution.upload_execution_outputs()\ntraining_model_rid = [a.asset_rid  for a  in uploaded_assets['deriva-ml/Execution_Asset'] if 'API_Model' in a.asset_types][0]\n\ndisplay(\n    Markdown(f'## Training Model: {training_model_rid}'),\n    JSON(ml_instance.retrieve_rid(training_model_rid))\n)\n</pre> ml_instance.add_term(MLVocab.workflow_type, \"Execution Notebook\", description=\"Notebook for demonstrating executions\") ml_instance.add_term(MLVocab.asset_type, \"API_Model\", description=\"Model for our API workflow\")  api_workflow = ml_instance.create_workflow(     name=\"Execution Notebook Workflow\",     workflow_type=\"Execution Notebook\",     description=\"Demonstration notebook\" )  notebook_execution = ml_instance.create_execution(ExecutionConfiguration( description=\"Sample Execution\", workflow=api_workflow))  # Now lets create model configuration for our program. model_file = notebook_execution.asset_file_path(\"Execution_Asset\",'modelfile.txt', asset_types=\"API_Model\") with builtins.open(model_file, \"w\") as fp:     fp.write(f\"My model\")  # Now upload the file and retrieve the RID of the new asset from the returned results. uploaded_assets = notebook_execution.upload_execution_outputs() training_model_rid = [a.asset_rid  for a  in uploaded_assets['deriva-ml/Execution_Asset'] if 'API_Model' in a.asset_types][0]  display(     Markdown(f'## Training Model: {training_model_rid}'),     JSON(ml_instance.retrieve_rid(training_model_rid)) ) In\u00a0[\u00a0]: Copied! <pre>ml_instance.add_term(MLVocab.workflow_type, \"ML Demo\", description=\"A ML Workflow that uses Deriva ML API\")\n\nconfig = ExecutionConfiguration(\n        assets = [training_model_rid],\n    description=\"Notebook ML Execution\",\n    workflow=api_workflow,\n    datasets=[DatasetSpec(rid=training_dataset_rid, version=ml_instance.dataset_version(training_dataset_rid)),\n            DatasetSpec(rid=testing_dataset_rid, version=ml_instance.dataset_version(training_dataset_rid), materialize=False)],\n)\n\nml_execution = ml_instance.create_execution(config)\n</pre> ml_instance.add_term(MLVocab.workflow_type, \"ML Demo\", description=\"A ML Workflow that uses Deriva ML API\")  config = ExecutionConfiguration(         assets = [training_model_rid],     description=\"Notebook ML Execution\",     workflow=api_workflow,     datasets=[DatasetSpec(rid=training_dataset_rid, version=ml_instance.dataset_version(training_dataset_rid)),             DatasetSpec(rid=testing_dataset_rid, version=ml_instance.dataset_version(training_dataset_rid), materialize=False)], )  ml_execution = ml_instance.create_execution(config) In\u00a0[\u00a0]: Copied! <pre>ml_execution.asset_paths\n</pre> ml_execution.asset_paths In\u00a0[\u00a0]: Copied! <pre>with ml_execution.execute() as deriva_exec:\n    # Get the input datasets:\n    training_dataset = ml_execution.datasets[0]  # Input dataset\n    image_rids = training_dataset.get_table_as_dataframe('Image')['RID']\n\n    # Get input files\n    with open(ml_execution.asset_paths[0], 'rt') as model_file:\n        training_model = model_file.read()\n        print(f'Got model file: {training_model}')\n\n    # Put your ML code here....\n    pass\n\n    # Write a new model\n    model_file = ml_execution.asset_path('API_Model', 'modelfile.txt')\n    with open(model_file, 'w') as f:\n        f.write(\"Hello there a new model;\\n\")\n\n    # Create some new feature values.\n    bb_csv_path, bb_asset_paths = ml_execution.execution_asset_path('BoundingBox')\n    bounding_box_files = [bb_asset_paths['BoundingBox'] / f\"box{i}.txt\" for i in range(10)]\n    for i in range(10):\n        bounding_box_files.append(fn := bb_asset_paths['BoundingBox'] / f\"box{i}.txt\")\n        with builtins.open(fn, \"w\") as fp:\n            fp.write(f\"Hi there {i}\")\n\n    ImageBoundingboxFeature = ml_instance.feature_record_class(\"Image\", \"BoundingBox\")\n    image_bounding_box_feature_list = [ImageBoundingboxFeature(Image=image_rid,\n                                                               Execution=ml_execution.execution_rid,\n                                                               BoundingBox=asset_rid)\n                                       for image_rid, asset_rid in zip(image_rids, itertools.cycle(bounding_box_files))]\n\n    ml_execution.add_features(image_bounding_box_feature_list)\n\nupload_status = ml_execution.upload_execution_outputs()\n</pre> with ml_execution.execute() as deriva_exec:     # Get the input datasets:     training_dataset = ml_execution.datasets[0]  # Input dataset     image_rids = training_dataset.get_table_as_dataframe('Image')['RID']      # Get input files     with open(ml_execution.asset_paths[0], 'rt') as model_file:         training_model = model_file.read()         print(f'Got model file: {training_model}')      # Put your ML code here....     pass      # Write a new model     model_file = ml_execution.asset_path('API_Model', 'modelfile.txt')     with open(model_file, 'w') as f:         f.write(\"Hello there a new model;\\n\")      # Create some new feature values.     bb_csv_path, bb_asset_paths = ml_execution.execution_asset_path('BoundingBox')     bounding_box_files = [bb_asset_paths['BoundingBox'] / f\"box{i}.txt\" for i in range(10)]     for i in range(10):         bounding_box_files.append(fn := bb_asset_paths['BoundingBox'] / f\"box{i}.txt\")         with builtins.open(fn, \"w\") as fp:             fp.write(f\"Hi there {i}\")      ImageBoundingboxFeature = ml_instance.feature_record_class(\"Image\", \"BoundingBox\")     image_bounding_box_feature_list = [ImageBoundingboxFeature(Image=image_rid,                                                                Execution=ml_execution.execution_rid,                                                                BoundingBox=asset_rid)                                        for image_rid, asset_rid in zip(image_rids, itertools.cycle(bounding_box_files))]      ml_execution.add_features(image_bounding_box_feature_list)  upload_status = ml_execution.upload_execution_outputs() <p>Now lets check the assets produced by this execution to make sure that they are what we expect.</p> In\u00a0[\u00a0]: Copied! <pre># Get datapath to the ML schema.\nschema_path = ml_instance.pathBuilder.schemas[ml_instance.ml_schema]\n\n# Now get path to the execution table, and get our execution record.  We filter on the RID for the\n# execution we are looking for.\nexecutions = schema_path.Execution.filter(schema_path.Execution.RID == ml_execution.execution_rid)\nexecution_info = list(executions.entities().fetch())[0]\n\n# To get the assets for the execution, we need to go through the linking table to the assets.\nasset_path = executions.link(schema_path.Execution_Asset_Execution).link(schema_path.Execution_Asset)\npd.DataFrame(asset_path.entities().fetch()).drop(columns=DerivaSystemColumns + ['MD5'])\n\n# Now lets display our results.\ndisplay(\n    Markdown(f'### Execution: {ml_execution.execution_rid}'),\n    JSON(execution_info),\n    Markdown(f'### Execution Assets'),\n    pd.DataFrame(asset_path.entities().fetch()).drop(columns=DerivaSystemColumns + ['MD5']),\n)\n</pre> # Get datapath to the ML schema. schema_path = ml_instance.pathBuilder.schemas[ml_instance.ml_schema]  # Now get path to the execution table, and get our execution record.  We filter on the RID for the # execution we are looking for. executions = schema_path.Execution.filter(schema_path.Execution.RID == ml_execution.execution_rid) execution_info = list(executions.entities().fetch())[0]  # To get the assets for the execution, we need to go through the linking table to the assets. asset_path = executions.link(schema_path.Execution_Asset_Execution).link(schema_path.Execution_Asset) pd.DataFrame(asset_path.entities().fetch()).drop(columns=DerivaSystemColumns + ['MD5'])  # Now lets display our results. display(     Markdown(f'### Execution: {ml_execution.execution_rid}'),     JSON(execution_info),     Markdown(f'### Execution Assets'),     pd.DataFrame(asset_path.entities().fetch()).drop(columns=DerivaSystemColumns + ['MD5']), ) In\u00a0[\u00a0]: Copied! <pre>test_catalog.delete_ermrest_catalog(really=True)\n</pre> test_catalog.delete_ermrest_catalog(really=True)"},{"location":"Notebooks/DerivaML%20Execution/#derivaml-execution","title":"DerivaML Execution\u00b6","text":"<p>DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library.</p>"},{"location":"Notebooks/DerivaML%20Execution/#initializing-the-environment-for-an-execution","title":"Initializing the environment for an execution\u00b6","text":"<p>In DerivaML, the catalog is the source of record for all of the data created and used by a machine learning experiment.  While we can use the Deriva API to interact directly with the catalog, DerivaML provides a much simpler way of retrieving and adding data to a catalog.</p> <p>The core concept in this process is an execution.  An execution can be the process of training a model, of executing a model, for running analysis scripts, or even a manual operation.  Every execution in DerivaML is uniquely identified by a resource identifier (RID).</p> <p>The steps involved in creating and using an execution are:</p> <ol> <li>Create an Execution configuration object that identifies the inputs, and code for the execution.</li> <li>Create a workflow object to represent the code/operation that you will perform</li> <li>Create an execution instance, which will download all of the required inputs from the catalog Locate the input files using methods in the execution instance</li> <li>Perform your computation, placing output files in locations provided by the execution instance methods</li> <li>Upload the results of the computation using the execution instance methods. This will upload all of your files and tag them with the execution RID so you know how they were generated.  In addition, and new tabular data in CSV format will be uploaded to corrisponding tables in the catalog.</li> </ol>"},{"location":"Notebooks/DerivaML%20Execution/#creating-an-exectutionconfiguration","title":"Creating an <code>ExectutionConfiguration</code>\u00b6","text":"<p>An execution can be described by the datasets and files that it needs, the code that it runs, and the resulting files that it creates. This information is captured in an ExecutionConfiguration object:</p> <pre><code>class ExecutionConfiguration:\n \"\"\"\n    Define the parameters that are used to configure a specific execution.\n\n    Arguments:\n        datasets: List of dataset RIDS, MINIDS for datasets to be downloaded prior to execution.  By default,\n                 all  the datasets are materialized. However, if the assets associated with a dataset are not\n                 needed, a dictionary that defines the rid and the materialization parameter for the\n                 download_dataset_bag method can be specified, e.g.  datasets=[{'rid': RID, 'materialize': True}].\n        assets: List of assets to be downloaded prior to execution.  The values must be RIDs in an asset table\n        workflow: A workflow instance.  Must have a name, URI to the workflow instance, and a type.\n        description: A description of the execution.  Can use markdown format.</code></pre>"},{"location":"Notebooks/DerivaML%20Execution/#creating-a-workflow","title":"Creating a <code>Workflow</code>\u00b6","text":"<p>The actual code that is being run is represented by a <code>Workflow</code> class.  A workflow class is intended to be quite general and could be a Python script, a Jupyter notebook, a manual process, or even a Airflow or some other type of workflow system.  In order to create a workflow class instance, we will need to have a name for the workflow, a URI to name the resource that the workflow is capturing, and a workflow type.</p> <p>The url for the workflow will depend on what the workflow is actually doing. In general, its a good idea to make the URL a reference to a tagged code or repository in GitHub. This will require some disiplane on your process to ensure that you always have workflows that are commited and tagged in a repo.</p> <p>The workflow type is a controlled vocabulary.  You can create new workflow types using the standard APIs for adding terms.</p>"},{"location":"Notebooks/DerivaML%20Execution/#setup-for-a-ml-run","title":"Setup for a ML run\u00b6","text":""},{"location":"Notebooks/DerivaML%20Features/","title":"DerivaML Features","text":"In\u00a0[\u00a0]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[\u00a0]: Copied! <pre>import builtins\nfrom deriva.core.utils.globus_auth_utils import GlobusNativeLogin\nfrom deriva_ml import ColumnDefinition, BuiltinTypes, MLVocab, DerivaSystemColumns\nfrom deriva_ml.demo_catalog import create_demo_catalog, DemoML\nfrom deriva_ml import ExecutionConfiguration\nfrom IPython.display import display, Markdown, HTML\nimport itertools\nimport pandas as pd\nimport random\n</pre> import builtins from deriva.core.utils.globus_auth_utils import GlobusNativeLogin from deriva_ml import ColumnDefinition, BuiltinTypes, MLVocab, DerivaSystemColumns from deriva_ml.demo_catalog import create_demo_catalog, DemoML from deriva_ml import ExecutionConfiguration from IPython.display import display, Markdown, HTML import itertools import pandas as pd import random <p>Set the details for the catalog we want and authenticate to the server if needed.</p> In\u00a0[\u00a0]: Copied! <pre>hostname = 'localhost'\ndomain_schema = 'demo-schema'\n\ngnl = GlobusNativeLogin(host=hostname)\nif gnl.is_logged_in([hostname]):\n    print(\"You are already logged in.\")\nelse:\n    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n    print(\"Login Successful\")\n</pre> hostname = 'localhost' domain_schema = 'demo-schema'  gnl = GlobusNativeLogin(host=hostname) if gnl.is_logged_in([hostname]):     print(\"You are already logged in.\") else:     gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)     print(\"Login Successful\") <p>Create a test catalog and get an instance of the DerivaML class.</p> In\u00a0[\u00a0]: Copied! <pre>test_catalog = create_demo_catalog(hostname, domain_schema)\nml_instance = DemoML(hostname, test_catalog.catalog_id)\ndisplay(f\"Created demo catalog at {hostname}:{test_catalog.catalog_id}\")\n</pre> test_catalog = create_demo_catalog(hostname, domain_schema) ml_instance = DemoML(hostname, test_catalog.catalog_id) display(f\"Created demo catalog at {hostname}:{test_catalog.catalog_id}\") In\u00a0[\u00a0]: Copied! <pre># Prerequisites for our feature, which will include a CV term and asset.\n\n# Create a vocabulary and add a term to it to use in our features.\nml_instance.create_vocabulary(\"SubjectHealth\", \"A vocab\")\nml_instance.add_term(\"SubjectHealth\", \"Sick\", description=\"The subject self reports that they are sick\")\nml_instance.add_term(\"SubjectHealth\", \"Well\", description=\"The subject self reports that they feel well\")\n\nml_instance.create_vocabulary(\"ImageQuality\", \"Controlled vocabulary for image quality\")\nml_instance.add_term(\"ImageQuality\", \"Good\", description=\"The image is good\")\nml_instance.add_term(\"ImageQuality\", \"Bad\", description=\"The image is bad\")\n\nbox_asset = ml_instance.create_asset(\"BoundingBox\", comment=\"A file that contains a cropped version of a image\")\n</pre> # Prerequisites for our feature, which will include a CV term and asset.  # Create a vocabulary and add a term to it to use in our features. ml_instance.create_vocabulary(\"SubjectHealth\", \"A vocab\") ml_instance.add_term(\"SubjectHealth\", \"Sick\", description=\"The subject self reports that they are sick\") ml_instance.add_term(\"SubjectHealth\", \"Well\", description=\"The subject self reports that they feel well\")  ml_instance.create_vocabulary(\"ImageQuality\", \"Controlled vocabulary for image quality\") ml_instance.add_term(\"ImageQuality\", \"Good\", description=\"The image is good\") ml_instance.add_term(\"ImageQuality\", \"Bad\", description=\"The image is bad\")  box_asset = ml_instance.create_asset(\"BoundingBox\", comment=\"A file that contains a cropped version of a image\") <p>We are now ready to create our new features. Each feature will be associated with a table, have a name, and then the set of values that define the feature. After we create the features, we can list the features associated with each table type that we have.</p> In\u00a0[\u00a0]: Copied! <pre>ml_instance.create_feature(\"Subject\", \"Health\",\n                                        terms=[\"SubjectHealth\"],\n                                        metadata=[ColumnDefinition(name='Scale', type=BuiltinTypes.int2, nullok=True)],\n                           optional=['Scale'])\n\nml_instance.create_feature('Image', 'BoundingBox', assets=[box_asset])\nml_instance.create_feature('Image', 'Quality', terms=[\"ImageQuality\"])\n\ndisplay(\n    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Subject\")],\n    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Image\")]\n)\n</pre> ml_instance.create_feature(\"Subject\", \"Health\",                                         terms=[\"SubjectHealth\"],                                         metadata=[ColumnDefinition(name='Scale', type=BuiltinTypes.int2, nullok=True)],                            optional=['Scale'])  ml_instance.create_feature('Image', 'BoundingBox', assets=[box_asset]) ml_instance.create_feature('Image', 'Quality', terms=[\"ImageQuality\"])  display(     [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Subject\")],     [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Image\")] ) <p>Now we can add some features to our images.  To streamline the creation of new feature, we create a class that is specific to the arguments required to create it.</p> In\u00a0[\u00a0]: Copied! <pre>ImageQualityFeature = ml_instance.feature_record_class(\"Image\", \"Quality\")\nImageBoundingboxFeature = ml_instance.feature_record_class(\"Image\", \"BoundingBox\")\nSubjectWellnessFeature= ml_instance.feature_record_class(\"Subject\", \"Health\")\n\ndisplay(\n    Markdown('### SubjectWellnessFeature'),\n    Markdown(f'* feature_columns: ' f'```{[c.name for c in SubjectWellnessFeature.feature_columns()]}```'),\n    Markdown(f'* required columns: ' f'```{[c.name  for c in SubjectWellnessFeature.feature_columns() if not c.nullok]}```'),\n    Markdown(f'* term columns: ' f'```{[c.name for c in SubjectWellnessFeature.term_columns()]}```'),\n    Markdown(f'* value columns: ' f'```{[c.name for c in SubjectWellnessFeature.value_columns()]}```'),\n    Markdown(f'* asset columns: ' f'```{[c.name for c in SubjectWellnessFeature.asset_columns()]}```'),\n\n    Markdown('### ImageQualityFeature'),\n    Markdown( f'* feature_columns:* ' f'```{[c.name for c in ImageQualityFeature.feature_columns()]}```'),\n    Markdown(f'*  required columns:* ' f'```{[c.name  for c in ImageQualityFeature.feature_columns() if not c.nullok]}```'),\n    Markdown(f'* term columns: * ' f'```{[c.name for c in ImageQualityFeature.term_columns()]}```'),\n    Markdown(f'* value columns: * ' f'```{[c.name for c in ImageQualityFeature.value_columns()]}```'),\n    Markdown(f'* asset columns: * ' f'```{[c.name for c in ImageQualityFeature.asset_columns()]}```'),\n\n    Markdown('### ImageBoundingboxFeature'),\n    Markdown( f'* feature_columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.feature_columns()]}```'),\n    Markdown(f'* required columns:* ' f'```{[c.name  for c in ImageBoundingboxFeature.feature_columns() if not c.nullok]}```'),\n    Markdown( f'* term columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.term_columns()]}```'),\n    Markdown( f'* value columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.value_columns()]}```'),\n    Markdown( f'* asset columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.asset_columns()]}```'),\n)\n</pre> ImageQualityFeature = ml_instance.feature_record_class(\"Image\", \"Quality\") ImageBoundingboxFeature = ml_instance.feature_record_class(\"Image\", \"BoundingBox\") SubjectWellnessFeature= ml_instance.feature_record_class(\"Subject\", \"Health\")  display(     Markdown('### SubjectWellnessFeature'),     Markdown(f'* feature_columns: ' f'```{[c.name for c in SubjectWellnessFeature.feature_columns()]}```'),     Markdown(f'* required columns: ' f'```{[c.name  for c in SubjectWellnessFeature.feature_columns() if not c.nullok]}```'),     Markdown(f'* term columns: ' f'```{[c.name for c in SubjectWellnessFeature.term_columns()]}```'),     Markdown(f'* value columns: ' f'```{[c.name for c in SubjectWellnessFeature.value_columns()]}```'),     Markdown(f'* asset columns: ' f'```{[c.name for c in SubjectWellnessFeature.asset_columns()]}```'),      Markdown('### ImageQualityFeature'),     Markdown( f'* feature_columns:* ' f'```{[c.name for c in ImageQualityFeature.feature_columns()]}```'),     Markdown(f'*  required columns:* ' f'```{[c.name  for c in ImageQualityFeature.feature_columns() if not c.nullok]}```'),     Markdown(f'* term columns: * ' f'```{[c.name for c in ImageQualityFeature.term_columns()]}```'),     Markdown(f'* value columns: * ' f'```{[c.name for c in ImageQualityFeature.value_columns()]}```'),     Markdown(f'* asset columns: * ' f'```{[c.name for c in ImageQualityFeature.asset_columns()]}```'),      Markdown('### ImageBoundingboxFeature'),     Markdown( f'* feature_columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.feature_columns()]}```'),     Markdown(f'* required columns:* ' f'```{[c.name  for c in ImageBoundingboxFeature.feature_columns() if not c.nullok]}```'),     Markdown( f'* term columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.term_columns()]}```'),     Markdown( f'* value columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.value_columns()]}```'),     Markdown( f'* asset columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.asset_columns()]}```'), ) In\u00a0[\u00a0]: Copied! <pre>ml_instance.add_term(MLVocab.workflow_type, \"Feature Notebook Workflow\", description=\"A Workflow that uses Deriva ML API\")\nml_instance.add_term(MLVocab.asset_type, \"API_Model\", description=\"Model for our Notebook workflow\")\n\n# Get the workflow for this notebook\nnotebook_workflow = ml_instance.create_workflow(\n    name=\"API Workflow\", \n    workflow_type=\"Feature Notebook Workflow\"\n)\n\nfeature_execution = ml_instance.create_execution(\n    ExecutionConfiguration(\n        workflow=notebook_workflow,\n        description=\"Our Sample Workflow instance\")\n)\n</pre> ml_instance.add_term(MLVocab.workflow_type, \"Feature Notebook Workflow\", description=\"A Workflow that uses Deriva ML API\") ml_instance.add_term(MLVocab.asset_type, \"API_Model\", description=\"Model for our Notebook workflow\")  # Get the workflow for this notebook notebook_workflow = ml_instance.create_workflow(     name=\"API Workflow\",      workflow_type=\"Feature Notebook Workflow\" )  feature_execution = ml_instance.create_execution(     ExecutionConfiguration(         workflow=notebook_workflow,         description=\"Our Sample Workflow instance\") ) In\u00a0[\u00a0]: Copied! <pre># Get the IDs of al of the things that we are going to want to attach features to.\nsubject_rids = [i['RID'] for i in ml_instance.domain_path.tables['Subject'].entities().fetch()]\nimage_rids = [i['RID'] for i in ml_instance.domain_path.tables['Image'].entities().fetch()]\n</pre> # Get the IDs of al of the things that we are going to want to attach features to. subject_rids = [i['RID'] for i in ml_instance.domain_path.tables['Subject'].entities().fetch()] image_rids = [i['RID'] for i in ml_instance.domain_path.tables['Image'].entities().fetch()] <p>Now that we have the list of objects that we want to add features to, we can define the sets of feature values we want to record and then add these features in the catalog.</p> In\u00a0[\u00a0]: Copied! <pre># Create a new set of images.  For fun, lets wrap this in an execution so we get status updates\nimage_bounding_box_feature_list = []\nfor cnt, image_rid in enumerate(image_rids):\n    bounding_box_file = feature_execution.asset_file_path(\"BoundingBox\", f\"box{cnt}.txt\")\n    with open(bounding_box_file, \"w\") as fp:\n        fp.write(f\"Hi there {cnt}\")\n    image_bounding_box_feature_list.append(   ImageBoundingboxFeature(Image=image_rid, BoundingBox=bounding_box_file)\n    )\n\nimage_quality_feature_list = [\n    ImageQualityFeature(\n        Image=image_rid,\n        ImageQuality=[\"Good\", \"Bad\"][random.randint(0, 1)],\n    )\n    for image_rid in image_rids\n]\n\nsubject_feature_list = [\n    SubjectWellnessFeature(\n        Subject=subject_rid,\n        SubjectHealth=[\"Well\", \"Sick\"][random.randint(0, 1)],\n        Scale=random.randint(1, 10),\n    )\n    for subject_rid in subject_rids\n]\n\nwith feature_execution.execute() as execution:\n    feature_execution.add_features(image_bounding_box_feature_list)\n    feature_execution.add_features(image_quality_feature_list)\n    feature_execution.add_features(subject_feature_list)\n\n# Upload all of the new assets that we have created during the execution.\nfeature_execution.upload_execution_outputs()\n</pre> # Create a new set of images.  For fun, lets wrap this in an execution so we get status updates image_bounding_box_feature_list = [] for cnt, image_rid in enumerate(image_rids):     bounding_box_file = feature_execution.asset_file_path(\"BoundingBox\", f\"box{cnt}.txt\")     with open(bounding_box_file, \"w\") as fp:         fp.write(f\"Hi there {cnt}\")     image_bounding_box_feature_list.append(   ImageBoundingboxFeature(Image=image_rid, BoundingBox=bounding_box_file)     )  image_quality_feature_list = [     ImageQualityFeature(         Image=image_rid,         ImageQuality=[\"Good\", \"Bad\"][random.randint(0, 1)],     )     for image_rid in image_rids ]  subject_feature_list = [     SubjectWellnessFeature(         Subject=subject_rid,         SubjectHealth=[\"Well\", \"Sick\"][random.randint(0, 1)],         Scale=random.randint(1, 10),     )     for subject_rid in subject_rids ]  with feature_execution.execute() as execution:     feature_execution.add_features(image_bounding_box_feature_list)     feature_execution.add_features(image_quality_feature_list)     feature_execution.add_features(subject_feature_list)  # Upload all of the new assets that we have created during the execution. feature_execution.upload_execution_outputs() In\u00a0[\u00a0]: Copied! <pre>display(\n    Markdown('### Wellness'),\n    pd.DataFrame(ml_instance.list_feature_values(\"Subject\", \"Health\")).drop(columns=DerivaSystemColumns + ['Feature_Name']),\n    Markdown('### Image Quality'),\n    pd.DataFrame(ml_instance.list_feature_values(\"Image\", \"Quality\")).drop(columns=DerivaSystemColumns + ['Feature_Name']),\n    Markdown('### BoundingBox'),\n    pd.DataFrame(ml_instance.list_feature_values(\"Image\", \"BoundingBox\")).drop(columns=DerivaSystemColumns + ['Feature_Name']),\n)\n</pre> display(     Markdown('### Wellness'),     pd.DataFrame(ml_instance.list_feature_values(\"Subject\", \"Health\")).drop(columns=DerivaSystemColumns + ['Feature_Name']),     Markdown('### Image Quality'),     pd.DataFrame(ml_instance.list_feature_values(\"Image\", \"Quality\")).drop(columns=DerivaSystemColumns + ['Feature_Name']),     Markdown('### BoundingBox'),     pd.DataFrame(ml_instance.list_feature_values(\"Image\", \"BoundingBox\")).drop(columns=DerivaSystemColumns + ['Feature_Name']), ) In\u00a0[\u00a0]: Copied! <pre>display(HTML(f'&lt;a href={ml_instance.chaise_url(\"Subject\")}&gt;Browse Subject Table&lt;/a&gt;'))\n</pre> display(HTML(f'Browse Subject Table')) In\u00a0[\u00a0]: Copied! <pre>test_catalog.delete_ermrest_catalog(really=True)\n</pre> test_catalog.delete_ermrest_catalog(really=True)"},{"location":"Notebooks/DerivaML%20Features/#derivaml-features","title":"DerivaML Features\u00b6","text":"<p>DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library.</p> <p>In DerivaML, \"features\" are the way we attach values to objects in the catalog. A feature could be a computed value that serves as input to a ML model, or it could be a label, that is the result of running a model.  A feature can be a controlled vocabulary term, an asset, or a value.</p> <p>Each feature in the catalog is distinguished by the name of the feature, the identity of the object that the feature is being attached to, and the execution RID of the process that generated the feature value</p>"},{"location":"Notebooks/DerivaML%20Features/#set-up-deriva-for-test-case","title":"Set up Deriva for test case\u00b6","text":""},{"location":"Notebooks/DerivaML%20Features/#define-features","title":"Define Features\u00b6","text":"<p>A feature is a set of values that are attached to a table in the DerivaML catalog. Instances of features are distinguished from one another by the ID of the execution that produced the feature value. The execution could be the result of a program, or it could be a manual process by which a person defines a set of values</p> <p>To create a new feature, we need to know the name of the feature, the table to which it is attached, and the set of values that make up the feature.  The values could be terms from a controlled vocabulary, a set of one or more file based assets, or other values, such as integers, or strings. However, use of strings outside of controlled vocabularies is discouraged.</p> <p>For our example, we are going to define three features.  Two of them will use values from a controlled vocabulary, which we need to create.  The third feature will consist of a file whose contents we will generate.  To start, we will need to create the controlled vocabularies, and create an asset table for the feature values.</p>"},{"location":"Notebooks/DerivaML%20Features/#add-feature-values","title":"Add feature values\u00b6","text":"<p>Now using feature classes, we can create some instances of the feature and add them.  We must have a execution_rid in order to define the feature. In our example, we will assume that the execution that calculates the feature values will use a model file to configure it, so ww will need to create and upload the file before we can start the execution.</p>"},{"location":"Notebooks/DerivaML%20Ingest/","title":"DerivaML Ingest","text":"In\u00a0[\u00a0]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[\u00a0]: Copied! <pre>from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\nfrom deriva_ml.demo_catalog import create_demo_catalog, DemoML\nfrom deriva_ml import MLVocab, ExecutionConfiguration, Workflow, DerivaSystemColumns, VersionPart, DatasetSpec, FileSpec\nfrom IPython.display import display, Markdown, HTML, JSON\n</pre> from deriva.core.utils.globus_auth_utils import GlobusNativeLogin from deriva_ml.demo_catalog import create_demo_catalog, DemoML from deriva_ml import MLVocab, ExecutionConfiguration, Workflow, DerivaSystemColumns, VersionPart, DatasetSpec, FileSpec from IPython.display import display, Markdown, HTML, JSON <p>Set the details for the catalog we want and authenticate to the server if needed.</p> In\u00a0[\u00a0]: parameters Copied! <pre>hostname = 'dev.eye-ai.org'\ndomain_schema = 'demo-schema'\n</pre> hostname = 'dev.eye-ai.org' domain_schema = 'demo-schema' In\u00a0[\u00a0]: Copied! <pre>gnl = GlobusNativeLogin(host=hostname)\nif gnl.is_logged_in([hostname]):\n    print(\"You are already logged in.\")\nelse:\n    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n    print(\"Login Successful\")\n</pre> gnl = GlobusNativeLogin(host=hostname) if gnl.is_logged_in([hostname]):     print(\"You are already logged in.\") else:     gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)     print(\"Login Successful\")  <p>Create a test catalog and get an instance of the DemoML class.</p> In\u00a0[\u00a0]: Copied! <pre>test_catalog = create_demo_catalog(hostname, domain_schema)\nml_instance = DemoML(hostname, test_catalog.catalog_id, use_minid=False)\n</pre> test_catalog = create_demo_catalog(hostname, domain_schema) ml_instance = DemoML(hostname, test_catalog.catalog_id, use_minid=False) <p>Now that we have configured our datasets, we need to identify the dataset types so we can distinguish between them.</p> <p>Now create datasets and populate with elements from the test catalogs.</p> In\u00a0[\u00a0]: Copied! <pre>ml_instance.add_term(MLVocab.workflow_type, \"Data Ingest Notebook\", description=\"A Workflow that Ingests data into a catalog\")\n\n# Now lets create model configuration for our program.\napi_workflow = ml_instance.create_workflow(\n    name=\"Data Ingest\",\n    workflow_type=\"Data Ingest Notebook\",\n    description=\"An example of how to use the file table\"\n)\n\ningest_execution = ml_instance.create_execution(\n    ExecutionConfiguration(\n        workflow=api_workflow,\n        description=\"Our Sample Workflow instance\")\n)\n</pre> ml_instance.add_term(MLVocab.workflow_type, \"Data Ingest Notebook\", description=\"A Workflow that Ingests data into a catalog\")  # Now lets create model configuration for our program. api_workflow = ml_instance.create_workflow(     name=\"Data Ingest\",     workflow_type=\"Data Ingest Notebook\",     description=\"An example of how to use the file table\" )  ingest_execution = ml_instance.create_execution(     ExecutionConfiguration(         workflow=api_workflow,         description=\"Our Sample Workflow instance\") ) In\u00a0[\u00a0]: Copied! <pre>with ingest_execution.execute() as exe:\n    files = FileSpec.create_filespecs('/Users/carl/Repos/Projects/deriva-ml/src', 'my stuff')\n    exe.add_files(files, file_types=[])\n</pre> with ingest_execution.execute() as exe:     files = FileSpec.create_filespecs('/Users/carl/Repos/Projects/deriva-ml/src', 'my stuff')     exe.add_files(files, file_types=[]) <p>And now that we have defined some datasets, we can add elements of the appropriate type to them.  We can see what is in our new datasets by listing the dataset members.</p> In\u00a0[\u00a0]: Copied! <pre># Get list of subjects and images from the catalog using the DataPath API.\nml_instance.list_files()\n</pre> # Get list of subjects and images from the catalog using the DataPath API. ml_instance.list_files() <p>For ths example, lets partition the data based on the name of the subject.  Of course in real examples, we would do a more complex analysis in deciding what subset goes into each data set.</p> In\u00a0[\u00a0]: Copied! <pre>display(HTML(f'&lt;a href={ml_instance.chaise_url(\"Dataset\")}&gt;Browse Datasets&lt;/a&gt;'))\n</pre> display(HTML(f'Browse Datasets')) In\u00a0[\u00a0]: Copied! <pre>test_catalog.delete_ermrest_catalog(really=True)\n</pre> test_catalog.delete_ermrest_catalog(really=True)"},{"location":"Notebooks/DerivaML%20Ingest/#derivaml-ingest","title":"DerivaML Ingest\u00b6","text":"<p>DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library.</p>"},{"location":"Notebooks/DerivaML%20Ingest/#set-up-derivaml-for-test-case","title":"Set up DerivaML  for test case\u00b6","text":""},{"location":"Notebooks/DerivaML%20Ingest/#configure-derivaml-datasets","title":"Configure DerivaML Datasets\u00b6","text":"<p>In Deriva-ML a dataset is used to aggregate instances of entities.  However, before we can create any datasets, we must configure Deriva-ML for the specifics of the datasets.  The first stp is we need to tell Deriva-ML what types of use defined objects can be associated with a dataset.</p> <p>Note that out of the box, Deriva-ML is configured to allow datasets to contained dataset (i.e. nested datasets), so we don't need to do anything for that specific configuration.</p>"},{"location":"Notebooks/DerivaML%20Vocabulary/","title":"DerivaML Vocabulary","text":"In\u00a0[\u00a0]: Copied! <pre>from IPython.display import display, Markdown, HTML\nimport pandas as pd\nfrom deriva.core.utils.globus_auth_utils import GlobusNativeLogin\nfrom deriva_ml.demo_catalog import create_demo_catalog, DemoML\nfrom deriva_ml import MLVocab\n</pre> from IPython.display import display, Markdown, HTML import pandas as pd from deriva.core.utils.globus_auth_utils import GlobusNativeLogin from deriva_ml.demo_catalog import create_demo_catalog, DemoML from deriva_ml import MLVocab In\u00a0[\u00a0]: Copied! <pre>hostname = 'dev.eye-ai.org'   # This needs to be changed.\n\ngnl = GlobusNativeLogin(host=hostname)\nif gnl.is_logged_in([hostname]):\n    print(\"You are already logged in.\")\nelse:\n    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n    print(\"Login Successful\")\n</pre> hostname = 'dev.eye-ai.org'   # This needs to be changed.  gnl = GlobusNativeLogin(host=hostname) if gnl.is_logged_in([hostname]):     print(\"You are already logged in.\") else:     gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)     print(\"Login Successful\") In\u00a0[\u00a0]: Copied! <pre>test_catalog = create_demo_catalog(hostname)\nml_instance = DemoML(hostname, test_catalog.catalog_id)\n</pre> test_catalog = create_demo_catalog(hostname) ml_instance = DemoML(hostname, test_catalog.catalog_id) In\u00a0[\u00a0]: Copied! <pre>ml_instance.find_vocabularies()\n</pre> ml_instance.find_vocabularies() <p>Let's look at the contents of one of the predefined vocabularies in the DerivaML library.  We can make this look nicer with a Panda. Many of the datatypes in DerivaML are represented by Pydantic data classes.  These have a number of methods that can make it easy to operate on them.  The one we are going to use here is <code>model_dump()</code>, which converts a dataclass into a dictionary.</p> In\u00a0[\u00a0]: Copied! <pre>display(\n    Markdown(f\"#### Contents of controlled vocabulary {MLVocab.execution_metadata_type}\"),\n    pd.DataFrame([v.model_dump() for v in ml_instance.list_vocabulary_terms(MLVocab.execution_metadata_type)])\n)\n</pre> display(     Markdown(f\"#### Contents of controlled vocabulary {MLVocab.execution_metadata_type}\"),     pd.DataFrame([v.model_dump() for v in ml_instance.list_vocabulary_terms(MLVocab.execution_metadata_type)]) ) In\u00a0[\u00a0]: Copied! <pre>ml_instance.create_vocabulary(\"My term set\", comment=\"Terms to use for generating tests\")\n</pre> ml_instance.create_vocabulary(\"My term set\", comment=\"Terms to use for generating tests\") In\u00a0[\u00a0]: Copied! <pre>ml_instance.find_vocabularies()\n</pre> ml_instance.find_vocabularies() In\u00a0[\u00a0]: Copied! <pre>for i in range(5):\n    ml_instance.add_term(\"My term set\", f\"Term{i}\", description=f\"My term {i}\", synonyms=[f\"t{i}\", f\"T{i}\"])\n</pre> for i in range(5):     ml_instance.add_term(\"My term set\", f\"Term{i}\", description=f\"My term {i}\", synonyms=[f\"t{i}\", f\"T{i}\"]) In\u00a0[\u00a0]: Copied! <pre>display(\n    Markdown('#### Contents of controlled vocabulary \"My term set'),\n    pd.DataFrame([v.model_dump() for v in ml_instance.list_vocabulary_terms(\"My term set\")])\n)\n</pre> display(     Markdown('#### Contents of controlled vocabulary \"My term set'),     pd.DataFrame([v.model_dump() for v in ml_instance.list_vocabulary_terms(\"My term set\")]) ) In\u00a0[\u00a0]: Copied! <pre>display(\n    ml_instance.lookup_term(\"My term set\", \"Term0\"),\n    ml_instance.lookup_term(\"My term set\", \"Term2\"),\n    ml_instance.lookup_term('My term set', 'T3'),\n)\n</pre> display(     ml_instance.lookup_term(\"My term set\", \"Term0\"),     ml_instance.lookup_term(\"My term set\", \"Term2\"),     ml_instance.lookup_term('My term set', 'T3'), ) In\u00a0[\u00a0]: Copied! <pre>display(HTML(f'&lt;a href={ml_instance.chaise_url(\"My term set\")}&gt;Browse vocabulary: My term set&lt;/a&gt;'))\n</pre> display(HTML(f'Browse vocabulary: My term set')) In\u00a0[\u00a0]: Copied! <pre>test_catalog.delete_ermrest_catalog(really=True)\n</pre> test_catalog.delete_ermrest_catalog(really=True)"},{"location":"Notebooks/DerivaML%20Vocabulary/#derivaml-vocabulary","title":"DerivaML Vocabulary\u00b6","text":"<p>DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library.</p> <p>A core aspect of DerivaML is the extensive use of controlled vocabulary terms.  A vocabulary term may be something defined outside of the study, for example from an ontology like Uberon or Schema.org, or it can be a term that is defined and used locally by the ML team.  The purpose of using controlled vocabulary is that it makes it easier to find data and can help ensure that proper communication is taking place between members of the ML team.</p>"},{"location":"Notebooks/DerivaML%20Vocabulary/#preliminaries","title":"Preliminaries.\u00b6","text":"<p>To start, we will do some preliminaries, loading needed modules and making sure we are logged into the DerivaML server.</p>"},{"location":"Notebooks/DerivaML%20Vocabulary/#create-a-test-catalog","title":"Create a test catalog.\u00b6","text":"<p>Create a test catalog and get an instance of the DerivaML class.  This will take around 30 seconds, so be patient.</p>"},{"location":"Notebooks/DerivaML%20Vocabulary/#explore-existing-vocabularies","title":"Explore existing vocabularies.\u00b6","text":"<p>Get a list of all the currently defined controlled vocabularies</p>"},{"location":"Notebooks/DerivaML%20Vocabulary/#creating-a-new-controlled-vocabulary","title":"Creating a new controlled vocabulary.\u00b6","text":"<p>Now let's create a new controlled vocabulary to house terms that are specific to the problem we are working on.</p>"},{"location":"Notebooks/DerivaML%20Vocabulary/#adding-terms","title":"Adding terms\u00b6","text":"<p>Given our new controlled vocabulary, we can add terms to it.  A term has a name, that should uniquely identify it within the vocabulary, a description of what the term means, and finally a list of synonyms. Each term is assigned a resource identifier (RID) by the deriva platform.  There are other additional features of terms that facilitate integration from preexisting vocabularies that are beyond the scope of this notebook.  You can look at the class documentation for these details.</p>"},{"location":"Notebooks/DerivaML%20Vocabulary/#looking-up-terms","title":"Looking up terms\u00b6","text":"<p>We can also look up individual terms, either by their name, or by a synonym</p>"},{"location":"Notebooks/DerivaML%20Vocabulary/#browsing-terms-in-the-user-interface","title":"Browsing terms in the user interface\u00b6","text":"<p>All the terms we define in the API are of course visible via the Chaise use interface.</p>"},{"location":"code-docs/dataset/","title":"Dataset Class","text":"<p>The Dataset class manages versioned datasets in a Deriva catalog. Datasets are collections of related data elements that can be versioned, downloaded as BDBags, and tracked through their lifecycle.</p> <p>Dataset management for DerivaML.</p> <p>This module provides functionality for managing datasets in DerivaML. A dataset represents a collection of related data that can be versioned, downloaded, and tracked. The module includes:</p> <ul> <li>Dataset class: Core class for dataset operations</li> <li>Version management: Track and update dataset versions</li> <li>History tracking: Record dataset changes over time</li> <li>Download capabilities: Export datasets as BDBags</li> <li>Relationship management: Handle dataset dependencies and hierarchies</li> </ul> <p>The Dataset class serves as a base class in DerivaML, making its methods accessible through DerivaML class instances.</p> Typical usage example <p>ml = DerivaML('deriva.example.org', 'my_catalog') with ml.create_execution(config) as exe: ...     dataset = exe.create_dataset( ...         dataset_types=['experiment'], ...         description='Experimental data' ...     ) ...     dataset.add_dataset_members(members=['1-abc123', '1-def456']) ...     dataset.increment_dataset_version( ...         component=VersionPart.minor, ...         description='Added new samples' ...     )</p>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset","title":"Dataset","text":"<p>Manages dataset operations in a Deriva catalog.</p> <p>The Dataset class provides functionality for creating, modifying, and tracking datasets in a Deriva catalog. It handles versioning, relationships between datasets, and data export.</p> <p>A Dataset is a versioned collection of related data elements. Each dataset: - Has a unique RID (Resource Identifier) within the catalog - Maintains a version history using semantic versioning (major.minor.patch) - Can contain nested datasets, forming a hierarchy - Can be exported as a BDBag for offline use or sharing</p> <p>The class implements the DatasetLike protocol, allowing code to work uniformly with both live catalog datasets and downloaded DatasetBag objects.</p> <p>Attributes:</p> Name Type Description <code>dataset_rid</code> <code>RID</code> <p>The unique Resource Identifier for this dataset.</p> <code>dataset_types</code> <code>list[str]</code> <p>List of vocabulary terms describing the dataset type.</p> <code>description</code> <code>str</code> <p>Human-readable description of the dataset.</p> <code>execution_rid</code> <code>RID | None</code> <p>Optional RID of the execution that created this dataset.</p> <code>_ml_instance</code> <code>DerivaMLCatalog</code> <p>Reference to the catalog containing this dataset.</p> Example Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>class Dataset:\n    \"\"\"Manages dataset operations in a Deriva catalog.\n\n    The Dataset class provides functionality for creating, modifying, and tracking datasets\n    in a Deriva catalog. It handles versioning, relationships between datasets, and data export.\n\n    A Dataset is a versioned collection of related data elements. Each dataset:\n    - Has a unique RID (Resource Identifier) within the catalog\n    - Maintains a version history using semantic versioning (major.minor.patch)\n    - Can contain nested datasets, forming a hierarchy\n    - Can be exported as a BDBag for offline use or sharing\n\n    The class implements the DatasetLike protocol, allowing code to work uniformly\n    with both live catalog datasets and downloaded DatasetBag objects.\n\n    Attributes:\n        dataset_rid (RID): The unique Resource Identifier for this dataset.\n        dataset_types (list[str]): List of vocabulary terms describing the dataset type.\n        description (str): Human-readable description of the dataset.\n        execution_rid (RID | None): Optional RID of the execution that created this dataset.\n        _ml_instance (DerivaMLCatalog): Reference to the catalog containing this dataset.\n\n    Example:\n        &gt;&gt;&gt; # Create a new dataset via an execution\n        &gt;&gt;&gt; with ml.create_execution(config) as exe:\n        ...     dataset = exe.create_dataset(\n        ...         dataset_types=[\"training_data\"],\n        ...         description=\"Image classification training set\"\n        ...     )\n        ...     # Add members to the dataset\n        ...     dataset.add_dataset_members(members=[\"1-abc\", \"1-def\"])\n        ...     # Increment version after changes\n        ...     new_version = dataset.increment_dataset_version(VersionPart.minor, \"Added samples\")\n        &gt;&gt;&gt; # Download for offline use\n        &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=new_version)\n    \"\"\"\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def __init__(\n        self,\n        catalog: DerivaMLCatalog,\n        dataset_rid: RID,\n        description: str = \"\",\n        execution_rid: RID | None = None,\n    ):\n        \"\"\"Initialize a Dataset object from an existing dataset in the catalog.\n\n        This constructor wraps an existing dataset record. To create a new dataset\n        in the catalog, use the static method Dataset.create_dataset() instead.\n\n        Args:\n            catalog: The DerivaMLCatalog instance containing this dataset.\n            dataset_rid: The RID of the existing dataset record.\n            description: Human-readable description of the dataset's purpose and contents.\n            execution_rid: Optional execution RID that created or is associated with this dataset.\n\n        Example:\n            &gt;&gt;&gt; # Wrap an existing dataset\n            &gt;&gt;&gt; dataset = Dataset(catalog=ml, dataset_rid=\"4HM\")\n        \"\"\"\n        self._logger = logging.getLogger(\"deriva_ml\")\n        self.dataset_rid = dataset_rid\n        self.execution_rid = execution_rid\n        self._ml_instance = catalog\n        self.description = description\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the Dataset for debugging.\"\"\"\n        return (f\"&lt;deriva_ml.Dataset object at {hex(id(self))}: rid='{self.dataset_rid}', \"\n                f\"version='{self.current_version}', types={self.dataset_types}&gt;\")\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Return hash based on dataset RID for use in sets and as dict keys.\n\n        This allows Dataset objects to be stored in sets and used as dictionary keys.\n        Two Dataset objects with the same RID will hash to the same value.\n        \"\"\"\n        return hash(self.dataset_rid)\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Check equality based on dataset RID.\n\n        Two Dataset objects are considered equal if they reference the same\n        dataset RID, regardless of other attributes like version or types.\n\n        Args:\n            other: Object to compare with.\n\n        Returns:\n            True if other is a Dataset with the same RID, False otherwise.\n            Returns NotImplemented for non-Dataset objects.\n        \"\"\"\n        if not isinstance(other, Dataset):\n            return NotImplemented\n        return self.dataset_rid == other.dataset_rid\n\n    def _get_dataset_type_association_table(self) -&gt; tuple[str, Any]:\n        \"\"\"Get the association table for dataset types.\n\n        Returns:\n            Tuple of (table_name, table_path) for the Dataset-Dataset_Type association table.\n        \"\"\"\n        associations = list(\n            self._ml_instance.model.schemas[self._ml_instance.ml_schema]\n            .tables[MLVocab.dataset_type]\n            .find_associations()\n        )\n        atable_name = associations[0].name if associations else None\n        pb = self._ml_instance.pathBuilder()\n        atable_path = pb.schemas[self._ml_instance.ml_schema].tables[atable_name]\n        return atable_name, atable_path\n\n    @property\n    def dataset_types(self) -&gt; list[str]:\n        \"\"\"Get the dataset types from the catalog.\n\n        This property fetches the current dataset types directly from the catalog,\n        ensuring consistency when multiple Dataset instances reference the same\n        dataset or when types are modified externally.\n\n        Returns:\n            List of dataset type term names from the Dataset_Type vocabulary.\n        \"\"\"\n        _, atable_path = self._get_dataset_type_association_table()\n        ds_types = (\n            atable_path.filter(atable_path.Dataset == self.dataset_rid)\n            .attributes(atable_path.Dataset_Type)\n            .fetch()\n        )\n        return [ds[MLVocab.dataset_type] for ds in ds_types]\n\n    @staticmethod\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def create_dataset(\n        ml_instance: DerivaMLCatalog,\n        execution_rid: RID,\n        dataset_types: str | list[str] | None = None,\n        description: str = \"\",\n        version: DatasetVersion | None = None,\n    ) -&gt; Self:\n        \"\"\"Creates a new dataset in the catalog.\n\n        Creates a dataset with specified types and description. The dataset must be\n        associated with an execution for provenance tracking.\n\n        Args:\n            ml_instance: DerivaMLCatalog instance.\n            execution_rid: Execution RID to associate with dataset creation (required).\n            dataset_types: One or more dataset type terms from Dataset_Type vocabulary.\n            description: Description of the dataset's purpose and contents.\n            version: Optional initial version number. Defaults to 0.1.0.\n\n        Returns:\n            Dataset: The newly created dataset.\n\n        Raises:\n            DerivaMLException: If dataset_types are invalid or creation fails.\n\n        Example:\n            &gt;&gt;&gt; with ml.create_execution(config) as exe:\n            ...     dataset = exe.create_dataset(\n            ...         dataset_types=[\"experiment\", \"raw_data\"],\n            ...         description=\"RNA sequencing experiment data\",\n            ...         version=DatasetVersion(1, 0, 0)\n            ...     )\n        \"\"\"\n\n        version = version or DatasetVersion(0, 1, 0)\n\n        # Validate dataset types\n        ds_types = [dataset_types] if isinstance(dataset_types, str) else dataset_types\n        dataset_types = [ml_instance.lookup_term(MLVocab.dataset_type, t) for t in ds_types]\n\n        # Create the entry for the new dataset_table and get its RID.\n        pb = ml_instance.pathBuilder()\n        dataset_table_path = pb.schemas[ml_instance._dataset_table.schema.name].tables[ml_instance._dataset_table.name]\n        dataset_rid = dataset_table_path.insert(\n            [\n                {\n                    \"Description\": description,\n                    \"Deleted\": False,\n                }\n            ]\n        )[0][\"RID\"]\n\n        pb.schemas[ml_instance.model.ml_schema].Dataset_Execution.insert(\n            [{\"Dataset\": dataset_rid, \"Execution\": execution_rid}]\n        )\n        Dataset._insert_dataset_versions(\n            ml_instance=ml_instance,\n            dataset_list=[DatasetSpec(rid=dataset_rid, version=version)],\n            execution_rid=execution_rid,\n            description=\"Initial dataset creation.\",\n        )\n        dataset = Dataset(\n            catalog=ml_instance,\n            dataset_rid=dataset_rid,\n            description=description,\n        )\n\n        # Skip version increment during initial creation (version already set above)\n        dataset.add_dataset_types(dataset_types, _skip_version_increment=True)\n        return dataset\n\n    def add_dataset_type(\n        self,\n        dataset_type: str | VocabularyTerm,\n        _skip_version_increment: bool = False,\n    ) -&gt; None:\n        \"\"\"Add a dataset type to this dataset.\n\n        Adds a type term to this dataset if it's not already present. The term must\n        exist in the Dataset_Type vocabulary. Also increments the dataset's minor\n        version to reflect the metadata change.\n\n        Args:\n            dataset_type: Term name (string) or VocabularyTerm object from Dataset_Type vocabulary.\n            _skip_version_increment: Internal parameter to skip version increment when\n                called from add_dataset_types (which handles versioning itself).\n\n        Raises:\n            DerivaMLInvalidTerm: If the term doesn't exist in the Dataset_Type vocabulary.\n\n        Example:\n            &gt;&gt;&gt; dataset.add_dataset_type(\"Training\")\n            &gt;&gt;&gt; dataset.add_dataset_type(\"Validation\")\n        \"\"\"\n        # Convert to VocabularyTerm if needed (validates the term exists)\n        if isinstance(dataset_type, VocabularyTerm):\n            vocab_term = dataset_type\n        else:\n            vocab_term = self._ml_instance.lookup_term(MLVocab.dataset_type, dataset_type)\n\n        # Check if already present\n        if vocab_term.name in self.dataset_types:\n            return\n\n        # Insert into association table\n        _, atable_path = self._get_dataset_type_association_table()\n        atable_path.insert([{MLVocab.dataset_type: vocab_term.name, \"Dataset\": self.dataset_rid}])\n\n        # Increment minor version to reflect metadata change (unless called from add_dataset_types)\n        if not _skip_version_increment:\n            self.increment_dataset_version(\n                VersionPart.minor,\n                description=f\"Added dataset type: {vocab_term.name}\",\n            )\n\n    def remove_dataset_type(self, dataset_type: str | VocabularyTerm) -&gt; None:\n        \"\"\"Remove a dataset type from this dataset.\n\n        Removes a type term from this dataset if it's currently associated. The term\n        must exist in the Dataset_Type vocabulary.\n\n        Args:\n            dataset_type: Term name (string) or VocabularyTerm object from Dataset_Type vocabulary.\n\n        Raises:\n            DerivaMLInvalidTerm: If the term doesn't exist in the Dataset_Type vocabulary.\n\n        Example:\n            &gt;&gt;&gt; dataset.remove_dataset_type(\"Training\")\n        \"\"\"\n        # Convert to VocabularyTerm if needed (validates the term exists)\n        if isinstance(dataset_type, VocabularyTerm):\n            vocab_term = dataset_type\n        else:\n            vocab_term = self._ml_instance.lookup_term(MLVocab.dataset_type, dataset_type)\n\n        # Check if present\n        if vocab_term.name not in self.dataset_types:\n            return\n\n        # Delete from association table\n        _, atable_path = self._get_dataset_type_association_table()\n        atable_path.filter(\n            (atable_path.Dataset == self.dataset_rid) &amp; (atable_path.Dataset_Type == vocab_term.name)\n        ).delete()\n\n    def add_dataset_types(\n        self,\n        dataset_types: str | VocabularyTerm | list[str | VocabularyTerm],\n        _skip_version_increment: bool = False,\n    ) -&gt; None:\n        \"\"\"Add one or more dataset types to this dataset.\n\n        Convenience method for adding multiple types at once. Each term must exist\n        in the Dataset_Type vocabulary. Types that are already associated with the\n        dataset are silently skipped. Increments the dataset's minor version once\n        after all types are added.\n\n        Args:\n            dataset_types: Single term or list of terms. Can be strings (term names)\n                or VocabularyTerm objects.\n            _skip_version_increment: Internal parameter to skip version increment\n                (used during initial dataset creation).\n\n        Raises:\n            DerivaMLInvalidTerm: If any term doesn't exist in the Dataset_Type vocabulary.\n\n        Example:\n            &gt;&gt;&gt; dataset.add_dataset_types([\"Training\", \"Image\"])\n            &gt;&gt;&gt; dataset.add_dataset_types(\"Testing\")\n        \"\"\"\n        # Normalize input to a list\n        types_to_add = [dataset_types] if not isinstance(dataset_types, list) else dataset_types\n\n        # Track which types were actually added (not already present)\n        added_types: list[str] = []\n        for term in types_to_add:\n            # Get term name before calling add_dataset_type\n            if isinstance(term, VocabularyTerm):\n                term_name = term.name\n            else:\n                term_name = self._ml_instance.lookup_term(MLVocab.dataset_type, term).name\n\n            # Check if already present before adding\n            if term_name not in self.dataset_types:\n                self.add_dataset_type(term, _skip_version_increment=True)\n                added_types.append(term_name)\n\n        # Increment version once for all added types (if any were added)\n        if added_types and not _skip_version_increment:\n            type_names = \", \".join(added_types)\n            self.increment_dataset_version(\n                VersionPart.minor,\n                description=f\"Added dataset type(s): {type_names}\",\n            )\n\n    @property\n    def _dataset_table(self) -&gt; Table:\n        \"\"\"Get the Dataset table from the catalog schema.\n\n        Returns:\n            Table: The Deriva Table object for the Dataset table in the ML schema.\n        \"\"\"\n        return self._ml_instance.model.schemas[self._ml_instance.ml_schema].tables[\"Dataset\"]\n\n    # ==================== Read Interface Methods ====================\n    # These methods implement the DatasetLike protocol for read operations.\n    # They delegate to the catalog instance for actual data retrieval.\n    # This allows Dataset and DatasetBag to share a common interface.\n\n    def list_dataset_element_types(self) -&gt; Iterable[Table]:\n        \"\"\"List the types of elements that can be contained in this dataset.\n\n        Returns:\n            Iterable of Table objects representing element types.\n        \"\"\"\n        return self._ml_instance.list_dataset_element_types()\n\n    def find_features(self, table: str | Table) -&gt; Iterable[Feature]:\n        \"\"\"Find features associated with a table.\n\n        Args:\n            table: Table to find features for.\n\n        Returns:\n            Iterable of Feature objects.\n        \"\"\"\n        return self._ml_instance.find_features(table)\n\n    def dataset_history(self) -&gt; list[DatasetHistory]:\n        \"\"\"Retrieves the version history of a dataset.\n\n        Returns a chronological list of dataset versions, including their version numbers,\n        creation times, and associated metadata.\n\n        Returns:\n            list[DatasetHistory]: List of history entries, each containing:\n                - dataset_version: Version number (major.minor.patch)\n                - minid: Minimal Viable Identifier\n                - snapshot: Catalog snapshot time\n                - dataset_rid: Dataset Resource Identifier\n                - version_rid: Version Resource Identifier\n                - description: Version description\n                - execution_rid: Associated execution RID\n\n        Raises:\n            DerivaMLException: If dataset_rid is not a valid dataset RID.\n\n        Example:\n            &gt;&gt;&gt; history = ml.dataset_history(\"1-abc123\")\n            &gt;&gt;&gt; for entry in history:\n            ...     print(f\"Version {entry.dataset_version}: {entry.description}\")\n        \"\"\"\n\n        if not self._ml_instance.model.is_dataset_rid(self.dataset_rid):\n            raise DerivaMLException(f\"RID is not for a data set: {self.dataset_rid}\")\n        version_path = self._ml_instance.pathBuilder().schemas[self._ml_instance.ml_schema].tables[\"Dataset_Version\"]\n        return [\n            DatasetHistory(\n                dataset_version=DatasetVersion.parse(v[\"Version\"]),\n                minid=v[\"Minid\"],\n                snapshot=v[\"Snapshot\"],\n                dataset_rid=self.dataset_rid,\n                version_rid=v[\"RID\"],\n                description=v[\"Description\"],\n                execution_rid=v[\"Execution\"],\n            )\n            for v in version_path.filter(version_path.Dataset == self.dataset_rid).entities().fetch()\n        ]\n\n    @property\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def current_version(self) -&gt; DatasetVersion:\n        \"\"\"Retrieve the current version of the specified dataset_table.\n\n        Return the most recent version of the dataset. It is important to remember that this version\n        captures the state of the catalog at the time the version was created, not the current state of the catalog.\n        This means that its possible that the values associated with an object in the catalog may be different\n        from the values of that object in the dataset.\n\n        Returns:\n            A tuple with the semantic version of the dataset_table.\n        \"\"\"\n        history = self.dataset_history()\n        if not history:\n            return DatasetVersion(0, 1, 0)\n        else:\n            # Ensure we return a DatasetVersion, not a string\n            versions = [h.dataset_version for h in history]\n            return max(versions) if versions else DatasetVersion(0, 1, 0)\n\n    def get_chaise_url(self) -&gt; str:\n        \"\"\"Get the Chaise URL for viewing this dataset in the browser.\n\n        Returns:\n            URL string for the dataset record in Chaise.\n        \"\"\"\n        return (\n            f\"https://{self._ml_instance.host_name}/chaise/record/\"\n            f\"#{self._ml_instance.catalog_id}/deriva-ml:Dataset/RID={self.dataset_rid}\"\n        )\n\n    def to_markdown(self, show_children: bool = False, indent: int = 0) -&gt; str:\n        \"\"\"Generate a markdown representation of this dataset.\n\n        Returns a formatted markdown string with a link to the dataset,\n        version, types, and description. Optionally includes nested children.\n\n        Args:\n            show_children: If True, include direct child datasets.\n            indent: Number of indent levels (each level is 2 spaces).\n\n        Returns:\n            Markdown-formatted string.\n\n        Example:\n            &gt;&gt;&gt; ds = ml.lookup_dataset(\"4HM\")\n            &gt;&gt;&gt; print(ds.to_markdown())\n        \"\"\"\n        prefix = \"  \" * indent\n        version = str(self.current_version) if self.current_version else \"n/a\"\n        types = \", \".join(self.dataset_types) if self.dataset_types else \"\"\n        desc = self.description or \"\"\n\n        line = f\"{prefix}- [{self.dataset_rid}]({self.get_chaise_url()}) v{version}\"\n        if types:\n            line += f\" [{types}]\"\n        if desc:\n            line += f\": {desc}\"\n\n        lines = [line]\n\n        if show_children:\n            children = self.list_dataset_children(recurse=False)\n            for child in children:\n                lines.append(child.to_markdown(show_children=False, indent=indent + 1))\n\n        return \"\\n\".join(lines)\n\n    def display_markdown(self, show_children: bool = False, indent: int = 0) -&gt; None:\n        \"\"\"Display a formatted markdown representation of this dataset in Jupyter.\n\n        Convenience method that calls to_markdown() and displays the result\n        using IPython.display.Markdown.\n\n        Args:\n            show_children: If True, include direct child datasets.\n            indent: Number of indent levels (each level is 2 spaces).\n\n        Example:\n            &gt;&gt;&gt; ds = ml.lookup_dataset(\"4HM\")\n            &gt;&gt;&gt; ds.display_markdown(show_children=True)\n        \"\"\"\n        from IPython.display import Markdown, display\n\n        display(Markdown(self.to_markdown(show_children, indent)))\n\n    def _build_dataset_graph(self) -&gt; Iterable[Dataset]:\n        \"\"\"Build a dependency graph of all related datasets and return in topological order.\n\n        This method is used when incrementing dataset versions. Because datasets can be\n        nested (parent-child relationships), changing the version of one dataset may\n        require updating related datasets.\n\n        The topological sort ensures that children are processed before parents,\n        so version updates propagate correctly through the hierarchy.\n\n        Returns:\n            Iterable[Dataset]: Datasets in topological order (children before parents).\n\n        Example:\n            If dataset A contains nested dataset B, which contains C:\n            A -&gt; B -&gt; C\n            The returned order would be [C, B, A], ensuring C's version is\n            updated before B's, and B's before A's.\n        \"\"\"\n        ts: TopologicalSorter = TopologicalSorter()\n        self._build_dataset_graph_1(ts, set())\n        return ts.static_order()\n\n    def _build_dataset_graph_1(self, ts: TopologicalSorter, visited: set[str]) -&gt; None:\n        \"\"\"Recursively build the dataset dependency graph.\n\n        Uses topological sort where parents depend on their children, ensuring\n        children are processed before parents in the resulting order.\n\n        Args:\n            ts: TopologicalSorter instance to add nodes and dependencies to.\n            visited: Set of already-visited dataset RIDs to avoid cycles.\n        \"\"\"\n        if self.dataset_rid in visited:\n            return\n\n        visited.add(self.dataset_rid)\n        # Use current catalog state for graph traversal, not version snapshot.\n        # Parent/child relationships need to reflect current state for version updates.\n        children = self._list_dataset_children_current()\n        parents = self._list_dataset_parents_current()\n\n        # Add this node with its children as dependencies.\n        # This means: self depends on children, so children will be ordered before self.\n        ts.add(self, *children)\n\n        # Recursively process children\n        for child in children:\n            child._build_dataset_graph_1(ts, visited)\n\n        # Recursively process parents (they will depend on this node)\n        for parent in parents:\n            parent._build_dataset_graph_1(ts, visited)\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def increment_dataset_version(\n        self,\n        component: VersionPart,\n        description: str | None = \"\",\n        execution_rid: RID | None = None,\n    ) -&gt; DatasetVersion:\n        \"\"\"Increments a dataset's version number.\n\n        Creates a new version of the dataset by incrementing the specified version component\n        (major, minor, or patch). The new version is recorded with an optional description\n        and execution reference.\n\n        Args:\n            component: Which version component to increment ('major', 'minor', or 'patch').\n            description: Optional description of the changes in this version.\n            execution_rid: Optional execution RID to associate with this version.\n\n        Returns:\n            DatasetVersion: The new version number.\n\n        Raises:\n            DerivaMLException: If dataset_rid is invalid or version increment fails.\n\n        Example:\n            &gt;&gt;&gt; new_version = ml.increment_dataset_version(\n            ...     dataset_rid=\"1-abc123\",\n            ...     component=\"minor\",\n            ...     description=\"Added new samples\"\n            ... )\n            &gt;&gt;&gt; print(f\"New version: {new_version}\")  # e.g., \"1.2.0\"\n        \"\"\"\n\n        # Find all the datasets that are reachable from this dataset and determine their new version numbers.\n        related_datasets = list(self._build_dataset_graph())\n        version_update_list = [\n            DatasetSpec(\n                rid=ds.dataset_rid,\n                version=ds.current_version.increment_version(component),\n            )\n            for ds in related_datasets\n        ]\n        Dataset._insert_dataset_versions(\n            self._ml_instance, version_update_list, description=description, execution_rid=execution_rid\n        )\n        return next((d.version for d in version_update_list if d.rid == self.dataset_rid))\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def list_dataset_members(\n        self,\n        recurse: bool = False,\n        limit: int | None = None,\n        _visited: set[RID] | None = None,\n        version: DatasetVersion | str | None = None,\n        **kwargs: Any,\n    ) -&gt; dict[str, list[dict[str, Any]]]:\n        \"\"\"Lists members of a dataset.\n\n        Returns a dictionary mapping member types to lists of member records. Can optionally\n        recurse through nested datasets and limit the number of results.\n\n        Args:\n            recurse: Whether to include members of nested datasets. Defaults to False.\n            limit: Maximum number of members to return per type. None for no limit.\n            _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n            version: Dataset version to list members from. Defaults to the current version.\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Returns:\n            dict[str, list[dict[str, Any]]]: Dictionary mapping member types to lists of members.\n                Each member is a dictionary containing the record's attributes.\n\n        Raises:\n            DerivaMLException: If dataset_rid is invalid.\n\n        Example:\n            &gt;&gt;&gt; members = ml.list_dataset_members(\"1-abc123\", recurse=True)\n            &gt;&gt;&gt; for type_name, records in members.items():\n            ...     print(f\"{type_name}: {len(records)} records\")\n        \"\"\"\n        # Initialize visited set for recursion guard\n        if _visited is None:\n            _visited = set()\n\n        # Prevent infinite recursion by checking if we've already visited this dataset\n        if self.dataset_rid in _visited:\n            return {}\n        _visited.add(self.dataset_rid)\n\n        # Look at each of the element types that might be in the dataset_table and get the list of rid for them from\n        # the appropriate association table.\n        members = defaultdict(list)\n        version_snapshot_catalog = self._version_snapshot_catalog(version)\n        pb = version_snapshot_catalog.pathBuilder()\n        for assoc_table in self._dataset_table.find_associations():\n            other_fkey = assoc_table.other_fkeys.pop()\n            target_table = other_fkey.pk_table\n            member_table = assoc_table.table\n\n            # Look at domain tables and nested datasets.\n            if not self._ml_instance.model.is_domain_schema(target_table.schema.name) and not (\n                target_table == self._dataset_table or target_table.name == \"File\"\n            ):\n                continue\n            member_column = (\n                \"Nested_Dataset\" if target_table == self._dataset_table else other_fkey.foreign_key_columns[0].name\n            )\n            # Use the actual referenced column from the FK definition, not always \"RID\".\n            # e.g. isa:Dataset_file.file -&gt; isa:file.id (integer), not RID.\n            target_column = other_fkey.referenced_columns[0].name\n\n            target_path = pb.schemas[target_table.schema.name].tables[target_table.name]\n            member_path = pb.schemas[member_table.schema.name].tables[member_table.name]\n\n            path = member_path.filter(member_path.Dataset == self.dataset_rid).link(\n                target_path,\n                on=(member_path.columns[member_column] == target_path.columns[target_column]),\n            )\n            target_entities = list(path.entities().fetch(limit=limit) if limit else path.entities().fetch())\n            members[target_table.name].extend(target_entities)\n            if recurse and target_table == self._dataset_table:\n                # Get the members for all the nested datasets and add to the member list.\n                nested_datasets = [d[\"RID\"] for d in target_entities]\n                for ds_rid in nested_datasets:\n                    ds = version_snapshot_catalog.lookup_dataset(ds_rid)\n                    for k, v in ds.list_dataset_members(version=version, recurse=recurse, _visited=_visited).items():\n                        members[k].extend(v)\n        return dict(members)\n\n    def _denormalize_datapath(\n        self,\n        include_tables: list[str],\n        version: DatasetVersion | str | None = None,\n    ) -&gt; Generator[dict[str, Any], None, None]:\n        \"\"\"Denormalize dataset members by joining related tables.\n\n        This method creates a \"wide table\" view by joining related tables together using\n        the Deriva datapath API, producing rows that contain columns from all specified\n        tables. The result has outer join semantics - rows from tables without FK\n        relationships are included with NULL values for unrelated columns.\n\n        The method:\n        1. Gets the list of dataset members for each included table\n        2. For each member in the first table, follows foreign key relationships to\n           get related records from other tables\n        3. Tables without FK connections to the first table are included with NULLs\n        4. Includes nested dataset members recursively\n\n        Args:\n            include_tables: List of table names to include in the output.\n            version: Dataset version to query. Defaults to current version.\n\n        Yields:\n            dict[str, Any]: Rows with column names prefixed by table name (e.g., \"Image_Filename\").\n                Unrelated tables have NULL values for their columns.\n\n        Note:\n            Column names in the result are prefixed with the table name to avoid\n            collisions (e.g., \"Image_Filename\", \"Subject_RID\").\n        \"\"\"\n        # Skip system columns in output\n        skip_columns = {\"RCT\", \"RMT\", \"RCB\", \"RMB\"}\n\n        # Get all members for the included tables (recursively includes nested datasets)\n        members = self.list_dataset_members(version=version, recurse=True)\n\n        # Build a lookup of columns for each table\n        table_columns: dict[str, list[str]] = {}\n        for table_name in include_tables:\n            table = self._ml_instance.model.name_to_table(table_name)\n            table_columns[table_name] = [\n                c.name for c in table.columns if c.name not in skip_columns\n            ]\n\n        # Find the primary table (first non-empty table in include_tables)\n        primary_table = None\n        for table_name in include_tables:\n            if table_name in members and members[table_name]:\n                primary_table = table_name\n                break\n\n        if primary_table is None:\n            # No data at all\n            return\n\n        primary_table_obj = self._ml_instance.model.name_to_table(primary_table)\n\n        for member in members[primary_table]:\n            # Build the row with all columns from all tables\n            row: dict[str, Any] = {}\n\n            # Add primary table columns\n            for col_name in table_columns[primary_table]:\n                prefixed_name = f\"{primary_table}_{col_name}\"\n                row[prefixed_name] = member.get(col_name)\n\n            # For each other table, try to join or add NULL values\n            for other_table_name in include_tables:\n                if other_table_name == primary_table:\n                    continue\n\n                other_table = self._ml_instance.model.name_to_table(other_table_name)\n                other_cols = table_columns[other_table_name]\n\n                # Initialize all columns to None (outer join behavior)\n                for col_name in other_cols:\n                    prefixed_name = f\"{other_table_name}_{col_name}\"\n                    row[prefixed_name] = None\n\n                # Try to find FK relationship and join\n                if other_table_name in members:\n                    try:\n                        relationship = self._ml_instance.model._table_relationship(\n                            primary_table_obj, other_table\n                        )\n                        fk_col, pk_col = relationship\n\n                        # Look up the related record\n                        fk_value = member.get(fk_col.name)\n                        if fk_value:\n                            for other_member in members.get(other_table_name, []):\n                                if other_member.get(pk_col.name) == fk_value:\n                                    for col_name in other_cols:\n                                        prefixed_name = f\"{other_table_name}_{col_name}\"\n                                        row[prefixed_name] = other_member.get(col_name)\n                                    break\n                    except DerivaMLException:\n                        # No FK relationship - columns remain NULL (outer join)\n                        pass\n\n            yield row\n\n    def denormalize_as_dataframe(\n        self,\n        include_tables: list[str],\n        version: DatasetVersion | str | None = None,\n        **kwargs: Any,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Denormalize the dataset into a single wide table (DataFrame).\n\n        Denormalization transforms normalized relational data into a single \"wide table\"\n        (also called a \"flat table\" or \"denormalized table\") by joining related tables\n        together. This produces a DataFrame where each row contains all related information\n        from multiple source tables, with columns from each table combined side-by-side.\n\n        Wide tables are the standard input format for most machine learning frameworks,\n        which expect all features for a single observation to be in one row. This method\n        bridges the gap between normalized database schemas and ML-ready tabular data.\n\n        **How it works:**\n\n        Tables are joined based on their foreign key relationships. For example, if\n        Image has a foreign key to Subject, and Diagnosis has a foreign key to Image,\n        then denormalizing [\"Subject\", \"Image\", \"Diagnosis\"] produces rows where each\n        image appears with its subject's metadata and any associated diagnoses.\n\n        **Column naming:**\n\n        Column names are prefixed with the source table name using underscores\n        to avoid collisions (e.g., \"Image_Filename\", \"Subject_RID\").\n\n        Args:\n            include_tables: List of table names to include in the output. Tables\n                are joined based on their foreign key relationships.\n                Order doesn't matter - the join order is determined automatically.\n            version: Dataset version to query. Defaults to current version.\n                Use this to get a reproducible snapshot of the data.\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Returns:\n            pd.DataFrame: Wide table with columns from all included tables.\n\n        Example:\n            Create a training dataset with images and their labels::\n\n                &gt;&gt;&gt; # Get all images with their diagnoses in one table\n                &gt;&gt;&gt; df = dataset.denormalize_as_dataframe([\"Image\", \"Diagnosis\"])\n                &gt;&gt;&gt; print(df.columns.tolist())\n                ['Image_RID', 'Image_Filename', 'Image_URL', 'Diagnosis_RID',\n                 'Diagnosis_Label', 'Diagnosis_Confidence']\n\n                &gt;&gt;&gt; # Use with scikit-learn\n                &gt;&gt;&gt; X = df[[\"Image_Filename\"]]  # Features\n                &gt;&gt;&gt; y = df[\"Diagnosis_Label\"]    # Labels\n\n            Include subject metadata for stratified splitting::\n\n                &gt;&gt;&gt; df = dataset.denormalize_as_dataframe(\n                ...     [\"Subject\", \"Image\", \"Diagnosis\"]\n                ... )\n                &gt;&gt;&gt; # Now df has Subject_Age, Subject_Gender, etc.\n                &gt;&gt;&gt; # for stratified train/test splits by subject\n\n        See Also:\n            denormalize_as_dict: Generator version for memory-efficient processing.\n        \"\"\"\n        rows = list(self._denormalize_datapath(include_tables, version))\n        return pd.DataFrame(rows)\n\n    def denormalize_as_dict(\n        self,\n        include_tables: list[str],\n        version: DatasetVersion | str | None = None,\n        **kwargs: Any,\n    ) -&gt; Generator[dict[str, Any], None, None]:\n        \"\"\"Denormalize the dataset and yield rows as dictionaries.\n\n        This is a memory-efficient alternative to denormalize_as_dataframe() that\n        yields one row at a time as a dictionary instead of loading all data into\n        a DataFrame. Use this when processing large datasets that may not fit in\n        memory, or when you want to process rows incrementally.\n\n        Like denormalize_as_dataframe(), this produces a \"wide table\" representation\n        where each yielded dictionary contains all columns from the joined tables.\n        See denormalize_as_dataframe() for detailed explanation of how denormalization\n        works.\n\n        **Column naming:**\n\n        Column names are prefixed with the source table name using underscores\n        to avoid collisions (e.g., \"Image_Filename\", \"Subject_RID\").\n\n        Args:\n            include_tables: List of table names to include in the output.\n                Tables are joined based on their foreign key relationships.\n            version: Dataset version to query. Defaults to current version.\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Yields:\n            dict[str, Any]: Dictionary representing one row of the wide table.\n                Keys are column names in \"Table_Column\" format.\n\n        Example:\n            Process images one at a time for training::\n\n                &gt;&gt;&gt; for row in dataset.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n                ...     # Load and preprocess each image\n                ...     img = load_image(row[\"Image_Filename\"])\n                ...     label = row[\"Diagnosis_Label\"]\n                ...     yield img, label  # Feed to training loop\n\n            Count labels without loading all data into memory::\n\n                &gt;&gt;&gt; from collections import Counter\n                &gt;&gt;&gt; labels = Counter()\n                &gt;&gt;&gt; for row in dataset.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n                ...     labels[row[\"Diagnosis_Label\"]] += 1\n                &gt;&gt;&gt; print(labels)\n                Counter({'Normal': 450, 'Abnormal': 150})\n\n        See Also:\n            denormalize_as_dataframe: Returns all data as a pandas DataFrame.\n        \"\"\"\n        yield from self._denormalize_datapath(include_tables, version)\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def add_dataset_members(\n        self,\n        members: list[RID] | dict[str, list[RID]],\n        validate: bool = True,\n        description: str | None = \"\",\n        execution_rid: RID | None = None,\n    ) -&gt; None:\n        \"\"\"Adds members to a dataset.\n\n        Associates one or more records with a dataset. Members can be provided in two forms:\n\n        **List of RIDs (simpler but slower):**\n        When `members` is a list of RIDs, each RID is resolved to determine which table\n        it belongs to. This uses batch RID resolution for efficiency, but still requires\n        querying the catalog to identify each RID's table.\n\n        **Dictionary by table name (faster, recommended for large datasets):**\n        When `members` is a dict mapping table names to lists of RIDs, no RID resolution\n        is needed. The RIDs are inserted directly into the dataset. Use this form when\n        you already know which table each RID belongs to.\n\n        **Important:** Members can only be added from tables that have been registered as\n        dataset element types. Use :meth:`DerivaML.add_dataset_element_type` to register\n        a table before adding its records to datasets.\n\n        Adding members automatically increments the dataset's minor version.\n\n        Args:\n            members: Either:\n                - list[RID]: List of RIDs to add. Each RID will be resolved to find its table.\n                - dict[str, list[RID]]: Mapping of table names to RID lists. Skips resolution.\n            validate: Whether to validate that members don't already exist. Defaults to True.\n            description: Optional description of the member additions.\n            execution_rid: Optional execution RID to associate with changes.\n\n        Raises:\n            DerivaMLException: If:\n                - Any RID is invalid or cannot be resolved\n                - Any RID belongs to a table that isn't registered as a dataset element type\n                - Adding members would create a cycle (for nested datasets)\n                - Validation finds duplicate members (when validate=True)\n\n        See Also:\n            :meth:`DerivaML.add_dataset_element_type`: Register a table as a dataset element type.\n            :meth:`DerivaML.list_dataset_element_types`: List registered dataset element types.\n\n        Examples:\n            Using a list of RIDs (simpler):\n                &gt;&gt;&gt; dataset.add_dataset_members(\n                ...     members=[\"1-ABC\", \"1-DEF\", \"1-GHI\"],\n                ...     description=\"Added sample images\"\n                ... )\n\n            Using a dict by table name (faster for large datasets):\n                &gt;&gt;&gt; dataset.add_dataset_members(\n                ...     members={\n                ...         \"Image\": [\"1-ABC\", \"1-DEF\"],\n                ...         \"Subject\": [\"2-XYZ\"]\n                ...     },\n                ...     description=\"Added images and subjects\"\n                ... )\n        \"\"\"\n        description = description or \"Updated dataset via add_dataset_members\"\n\n        def check_dataset_cycle(member_rid, path=None):\n            \"\"\"\n\n            Args:\n              member_rid:\n              path: (Default value = None)\n\n            Returns:\n\n            \"\"\"\n            path = path or set(self.dataset_rid)\n            return member_rid in path\n\n        if validate:\n            existing_rids = set(m[\"RID\"] for ms in self.list_dataset_members().values() for m in ms)\n            if overlap := set(existing_rids).intersection(members):\n                raise DerivaMLException(\n                    f\"Attempting to add existing member to dataset_table {self.dataset_rid}: {overlap}\"\n                )\n\n        # Now go through every rid to be added to the data set and sort them based on what association table entries\n        # need to be made.\n        dataset_elements: dict[str, list[RID]] = {}\n\n        # Build map of valid element tables to their association tables\n        associations = list(self._dataset_table.find_associations())\n        association_map = {a.other_fkeys.pop().pk_table.name: a.table.name for a in associations}\n\n        # Get a list of all the object types that can be linked to a dataset_table.\n        if type(members) is list:\n            members = set(members)\n\n            # Get candidate tables for batch resolution (only tables that can be dataset elements)\n            candidate_tables = [\n                self._ml_instance.model.name_to_table(table_name) for table_name in association_map.keys()\n            ]\n\n            # Batch resolve all RIDs at once instead of one-by-one\n            rid_results = self._ml_instance.resolve_rids(members, candidate_tables=candidate_tables)\n\n            # Group by table and validate\n            for rid, rid_info in rid_results.items():\n                if rid_info.table_name not in association_map:\n                    raise DerivaMLException(f\"RID table: {rid_info.table_name} not part of dataset_table\")\n                if rid_info.table == self._dataset_table and check_dataset_cycle(rid_info.rid):\n                    raise DerivaMLException(\"Creating cycle of datasets is not allowed\")\n                dataset_elements.setdefault(rid_info.table_name, []).append(rid_info.rid)\n        else:\n            dataset_elements = {t: list(set(ms)) for t, ms in members.items()}\n        # Now make the entries into the association tables.\n        pb = self._ml_instance.pathBuilder()\n        for table, elements in dataset_elements.items():\n            # Determine schema: ML schema for Dataset/File, otherwise use the table's actual schema\n            if table == \"Dataset\" or table == \"File\":\n                schema_name = self._ml_instance.ml_schema\n            else:\n                # Find the table and use its schema\n                table_obj = self._ml_instance.model.name_to_table(table)\n                schema_name = table_obj.schema.name\n            schema_path = pb.schemas[schema_name]\n            fk_column = \"Nested_Dataset\" if table == \"Dataset\" else table\n            if len(elements):\n                # Find out the name of the column in the association table.\n                schema_path.tables[association_map[table]].insert(\n                    [{\"Dataset\": self.dataset_rid, fk_column: e} for e in elements]\n                )\n        self.increment_dataset_version(\n            VersionPart.minor,\n            description=description,\n            execution_rid=execution_rid,\n        )\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def delete_dataset_members(\n        self,\n        members: list[RID],\n        description: str = \"\",\n        execution_rid: RID | None = None,\n    ) -&gt; None:\n        \"\"\"Remove members from this dataset.\n\n        Removes the specified members from the dataset. In addition to removing members,\n        the minor version number of the dataset is incremented and the description,\n        if provided, is applied to that new version.\n\n        Args:\n            members: List of member RIDs to remove from the dataset.\n            description: Optional description of the removal operation.\n            execution_rid: Optional RID of execution associated with this operation.\n\n        Raises:\n            DerivaMLException: If any RID is invalid or not part of this dataset.\n\n        Example:\n            &gt;&gt;&gt; dataset.delete_dataset_members(\n            ...     members=[\"1-ABC\", \"1-DEF\"],\n            ...     description=\"Removed corrupted samples\"\n            ... )\n        \"\"\"\n        members = set(members)\n        description = description or \"Deleted dataset members\"\n\n        # Go through every rid to be deleted and sort them based on what association table entries\n        # need to be removed.\n        dataset_elements = {}\n        association_map = {\n            a.other_fkeys.pop().pk_table.name: a.table.name for a in self._dataset_table.find_associations()\n        }\n        # Get a list of all the object types that can be linked to a dataset.\n        for m in members:\n            try:\n                rid_info = self._ml_instance.resolve_rid(m)\n            except KeyError:\n                raise DerivaMLException(f\"Invalid RID: {m}\")\n            if rid_info.table.name not in association_map:\n                raise DerivaMLException(f\"RID table: {rid_info.table.name} not part of dataset\")\n            dataset_elements.setdefault(rid_info.table.name, []).append(rid_info.rid)\n\n        # Delete the entries from the association tables.\n        pb = self._ml_instance.pathBuilder()\n        for table, elements in dataset_elements.items():\n            # Determine schema: ML schema for Dataset, otherwise use the table's actual schema\n            if table == \"Dataset\":\n                schema_name = self._ml_instance.ml_schema\n            else:\n                # Find the table and use its schema\n                table_obj = self._ml_instance.model.name_to_table(table)\n                schema_name = table_obj.schema.name\n            schema_path = pb.schemas[schema_name]\n            fk_column = \"Nested_Dataset\" if table == \"Dataset\" else table\n\n            if len(elements):\n                atable_path = schema_path.tables[association_map[table]]\n                for e in elements:\n                    entity = atable_path.filter(\n                        (atable_path.Dataset == self.dataset_rid) &amp; (atable_path.columns[fk_column] == e),\n                    )\n                    entity.delete()\n\n        self.increment_dataset_version(\n            VersionPart.minor,\n            description=description,\n            execution_rid=execution_rid,\n        )\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def list_dataset_parents(\n        self,\n        recurse: bool = False,\n        _visited: set[RID] | None = None,\n        version: DatasetVersion | str | None = None,\n        **kwargs: Any,\n    ) -&gt; list[Self]:\n        \"\"\"Given a dataset_table RID, return a list of RIDs of the parent datasets if this is included in a\n        nested dataset.\n\n        Args:\n            recurse: If True, recursively return all ancestor datasets.\n            _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n            version: Dataset version to list parents from. Defaults to the current version.\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Returns:\n            List of parent datasets.\n        \"\"\"\n        # Initialize visited set for recursion guard\n        if _visited is None:\n            _visited = set()\n\n        # Prevent infinite recursion by checking if we've already visited this dataset\n        if self.dataset_rid in _visited:\n            return []\n        _visited.add(self.dataset_rid)\n\n        # Get association table for nested datasets\n        version_snapshot_catalog = self._version_snapshot_catalog(version)\n        pb = version_snapshot_catalog.pathBuilder()\n        atable_path = pb.schemas[self._ml_instance.ml_schema].Dataset_Dataset\n        parents = [\n            version_snapshot_catalog.lookup_dataset(p[\"Dataset\"])\n            for p in atable_path.filter(atable_path.Nested_Dataset == self.dataset_rid).entities().fetch()\n        ]\n        if recurse:\n            for parent in parents.copy():\n                parents.extend(parent.list_dataset_parents(recurse=True, _visited=_visited, version=version))\n        return parents\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def list_dataset_children(\n        self,\n        recurse: bool = False,\n        _visited: set[RID] | None = None,\n        version: DatasetVersion | str | None = None,\n        **kwargs: Any,\n    ) -&gt; list[Self]:\n        \"\"\"Given a dataset_table RID, return a list of RIDs for any nested datasets.\n\n        Args:\n            recurse: If True, return a list of nested datasets RIDs.\n            _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n            version: Dataset version to list children from. Defaults to the current version.\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Returns:\n          list of nested dataset RIDs.\n\n        \"\"\"\n        # Initialize visited set for recursion guard\n        if _visited is None:\n            _visited = set()\n\n        version = DatasetVersion.parse(version) if isinstance(version, str) else version\n        version_snapshot_catalog = self._version_snapshot_catalog(version)\n        dataset_dataset_path = (\n           version_snapshot_catalog.pathBuilder().schemas[self._ml_instance.ml_schema].tables[\"Dataset_Dataset\"]\n        )\n        nested_datasets = list(dataset_dataset_path.entities().fetch())\n\n        def find_children(rid: RID) -&gt; list[RID]:\n            # Prevent infinite recursion by checking if we've already visited this dataset\n            if rid in _visited:\n                return []\n            _visited.add(rid)\n\n            children = [child[\"Nested_Dataset\"] for child in nested_datasets if child[\"Dataset\"] == rid]\n            if recurse:\n                for child in children.copy():\n                    children.extend(find_children(child))\n            return children\n\n        return [version_snapshot_catalog.lookup_dataset(rid) for rid in find_children(self.dataset_rid)]\n\n    def _list_dataset_parents_current(self) -&gt; list[Self]:\n        \"\"\"Return parent datasets using current catalog state (not version snapshot).\n\n        Used by _build_dataset_graph_1 to find all related datasets for version updates.\n        \"\"\"\n        pb = self._ml_instance.pathBuilder()\n        atable_path = pb.schemas[self._ml_instance.ml_schema].Dataset_Dataset\n        return [\n            self._ml_instance.lookup_dataset(p[\"Dataset\"])\n            for p in atable_path.filter(atable_path.Nested_Dataset == self.dataset_rid).entities().fetch()\n        ]\n\n    def _list_dataset_children_current(self) -&gt; list[Self]:\n        \"\"\"Return child datasets using current catalog state (not version snapshot).\n\n        Used by _build_dataset_graph_1 to find all related datasets for version updates.\n        \"\"\"\n        dataset_dataset_path = (\n            self._ml_instance.pathBuilder().schemas[self._ml_instance.ml_schema].tables[\"Dataset_Dataset\"]\n        )\n        nested_datasets = list(dataset_dataset_path.entities().fetch())\n\n        def find_children(rid: RID) -&gt; list[RID]:\n            return [child[\"Nested_Dataset\"] for child in nested_datasets if child[\"Dataset\"] == rid]\n\n        return [self._ml_instance.lookup_dataset(rid) for rid in find_children(self.dataset_rid)]\n\n    def list_executions(self) -&gt; list[\"Execution\"]:\n        \"\"\"List all executions associated with this dataset.\n\n        Returns all executions that used this dataset as input. This is\n        tracked through the Dataset_Execution association table.\n\n        Returns:\n            List of Execution objects associated with this dataset.\n\n        Example:\n            &gt;&gt;&gt; dataset = ml.lookup_dataset(\"1-abc123\")\n            &gt;&gt;&gt; executions = dataset.list_executions()\n            &gt;&gt;&gt; for exe in executions:\n            ...     print(f\"Execution {exe.execution_rid}: {exe.status}\")\n        \"\"\"\n        # Import here to avoid circular dependency\n\n        pb = self._ml_instance.pathBuilder()\n        dataset_execution_path = pb.schemas[self._ml_instance.ml_schema].Dataset_Execution\n\n        # Query for all executions associated with this dataset\n        records = list(\n            dataset_execution_path.filter(dataset_execution_path.Dataset == self.dataset_rid)\n            .entities()\n            .fetch()\n        )\n\n        return [self._ml_instance.lookup_execution(record[\"Execution\"]) for record in records]\n\n    @staticmethod\n    def _insert_dataset_versions(\n        ml_instance: DerivaMLCatalog,\n        dataset_list: list[DatasetSpec],\n        description: str | None = \"\",\n        execution_rid: RID | None = None,\n    ) -&gt; None:\n        \"\"\"Insert new version records for a list of datasets.\n\n        This internal method creates Dataset_Version records in the catalog for\n        each dataset in the list. It also captures a catalog snapshot timestamp\n        to associate with these versions.\n\n        The version record links:\n        - The dataset RID to its new version number\n        - An optional description of what changed\n        - An optional execution that triggered the version change\n        - The catalog snapshot time for reproducibility\n\n        Args:\n            ml_instance: The catalog instance to insert versions into.\n            dataset_list: List of DatasetSpec objects containing RID and version info.\n            description: Optional description of the version change.\n            execution_rid: Optional execution RID to associate with the version.\n        \"\"\"\n        schema_path = ml_instance.pathBuilder().schemas[ml_instance.ml_schema]\n\n        # Insert version records for all datasets in the list\n        version_records = schema_path.tables[\"Dataset_Version\"].insert(\n            [\n                {\n                    \"Dataset\": dataset.rid,\n                    \"Version\": str(dataset.version),\n                    \"Description\": description,\n                    \"Execution\": execution_rid,\n                }\n                for dataset in dataset_list\n            ]\n        )\n        version_records = list(version_records)\n\n        # Capture the current catalog snapshot timestamp. This allows us to\n        # recreate the exact state of the catalog when this version was created.\n        snap = ml_instance.catalog.get(\"/\").json()[\"snaptime\"]\n\n        # Update version records with the snapshot timestamp\n        schema_path.tables[\"Dataset_Version\"].update(\n            [{\"RID\": v[\"RID\"], \"Dataset\": v[\"Dataset\"], \"Snapshot\": snap} for v in version_records]\n        )\n\n        # Update each dataset's current version pointer to the new version record\n        schema_path.tables[\"Dataset\"].update([{\"Version\": v[\"RID\"], \"RID\": v[\"Dataset\"]} for v in version_records])\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def download_dataset_bag(\n        self,\n        version: DatasetVersion | str,\n        materialize: bool = True,\n        use_minid: bool = False,\n        exclude_tables: set[str] | None = None,\n    ) -&gt; DatasetBag:\n        \"\"\"Downloads a dataset to the local filesystem and optionally creates a MINID.\n\n        Downloads a dataset to the local file system. If the dataset has a version set, that version is used.\n        If the dataset has a version and a version is provided, the version specified takes precedence.\n\n        The exported bag contains all data reachable from this dataset's members by following\n        foreign key relationships (both incoming and outgoing). Starting from each member element\n        type, the export traverses all FK-connected tables, with vocabulary tables acting as\n        natural path terminators. Only paths starting from element types that have members in\n        this dataset are included.\n\n        Args:\n            version: Dataset version to download. If not specified, the version must be set in the dataset.\n            materialize: If True, materialize the dataset after downloading.\n            use_minid: If True, upload the bag to S3 and create a MINID for the dataset.\n                Requires s3_bucket to be configured on the catalog. Defaults to False.\n            exclude_tables: Optional set of table names to exclude from FK path traversal\n                during bag export. Tables in this set will not be visited, pruning branches\n                of the FK graph that pass through them. Useful for avoiding query timeouts\n                caused by expensive joins through large or unnecessary tables.\n\n        Returns:\n            DatasetBag: Object containing:\n                - path: Local filesystem path to downloaded dataset\n                - rid: Dataset's Resource Identifier\n                - minid: Dataset's Minimal Viable Identifier (if use_minid=True)\n\n        Raises:\n            DerivaMLException: If use_minid=True but s3_bucket is not configured on the catalog.\n\n        Examples:\n            Download without MINID (default):\n                &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\")\n                &gt;&gt;&gt; print(f\"Downloaded to {bag.path}\")\n\n            Download with MINID (requires s3_bucket configured):\n                &gt;&gt;&gt; # Catalog must be created with s3_bucket=\"s3://my-bucket\"\n                &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\", use_minid=True)\n\n            Exclude tables that cause query timeouts:\n                &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\", exclude_tables={\"Process\"})\n        \"\"\"\n        if isinstance(version, str):\n            version = DatasetVersion.parse(version)\n\n        # Validate use_minid requires s3_bucket configuration\n        if use_minid and not self._ml_instance.s3_bucket:\n            raise DerivaMLException(\n                \"Cannot use use_minid=True without s3_bucket configured. \"\n                \"Configure s3_bucket when creating the DerivaML instance to enable MINID support.\"\n            )\n\n        minid = self._get_dataset_minid(version, create=True, use_minid=use_minid, exclude_tables=exclude_tables)\n\n        bag_path = (\n            self._materialize_dataset_bag(minid, use_minid=use_minid)\n            if materialize\n            else self._download_dataset_minid(minid, use_minid)\n        )\n        from deriva_ml.model.deriva_ml_database import DerivaMLDatabase\n        db_model = DatabaseModel(minid, bag_path, self._ml_instance.working_dir)\n        return DerivaMLDatabase(db_model).lookup_dataset(self.dataset_rid)\n\n    def _version_snapshot_catalog(self, dataset_version: DatasetVersion | str | None) -&gt; DerivaMLCatalog:\n        \"\"\"Get a catalog instance bound to a specific version's snapshot.\n\n        Dataset versions are associated with catalog snapshots, which represent\n        the exact state of the catalog at the time the version was created.\n        This method returns a catalog instance that queries against that snapshot,\n        ensuring reproducible access to historical data.\n\n        Args:\n            dataset_version: The version to get a snapshot for, or None to use\n                the current catalog state.\n\n        Returns:\n            DerivaMLCatalog: Either a snapshot-bound catalog or the current catalog.\n        \"\"\"\n        if isinstance(dataset_version, str) and str:\n            dataset_version = DatasetVersion.parse(dataset_version)\n        if dataset_version:\n            return self._ml_instance.catalog_snapshot(self._version_snapshot_catalog_id(dataset_version))\n        else:\n            return self._ml_instance\n\n    def _version_snapshot_catalog_id(self, version: DatasetVersion | str) -&gt; str:\n        \"\"\"Get the catalog ID with snapshot suffix for a specific version.\n\n        Constructs a catalog identifier in the format \"catalog_id@snapshot_time\"\n        that can be used to access the catalog state at the time the version\n        was created.\n\n        Args:\n            version: The dataset version to get the snapshot for.\n\n        Returns:\n            str: Catalog ID with snapshot suffix (e.g., \"1@2023-01-15T10:30:00\").\n\n        Raises:\n            DerivaMLException: If the specified version doesn't exist.\n        \"\"\"\n        version = str(version)\n        try:\n            version_record = next(h for h in self.dataset_history() if h.dataset_version == version)\n        except StopIteration:\n            raise DerivaMLException(f\"Dataset version {version} not found for dataset {self.dataset_rid}\")\n        return (\n            f\"{self._ml_instance.catalog.catalog_id}@{version_record.snapshot}\"\n            if version_record.snapshot\n            else self._ml_instance.catalog.catalog_id\n        )\n\n    def _download_dataset_minid(self, minid: DatasetMinid, use_minid: bool) -&gt; Path:\n        \"\"\"Download and extract a dataset bag from a MINID or direct URL.\n\n        This method handles the download of a BDBag archive, either from S3 storage\n        (if using MINIDs) or directly from the catalog server. Downloaded bags are\n        cached by checksum to avoid redundant downloads.\n\n        Args:\n            minid: DatasetMinid containing the bag URL and metadata.\n            use_minid: If True, download from S3 using the MINID URL.\n                If False, download directly from the catalog server.\n\n        Returns:\n            Path: The path to the extracted and validated bag directory.\n\n        Note:\n            Bags are cached in the cache_dir with the naming convention:\n            \"{dataset_rid}_{checksum}/Dataset_{dataset_rid}\"\n        \"\"\"\n\n        # Check to see if we have an existing idempotent materialization of the desired bag. If so, then reuse\n        # it.  If not, then we need to extract the contents of the archive into our cache directory.\n        bag_dir = self._ml_instance.cache_dir / f\"{minid.dataset_rid}_{minid.checksum}\"\n        if bag_dir.exists():\n            self._logger.info(f\"Using cached bag for  {minid.dataset_rid} Version:{minid.dataset_version}\")\n            return Path(bag_dir / f\"Dataset_{minid.dataset_rid}\")\n\n        # Either bag hasn't been downloaded yet, or we are not using a Minid, so we don't know the checksum yet.\n        with TemporaryDirectory() as tmp_dir:\n            if use_minid:\n                # Get bag from S3\n                bag_path = Path(tmp_dir) / Path(urlparse(minid.bag_url).path).name\n                archive_path = fetch_single_file(minid.bag_url, output_path=bag_path)\n            elif minid.bag_url.startswith(\"file://\"):\n                # Client-side generated bag \u2014 already local\n                archive_path = urlparse(minid.bag_url).path\n            else:\n                exporter = DerivaExport(host=self._ml_instance.catalog.deriva_server.server, output_dir=tmp_dir)\n                archive_path = exporter.retrieve_file(minid.bag_url)\n            if not use_minid:\n                hashes = hash_utils.compute_file_hashes(archive_path, hashes=[\"md5\", \"sha256\"])\n                checksum = hashes[\"sha256\"][0]\n                bag_dir = self._ml_instance.cache_dir / f\"{minid.dataset_rid}_{checksum}\"\n                if bag_dir.exists():\n                    self._logger.info(f\"Using cached bag for  {minid.dataset_rid} Version:{minid.dataset_version}\")\n                    return Path(bag_dir / f\"Dataset_{minid.dataset_rid}\")\n            bag_path = bdb.extract_bag(archive_path, bag_dir.as_posix())\n        bdb.validate_bag_structure(bag_path)\n        return Path(bag_path)\n\n    def _create_dataset_minid(self, version: DatasetVersion, use_minid=True, exclude_tables: set[str] | None = None) -&gt; str:\n        \"\"\"Create a new MINID (Minimal Viable Identifier) for the dataset.\n\n        This method generates a BDBag export of the dataset and optionally\n        registers it with a MINID service for persistent identification.\n        The bag is uploaded to S3 storage when using MINIDs.\n\n        Args:\n            version: The dataset version to create a MINID for.\n            use_minid: If True, register with MINID service and upload to S3.\n                If False, just generate the bag and return a local URL.\n\n        Returns:\n            str: URL to the MINID landing page (if use_minid=True) or\n                the direct bag download URL.\n        \"\"\"\n        with TemporaryDirectory() as tmp_dir:\n            # Generate a download specification file for the current catalog schema. By default, this spec\n            # will generate a minid and place the bag into S3 storage.\n            spec_file = Path(tmp_dir) / \"download_spec.json\"\n            version_snapshot_catalog = self._version_snapshot_catalog(version)\n            downloader = CatalogGraph(\n                version_snapshot_catalog,\n                s3_bucket=self._ml_instance.s3_bucket,\n                use_minid=use_minid,\n                exclude_tables=exclude_tables,\n            )\n            spec = downloader.generate_dataset_download_spec(self)\n            with spec_file.open(\"w\", encoding=\"utf-8\") as ds:\n                json.dump(spec, ds)\n\n            self._logger.info(\n                \"Downloading dataset %s for catalog: %s@%s\"\n                % (\n                    \"minid\" if use_minid else \"bag\",\n                    self.dataset_rid,\n                    str(version),\n                )\n            )\n\n            if use_minid:\n                # Server-side export: generates bag, uploads to S3, registers MINID.\n                try:\n                    exporter = DerivaExport(\n                        host=self._ml_instance.catalog.deriva_server.server,\n                        config_file=spec_file,\n                        output_dir=tmp_dir,\n                        defer_download=True,\n                        timeout=(10, 610),\n                        envars={\"RID\": self.dataset_rid},\n                    )\n                    minid_page_url = exporter.export()[0]\n                except (\n                    DerivaDownloadError,\n                    DerivaDownloadConfigurationError,\n                    DerivaDownloadAuthenticationError,\n                    DerivaDownloadAuthorizationError,\n                    DerivaDownloadTimeoutError,\n                ) as e:\n                    raise DerivaMLException(format_exception(e))\n                # Update version table with MINID.\n                version_path = (\n                    self._ml_instance.pathBuilder().schemas[self._ml_instance.ml_schema].tables[\"Dataset_Version\"]\n                )\n                version_rid = [h for h in self.dataset_history() if h.dataset_version == version][0].version_rid\n                version_path.update([{\"RID\": version_rid, \"Minid\": minid_page_url}])\n                return minid_page_url\n            else:\n                # Client-side download: runs queries locally with paged query support\n                # for automatic retry on query timeout errors. This avoids server-side\n                # export lock contention and gives better control over query execution.\n                return self._create_dataset_bag_client(version, spec)\n\n    def _create_dataset_bag_client(self, version: DatasetVersion, spec: dict) -&gt; str:\n        \"\"\"Create a dataset bag using client-side download.\n\n        Executes ERMrest queries directly using ErmrestCatalog.get_as_file() with\n        paged query support, building a BDBag from the results.\n\n        If any CSV data query fails (e.g., due to server-side query timeouts on deep\n        multi-table joins), the method raises a DerivaMLException listing the failed\n        tables and suggesting that the user add those records as direct dataset members.\n\n        Args:\n            version: The dataset version to export.\n            spec: The download specification dict (from generate_dataset_download_spec).\n\n        Returns:\n            str: A file:// URI pointing to the generated bag zip archive.\n\n        Raises:\n            DerivaMLException: If any data query fails during export.\n        \"\"\"\n        import csv\n        import codecs\n        import uuid\n\n        from deriva.core import DerivaServer, get_credential\n\n        snapshot_catalog_id = self._version_snapshot_catalog_id(version)\n        hostname = self._ml_instance.catalog.deriva_server.server\n        protocol = self._ml_instance.catalog.deriva_server.scheme\n\n        # Connect to the snapshot catalog\n        credentials = get_credential(hostname)\n        server = DerivaServer(protocol, hostname, credentials=credentials)\n        catalog = server.connect_ermrest(snapshot_catalog_id)\n\n        # Build bag in a persistent directory (survives for _download_dataset_minid)\n        tmp_dir = Path(self._ml_instance.working_dir) / \"client_export\" / str(uuid.uuid4())[:8]\n        tmp_dir.mkdir(parents=True, exist_ok=True)\n\n        # Format environment variables\n        envars = {\"RID\": self.dataset_rid}\n        bag_config = spec.get(\"bag\", {})\n        bag_name = bag_config.get(\"bag_name\", f\"Dataset_{self.dataset_rid}\").format(**envars)\n        bag_path = tmp_dir / bag_name\n        bag_algorithms = bag_config.get(\"bag_algorithms\", [\"md5\"])\n\n        # Create the bag\n        bdb.ensure_bag_path_exists(str(bag_path))\n        bag = bdb.make_bag(str(bag_path), algs=bag_algorithms, idempotent=True)\n\n        # Process query_processors from the spec\n        query_processors = spec.get(\"catalog\", {}).get(\"query_processors\", [])\n        failed_queries = []\n        skipped_empty = []\n        fetch_entries = []  # (url, length, rel_path, md5) tuples for fetch.txt\n\n        for qp in query_processors:\n            processor_name = qp.get(\"processor\", \"\")\n            params = qp.get(\"processor_params\", {})\n\n            if processor_name == \"env\":\n                # Environment variable processors \u2014 execute and capture values\n                query_path = params.get(\"query_path\", \"\")\n                if not query_path:\n                    continue\n                query_path = query_path.format(**envars)\n                query_keys = params.get(\"query_keys\", [])\n                try:\n                    if query_path == \"/\":\n                        # Root query returns catalog metadata including snaptime\n                        resp = catalog.get(\"/\").json()\n                    else:\n                        resp = catalog.get(query_path).json()\n                    if isinstance(resp, list) and resp:\n                        resp = resp[0]\n                    if resp and query_keys:\n                        for key in query_keys:\n                            if key in resp:\n                                envars[key] = resp[key]\n                except Exception as e:\n                    self._logger.warning(\"Failed to execute env query %s: %s\", query_path, e)\n\n            elif processor_name == \"json\":\n                # JSON query (e.g., schema dump)\n                query_path = params.get(\"query_path\", \"\")\n                output_path = params.get(\"output_path\", \"\")\n                if not query_path:\n                    continue\n                query_path = query_path.format(**envars)\n                # Output path becomes filename with .json extension\n                dest_file = bag_path / \"data\" / (output_path + \".json\")\n                dest_file.parent.mkdir(parents=True, exist_ok=True)\n                try:\n                    resp = catalog.get(query_path).json()\n                    dest_file.write_text(json.dumps(resp, indent=2), encoding=\"utf-8\")\n                except Exception as e:\n                    raise RuntimeError(\n                        f\"Failed to download {output_path} from snapshot catalog \"\n                        f\"({query_path}): {e}\"\n                    ) from e\n\n            elif processor_name == \"csv\":\n                # Data query \u2014 use paged mode for resilience\n                query_path = params.get(\"query_path\", \"\")\n                output_path = params.get(\"output_path\", \"\")\n                if not query_path:\n                    continue\n                query_path = query_path.format(**envars)\n                paged = params.get(\"paged_query\", False)\n\n                dest_dir = bag_path / \"data\" / output_path\n                dest_dir.mkdir(parents=True, exist_ok=True)\n                dest_file = str(dest_dir) + \".csv\"\n\n                try:\n                    catalog.get_as_file(\n                        query_path,\n                        dest_file,\n                        headers={\"accept\": \"text/csv\"},\n                        delete_if_empty=True,\n                        paged=paged,\n                        page_size=100000,\n                    )\n                    if not os.path.isfile(dest_file):\n                        skipped_empty.append(output_path)\n                except Exception as e:\n                    # Tolerate individual query failures \u2014 log and continue.\n                    # This handles snapshot catalog timeouts for large joins.\n                    self._logger.warning(\n                        \"Query failed for %s (will be missing from bag): %s\",\n                        output_path,\n                        e,\n                    )\n                    failed_queries.append(output_path)\n                    # Clean up partial file if it exists\n                    if os.path.isfile(dest_file):\n                        os.remove(dest_file)\n\n            elif processor_name == \"fetch\":\n                # Asset file references \u2014 write entries to fetch.txt for lazy materialization.\n                # The actual binary files are downloaded later by bdbag.materialize() when\n                # materialize=True is set on download_dataset_bag().\n                query_path = params.get(\"query_path\", \"\")\n                output_path = params.get(\"output_path\", \"\")\n                if not query_path:\n                    continue\n                query_path = query_path.format(**envars)\n\n                try:\n                    resp = catalog.get(query_path).json()\n                    for record in resp:\n                        url = record.get(\"url\")\n                        filename = record.get(\"filename\", \"unknown\")\n                        length = record.get(\"length\", \"\")\n                        md5 = record.get(\"md5\", \"\")\n                        asset_rid = record.get(\"asset_rid\", \"unknown\")\n                        if not url:\n                            continue\n                        # Build the full URL for the asset\n                        if url.startswith(\"/\"):\n                            asset_url = f\"{protocol}://{hostname}{url}\"\n                        else:\n                            asset_url = url\n                        # Build relative path within bag data directory\n                        file_output_path = output_path.format(asset_rid=asset_rid)\n                        rel_path = f\"data/{file_output_path}/{filename}\"\n                        # Add to fetch.txt entries\n                        fetch_entries.append((asset_url, length, rel_path, md5))\n                except Exception as e:\n                    self._logger.warning(\"Asset query failed for %s: %s\", output_path, e)\n\n        # Remove empty directories left behind by empty/failed queries\n        for dirpath, dirnames, filenames in os.walk(str(bag_path / \"data\"), topdown=False):\n            if not dirnames and not filenames:\n                try:\n                    os.rmdir(dirpath)\n                except OSError:\n                    pass\n\n        if failed_queries:\n            # Extract table names from output paths (format: \"schema/table\")\n            failed_tables = [q.rsplit(\"/\", 1)[-1] if \"/\" in q else q for q in failed_queries]\n            raise DerivaMLException(\n                f\"Dataset bag export failed: {len(failed_queries)} queries timed out or \"\n                f\"failed for tables: {failed_tables}. \"\n                f\"This typically happens when deep multi-table joins exceed server query \"\n                f\"time limits. To fix this, add the desired records as direct dataset \"\n                f\"members using add_dataset_members() with the relevant table's RIDs. \"\n                f\"For example, if Image data is missing, register Image as a dataset \"\n                f\"element type (add_dataset_element_type('Image')) and add Image RIDs \"\n                f\"as members so they are exported via a direct association path rather \"\n                f\"than a deep FK join. Failed paths: {failed_queries}\"\n            )\n\n        # Write fetch.txt for remote asset references.\n        # BDBag's materialize() handles directory creation for fetch targets.\n        if fetch_entries:\n            fetch_file = bag_path / \"fetch.txt\"\n            with fetch_file.open(\"w\", encoding=\"utf-8\") as f:\n                for url, length, rel_path, md5 in fetch_entries:\n                    length_str = str(length) if length else \"-\"\n                    f.write(f\"{url}\\t{length_str}\\t{rel_path}\\n\")\n            self._logger.info(\"Wrote %d fetch entries for remote assets\", len(fetch_entries))\n\n        # Update and archive the bag\n        bdb.make_bag(str(bag_path), algs=bag_algorithms, update=True, idempotent=True)\n        archive_path = bdb.archive_bag(str(bag_path), bag_config.get(\"bag_archiver\", \"zip\"))\n        return Path(archive_path).as_uri()\n\n    def _get_dataset_minid(\n        self,\n        version: DatasetVersion,\n        create: bool,\n        use_minid: bool,\n        exclude_tables: set[str] | None = None,\n    ) -&gt; DatasetMinid | None:\n        \"\"\"Get or create a MINID for the specified dataset version.\n\n        This method retrieves the MINID associated with a specific dataset version,\n        optionally creating one if it doesn't exist.\n\n        Args:\n            version: The dataset version to get the MINID for.\n            create: If True, create a new MINID if one doesn't already exist.\n                If False, raise an exception if no MINID exists.\n            use_minid: If True, use the MINID service for persistent identification.\n                If False, generate a direct download URL without MINID registration.\n\n        Returns:\n            DatasetMinid: Object containing the MINID URL, checksum, and metadata.\n\n        Raises:\n            DerivaMLException: If the version doesn't exist, or if create=False\n                and no MINID exists.\n        \"\"\"\n\n        # Find dataset version record\n        version_str = str(version)\n        history = self.dataset_history()\n        try:\n            version_record = next(v for v in history if v.dataset_version == version_str)\n        except StopIteration:\n            raise DerivaMLException(f\"Version {version_str} does not exist for RID {self.dataset_rid}\")\n\n        # Check or create MINID\n        minid_url = version_record.minid\n        # If we either don't have a MINID, or we have a MINID, but we don't want to use it, generate a new one.\n        if (not minid_url) or (not use_minid):\n            if not create:\n                raise DerivaMLException(f\"Minid for dataset {self.dataset_rid} doesn't exist\")\n            if use_minid:\n                self._logger.info(\"Creating new MINID for dataset %s\", self.dataset_rid)\n            minid_url = self._create_dataset_minid(version, use_minid=use_minid, exclude_tables=exclude_tables)\n\n        # Return based on MINID usage\n        if use_minid:\n            return self._fetch_minid_metadata(version, minid_url)\n        return DatasetMinid(\n            dataset_version=version,\n            RID=f\"{self.dataset_rid}@{version_record.snapshot}\",\n            location=minid_url,\n        )\n\n    def _fetch_minid_metadata(self, version: DatasetVersion, url: str) -&gt; DatasetMinid:\n        \"\"\"Fetch MINID metadata from the MINID service.\n\n        Args:\n            version: The dataset version associated with this MINID.\n            url: The MINID landing page URL.\n\n        Returns:\n            DatasetMinid: Parsed metadata including bag URL, checksum, and identifiers.\n\n        Raises:\n            requests.HTTPError: If the MINID service request fails.\n        \"\"\"\n        r = requests.get(url, headers={\"accept\": \"application/json\"})\n        r.raise_for_status()\n        return DatasetMinid(dataset_version=version, **r.json())\n\n    def _materialize_dataset_bag(\n        self,\n        minid: DatasetMinid,\n        use_minid: bool,\n    ) -&gt; Path:\n        \"\"\"Materialize a dataset bag by downloading all referenced files.\n\n        This method downloads a BDBag and then \"materializes\" it by fetching\n        all files referenced in the bag's fetch.txt manifest. This includes\n        data files, assets, and any other content referenced by the bag.\n\n        Progress is reported through callbacks that update the execution status\n        if this download is associated with an execution.\n\n        Args:\n            minid: DatasetMinid containing the bag URL and metadata.\n            use_minid: If True, download from S3 using the MINID URL.\n\n        Returns:\n            Path: The path to the fully materialized bag directory.\n\n        Note:\n            Materialization status is cached via a 'validated_check.txt' marker\n            file to avoid re-downloading already-materialized bags.\n        \"\"\"\n\n        def update_status(status: Status, msg: str) -&gt; None:\n            \"\"\"Update the current status for this execution in the catalog\"\"\"\n            if self.execution_rid and self.execution_rid != DRY_RUN_RID:\n                self._ml_instance.pathBuilder().schemas[self._ml_instance.ml_schema].Execution.update(\n                    [\n                        {\n                            \"RID\": self.execution_rid,\n                            \"Status\": status.value,\n                            \"Status_Detail\": msg,\n                        }\n                    ]\n                )\n            self._logger.info(msg)\n\n        def fetch_progress_callback(current, total):\n            msg = f\"Materializing bag: {current} of {total} file(s) downloaded.\"\n            if self.execution_rid:\n                update_status(Status.running, msg)\n            return True\n\n        def validation_progress_callback(current, total):\n            msg = f\"Validating bag: {current} of {total} file(s) validated.\"\n            if self.execution_rid:\n                update_status(Status.running, msg)\n            return True\n\n        # request metadata\n        bag_path = self._download_dataset_minid(minid, use_minid)\n        bag_dir = bag_path.parent\n        validated_check = bag_dir / \"validated_check.txt\"\n\n        # If this bag has already been validated, our work is done.  Otherwise, materialize the bag.\n        if not validated_check.exists():\n            self._logger.info(f\"Materializing bag {minid.dataset_rid} Version:{minid.dataset_version}\")\n            # Ensure parent directories exist for all fetch entries\n            fetch_file = bag_path / \"fetch.txt\"\n            if fetch_file.exists():\n                with fetch_file.open(\"r\", encoding=\"utf-8\") as f:\n                    for line in f:\n                        parts = line.strip().split(\"\\t\")\n                        if len(parts) &gt;= 3:\n                            rel_path = parts[2]\n                            (bag_path / rel_path).parent.mkdir(parents=True, exist_ok=True)\n            bdb.materialize(\n                bag_path.as_posix(),\n                fetch_callback=fetch_progress_callback,\n                validation_callback=validation_progress_callback,\n            )\n            validated_check.touch()\n        return Path(bag_path)\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset--create-a-new-dataset-via-an-execution","title":"Create a new dataset via an execution","text":"<p>with ml.create_execution(config) as exe: ...     dataset = exe.create_dataset( ...         dataset_types=[\"training_data\"], ...         description=\"Image classification training set\" ...     ) ...     # Add members to the dataset ...     dataset.add_dataset_members(members=[\"1-abc\", \"1-def\"]) ...     # Increment version after changes ...     new_version = dataset.increment_dataset_version(VersionPart.minor, \"Added samples\")</p>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset--download-for-offline-use","title":"Download for offline use","text":"<p>bag = dataset.download_dataset_bag(version=new_version)</p>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.current_version","title":"current_version  <code>property</code>","text":"<pre><code>current_version: DatasetVersion\n</code></pre> <p>Retrieve the current version of the specified dataset_table.</p> <p>Return the most recent version of the dataset. It is important to remember that this version captures the state of the catalog at the time the version was created, not the current state of the catalog. This means that its possible that the values associated with an object in the catalog may be different from the values of that object in the dataset.</p> <p>Returns:</p> Type Description <code>DatasetVersion</code> <p>A tuple with the semantic version of the dataset_table.</p>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.dataset_types","title":"dataset_types  <code>property</code>","text":"<pre><code>dataset_types: list[str]\n</code></pre> <p>Get the dataset types from the catalog.</p> <p>This property fetches the current dataset types directly from the catalog, ensuring consistency when multiple Dataset instances reference the same dataset or when types are modified externally.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of dataset type term names from the Dataset_Type vocabulary.</p>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.__eq__","title":"__eq__","text":"<pre><code>__eq__(other: object) -&gt; bool\n</code></pre> <p>Check equality based on dataset RID.</p> <p>Two Dataset objects are considered equal if they reference the same dataset RID, regardless of other attributes like version or types.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>object</code> <p>Object to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if other is a Dataset with the same RID, False otherwise.</p> <code>bool</code> <p>Returns NotImplemented for non-Dataset objects.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Check equality based on dataset RID.\n\n    Two Dataset objects are considered equal if they reference the same\n    dataset RID, regardless of other attributes like version or types.\n\n    Args:\n        other: Object to compare with.\n\n    Returns:\n        True if other is a Dataset with the same RID, False otherwise.\n        Returns NotImplemented for non-Dataset objects.\n    \"\"\"\n    if not isinstance(other, Dataset):\n        return NotImplemented\n    return self.dataset_rid == other.dataset_rid\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.__hash__","title":"__hash__","text":"<pre><code>__hash__() -&gt; int\n</code></pre> <p>Return hash based on dataset RID for use in sets and as dict keys.</p> <p>This allows Dataset objects to be stored in sets and used as dictionary keys. Two Dataset objects with the same RID will hash to the same value.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Return hash based on dataset RID for use in sets and as dict keys.\n\n    This allows Dataset objects to be stored in sets and used as dictionary keys.\n    Two Dataset objects with the same RID will hash to the same value.\n    \"\"\"\n    return hash(self.dataset_rid)\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.__init__","title":"__init__","text":"<pre><code>__init__(\n    catalog: DerivaMLCatalog,\n    dataset_rid: RID,\n    description: str = \"\",\n    execution_rid: RID | None = None,\n)\n</code></pre> <p>Initialize a Dataset object from an existing dataset in the catalog.</p> <p>This constructor wraps an existing dataset record. To create a new dataset in the catalog, use the static method Dataset.create_dataset() instead.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>DerivaMLCatalog</code> <p>The DerivaMLCatalog instance containing this dataset.</p> required <code>dataset_rid</code> <code>RID</code> <p>The RID of the existing dataset record.</p> required <code>description</code> <code>str</code> <p>Human-readable description of the dataset's purpose and contents.</p> <code>''</code> <code>execution_rid</code> <code>RID | None</code> <p>Optional execution RID that created or is associated with this dataset.</p> <code>None</code> Example Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef __init__(\n    self,\n    catalog: DerivaMLCatalog,\n    dataset_rid: RID,\n    description: str = \"\",\n    execution_rid: RID | None = None,\n):\n    \"\"\"Initialize a Dataset object from an existing dataset in the catalog.\n\n    This constructor wraps an existing dataset record. To create a new dataset\n    in the catalog, use the static method Dataset.create_dataset() instead.\n\n    Args:\n        catalog: The DerivaMLCatalog instance containing this dataset.\n        dataset_rid: The RID of the existing dataset record.\n        description: Human-readable description of the dataset's purpose and contents.\n        execution_rid: Optional execution RID that created or is associated with this dataset.\n\n    Example:\n        &gt;&gt;&gt; # Wrap an existing dataset\n        &gt;&gt;&gt; dataset = Dataset(catalog=ml, dataset_rid=\"4HM\")\n    \"\"\"\n    self._logger = logging.getLogger(\"deriva_ml\")\n    self.dataset_rid = dataset_rid\n    self.execution_rid = execution_rid\n    self._ml_instance = catalog\n    self.description = description\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.__init__--wrap-an-existing-dataset","title":"Wrap an existing dataset","text":"<p>dataset = Dataset(catalog=ml, dataset_rid=\"4HM\")</p>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Return a string representation of the Dataset for debugging.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the Dataset for debugging.\"\"\"\n    return (f\"&lt;deriva_ml.Dataset object at {hex(id(self))}: rid='{self.dataset_rid}', \"\n            f\"version='{self.current_version}', types={self.dataset_types}&gt;\")\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.add_dataset_members","title":"add_dataset_members","text":"<pre><code>add_dataset_members(\n    members: list[RID]\n    | dict[str, list[RID]],\n    validate: bool = True,\n    description: str | None = \"\",\n    execution_rid: RID | None = None,\n) -&gt; None\n</code></pre> <p>Adds members to a dataset.</p> <p>Associates one or more records with a dataset. Members can be provided in two forms:</p> <p>List of RIDs (simpler but slower): When <code>members</code> is a list of RIDs, each RID is resolved to determine which table it belongs to. This uses batch RID resolution for efficiency, but still requires querying the catalog to identify each RID's table.</p> <p>Dictionary by table name (faster, recommended for large datasets): When <code>members</code> is a dict mapping table names to lists of RIDs, no RID resolution is needed. The RIDs are inserted directly into the dataset. Use this form when you already know which table each RID belongs to.</p> <p>Important: Members can only be added from tables that have been registered as dataset element types. Use :meth:<code>DerivaML.add_dataset_element_type</code> to register a table before adding its records to datasets.</p> <p>Adding members automatically increments the dataset's minor version.</p> <p>Parameters:</p> Name Type Description Default <code>members</code> <code>list[RID] | dict[str, list[RID]]</code> <p>Either: - list[RID]: List of RIDs to add. Each RID will be resolved to find its table. - dict[str, list[RID]]: Mapping of table names to RID lists. Skips resolution.</p> required <code>validate</code> <code>bool</code> <p>Whether to validate that members don't already exist. Defaults to True.</p> <code>True</code> <code>description</code> <code>str | None</code> <p>Optional description of the member additions.</p> <code>''</code> <code>execution_rid</code> <code>RID | None</code> <p>Optional execution RID to associate with changes.</p> <code>None</code> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If: - Any RID is invalid or cannot be resolved - Any RID belongs to a table that isn't registered as a dataset element type - Adding members would create a cycle (for nested datasets) - Validation finds duplicate members (when validate=True)</p> See Also <p>:meth:<code>DerivaML.add_dataset_element_type</code>: Register a table as a dataset element type. :meth:<code>DerivaML.list_dataset_element_types</code>: List registered dataset element types.</p> <p>Examples:</p> <p>Using a list of RIDs (simpler):     &gt;&gt;&gt; dataset.add_dataset_members(     ...     members=[\"1-ABC\", \"1-DEF\", \"1-GHI\"],     ...     description=\"Added sample images\"     ... )</p> <p>Using a dict by table name (faster for large datasets):     &gt;&gt;&gt; dataset.add_dataset_members(     ...     members={     ...         \"Image\": [\"1-ABC\", \"1-DEF\"],     ...         \"Subject\": [\"2-XYZ\"]     ...     },     ...     description=\"Added images and subjects\"     ... )</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef add_dataset_members(\n    self,\n    members: list[RID] | dict[str, list[RID]],\n    validate: bool = True,\n    description: str | None = \"\",\n    execution_rid: RID | None = None,\n) -&gt; None:\n    \"\"\"Adds members to a dataset.\n\n    Associates one or more records with a dataset. Members can be provided in two forms:\n\n    **List of RIDs (simpler but slower):**\n    When `members` is a list of RIDs, each RID is resolved to determine which table\n    it belongs to. This uses batch RID resolution for efficiency, but still requires\n    querying the catalog to identify each RID's table.\n\n    **Dictionary by table name (faster, recommended for large datasets):**\n    When `members` is a dict mapping table names to lists of RIDs, no RID resolution\n    is needed. The RIDs are inserted directly into the dataset. Use this form when\n    you already know which table each RID belongs to.\n\n    **Important:** Members can only be added from tables that have been registered as\n    dataset element types. Use :meth:`DerivaML.add_dataset_element_type` to register\n    a table before adding its records to datasets.\n\n    Adding members automatically increments the dataset's minor version.\n\n    Args:\n        members: Either:\n            - list[RID]: List of RIDs to add. Each RID will be resolved to find its table.\n            - dict[str, list[RID]]: Mapping of table names to RID lists. Skips resolution.\n        validate: Whether to validate that members don't already exist. Defaults to True.\n        description: Optional description of the member additions.\n        execution_rid: Optional execution RID to associate with changes.\n\n    Raises:\n        DerivaMLException: If:\n            - Any RID is invalid or cannot be resolved\n            - Any RID belongs to a table that isn't registered as a dataset element type\n            - Adding members would create a cycle (for nested datasets)\n            - Validation finds duplicate members (when validate=True)\n\n    See Also:\n        :meth:`DerivaML.add_dataset_element_type`: Register a table as a dataset element type.\n        :meth:`DerivaML.list_dataset_element_types`: List registered dataset element types.\n\n    Examples:\n        Using a list of RIDs (simpler):\n            &gt;&gt;&gt; dataset.add_dataset_members(\n            ...     members=[\"1-ABC\", \"1-DEF\", \"1-GHI\"],\n            ...     description=\"Added sample images\"\n            ... )\n\n        Using a dict by table name (faster for large datasets):\n            &gt;&gt;&gt; dataset.add_dataset_members(\n            ...     members={\n            ...         \"Image\": [\"1-ABC\", \"1-DEF\"],\n            ...         \"Subject\": [\"2-XYZ\"]\n            ...     },\n            ...     description=\"Added images and subjects\"\n            ... )\n    \"\"\"\n    description = description or \"Updated dataset via add_dataset_members\"\n\n    def check_dataset_cycle(member_rid, path=None):\n        \"\"\"\n\n        Args:\n          member_rid:\n          path: (Default value = None)\n\n        Returns:\n\n        \"\"\"\n        path = path or set(self.dataset_rid)\n        return member_rid in path\n\n    if validate:\n        existing_rids = set(m[\"RID\"] for ms in self.list_dataset_members().values() for m in ms)\n        if overlap := set(existing_rids).intersection(members):\n            raise DerivaMLException(\n                f\"Attempting to add existing member to dataset_table {self.dataset_rid}: {overlap}\"\n            )\n\n    # Now go through every rid to be added to the data set and sort them based on what association table entries\n    # need to be made.\n    dataset_elements: dict[str, list[RID]] = {}\n\n    # Build map of valid element tables to their association tables\n    associations = list(self._dataset_table.find_associations())\n    association_map = {a.other_fkeys.pop().pk_table.name: a.table.name for a in associations}\n\n    # Get a list of all the object types that can be linked to a dataset_table.\n    if type(members) is list:\n        members = set(members)\n\n        # Get candidate tables for batch resolution (only tables that can be dataset elements)\n        candidate_tables = [\n            self._ml_instance.model.name_to_table(table_name) for table_name in association_map.keys()\n        ]\n\n        # Batch resolve all RIDs at once instead of one-by-one\n        rid_results = self._ml_instance.resolve_rids(members, candidate_tables=candidate_tables)\n\n        # Group by table and validate\n        for rid, rid_info in rid_results.items():\n            if rid_info.table_name not in association_map:\n                raise DerivaMLException(f\"RID table: {rid_info.table_name} not part of dataset_table\")\n            if rid_info.table == self._dataset_table and check_dataset_cycle(rid_info.rid):\n                raise DerivaMLException(\"Creating cycle of datasets is not allowed\")\n            dataset_elements.setdefault(rid_info.table_name, []).append(rid_info.rid)\n    else:\n        dataset_elements = {t: list(set(ms)) for t, ms in members.items()}\n    # Now make the entries into the association tables.\n    pb = self._ml_instance.pathBuilder()\n    for table, elements in dataset_elements.items():\n        # Determine schema: ML schema for Dataset/File, otherwise use the table's actual schema\n        if table == \"Dataset\" or table == \"File\":\n            schema_name = self._ml_instance.ml_schema\n        else:\n            # Find the table and use its schema\n            table_obj = self._ml_instance.model.name_to_table(table)\n            schema_name = table_obj.schema.name\n        schema_path = pb.schemas[schema_name]\n        fk_column = \"Nested_Dataset\" if table == \"Dataset\" else table\n        if len(elements):\n            # Find out the name of the column in the association table.\n            schema_path.tables[association_map[table]].insert(\n                [{\"Dataset\": self.dataset_rid, fk_column: e} for e in elements]\n            )\n    self.increment_dataset_version(\n        VersionPart.minor,\n        description=description,\n        execution_rid=execution_rid,\n    )\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.add_dataset_type","title":"add_dataset_type","text":"<pre><code>add_dataset_type(\n    dataset_type: str | VocabularyTerm,\n    _skip_version_increment: bool = False,\n) -&gt; None\n</code></pre> <p>Add a dataset type to this dataset.</p> <p>Adds a type term to this dataset if it's not already present. The term must exist in the Dataset_Type vocabulary. Also increments the dataset's minor version to reflect the metadata change.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_type</code> <code>str | VocabularyTerm</code> <p>Term name (string) or VocabularyTerm object from Dataset_Type vocabulary.</p> required <code>_skip_version_increment</code> <code>bool</code> <p>Internal parameter to skip version increment when called from add_dataset_types (which handles versioning itself).</p> <code>False</code> <p>Raises:</p> Type Description <code>DerivaMLInvalidTerm</code> <p>If the term doesn't exist in the Dataset_Type vocabulary.</p> Example <p>dataset.add_dataset_type(\"Training\") dataset.add_dataset_type(\"Validation\")</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def add_dataset_type(\n    self,\n    dataset_type: str | VocabularyTerm,\n    _skip_version_increment: bool = False,\n) -&gt; None:\n    \"\"\"Add a dataset type to this dataset.\n\n    Adds a type term to this dataset if it's not already present. The term must\n    exist in the Dataset_Type vocabulary. Also increments the dataset's minor\n    version to reflect the metadata change.\n\n    Args:\n        dataset_type: Term name (string) or VocabularyTerm object from Dataset_Type vocabulary.\n        _skip_version_increment: Internal parameter to skip version increment when\n            called from add_dataset_types (which handles versioning itself).\n\n    Raises:\n        DerivaMLInvalidTerm: If the term doesn't exist in the Dataset_Type vocabulary.\n\n    Example:\n        &gt;&gt;&gt; dataset.add_dataset_type(\"Training\")\n        &gt;&gt;&gt; dataset.add_dataset_type(\"Validation\")\n    \"\"\"\n    # Convert to VocabularyTerm if needed (validates the term exists)\n    if isinstance(dataset_type, VocabularyTerm):\n        vocab_term = dataset_type\n    else:\n        vocab_term = self._ml_instance.lookup_term(MLVocab.dataset_type, dataset_type)\n\n    # Check if already present\n    if vocab_term.name in self.dataset_types:\n        return\n\n    # Insert into association table\n    _, atable_path = self._get_dataset_type_association_table()\n    atable_path.insert([{MLVocab.dataset_type: vocab_term.name, \"Dataset\": self.dataset_rid}])\n\n    # Increment minor version to reflect metadata change (unless called from add_dataset_types)\n    if not _skip_version_increment:\n        self.increment_dataset_version(\n            VersionPart.minor,\n            description=f\"Added dataset type: {vocab_term.name}\",\n        )\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.add_dataset_types","title":"add_dataset_types","text":"<pre><code>add_dataset_types(\n    dataset_types: str\n    | VocabularyTerm\n    | list[str | VocabularyTerm],\n    _skip_version_increment: bool = False,\n) -&gt; None\n</code></pre> <p>Add one or more dataset types to this dataset.</p> <p>Convenience method for adding multiple types at once. Each term must exist in the Dataset_Type vocabulary. Types that are already associated with the dataset are silently skipped. Increments the dataset's minor version once after all types are added.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_types</code> <code>str | VocabularyTerm | list[str | VocabularyTerm]</code> <p>Single term or list of terms. Can be strings (term names) or VocabularyTerm objects.</p> required <code>_skip_version_increment</code> <code>bool</code> <p>Internal parameter to skip version increment (used during initial dataset creation).</p> <code>False</code> <p>Raises:</p> Type Description <code>DerivaMLInvalidTerm</code> <p>If any term doesn't exist in the Dataset_Type vocabulary.</p> Example <p>dataset.add_dataset_types([\"Training\", \"Image\"]) dataset.add_dataset_types(\"Testing\")</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def add_dataset_types(\n    self,\n    dataset_types: str | VocabularyTerm | list[str | VocabularyTerm],\n    _skip_version_increment: bool = False,\n) -&gt; None:\n    \"\"\"Add one or more dataset types to this dataset.\n\n    Convenience method for adding multiple types at once. Each term must exist\n    in the Dataset_Type vocabulary. Types that are already associated with the\n    dataset are silently skipped. Increments the dataset's minor version once\n    after all types are added.\n\n    Args:\n        dataset_types: Single term or list of terms. Can be strings (term names)\n            or VocabularyTerm objects.\n        _skip_version_increment: Internal parameter to skip version increment\n            (used during initial dataset creation).\n\n    Raises:\n        DerivaMLInvalidTerm: If any term doesn't exist in the Dataset_Type vocabulary.\n\n    Example:\n        &gt;&gt;&gt; dataset.add_dataset_types([\"Training\", \"Image\"])\n        &gt;&gt;&gt; dataset.add_dataset_types(\"Testing\")\n    \"\"\"\n    # Normalize input to a list\n    types_to_add = [dataset_types] if not isinstance(dataset_types, list) else dataset_types\n\n    # Track which types were actually added (not already present)\n    added_types: list[str] = []\n    for term in types_to_add:\n        # Get term name before calling add_dataset_type\n        if isinstance(term, VocabularyTerm):\n            term_name = term.name\n        else:\n            term_name = self._ml_instance.lookup_term(MLVocab.dataset_type, term).name\n\n        # Check if already present before adding\n        if term_name not in self.dataset_types:\n            self.add_dataset_type(term, _skip_version_increment=True)\n            added_types.append(term_name)\n\n    # Increment version once for all added types (if any were added)\n    if added_types and not _skip_version_increment:\n        type_names = \", \".join(added_types)\n        self.increment_dataset_version(\n            VersionPart.minor,\n            description=f\"Added dataset type(s): {type_names}\",\n        )\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.create_dataset","title":"create_dataset  <code>staticmethod</code>","text":"<pre><code>create_dataset(\n    ml_instance: DerivaMLCatalog,\n    execution_rid: RID,\n    dataset_types: str\n    | list[str]\n    | None = None,\n    description: str = \"\",\n    version: DatasetVersion\n    | None = None,\n) -&gt; Self\n</code></pre> <p>Creates a new dataset in the catalog.</p> <p>Creates a dataset with specified types and description. The dataset must be associated with an execution for provenance tracking.</p> <p>Parameters:</p> Name Type Description Default <code>ml_instance</code> <code>DerivaMLCatalog</code> <p>DerivaMLCatalog instance.</p> required <code>execution_rid</code> <code>RID</code> <p>Execution RID to associate with dataset creation (required).</p> required <code>dataset_types</code> <code>str | list[str] | None</code> <p>One or more dataset type terms from Dataset_Type vocabulary.</p> <code>None</code> <code>description</code> <code>str</code> <p>Description of the dataset's purpose and contents.</p> <code>''</code> <code>version</code> <code>DatasetVersion | None</code> <p>Optional initial version number. Defaults to 0.1.0.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Self</code> <p>The newly created dataset.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If dataset_types are invalid or creation fails.</p> Example <p>with ml.create_execution(config) as exe: ...     dataset = exe.create_dataset( ...         dataset_types=[\"experiment\", \"raw_data\"], ...         description=\"RNA sequencing experiment data\", ...         version=DatasetVersion(1, 0, 0) ...     )</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@staticmethod\n@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef create_dataset(\n    ml_instance: DerivaMLCatalog,\n    execution_rid: RID,\n    dataset_types: str | list[str] | None = None,\n    description: str = \"\",\n    version: DatasetVersion | None = None,\n) -&gt; Self:\n    \"\"\"Creates a new dataset in the catalog.\n\n    Creates a dataset with specified types and description. The dataset must be\n    associated with an execution for provenance tracking.\n\n    Args:\n        ml_instance: DerivaMLCatalog instance.\n        execution_rid: Execution RID to associate with dataset creation (required).\n        dataset_types: One or more dataset type terms from Dataset_Type vocabulary.\n        description: Description of the dataset's purpose and contents.\n        version: Optional initial version number. Defaults to 0.1.0.\n\n    Returns:\n        Dataset: The newly created dataset.\n\n    Raises:\n        DerivaMLException: If dataset_types are invalid or creation fails.\n\n    Example:\n        &gt;&gt;&gt; with ml.create_execution(config) as exe:\n        ...     dataset = exe.create_dataset(\n        ...         dataset_types=[\"experiment\", \"raw_data\"],\n        ...         description=\"RNA sequencing experiment data\",\n        ...         version=DatasetVersion(1, 0, 0)\n        ...     )\n    \"\"\"\n\n    version = version or DatasetVersion(0, 1, 0)\n\n    # Validate dataset types\n    ds_types = [dataset_types] if isinstance(dataset_types, str) else dataset_types\n    dataset_types = [ml_instance.lookup_term(MLVocab.dataset_type, t) for t in ds_types]\n\n    # Create the entry for the new dataset_table and get its RID.\n    pb = ml_instance.pathBuilder()\n    dataset_table_path = pb.schemas[ml_instance._dataset_table.schema.name].tables[ml_instance._dataset_table.name]\n    dataset_rid = dataset_table_path.insert(\n        [\n            {\n                \"Description\": description,\n                \"Deleted\": False,\n            }\n        ]\n    )[0][\"RID\"]\n\n    pb.schemas[ml_instance.model.ml_schema].Dataset_Execution.insert(\n        [{\"Dataset\": dataset_rid, \"Execution\": execution_rid}]\n    )\n    Dataset._insert_dataset_versions(\n        ml_instance=ml_instance,\n        dataset_list=[DatasetSpec(rid=dataset_rid, version=version)],\n        execution_rid=execution_rid,\n        description=\"Initial dataset creation.\",\n    )\n    dataset = Dataset(\n        catalog=ml_instance,\n        dataset_rid=dataset_rid,\n        description=description,\n    )\n\n    # Skip version increment during initial creation (version already set above)\n    dataset.add_dataset_types(dataset_types, _skip_version_increment=True)\n    return dataset\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.dataset_history","title":"dataset_history","text":"<pre><code>dataset_history() -&gt; list[\n    DatasetHistory\n]\n</code></pre> <p>Retrieves the version history of a dataset.</p> <p>Returns a chronological list of dataset versions, including their version numbers, creation times, and associated metadata.</p> <p>Returns:</p> Type Description <code>list[DatasetHistory]</code> <p>list[DatasetHistory]: List of history entries, each containing: - dataset_version: Version number (major.minor.patch) - minid: Minimal Viable Identifier - snapshot: Catalog snapshot time - dataset_rid: Dataset Resource Identifier - version_rid: Version Resource Identifier - description: Version description - execution_rid: Associated execution RID</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If dataset_rid is not a valid dataset RID.</p> Example <p>history = ml.dataset_history(\"1-abc123\") for entry in history: ...     print(f\"Version {entry.dataset_version}: {entry.description}\")</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def dataset_history(self) -&gt; list[DatasetHistory]:\n    \"\"\"Retrieves the version history of a dataset.\n\n    Returns a chronological list of dataset versions, including their version numbers,\n    creation times, and associated metadata.\n\n    Returns:\n        list[DatasetHistory]: List of history entries, each containing:\n            - dataset_version: Version number (major.minor.patch)\n            - minid: Minimal Viable Identifier\n            - snapshot: Catalog snapshot time\n            - dataset_rid: Dataset Resource Identifier\n            - version_rid: Version Resource Identifier\n            - description: Version description\n            - execution_rid: Associated execution RID\n\n    Raises:\n        DerivaMLException: If dataset_rid is not a valid dataset RID.\n\n    Example:\n        &gt;&gt;&gt; history = ml.dataset_history(\"1-abc123\")\n        &gt;&gt;&gt; for entry in history:\n        ...     print(f\"Version {entry.dataset_version}: {entry.description}\")\n    \"\"\"\n\n    if not self._ml_instance.model.is_dataset_rid(self.dataset_rid):\n        raise DerivaMLException(f\"RID is not for a data set: {self.dataset_rid}\")\n    version_path = self._ml_instance.pathBuilder().schemas[self._ml_instance.ml_schema].tables[\"Dataset_Version\"]\n    return [\n        DatasetHistory(\n            dataset_version=DatasetVersion.parse(v[\"Version\"]),\n            minid=v[\"Minid\"],\n            snapshot=v[\"Snapshot\"],\n            dataset_rid=self.dataset_rid,\n            version_rid=v[\"RID\"],\n            description=v[\"Description\"],\n            execution_rid=v[\"Execution\"],\n        )\n        for v in version_path.filter(version_path.Dataset == self.dataset_rid).entities().fetch()\n    ]\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.delete_dataset_members","title":"delete_dataset_members","text":"<pre><code>delete_dataset_members(\n    members: list[RID],\n    description: str = \"\",\n    execution_rid: RID | None = None,\n) -&gt; None\n</code></pre> <p>Remove members from this dataset.</p> <p>Removes the specified members from the dataset. In addition to removing members, the minor version number of the dataset is incremented and the description, if provided, is applied to that new version.</p> <p>Parameters:</p> Name Type Description Default <code>members</code> <code>list[RID]</code> <p>List of member RIDs to remove from the dataset.</p> required <code>description</code> <code>str</code> <p>Optional description of the removal operation.</p> <code>''</code> <code>execution_rid</code> <code>RID | None</code> <p>Optional RID of execution associated with this operation.</p> <code>None</code> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If any RID is invalid or not part of this dataset.</p> Example <p>dataset.delete_dataset_members( ...     members=[\"1-ABC\", \"1-DEF\"], ...     description=\"Removed corrupted samples\" ... )</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef delete_dataset_members(\n    self,\n    members: list[RID],\n    description: str = \"\",\n    execution_rid: RID | None = None,\n) -&gt; None:\n    \"\"\"Remove members from this dataset.\n\n    Removes the specified members from the dataset. In addition to removing members,\n    the minor version number of the dataset is incremented and the description,\n    if provided, is applied to that new version.\n\n    Args:\n        members: List of member RIDs to remove from the dataset.\n        description: Optional description of the removal operation.\n        execution_rid: Optional RID of execution associated with this operation.\n\n    Raises:\n        DerivaMLException: If any RID is invalid or not part of this dataset.\n\n    Example:\n        &gt;&gt;&gt; dataset.delete_dataset_members(\n        ...     members=[\"1-ABC\", \"1-DEF\"],\n        ...     description=\"Removed corrupted samples\"\n        ... )\n    \"\"\"\n    members = set(members)\n    description = description or \"Deleted dataset members\"\n\n    # Go through every rid to be deleted and sort them based on what association table entries\n    # need to be removed.\n    dataset_elements = {}\n    association_map = {\n        a.other_fkeys.pop().pk_table.name: a.table.name for a in self._dataset_table.find_associations()\n    }\n    # Get a list of all the object types that can be linked to a dataset.\n    for m in members:\n        try:\n            rid_info = self._ml_instance.resolve_rid(m)\n        except KeyError:\n            raise DerivaMLException(f\"Invalid RID: {m}\")\n        if rid_info.table.name not in association_map:\n            raise DerivaMLException(f\"RID table: {rid_info.table.name} not part of dataset\")\n        dataset_elements.setdefault(rid_info.table.name, []).append(rid_info.rid)\n\n    # Delete the entries from the association tables.\n    pb = self._ml_instance.pathBuilder()\n    for table, elements in dataset_elements.items():\n        # Determine schema: ML schema for Dataset, otherwise use the table's actual schema\n        if table == \"Dataset\":\n            schema_name = self._ml_instance.ml_schema\n        else:\n            # Find the table and use its schema\n            table_obj = self._ml_instance.model.name_to_table(table)\n            schema_name = table_obj.schema.name\n        schema_path = pb.schemas[schema_name]\n        fk_column = \"Nested_Dataset\" if table == \"Dataset\" else table\n\n        if len(elements):\n            atable_path = schema_path.tables[association_map[table]]\n            for e in elements:\n                entity = atable_path.filter(\n                    (atable_path.Dataset == self.dataset_rid) &amp; (atable_path.columns[fk_column] == e),\n                )\n                entity.delete()\n\n    self.increment_dataset_version(\n        VersionPart.minor,\n        description=description,\n        execution_rid=execution_rid,\n    )\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.denormalize_as_dataframe","title":"denormalize_as_dataframe","text":"<pre><code>denormalize_as_dataframe(\n    include_tables: list[str],\n    version: DatasetVersion\n    | str\n    | None = None,\n    **kwargs: Any,\n) -&gt; pd.DataFrame\n</code></pre> <p>Denormalize the dataset into a single wide table (DataFrame).</p> <p>Denormalization transforms normalized relational data into a single \"wide table\" (also called a \"flat table\" or \"denormalized table\") by joining related tables together. This produces a DataFrame where each row contains all related information from multiple source tables, with columns from each table combined side-by-side.</p> <p>Wide tables are the standard input format for most machine learning frameworks, which expect all features for a single observation to be in one row. This method bridges the gap between normalized database schemas and ML-ready tabular data.</p> <p>How it works:</p> <p>Tables are joined based on their foreign key relationships. For example, if Image has a foreign key to Subject, and Diagnosis has a foreign key to Image, then denormalizing [\"Subject\", \"Image\", \"Diagnosis\"] produces rows where each image appears with its subject's metadata and any associated diagnoses.</p> <p>Column naming:</p> <p>Column names are prefixed with the source table name using underscores to avoid collisions (e.g., \"Image_Filename\", \"Subject_RID\").</p> <p>Parameters:</p> Name Type Description Default <code>include_tables</code> <code>list[str]</code> <p>List of table names to include in the output. Tables are joined based on their foreign key relationships. Order doesn't matter - the join order is determined automatically.</p> required <code>version</code> <code>DatasetVersion | str | None</code> <p>Dataset version to query. Defaults to current version. Use this to get a reproducible snapshot of the data.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Wide table with columns from all included tables.</p> Example <p>Create a training dataset with images and their labels::</p> <pre><code>&gt;&gt;&gt; # Get all images with their diagnoses in one table\n&gt;&gt;&gt; df = dataset.denormalize_as_dataframe([\"Image\", \"Diagnosis\"])\n&gt;&gt;&gt; print(df.columns.tolist())\n['Image_RID', 'Image_Filename', 'Image_URL', 'Diagnosis_RID',\n 'Diagnosis_Label', 'Diagnosis_Confidence']\n\n&gt;&gt;&gt; # Use with scikit-learn\n&gt;&gt;&gt; X = df[[\"Image_Filename\"]]  # Features\n&gt;&gt;&gt; y = df[\"Diagnosis_Label\"]    # Labels\n</code></pre> <p>Include subject metadata for stratified splitting::</p> <pre><code>&gt;&gt;&gt; df = dataset.denormalize_as_dataframe(\n...     [\"Subject\", \"Image\", \"Diagnosis\"]\n... )\n&gt;&gt;&gt; # Now df has Subject_Age, Subject_Gender, etc.\n&gt;&gt;&gt; # for stratified train/test splits by subject\n</code></pre> See Also <p>denormalize_as_dict: Generator version for memory-efficient processing.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def denormalize_as_dataframe(\n    self,\n    include_tables: list[str],\n    version: DatasetVersion | str | None = None,\n    **kwargs: Any,\n) -&gt; pd.DataFrame:\n    \"\"\"Denormalize the dataset into a single wide table (DataFrame).\n\n    Denormalization transforms normalized relational data into a single \"wide table\"\n    (also called a \"flat table\" or \"denormalized table\") by joining related tables\n    together. This produces a DataFrame where each row contains all related information\n    from multiple source tables, with columns from each table combined side-by-side.\n\n    Wide tables are the standard input format for most machine learning frameworks,\n    which expect all features for a single observation to be in one row. This method\n    bridges the gap between normalized database schemas and ML-ready tabular data.\n\n    **How it works:**\n\n    Tables are joined based on their foreign key relationships. For example, if\n    Image has a foreign key to Subject, and Diagnosis has a foreign key to Image,\n    then denormalizing [\"Subject\", \"Image\", \"Diagnosis\"] produces rows where each\n    image appears with its subject's metadata and any associated diagnoses.\n\n    **Column naming:**\n\n    Column names are prefixed with the source table name using underscores\n    to avoid collisions (e.g., \"Image_Filename\", \"Subject_RID\").\n\n    Args:\n        include_tables: List of table names to include in the output. Tables\n            are joined based on their foreign key relationships.\n            Order doesn't matter - the join order is determined automatically.\n        version: Dataset version to query. Defaults to current version.\n            Use this to get a reproducible snapshot of the data.\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Returns:\n        pd.DataFrame: Wide table with columns from all included tables.\n\n    Example:\n        Create a training dataset with images and their labels::\n\n            &gt;&gt;&gt; # Get all images with their diagnoses in one table\n            &gt;&gt;&gt; df = dataset.denormalize_as_dataframe([\"Image\", \"Diagnosis\"])\n            &gt;&gt;&gt; print(df.columns.tolist())\n            ['Image_RID', 'Image_Filename', 'Image_URL', 'Diagnosis_RID',\n             'Diagnosis_Label', 'Diagnosis_Confidence']\n\n            &gt;&gt;&gt; # Use with scikit-learn\n            &gt;&gt;&gt; X = df[[\"Image_Filename\"]]  # Features\n            &gt;&gt;&gt; y = df[\"Diagnosis_Label\"]    # Labels\n\n        Include subject metadata for stratified splitting::\n\n            &gt;&gt;&gt; df = dataset.denormalize_as_dataframe(\n            ...     [\"Subject\", \"Image\", \"Diagnosis\"]\n            ... )\n            &gt;&gt;&gt; # Now df has Subject_Age, Subject_Gender, etc.\n            &gt;&gt;&gt; # for stratified train/test splits by subject\n\n    See Also:\n        denormalize_as_dict: Generator version for memory-efficient processing.\n    \"\"\"\n    rows = list(self._denormalize_datapath(include_tables, version))\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.denormalize_as_dict","title":"denormalize_as_dict","text":"<pre><code>denormalize_as_dict(\n    include_tables: list[str],\n    version: DatasetVersion\n    | str\n    | None = None,\n    **kwargs: Any,\n) -&gt; Generator[\n    dict[str, Any], None, None\n]\n</code></pre> <p>Denormalize the dataset and yield rows as dictionaries.</p> <p>This is a memory-efficient alternative to denormalize_as_dataframe() that yields one row at a time as a dictionary instead of loading all data into a DataFrame. Use this when processing large datasets that may not fit in memory, or when you want to process rows incrementally.</p> <p>Like denormalize_as_dataframe(), this produces a \"wide table\" representation where each yielded dictionary contains all columns from the joined tables. See denormalize_as_dataframe() for detailed explanation of how denormalization works.</p> <p>Column naming:</p> <p>Column names are prefixed with the source table name using underscores to avoid collisions (e.g., \"Image_Filename\", \"Subject_RID\").</p> <p>Parameters:</p> Name Type Description Default <code>include_tables</code> <code>list[str]</code> <p>List of table names to include in the output. Tables are joined based on their foreign key relationships.</p> required <code>version</code> <code>DatasetVersion | str | None</code> <p>Dataset version to query. Defaults to current version.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Yields:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary representing one row of the wide table. Keys are column names in \"Table_Column\" format.</p> Example <p>Process images one at a time for training::</p> <pre><code>&gt;&gt;&gt; for row in dataset.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n...     # Load and preprocess each image\n...     img = load_image(row[\"Image_Filename\"])\n...     label = row[\"Diagnosis_Label\"]\n...     yield img, label  # Feed to training loop\n</code></pre> <p>Count labels without loading all data into memory::</p> <pre><code>&gt;&gt;&gt; from collections import Counter\n&gt;&gt;&gt; labels = Counter()\n&gt;&gt;&gt; for row in dataset.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n...     labels[row[\"Diagnosis_Label\"]] += 1\n&gt;&gt;&gt; print(labels)\nCounter({'Normal': 450, 'Abnormal': 150})\n</code></pre> See Also <p>denormalize_as_dataframe: Returns all data as a pandas DataFrame.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def denormalize_as_dict(\n    self,\n    include_tables: list[str],\n    version: DatasetVersion | str | None = None,\n    **kwargs: Any,\n) -&gt; Generator[dict[str, Any], None, None]:\n    \"\"\"Denormalize the dataset and yield rows as dictionaries.\n\n    This is a memory-efficient alternative to denormalize_as_dataframe() that\n    yields one row at a time as a dictionary instead of loading all data into\n    a DataFrame. Use this when processing large datasets that may not fit in\n    memory, or when you want to process rows incrementally.\n\n    Like denormalize_as_dataframe(), this produces a \"wide table\" representation\n    where each yielded dictionary contains all columns from the joined tables.\n    See denormalize_as_dataframe() for detailed explanation of how denormalization\n    works.\n\n    **Column naming:**\n\n    Column names are prefixed with the source table name using underscores\n    to avoid collisions (e.g., \"Image_Filename\", \"Subject_RID\").\n\n    Args:\n        include_tables: List of table names to include in the output.\n            Tables are joined based on their foreign key relationships.\n        version: Dataset version to query. Defaults to current version.\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Yields:\n        dict[str, Any]: Dictionary representing one row of the wide table.\n            Keys are column names in \"Table_Column\" format.\n\n    Example:\n        Process images one at a time for training::\n\n            &gt;&gt;&gt; for row in dataset.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n            ...     # Load and preprocess each image\n            ...     img = load_image(row[\"Image_Filename\"])\n            ...     label = row[\"Diagnosis_Label\"]\n            ...     yield img, label  # Feed to training loop\n\n        Count labels without loading all data into memory::\n\n            &gt;&gt;&gt; from collections import Counter\n            &gt;&gt;&gt; labels = Counter()\n            &gt;&gt;&gt; for row in dataset.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n            ...     labels[row[\"Diagnosis_Label\"]] += 1\n            &gt;&gt;&gt; print(labels)\n            Counter({'Normal': 450, 'Abnormal': 150})\n\n    See Also:\n        denormalize_as_dataframe: Returns all data as a pandas DataFrame.\n    \"\"\"\n    yield from self._denormalize_datapath(include_tables, version)\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.display_markdown","title":"display_markdown","text":"<pre><code>display_markdown(\n    show_children: bool = False,\n    indent: int = 0,\n) -&gt; None\n</code></pre> <p>Display a formatted markdown representation of this dataset in Jupyter.</p> <p>Convenience method that calls to_markdown() and displays the result using IPython.display.Markdown.</p> <p>Parameters:</p> Name Type Description Default <code>show_children</code> <code>bool</code> <p>If True, include direct child datasets.</p> <code>False</code> <code>indent</code> <code>int</code> <p>Number of indent levels (each level is 2 spaces).</p> <code>0</code> Example <p>ds = ml.lookup_dataset(\"4HM\") ds.display_markdown(show_children=True)</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def display_markdown(self, show_children: bool = False, indent: int = 0) -&gt; None:\n    \"\"\"Display a formatted markdown representation of this dataset in Jupyter.\n\n    Convenience method that calls to_markdown() and displays the result\n    using IPython.display.Markdown.\n\n    Args:\n        show_children: If True, include direct child datasets.\n        indent: Number of indent levels (each level is 2 spaces).\n\n    Example:\n        &gt;&gt;&gt; ds = ml.lookup_dataset(\"4HM\")\n        &gt;&gt;&gt; ds.display_markdown(show_children=True)\n    \"\"\"\n    from IPython.display import Markdown, display\n\n    display(Markdown(self.to_markdown(show_children, indent)))\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.download_dataset_bag","title":"download_dataset_bag","text":"<pre><code>download_dataset_bag(\n    version: DatasetVersion | str,\n    materialize: bool = True,\n    use_minid: bool = False,\n    exclude_tables: set[str]\n    | None = None,\n) -&gt; DatasetBag\n</code></pre> <p>Downloads a dataset to the local filesystem and optionally creates a MINID.</p> <p>Downloads a dataset to the local file system. If the dataset has a version set, that version is used. If the dataset has a version and a version is provided, the version specified takes precedence.</p> <p>The exported bag contains all data reachable from this dataset's members by following foreign key relationships (both incoming and outgoing). Starting from each member element type, the export traverses all FK-connected tables, with vocabulary tables acting as natural path terminators. Only paths starting from element types that have members in this dataset are included.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>DatasetVersion | str</code> <p>Dataset version to download. If not specified, the version must be set in the dataset.</p> required <code>materialize</code> <code>bool</code> <p>If True, materialize the dataset after downloading.</p> <code>True</code> <code>use_minid</code> <code>bool</code> <p>If True, upload the bag to S3 and create a MINID for the dataset. Requires s3_bucket to be configured on the catalog. Defaults to False.</p> <code>False</code> <code>exclude_tables</code> <code>set[str] | None</code> <p>Optional set of table names to exclude from FK path traversal during bag export. Tables in this set will not be visited, pruning branches of the FK graph that pass through them. Useful for avoiding query timeouts caused by expensive joins through large or unnecessary tables.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DatasetBag</code> <code>DatasetBag</code> <p>Object containing: - path: Local filesystem path to downloaded dataset - rid: Dataset's Resource Identifier - minid: Dataset's Minimal Viable Identifier (if use_minid=True)</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If use_minid=True but s3_bucket is not configured on the catalog.</p> <p>Examples:</p> <p>Download without MINID (default):     &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\")     &gt;&gt;&gt; print(f\"Downloaded to {bag.path}\")</p> <p>Download with MINID (requires s3_bucket configured):     &gt;&gt;&gt; # Catalog must be created with s3_bucket=\"s3://my-bucket\"     &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\", use_minid=True)</p> <p>Exclude tables that cause query timeouts:     &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\", exclude_tables={\"Process\"})</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef download_dataset_bag(\n    self,\n    version: DatasetVersion | str,\n    materialize: bool = True,\n    use_minid: bool = False,\n    exclude_tables: set[str] | None = None,\n) -&gt; DatasetBag:\n    \"\"\"Downloads a dataset to the local filesystem and optionally creates a MINID.\n\n    Downloads a dataset to the local file system. If the dataset has a version set, that version is used.\n    If the dataset has a version and a version is provided, the version specified takes precedence.\n\n    The exported bag contains all data reachable from this dataset's members by following\n    foreign key relationships (both incoming and outgoing). Starting from each member element\n    type, the export traverses all FK-connected tables, with vocabulary tables acting as\n    natural path terminators. Only paths starting from element types that have members in\n    this dataset are included.\n\n    Args:\n        version: Dataset version to download. If not specified, the version must be set in the dataset.\n        materialize: If True, materialize the dataset after downloading.\n        use_minid: If True, upload the bag to S3 and create a MINID for the dataset.\n            Requires s3_bucket to be configured on the catalog. Defaults to False.\n        exclude_tables: Optional set of table names to exclude from FK path traversal\n            during bag export. Tables in this set will not be visited, pruning branches\n            of the FK graph that pass through them. Useful for avoiding query timeouts\n            caused by expensive joins through large or unnecessary tables.\n\n    Returns:\n        DatasetBag: Object containing:\n            - path: Local filesystem path to downloaded dataset\n            - rid: Dataset's Resource Identifier\n            - minid: Dataset's Minimal Viable Identifier (if use_minid=True)\n\n    Raises:\n        DerivaMLException: If use_minid=True but s3_bucket is not configured on the catalog.\n\n    Examples:\n        Download without MINID (default):\n            &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\")\n            &gt;&gt;&gt; print(f\"Downloaded to {bag.path}\")\n\n        Download with MINID (requires s3_bucket configured):\n            &gt;&gt;&gt; # Catalog must be created with s3_bucket=\"s3://my-bucket\"\n            &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\", use_minid=True)\n\n        Exclude tables that cause query timeouts:\n            &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\", exclude_tables={\"Process\"})\n    \"\"\"\n    if isinstance(version, str):\n        version = DatasetVersion.parse(version)\n\n    # Validate use_minid requires s3_bucket configuration\n    if use_minid and not self._ml_instance.s3_bucket:\n        raise DerivaMLException(\n            \"Cannot use use_minid=True without s3_bucket configured. \"\n            \"Configure s3_bucket when creating the DerivaML instance to enable MINID support.\"\n        )\n\n    minid = self._get_dataset_minid(version, create=True, use_minid=use_minid, exclude_tables=exclude_tables)\n\n    bag_path = (\n        self._materialize_dataset_bag(minid, use_minid=use_minid)\n        if materialize\n        else self._download_dataset_minid(minid, use_minid)\n    )\n    from deriva_ml.model.deriva_ml_database import DerivaMLDatabase\n    db_model = DatabaseModel(minid, bag_path, self._ml_instance.working_dir)\n    return DerivaMLDatabase(db_model).lookup_dataset(self.dataset_rid)\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.find_features","title":"find_features","text":"<pre><code>find_features(\n    table: str | Table,\n) -&gt; Iterable[Feature]\n</code></pre> <p>Find features associated with a table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table to find features for.</p> required <p>Returns:</p> Type Description <code>Iterable[Feature]</code> <p>Iterable of Feature objects.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def find_features(self, table: str | Table) -&gt; Iterable[Feature]:\n    \"\"\"Find features associated with a table.\n\n    Args:\n        table: Table to find features for.\n\n    Returns:\n        Iterable of Feature objects.\n    \"\"\"\n    return self._ml_instance.find_features(table)\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.get_chaise_url","title":"get_chaise_url","text":"<pre><code>get_chaise_url() -&gt; str\n</code></pre> <p>Get the Chaise URL for viewing this dataset in the browser.</p> <p>Returns:</p> Type Description <code>str</code> <p>URL string for the dataset record in Chaise.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def get_chaise_url(self) -&gt; str:\n    \"\"\"Get the Chaise URL for viewing this dataset in the browser.\n\n    Returns:\n        URL string for the dataset record in Chaise.\n    \"\"\"\n    return (\n        f\"https://{self._ml_instance.host_name}/chaise/record/\"\n        f\"#{self._ml_instance.catalog_id}/deriva-ml:Dataset/RID={self.dataset_rid}\"\n    )\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.increment_dataset_version","title":"increment_dataset_version","text":"<pre><code>increment_dataset_version(\n    component: VersionPart,\n    description: str | None = \"\",\n    execution_rid: RID | None = None,\n) -&gt; DatasetVersion\n</code></pre> <p>Increments a dataset's version number.</p> <p>Creates a new version of the dataset by incrementing the specified version component (major, minor, or patch). The new version is recorded with an optional description and execution reference.</p> <p>Parameters:</p> Name Type Description Default <code>component</code> <code>VersionPart</code> <p>Which version component to increment ('major', 'minor', or 'patch').</p> required <code>description</code> <code>str | None</code> <p>Optional description of the changes in this version.</p> <code>''</code> <code>execution_rid</code> <code>RID | None</code> <p>Optional execution RID to associate with this version.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DatasetVersion</code> <code>DatasetVersion</code> <p>The new version number.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If dataset_rid is invalid or version increment fails.</p> Example <p>new_version = ml.increment_dataset_version( ...     dataset_rid=\"1-abc123\", ...     component=\"minor\", ...     description=\"Added new samples\" ... ) print(f\"New version: {new_version}\")  # e.g., \"1.2.0\"</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef increment_dataset_version(\n    self,\n    component: VersionPart,\n    description: str | None = \"\",\n    execution_rid: RID | None = None,\n) -&gt; DatasetVersion:\n    \"\"\"Increments a dataset's version number.\n\n    Creates a new version of the dataset by incrementing the specified version component\n    (major, minor, or patch). The new version is recorded with an optional description\n    and execution reference.\n\n    Args:\n        component: Which version component to increment ('major', 'minor', or 'patch').\n        description: Optional description of the changes in this version.\n        execution_rid: Optional execution RID to associate with this version.\n\n    Returns:\n        DatasetVersion: The new version number.\n\n    Raises:\n        DerivaMLException: If dataset_rid is invalid or version increment fails.\n\n    Example:\n        &gt;&gt;&gt; new_version = ml.increment_dataset_version(\n        ...     dataset_rid=\"1-abc123\",\n        ...     component=\"minor\",\n        ...     description=\"Added new samples\"\n        ... )\n        &gt;&gt;&gt; print(f\"New version: {new_version}\")  # e.g., \"1.2.0\"\n    \"\"\"\n\n    # Find all the datasets that are reachable from this dataset and determine their new version numbers.\n    related_datasets = list(self._build_dataset_graph())\n    version_update_list = [\n        DatasetSpec(\n            rid=ds.dataset_rid,\n            version=ds.current_version.increment_version(component),\n        )\n        for ds in related_datasets\n    ]\n    Dataset._insert_dataset_versions(\n        self._ml_instance, version_update_list, description=description, execution_rid=execution_rid\n    )\n    return next((d.version for d in version_update_list if d.rid == self.dataset_rid))\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.list_dataset_children","title":"list_dataset_children","text":"<pre><code>list_dataset_children(\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n    version: DatasetVersion\n    | str\n    | None = None,\n    **kwargs: Any,\n) -&gt; list[Self]\n</code></pre> <p>Given a dataset_table RID, return a list of RIDs for any nested datasets.</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>If True, return a list of nested datasets RIDs.</p> <code>False</code> <code>_visited</code> <code>set[RID] | None</code> <p>Internal parameter to track visited datasets and prevent infinite recursion.</p> <code>None</code> <code>version</code> <code>DatasetVersion | str | None</code> <p>Dataset version to list children from. Defaults to the current version.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[Self]</code> <p>list of nested dataset RIDs.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef list_dataset_children(\n    self,\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n    version: DatasetVersion | str | None = None,\n    **kwargs: Any,\n) -&gt; list[Self]:\n    \"\"\"Given a dataset_table RID, return a list of RIDs for any nested datasets.\n\n    Args:\n        recurse: If True, return a list of nested datasets RIDs.\n        _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n        version: Dataset version to list children from. Defaults to the current version.\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Returns:\n      list of nested dataset RIDs.\n\n    \"\"\"\n    # Initialize visited set for recursion guard\n    if _visited is None:\n        _visited = set()\n\n    version = DatasetVersion.parse(version) if isinstance(version, str) else version\n    version_snapshot_catalog = self._version_snapshot_catalog(version)\n    dataset_dataset_path = (\n       version_snapshot_catalog.pathBuilder().schemas[self._ml_instance.ml_schema].tables[\"Dataset_Dataset\"]\n    )\n    nested_datasets = list(dataset_dataset_path.entities().fetch())\n\n    def find_children(rid: RID) -&gt; list[RID]:\n        # Prevent infinite recursion by checking if we've already visited this dataset\n        if rid in _visited:\n            return []\n        _visited.add(rid)\n\n        children = [child[\"Nested_Dataset\"] for child in nested_datasets if child[\"Dataset\"] == rid]\n        if recurse:\n            for child in children.copy():\n                children.extend(find_children(child))\n        return children\n\n    return [version_snapshot_catalog.lookup_dataset(rid) for rid in find_children(self.dataset_rid)]\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.list_dataset_element_types","title":"list_dataset_element_types","text":"<pre><code>list_dataset_element_types() -&gt; (\n    Iterable[Table]\n)\n</code></pre> <p>List the types of elements that can be contained in this dataset.</p> <p>Returns:</p> Type Description <code>Iterable[Table]</code> <p>Iterable of Table objects representing element types.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def list_dataset_element_types(self) -&gt; Iterable[Table]:\n    \"\"\"List the types of elements that can be contained in this dataset.\n\n    Returns:\n        Iterable of Table objects representing element types.\n    \"\"\"\n    return self._ml_instance.list_dataset_element_types()\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.list_dataset_members","title":"list_dataset_members","text":"<pre><code>list_dataset_members(\n    recurse: bool = False,\n    limit: int | None = None,\n    _visited: set[RID] | None = None,\n    version: DatasetVersion\n    | str\n    | None = None,\n    **kwargs: Any,\n) -&gt; dict[str, list[dict[str, Any]]]\n</code></pre> <p>Lists members of a dataset.</p> <p>Returns a dictionary mapping member types to lists of member records. Can optionally recurse through nested datasets and limit the number of results.</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>Whether to include members of nested datasets. Defaults to False.</p> <code>False</code> <code>limit</code> <code>int | None</code> <p>Maximum number of members to return per type. None for no limit.</p> <code>None</code> <code>_visited</code> <code>set[RID] | None</code> <p>Internal parameter to track visited datasets and prevent infinite recursion.</p> <code>None</code> <code>version</code> <code>DatasetVersion | str | None</code> <p>Dataset version to list members from. Defaults to the current version.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, list[dict[str, Any]]]</code> <p>dict[str, list[dict[str, Any]]]: Dictionary mapping member types to lists of members. Each member is a dictionary containing the record's attributes.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If dataset_rid is invalid.</p> Example <p>members = ml.list_dataset_members(\"1-abc123\", recurse=True) for type_name, records in members.items(): ...     print(f\"{type_name}: {len(records)} records\")</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef list_dataset_members(\n    self,\n    recurse: bool = False,\n    limit: int | None = None,\n    _visited: set[RID] | None = None,\n    version: DatasetVersion | str | None = None,\n    **kwargs: Any,\n) -&gt; dict[str, list[dict[str, Any]]]:\n    \"\"\"Lists members of a dataset.\n\n    Returns a dictionary mapping member types to lists of member records. Can optionally\n    recurse through nested datasets and limit the number of results.\n\n    Args:\n        recurse: Whether to include members of nested datasets. Defaults to False.\n        limit: Maximum number of members to return per type. None for no limit.\n        _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n        version: Dataset version to list members from. Defaults to the current version.\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Returns:\n        dict[str, list[dict[str, Any]]]: Dictionary mapping member types to lists of members.\n            Each member is a dictionary containing the record's attributes.\n\n    Raises:\n        DerivaMLException: If dataset_rid is invalid.\n\n    Example:\n        &gt;&gt;&gt; members = ml.list_dataset_members(\"1-abc123\", recurse=True)\n        &gt;&gt;&gt; for type_name, records in members.items():\n        ...     print(f\"{type_name}: {len(records)} records\")\n    \"\"\"\n    # Initialize visited set for recursion guard\n    if _visited is None:\n        _visited = set()\n\n    # Prevent infinite recursion by checking if we've already visited this dataset\n    if self.dataset_rid in _visited:\n        return {}\n    _visited.add(self.dataset_rid)\n\n    # Look at each of the element types that might be in the dataset_table and get the list of rid for them from\n    # the appropriate association table.\n    members = defaultdict(list)\n    version_snapshot_catalog = self._version_snapshot_catalog(version)\n    pb = version_snapshot_catalog.pathBuilder()\n    for assoc_table in self._dataset_table.find_associations():\n        other_fkey = assoc_table.other_fkeys.pop()\n        target_table = other_fkey.pk_table\n        member_table = assoc_table.table\n\n        # Look at domain tables and nested datasets.\n        if not self._ml_instance.model.is_domain_schema(target_table.schema.name) and not (\n            target_table == self._dataset_table or target_table.name == \"File\"\n        ):\n            continue\n        member_column = (\n            \"Nested_Dataset\" if target_table == self._dataset_table else other_fkey.foreign_key_columns[0].name\n        )\n        # Use the actual referenced column from the FK definition, not always \"RID\".\n        # e.g. isa:Dataset_file.file -&gt; isa:file.id (integer), not RID.\n        target_column = other_fkey.referenced_columns[0].name\n\n        target_path = pb.schemas[target_table.schema.name].tables[target_table.name]\n        member_path = pb.schemas[member_table.schema.name].tables[member_table.name]\n\n        path = member_path.filter(member_path.Dataset == self.dataset_rid).link(\n            target_path,\n            on=(member_path.columns[member_column] == target_path.columns[target_column]),\n        )\n        target_entities = list(path.entities().fetch(limit=limit) if limit else path.entities().fetch())\n        members[target_table.name].extend(target_entities)\n        if recurse and target_table == self._dataset_table:\n            # Get the members for all the nested datasets and add to the member list.\n            nested_datasets = [d[\"RID\"] for d in target_entities]\n            for ds_rid in nested_datasets:\n                ds = version_snapshot_catalog.lookup_dataset(ds_rid)\n                for k, v in ds.list_dataset_members(version=version, recurse=recurse, _visited=_visited).items():\n                    members[k].extend(v)\n    return dict(members)\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.list_dataset_parents","title":"list_dataset_parents","text":"<pre><code>list_dataset_parents(\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n    version: DatasetVersion\n    | str\n    | None = None,\n    **kwargs: Any,\n) -&gt; list[Self]\n</code></pre> <p>Given a dataset_table RID, return a list of RIDs of the parent datasets if this is included in a nested dataset.</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>If True, recursively return all ancestor datasets.</p> <code>False</code> <code>_visited</code> <code>set[RID] | None</code> <p>Internal parameter to track visited datasets and prevent infinite recursion.</p> <code>None</code> <code>version</code> <code>DatasetVersion | str | None</code> <p>Dataset version to list parents from. Defaults to the current version.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[Self]</code> <p>List of parent datasets.</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef list_dataset_parents(\n    self,\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n    version: DatasetVersion | str | None = None,\n    **kwargs: Any,\n) -&gt; list[Self]:\n    \"\"\"Given a dataset_table RID, return a list of RIDs of the parent datasets if this is included in a\n    nested dataset.\n\n    Args:\n        recurse: If True, recursively return all ancestor datasets.\n        _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n        version: Dataset version to list parents from. Defaults to the current version.\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Returns:\n        List of parent datasets.\n    \"\"\"\n    # Initialize visited set for recursion guard\n    if _visited is None:\n        _visited = set()\n\n    # Prevent infinite recursion by checking if we've already visited this dataset\n    if self.dataset_rid in _visited:\n        return []\n    _visited.add(self.dataset_rid)\n\n    # Get association table for nested datasets\n    version_snapshot_catalog = self._version_snapshot_catalog(version)\n    pb = version_snapshot_catalog.pathBuilder()\n    atable_path = pb.schemas[self._ml_instance.ml_schema].Dataset_Dataset\n    parents = [\n        version_snapshot_catalog.lookup_dataset(p[\"Dataset\"])\n        for p in atable_path.filter(atable_path.Nested_Dataset == self.dataset_rid).entities().fetch()\n    ]\n    if recurse:\n        for parent in parents.copy():\n            parents.extend(parent.list_dataset_parents(recurse=True, _visited=_visited, version=version))\n    return parents\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.list_executions","title":"list_executions","text":"<pre><code>list_executions() -&gt; list['Execution']\n</code></pre> <p>List all executions associated with this dataset.</p> <p>Returns all executions that used this dataset as input. This is tracked through the Dataset_Execution association table.</p> <p>Returns:</p> Type Description <code>list['Execution']</code> <p>List of Execution objects associated with this dataset.</p> Example <p>dataset = ml.lookup_dataset(\"1-abc123\") executions = dataset.list_executions() for exe in executions: ...     print(f\"Execution {exe.execution_rid}: {exe.status}\")</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def list_executions(self) -&gt; list[\"Execution\"]:\n    \"\"\"List all executions associated with this dataset.\n\n    Returns all executions that used this dataset as input. This is\n    tracked through the Dataset_Execution association table.\n\n    Returns:\n        List of Execution objects associated with this dataset.\n\n    Example:\n        &gt;&gt;&gt; dataset = ml.lookup_dataset(\"1-abc123\")\n        &gt;&gt;&gt; executions = dataset.list_executions()\n        &gt;&gt;&gt; for exe in executions:\n        ...     print(f\"Execution {exe.execution_rid}: {exe.status}\")\n    \"\"\"\n    # Import here to avoid circular dependency\n\n    pb = self._ml_instance.pathBuilder()\n    dataset_execution_path = pb.schemas[self._ml_instance.ml_schema].Dataset_Execution\n\n    # Query for all executions associated with this dataset\n    records = list(\n        dataset_execution_path.filter(dataset_execution_path.Dataset == self.dataset_rid)\n        .entities()\n        .fetch()\n    )\n\n    return [self._ml_instance.lookup_execution(record[\"Execution\"]) for record in records]\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.remove_dataset_type","title":"remove_dataset_type","text":"<pre><code>remove_dataset_type(\n    dataset_type: str | VocabularyTerm,\n) -&gt; None\n</code></pre> <p>Remove a dataset type from this dataset.</p> <p>Removes a type term from this dataset if it's currently associated. The term must exist in the Dataset_Type vocabulary.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_type</code> <code>str | VocabularyTerm</code> <p>Term name (string) or VocabularyTerm object from Dataset_Type vocabulary.</p> required <p>Raises:</p> Type Description <code>DerivaMLInvalidTerm</code> <p>If the term doesn't exist in the Dataset_Type vocabulary.</p> Example <p>dataset.remove_dataset_type(\"Training\")</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def remove_dataset_type(self, dataset_type: str | VocabularyTerm) -&gt; None:\n    \"\"\"Remove a dataset type from this dataset.\n\n    Removes a type term from this dataset if it's currently associated. The term\n    must exist in the Dataset_Type vocabulary.\n\n    Args:\n        dataset_type: Term name (string) or VocabularyTerm object from Dataset_Type vocabulary.\n\n    Raises:\n        DerivaMLInvalidTerm: If the term doesn't exist in the Dataset_Type vocabulary.\n\n    Example:\n        &gt;&gt;&gt; dataset.remove_dataset_type(\"Training\")\n    \"\"\"\n    # Convert to VocabularyTerm if needed (validates the term exists)\n    if isinstance(dataset_type, VocabularyTerm):\n        vocab_term = dataset_type\n    else:\n        vocab_term = self._ml_instance.lookup_term(MLVocab.dataset_type, dataset_type)\n\n    # Check if present\n    if vocab_term.name not in self.dataset_types:\n        return\n\n    # Delete from association table\n    _, atable_path = self._get_dataset_type_association_table()\n    atable_path.filter(\n        (atable_path.Dataset == self.dataset_rid) &amp; (atable_path.Dataset_Type == vocab_term.name)\n    ).delete()\n</code></pre>"},{"location":"code-docs/dataset/#deriva_ml.dataset.dataset.Dataset.to_markdown","title":"to_markdown","text":"<pre><code>to_markdown(\n    show_children: bool = False,\n    indent: int = 0,\n) -&gt; str\n</code></pre> <p>Generate a markdown representation of this dataset.</p> <p>Returns a formatted markdown string with a link to the dataset, version, types, and description. Optionally includes nested children.</p> <p>Parameters:</p> Name Type Description Default <code>show_children</code> <code>bool</code> <p>If True, include direct child datasets.</p> <code>False</code> <code>indent</code> <code>int</code> <p>Number of indent levels (each level is 2 spaces).</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>Markdown-formatted string.</p> Example <p>ds = ml.lookup_dataset(\"4HM\") print(ds.to_markdown())</p> Source code in <code>src/deriva_ml/dataset/dataset.py</code> <pre><code>def to_markdown(self, show_children: bool = False, indent: int = 0) -&gt; str:\n    \"\"\"Generate a markdown representation of this dataset.\n\n    Returns a formatted markdown string with a link to the dataset,\n    version, types, and description. Optionally includes nested children.\n\n    Args:\n        show_children: If True, include direct child datasets.\n        indent: Number of indent levels (each level is 2 spaces).\n\n    Returns:\n        Markdown-formatted string.\n\n    Example:\n        &gt;&gt;&gt; ds = ml.lookup_dataset(\"4HM\")\n        &gt;&gt;&gt; print(ds.to_markdown())\n    \"\"\"\n    prefix = \"  \" * indent\n    version = str(self.current_version) if self.current_version else \"n/a\"\n    types = \", \".join(self.dataset_types) if self.dataset_types else \"\"\n    desc = self.description or \"\"\n\n    line = f\"{prefix}- [{self.dataset_rid}]({self.get_chaise_url()}) v{version}\"\n    if types:\n        line += f\" [{types}]\"\n    if desc:\n        line += f\": {desc}\"\n\n    lines = [line]\n\n    if show_children:\n        children = self.list_dataset_children(recurse=False)\n        for child in children:\n            lines.append(child.to_markdown(show_children=False, indent=indent + 1))\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/","title":"Dataset Auxiliary Classes","text":"<p>Supporting classes for dataset operations including version management, dataset specifications, and history tracking.</p> <p>THis module defines the DataSet class with is used to manipulate n</p>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetHistory","title":"DatasetHistory","text":"<p>               Bases: <code>BaseModel</code></p> <p>Class representing a dataset history.</p> <p>Attributes:</p> Name Type Description <code>dataset_version</code> <code>DatasetVersion</code> <p>A DatasetVersion object which captures the semantic versioning of the dataset.</p> <code>dataset_rid</code> <code>RID</code> <p>The RID of the dataset.</p> <code>version_rid</code> <code>RID</code> <p>The RID of the version record for the dataset in the Dataset_Version table.</p> <code>minid</code> <code>str</code> <p>The URL that represents the handle of the dataset bag.  This will be None if a MINID has not          been created yet.</p> <code>snapshot</code> <code>str</code> <p>Catalog snapshot ID of when the version record was created.</p> Source code in <code>src/deriva_ml/dataset/aux_classes.py</code> <pre><code>class DatasetHistory(BaseModel):\n    \"\"\"\n    Class representing a dataset history.\n\n    Attributes:\n        dataset_version (DatasetVersion): A DatasetVersion object which captures the semantic versioning of the dataset.\n        dataset_rid (RID): The RID of the dataset.\n        version_rid (RID): The RID of the version record for the dataset in the Dataset_Version table.\n        minid (str): The URL that represents the handle of the dataset bag.  This will be None if a MINID has not\n                     been created yet.\n        snapshot (str): Catalog snapshot ID of when the version record was created.\n    \"\"\"\n\n    dataset_version: DatasetVersion\n    dataset_rid: RID\n    version_rid: RID\n    execution_rid: Optional[RID] = None\n    description: str | None = \"\"\n    minid: str | None = None\n    snapshot: str | None = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @field_validator(\"execution_rid\", mode=\"before\")\n    @classmethod\n    def _default_execution_rid(cls, v: str | None) -&gt; str | None:\n        return None if v == \"\" else v\n\n    @field_validator(\"description\", mode=\"after\")\n    def _default_description(cls, v: str | None) -&gt; str:\n        return v or \"\"\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetMinid","title":"DatasetMinid","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represent information about a MINID that refers to a dataset</p> <p>Attributes:</p> Name Type Description <code>dataset_version</code> <code>DatasetVersion</code> <p>A DatasetVersion object which captures the semantic versioning of the dataset.</p> <code>metadata</code> <code>dict</code> <p>A dictionary containing metadata from the MINID landing page.</p> <code>minid</code> <code>str</code> <p>The URL that represents the handle of the MINID associated with the dataset.</p> <code>bag_url</code> <code>str</code> <p>The URL to the dataset bag</p> <code>identifier</code> <code>str</code> <p>The identifier of the MINID in CURI form</p> <code>landing_page</code> <code>str</code> <p>The URL to the landing page of the MINID</p> <code>version_rid</code> <code>str</code> <p>RID of the dataset version.</p> <code>checksum</code> <code>str</code> <p>The checksum of the MINID in SHA256 form</p> Source code in <code>src/deriva_ml/dataset/aux_classes.py</code> <pre><code>class DatasetMinid(BaseModel):\n    \"\"\"Represent information about a MINID that refers to a dataset\n\n    Attributes:\n        dataset_version (DatasetVersion): A DatasetVersion object which captures the semantic versioning of the dataset.\n        metadata (dict): A dictionary containing metadata from the MINID landing page.\n        minid (str): The URL that represents the handle of the MINID associated with the dataset.\n        bag_url (str): The URL to the dataset bag\n        identifier (str): The identifier of the MINID in CURI form\n        landing_page (str): The URL to the landing page of the MINID\n        version_rid (str): RID of the dataset version.\n        checksum (str): The checksum of the MINID in SHA256 form\n\n    \"\"\"\n\n    dataset_version: DatasetVersion\n    metadata: dict[str, str | int] = {}\n    minid: str = Field(alias=\"compact_uri\", default=None)\n    bag_url: str = Field(alias=\"location\")\n    identifier: Optional[str] = None\n    landing_page: Optional[str] = None\n    version_rid: RID = Field(alias=\"RID\")\n    checksum: str = Field(alias=\"checksums\", default=\"\")\n\n    @computed_field\n    @property\n    def dataset_rid(self) -&gt; str:\n        rid_parts = self.version_rid.split(\"@\")\n        return rid_parts[0]\n\n    @computed_field\n    @property\n    def dataset_snapshot(self) -&gt; str:\n        return self.version_rid.split(\"@\")[1]\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def insert_metadata(cls, data: dict) -&gt; dict:\n        if isinstance(data, dict):\n            if \"metadata\" in data:\n                data = data | data[\"metadata\"]\n        return data\n\n    @field_validator(\"bag_url\", mode=\"before\")\n    @classmethod\n    def convert_location_to_str(cls, value: list[str] | str) -&gt; str:\n        return value[0] if isinstance(value, list) else value\n\n    @field_validator(\"checksum\", mode=\"before\")\n    @classmethod\n    def convert_checksum_to_value(cls, checksums: list[dict]) -&gt; str:\n        checksum_value = \"\"\n        for checksum in checksums:\n            if checksum.get(\"function\") == \"sha256\":\n                checksum_value = checksum.get(\"value\")\n                break\n        return checksum_value\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetSpec","title":"DatasetSpec","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represent a dataset_table in an execution configuration dataset_table list</p> <p>Attributes:</p> Name Type Description <code>rid</code> <code>RID</code> <p>A dataset_table RID</p> <code>materialize</code> <code>bool</code> <p>If False do not materialize datasets, only download table data, no assets.  Defaults to True</p> <code>version</code> <code>DatasetVersion</code> <p>The version of the dataset.  Should follow semantic versioning.</p> <code>exclude_tables</code> <code>set[str] | None</code> <p>Optional set of table names to exclude from FK path traversal during bag export. Tables in this set will not be visited, pruning branches of the FK graph. Useful for avoiding query timeouts on large tables.</p> Source code in <code>src/deriva_ml/dataset/aux_classes.py</code> <pre><code>class DatasetSpec(BaseModel):\n    \"\"\"Represent a dataset_table in an execution configuration dataset_table list\n\n    Attributes:\n        rid (RID): A dataset_table RID\n        materialize (bool): If False do not materialize datasets, only download table data, no assets.  Defaults to True\n        version (DatasetVersion): The version of the dataset.  Should follow semantic versioning.\n        exclude_tables (set[str] | None): Optional set of table names to exclude from FK path\n            traversal during bag export. Tables in this set will not be visited, pruning branches\n            of the FK graph. Useful for avoiding query timeouts on large tables.\n    \"\"\"\n\n    rid: RID\n    version: DatasetVersion | conlist(item_type=int, min_length=3, max_length=3) | tuple[int, int, int] | str\n    materialize: bool = True\n    description: str = \"\"\n    exclude_tables: set[str] | None = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @field_validator(\"version\", mode=\"before\")\n    @classmethod\n    def version_field_validator(cls, v: Any) -&gt; Any:\n        if isinstance(v, dict):\n            return DatasetVersion(**v)\n        elif isinstance(v, str):\n            return DatasetVersion.parse(v)\n        elif (isinstance(v, list) or isinstance(v, tuple)) and len(v) == 3:\n            return DatasetVersion(int(v[0]), int(v[1]), int(v[2]))\n        else:\n            return v\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def _check_bare_rid(cls, data: Any) -&gt; dict[str, str | bool]:\n        # If you are just given a string, assume it's a rid and put into dict for further validation.\n        return {\"rid\": data} if isinstance(data, str) else data\n\n    @field_serializer(\"version\")\n    def serialize_version(self, version: DatasetVersion) -&gt; dict[str, Any]:\n        return version.to_dict()\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion","title":"DatasetVersion","text":"<p>               Bases: <code>Version</code></p> <p>Represent the version associated with a dataset using semantic versioning.</p> <p>Methods:</p> Name Description <code>replace</code> <p>Replace the major and minor versions</p> Source code in <code>src/deriva_ml/dataset/aux_classes.py</code> <pre><code>class DatasetVersion(Version):\n    \"\"\"Represent the version associated with a dataset using semantic versioning.\n\n    Methods:\n        replace(major, minor, patch): Replace the major and minor versions\n    \"\"\"\n\n    def __init__(self, major: SupportsInt, minor: SupportsInt = 0, patch: SupportsInt = 0) -&gt; None:\n        \"\"\"Initialize a DatasetVersion object.\n\n        Args:\n            major: Major version number. Used to indicate schema changes.\n            minor: Minor version number.  Used to indicate additional members added, or change in member values.\n            patch: Patch number of the dataset.  Used to indicate minor clean-up and edits\n        \"\"\"\n        super().__init__(major, minor, patch)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"\n\n        Returns:\n            dictionary of version information\n\n        \"\"\"\n        return {\"major\": self.major, \"minor\": self.minor, \"patch\": self.patch}\n\n    def to_tuple(self) -&gt; tuple[int, int, int]:\n        \"\"\"\n\n        Returns:\n            tuple of version information\n\n        \"\"\"\n        return self.major, self.minor, self.patch\n\n    @classmethod\n    def parse(cls, version: str, optional_minor_an_path: bool = False) -&gt; \"DatasetVersion\":\n        v = Version.parse(version)\n        return DatasetVersion(v.major, v.minor, v.patch)\n\n    def increment_version(self, component: VersionPart) -&gt; \"DatasetVersion\":\n        match component:\n            case VersionPart.major:\n                return self.bump_major()\n            case VersionPart.minor:\n                return self.bump_minor()\n            case VersionPart.patch:\n                return self.bump_patch()\n            case _:\n                return self\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.build","title":"build  <code>property</code> <code>writable</code>","text":"<pre><code>build: Optional[str]\n</code></pre> <p>The build part of a version (read-only).</p>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.major","title":"major  <code>property</code> <code>writable</code>","text":"<pre><code>major: int\n</code></pre> <p>The major part of a version (read-only).</p>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.minor","title":"minor  <code>property</code> <code>writable</code>","text":"<pre><code>minor: int\n</code></pre> <p>The minor part of a version (read-only).</p>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.patch","title":"patch  <code>property</code> <code>writable</code>","text":"<pre><code>patch: int\n</code></pre> <p>The patch part of a version (read-only).</p>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.prerelease","title":"prerelease  <code>property</code> <code>writable</code>","text":"<pre><code>prerelease: Optional[str]\n</code></pre> <p>The prerelease part of a version (read-only).</p>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(\n    index: Union[int, slice],\n) -&gt; Union[\n    int,\n    Optional[str],\n    Tuple[Union[int, str], ...],\n]\n</code></pre> <p>self.getitem(index) &lt;==&gt; self[index] Implement getitem.</p> <p>If the part  requested is undefined, or a part of the range requested is undefined, it will throw an index error. Negative indices are not supported.</p> <p>:param index: a positive integer indicating the        offset or a :func:<code>slice</code> object :raises IndexError: if index is beyond the range or a part is None :return: the requested part of the version at position index</p> <p>ver = semver.Version.parse(\"3.4.5\") ver[0], ver[1], ver[2] (3, 4, 5)</p> Source code in <code>semver/version.py</code> <pre><code>def __getitem__(\n    self, index: Union[int, slice]\n) -&gt; Union[int, Optional[str], Tuple[Union[int, str], ...]]:\n    \"\"\"\n    self.__getitem__(index) &lt;==&gt; self[index] Implement getitem.\n\n    If the part  requested is undefined, or a part of the range requested\n    is undefined, it will throw an index error.\n    Negative indices are not supported.\n\n    :param index: a positive integer indicating the\n           offset or a :func:`slice` object\n    :raises IndexError: if index is beyond the range or a part is None\n    :return: the requested part of the version at position index\n\n    &gt;&gt;&gt; ver = semver.Version.parse(\"3.4.5\")\n    &gt;&gt;&gt; ver[0], ver[1], ver[2]\n    (3, 4, 5)\n    \"\"\"\n    if isinstance(index, int):\n        index = slice(index, index + 1)\n    index = cast(slice, index)\n\n    if (\n        isinstance(index, slice)\n        and (index.start is not None and index.start &lt; 0)\n        or (index.stop is not None and index.stop &lt; 0)\n    ):\n        raise IndexError(\"Version index cannot be negative\")\n\n    part = tuple(\n        filter(lambda p: p is not None, cast(Iterable, self.to_tuple()[index]))\n    )\n\n    if len(part) == 1:\n        return part[0]\n    elif not part:\n        raise IndexError(\"Version part undefined\")\n    return part\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.__init__","title":"__init__","text":"<pre><code>__init__(\n    major: SupportsInt,\n    minor: SupportsInt = 0,\n    patch: SupportsInt = 0,\n) -&gt; None\n</code></pre> <p>Initialize a DatasetVersion object.</p> <p>Parameters:</p> Name Type Description Default <code>major</code> <code>SupportsInt</code> <p>Major version number. Used to indicate schema changes.</p> required <code>minor</code> <code>SupportsInt</code> <p>Minor version number.  Used to indicate additional members added, or change in member values.</p> <code>0</code> <code>patch</code> <code>SupportsInt</code> <p>Patch number of the dataset.  Used to indicate minor clean-up and edits</p> <code>0</code> Source code in <code>src/deriva_ml/dataset/aux_classes.py</code> <pre><code>def __init__(self, major: SupportsInt, minor: SupportsInt = 0, patch: SupportsInt = 0) -&gt; None:\n    \"\"\"Initialize a DatasetVersion object.\n\n    Args:\n        major: Major version number. Used to indicate schema changes.\n        minor: Minor version number.  Used to indicate additional members added, or change in member values.\n        patch: Patch number of the dataset.  Used to indicate minor clean-up and edits\n    \"\"\"\n    super().__init__(major, minor, patch)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; VersionIterator\n</code></pre> <p>Return iter(self).</p> Source code in <code>semver/version.py</code> <pre><code>def __iter__(self) -&gt; VersionIterator:\n    \"\"\"Return iter(self).\"\"\"\n    yield from self.to_tuple()\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.bump_build","title":"bump_build","text":"<pre><code>bump_build(\n    token: Optional[str] = \"build\",\n) -&gt; Version\n</code></pre> <p>Raise the build part of the version, return a new object but leave self untouched.</p> <p>:param token: defaults to <code>'build'</code> :return: new :class:<code>Version</code> object with the raised build part.     The original object is not modified.</p> <p>ver = semver.parse(\"3.4.5-rc.1+build.9\") ver.bump_build() Version(major=3, minor=4, patch=5, prerelease='rc.1', build='build.10')</p> Source code in <code>semver/version.py</code> <pre><code>    def bump_build(self, token: Optional[str] = \"build\") -&gt; \"Version\":\n        \"\"\"\n        Raise the build part of the version, return a new object but leave self\n        untouched.\n\n        :param token: defaults to ``'build'``\n        :return: new :class:`Version` object with the raised build part.\n            The original object is not modified.\n\n        &gt;&gt;&gt; ver = semver.parse(\"3.4.5-rc.1+build.9\")\n        &gt;&gt;&gt; ver.bump_build()\n        Version(major=3, minor=4, patch=5, prerelease='rc.1', \\\nbuild='build.10')\n        \"\"\"\n        cls = type(self)\n        if self._build is not None:\n            build = self._build\n        elif token == \"\":\n            build = \"0\"\n        elif token is None:\n            build = \"build.0\"\n        else:\n            build = str(token) + \".0\"\n\n        # self._build or (token or \"build\") + \".0\"\n        build = cls._increment_string(build)\n        if self._build is not None:\n            build = self._build\n        elif token == \"\":\n            build = \"0\"\n        elif token is None:\n            build = \"build.0\"\n        else:\n            build = str(token) + \".0\"\n\n        # self._build or (token or \"build\") + \".0\"\n        build = cls._increment_string(build)\n        return cls(self._major, self._minor, self._patch, self._prerelease, build)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.bump_major","title":"bump_major","text":"<pre><code>bump_major() -&gt; Version\n</code></pre> <p>Raise the major part of the version, return a new object but leave self untouched.</p> <p>:return: new object with the raised major part</p> <p>ver = semver.parse(\"3.4.5\") ver.bump_major() Version(major=4, minor=0, patch=0, prerelease=None, build=None)</p> Source code in <code>semver/version.py</code> <pre><code>def bump_major(self) -&gt; \"Version\":\n    \"\"\"\n    Raise the major part of the version, return a new object but leave self\n    untouched.\n\n    :return: new object with the raised major part\n\n    &gt;&gt;&gt; ver = semver.parse(\"3.4.5\")\n    &gt;&gt;&gt; ver.bump_major()\n    Version(major=4, minor=0, patch=0, prerelease=None, build=None)\n    \"\"\"\n    cls = type(self)\n    return cls(self._major + 1)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.bump_minor","title":"bump_minor","text":"<pre><code>bump_minor() -&gt; Version\n</code></pre> <p>Raise the minor part of the version, return a new object but leave self untouched.</p> <p>:return: new object with the raised minor part</p> <p>ver = semver.parse(\"3.4.5\") ver.bump_minor() Version(major=3, minor=5, patch=0, prerelease=None, build=None)</p> Source code in <code>semver/version.py</code> <pre><code>def bump_minor(self) -&gt; \"Version\":\n    \"\"\"\n    Raise the minor part of the version, return a new object but leave self\n    untouched.\n\n    :return: new object with the raised minor part\n\n    &gt;&gt;&gt; ver = semver.parse(\"3.4.5\")\n    &gt;&gt;&gt; ver.bump_minor()\n    Version(major=3, minor=5, patch=0, prerelease=None, build=None)\n    \"\"\"\n    cls = type(self)\n    return cls(self._major, self._minor + 1)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.bump_patch","title":"bump_patch","text":"<pre><code>bump_patch() -&gt; Version\n</code></pre> <p>Raise the patch part of the version, return a new object but leave self untouched.</p> <p>:return: new object with the raised patch part</p> <p>ver = semver.parse(\"3.4.5\") ver.bump_patch() Version(major=3, minor=4, patch=6, prerelease=None, build=None)</p> Source code in <code>semver/version.py</code> <pre><code>def bump_patch(self) -&gt; \"Version\":\n    \"\"\"\n    Raise the patch part of the version, return a new object but leave self\n    untouched.\n\n    :return: new object with the raised patch part\n\n    &gt;&gt;&gt; ver = semver.parse(\"3.4.5\")\n    &gt;&gt;&gt; ver.bump_patch()\n    Version(major=3, minor=4, patch=6, prerelease=None, build=None)\n    \"\"\"\n    cls = type(self)\n    return cls(self._major, self._minor, self._patch + 1)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.bump_prerelease","title":"bump_prerelease","text":"<pre><code>bump_prerelease(\n    token: Optional[str] = \"rc\",\n) -&gt; Version\n</code></pre> <p>Raise the prerelease part of the version, return a new object but leave self untouched.</p> <p>:param token: defaults to <code>'rc'</code> :return: new :class:<code>Version</code> object with the raised prerelease part.     The original object is not modified.</p> <p>ver = semver.parse(\"3.4.5\") ver.bump_prerelease().prerelease 'rc.2' ver.bump_prerelease('').prerelease '1' ver.bump_prerelease(None).prerelease 'rc.1'</p> Source code in <code>semver/version.py</code> <pre><code>def bump_prerelease(self, token: Optional[str] = \"rc\") -&gt; \"Version\":\n    \"\"\"\n    Raise the prerelease part of the version, return a new object but leave\n    self untouched.\n\n    :param token: defaults to ``'rc'``\n    :return: new :class:`Version` object with the raised prerelease part.\n        The original object is not modified.\n\n    &gt;&gt;&gt; ver = semver.parse(\"3.4.5\")\n    &gt;&gt;&gt; ver.bump_prerelease().prerelease\n    'rc.2'\n    &gt;&gt;&gt; ver.bump_prerelease('').prerelease\n    '1'\n    &gt;&gt;&gt; ver.bump_prerelease(None).prerelease\n    'rc.1'\n    \"\"\"\n    cls = type(self)\n    if self._prerelease is not None:\n        prerelease = self._prerelease\n    elif token == \"\":\n        prerelease = \"0\"\n    elif token is None:\n        prerelease = \"rc.0\"\n    else:\n        prerelease = str(token) + \".0\"\n\n    prerelease = cls._increment_string(prerelease)\n    return cls(self._major, self._minor, self._patch, prerelease)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.compare","title":"compare","text":"<pre><code>compare(other: Comparable) -&gt; int\n</code></pre> <p>Compare self with other.</p> <p>:param other: the second version :return: The return value is negative if ver1 &lt; ver2,      zero if ver1 == ver2 and strictly positive if ver1 &gt; ver2</p> <p>Version.parse(\"1.0.0\").compare(\"2.0.0\") -1 Version.parse(\"2.0.0\").compare(\"1.0.0\") 1 Version.parse(\"2.0.0\").compare(\"2.0.0\") 0</p> Source code in <code>semver/version.py</code> <pre><code>def compare(self, other: Comparable) -&gt; int:\n    \"\"\"\n    Compare self with other.\n\n    :param other: the second version\n    :return: The return value is negative if ver1 &lt; ver2,\n         zero if ver1 == ver2 and strictly positive if ver1 &gt; ver2\n\n    &gt;&gt;&gt; Version.parse(\"1.0.0\").compare(\"2.0.0\")\n    -1\n    &gt;&gt;&gt; Version.parse(\"2.0.0\").compare(\"1.0.0\")\n    1\n    &gt;&gt;&gt; Version.parse(\"2.0.0\").compare(\"2.0.0\")\n    0\n    \"\"\"\n    cls = type(self)\n    if isinstance(other, String.__args__):  # type: ignore\n        other = cls.parse(other)\n    elif isinstance(other, dict):\n        other = cls(**other)\n    elif isinstance(other, (tuple, list)):\n        other = cls(*other)\n    elif not isinstance(other, cls):\n        raise TypeError(\n            f\"Expected str, bytes, dict, tuple, list, or {cls.__name__} instance, \"\n            f\"but got {type(other)}\"\n        )\n\n    v1 = self.to_tuple()[:3]\n    v2 = other.to_tuple()[:3]\n    x = _cmp(v1, v2)\n    if x:\n        return x\n\n    rc1, rc2 = self.prerelease, other.prerelease\n    rccmp = self._nat_cmp(rc1, rc2)\n\n    if not rccmp:\n        return 0\n    if not rc1:\n        return 1\n    elif not rc2:\n        return -1\n\n    return rccmp\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.finalize_version","title":"finalize_version","text":"<pre><code>finalize_version() -&gt; Version\n</code></pre> <p>Remove any prerelease and build metadata from the version.</p> <p>:return: a new instance with the finalized version string</p> <p>str(semver.Version.parse('1.2.3-rc.5').finalize_version()) '1.2.3'</p> Source code in <code>semver/version.py</code> <pre><code>def finalize_version(self) -&gt; \"Version\":\n    \"\"\"\n    Remove any prerelease and build metadata from the version.\n\n    :return: a new instance with the finalized version string\n\n    &gt;&gt;&gt; str(semver.Version.parse('1.2.3-rc.5').finalize_version())\n    '1.2.3'\n    \"\"\"\n    cls = type(self)\n    return cls(self.major, self.minor, self.patch)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.is_compatible","title":"is_compatible","text":"<pre><code>is_compatible(other: Version) -&gt; bool\n</code></pre> <p>Check if current version is compatible with other version.</p> <p>The result is True, if either of the following is true:</p> <ul> <li>both versions are equal, or</li> <li>both majors are equal and higher than 0. Same for both minors.   Both pre-releases are equal, or</li> <li>both majors are equal and higher than 0. The minor of b's   minor version is higher then a's. Both pre-releases are equal.</li> </ul> <p>The algorithm does not check patches.</p> <p>.. versionadded:: 3.0.0</p> <p>:param other: the version to check for compatibility :return: True, if <code>other</code> is compatible with the old version,          otherwise False</p> <p>Version(1, 1, 0).is_compatible(Version(1, 0, 0)) False Version(1, 0, 0).is_compatible(Version(1, 1, 0)) True</p> Source code in <code>semver/version.py</code> <pre><code>def is_compatible(self, other: \"Version\") -&gt; bool:\n    \"\"\"\n    Check if current version is compatible with other version.\n\n    The result is True, if either of the following is true:\n\n    * both versions are equal, or\n    * both majors are equal and higher than 0. Same for both minors.\n      Both pre-releases are equal, or\n    * both majors are equal and higher than 0. The minor of b's\n      minor version is higher then a's. Both pre-releases are equal.\n\n    The algorithm does *not* check patches.\n\n    .. versionadded:: 3.0.0\n\n    :param other: the version to check for compatibility\n    :return: True, if ``other`` is compatible with the old version,\n             otherwise False\n\n    &gt;&gt;&gt; Version(1, 1, 0).is_compatible(Version(1, 0, 0))\n    False\n    &gt;&gt;&gt; Version(1, 0, 0).is_compatible(Version(1, 1, 0))\n    True\n    \"\"\"\n    if not isinstance(other, Version):\n        raise TypeError(f\"Expected a Version type but got {type(other)}\")\n\n    # All major-0 versions should be incompatible with anything but itself\n    if (0 == self.major == other.major) and (self[:4] != other[:4]):\n        return False\n\n    return (\n        (self.major == other.major)\n        and (other.minor &gt;= self.minor)\n        and (self.prerelease == other.prerelease)\n    )\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.is_valid","title":"is_valid  <code>classmethod</code>","text":"<pre><code>is_valid(version: str) -&gt; bool\n</code></pre> <p>Check if the string is a valid semver version.</p> <p>.. versionadded:: 2.9.1</p> <p>.. versionchanged:: 3.0.0    Renamed from :meth:<code>~semver.version.Version.isvalid</code></p> <p>:param version: the version string to check :return: True if the version string is a valid semver version, False          otherwise.</p> Source code in <code>semver/version.py</code> <pre><code>@classmethod\ndef is_valid(cls, version: str) -&gt; bool:\n    \"\"\"\n    Check if the string is a valid semver version.\n\n    .. versionadded:: 2.9.1\n\n    .. versionchanged:: 3.0.0\n       Renamed from :meth:`~semver.version.Version.isvalid`\n\n    :param version: the version string to check\n    :return: True if the version string is a valid semver version, False\n             otherwise.\n    \"\"\"\n    try:\n        cls.parse(version)\n        return True\n    except ValueError:\n        return False\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.match","title":"match","text":"<pre><code>match(match_expr: str) -&gt; bool\n</code></pre> <p>Compare self to match a match expression.</p> <p>:param match_expr: optional operator and version; valid operators are       <code>&lt;</code>   smaller than       <code>&gt;</code>   greater than       <code>&gt;=</code>  greator or equal than       <code>&lt;=</code>  smaller or equal than       <code>==</code>  equal       <code>!=</code>  not equal :return: True if the expression matches the version, otherwise False</p> <p>semver.Version.parse(\"2.0.0\").match(\"&gt;=1.0.0\") True semver.Version.parse(\"1.0.0\").match(\"&gt;1.0.0\") False semver.Version.parse(\"4.0.4\").match(\"4.0.4\") True</p> Source code in <code>semver/version.py</code> <pre><code>def match(self, match_expr: str) -&gt; bool:\n    \"\"\"\n    Compare self to match a match expression.\n\n    :param match_expr: optional operator and version; valid operators are\n          ``&lt;``   smaller than\n          ``&gt;``   greater than\n          ``&gt;=``  greator or equal than\n          ``&lt;=``  smaller or equal than\n          ``==``  equal\n          ``!=``  not equal\n    :return: True if the expression matches the version, otherwise False\n\n    &gt;&gt;&gt; semver.Version.parse(\"2.0.0\").match(\"&gt;=1.0.0\")\n    True\n    &gt;&gt;&gt; semver.Version.parse(\"1.0.0\").match(\"&gt;1.0.0\")\n    False\n    &gt;&gt;&gt; semver.Version.parse(\"4.0.4\").match(\"4.0.4\")\n    True\n    \"\"\"\n    prefix = match_expr[:2]\n    if prefix in (\"&gt;=\", \"&lt;=\", \"==\", \"!=\"):\n        match_version = match_expr[2:]\n    elif prefix and prefix[0] in (\"&gt;\", \"&lt;\"):\n        prefix = prefix[0]\n        match_version = match_expr[1:]\n    elif match_expr and match_expr[0] in \"0123456789\":\n        prefix = \"==\"\n        match_version = match_expr\n    else:\n        raise ValueError(\n            \"match_expr parameter should be in format &lt;op&gt;&lt;ver&gt;, \"\n            \"where &lt;op&gt; is one of \"\n            \"['&lt;', '&gt;', '==', '&lt;=', '&gt;=', '!=']. \"\n            \"You provided: %r\" % match_expr\n        )\n\n    possibilities_dict = {\n        \"&gt;\": (1,),\n        \"&lt;\": (-1,),\n        \"==\": (0,),\n        \"!=\": (-1, 1),\n        \"&gt;=\": (0, 1),\n        \"&lt;=\": (-1, 0),\n    }\n\n    possibilities = possibilities_dict[prefix]\n    cmp_res = self.compare(match_version)\n\n    return cmp_res in possibilities\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.next_version","title":"next_version","text":"<pre><code>next_version(\n    part: str,\n    prerelease_token: str = \"rc\",\n) -&gt; Version\n</code></pre> <p>Determines next version, preserving natural order.</p> <p>.. versionadded:: 2.10.0</p> <p>This function is taking prereleases into account. The \"major\", \"minor\", and \"patch\" raises the respective parts like the <code>bump_*</code> functions. The real difference is using the \"prerelease\" part. It gives you the next patch version of the prerelease, for example:</p> <p>str(semver.parse(\"0.1.4\").next_version(\"prerelease\")) '0.1.5-rc.1'</p> <p>:param part: One of \"major\", \"minor\", \"patch\", or \"prerelease\" :param prerelease_token: prefix string of prerelease, defaults to 'rc' :return: new object with the appropriate part raised</p> Source code in <code>semver/version.py</code> <pre><code>def next_version(self, part: str, prerelease_token: str = \"rc\") -&gt; \"Version\":\n    \"\"\"\n    Determines next version, preserving natural order.\n\n    .. versionadded:: 2.10.0\n\n    This function is taking prereleases into account.\n    The \"major\", \"minor\", and \"patch\" raises the respective parts like\n    the ``bump_*`` functions. The real difference is using the\n    \"prerelease\" part. It gives you the next patch version of the\n    prerelease, for example:\n\n    &gt;&gt;&gt; str(semver.parse(\"0.1.4\").next_version(\"prerelease\"))\n    '0.1.5-rc.1'\n\n    :param part: One of \"major\", \"minor\", \"patch\", or \"prerelease\"\n    :param prerelease_token: prefix string of prerelease, defaults to 'rc'\n    :return: new object with the appropriate part raised\n    \"\"\"\n    cls = type(self)\n    # \"build\" is currently not used, that's why we use [:-1]\n    validparts = cls.NAMES[:-1]\n    if part not in validparts:\n        raise ValueError(\n            f\"Invalid part. Expected one of {validparts}, but got {part!r}\"\n        )\n    version = self\n    if (version.prerelease or version.build) and (\n        part == \"patch\"\n        or (part == \"minor\" and version.patch == 0)\n        or (part == \"major\" and version.minor == version.patch == 0)\n    ):\n        return version.replace(prerelease=None, build=None)\n\n    # Only check the main parts:\n    if part in cls.NAMES[:3]:\n        return getattr(version, \"bump_\" + part)()\n\n    if not version.prerelease:\n        version = version.bump_patch()\n    return version.bump_prerelease(prerelease_token)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.replace","title":"replace","text":"<pre><code>replace(\n    **parts: Union[int, Optional[str]],\n) -&gt; Version\n</code></pre> <p>Replace one or more parts of a version and return a new :class:<code>Version</code> object, but leave self untouched.</p> <p>.. versionadded:: 2.9.0    Added :func:<code>Version.replace</code></p> <p>:param parts: the parts to be updated. Valid keys are:   <code>major</code>, <code>minor</code>, <code>patch</code>, <code>prerelease</code>, or <code>build</code> :return: the new :class:<code>~semver.version.Version</code> object with   the changed parts :raises TypeError: if <code>parts</code> contain invalid keys</p> Source code in <code>semver/version.py</code> <pre><code>def replace(self, **parts: Union[int, Optional[str]]) -&gt; \"Version\":\n    \"\"\"\n    Replace one or more parts of a version and return a new :class:`Version`\n    object, but leave self untouched.\n\n    .. versionadded:: 2.9.0\n       Added :func:`Version.replace`\n\n    :param parts: the parts to be updated. Valid keys are:\n      ``major``, ``minor``, ``patch``, ``prerelease``, or ``build``\n    :return: the new :class:`~semver.version.Version` object with\n      the changed parts\n    :raises TypeError: if ``parts`` contain invalid keys\n    \"\"\"\n    version = self.to_dict()\n    version.update(parts)\n    try:\n        return type(self)(**version)  # type: ignore\n    except TypeError:\n        unknownkeys = set(parts) - set(self.to_dict())\n        error = \"replace() got %d unexpected keyword argument(s): %s\" % (\n            len(unknownkeys),\n            \", \".join(unknownkeys),\n        )\n        raise TypeError(error)\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dictionary of version information</p> Source code in <code>src/deriva_ml/dataset/aux_classes.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"\n\n    Returns:\n        dictionary of version information\n\n    \"\"\"\n    return {\"major\": self.major, \"minor\": self.minor, \"patch\": self.patch}\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.DatasetVersion.to_tuple","title":"to_tuple","text":"<pre><code>to_tuple() -&gt; tuple[int, int, int]\n</code></pre> <p>Returns:</p> Type Description <code>tuple[int, int, int]</code> <p>tuple of version information</p> Source code in <code>src/deriva_ml/dataset/aux_classes.py</code> <pre><code>def to_tuple(self) -&gt; tuple[int, int, int]:\n    \"\"\"\n\n    Returns:\n        tuple of version information\n\n    \"\"\"\n    return self.major, self.minor, self.patch\n</code></pre>"},{"location":"code-docs/dataset_aux_classes/#deriva_ml.dataset.aux_classes.VersionPart","title":"VersionPart","text":"<p>               Bases: <code>Enum</code></p> <p>Simple enumeration for semantic versioning.</p> <p>Attributes:</p> Name Type Description <code>major</code> <code>int</code> <p>Major version number</p> <code>minor</code> <code>int</code> <p>Minor version number</p> <code>patch</code> <code>int</code> <p>Patch version number</p> Source code in <code>src/deriva_ml/dataset/aux_classes.py</code> <pre><code>class VersionPart(Enum):\n    \"\"\"Simple enumeration for semantic versioning.\n\n    Attributes:\n        major (int): Major version number\n        minor (int): Minor version number\n        patch (int): Patch version number\n\n    \"\"\"\n\n    major = \"major\"\n    minor = \"minor\"\n    patch = \"patch\"\n</code></pre>"},{"location":"code-docs/dataset_bag/","title":"DatasetBag Class","text":"<p>The DatasetBag class represents a downloaded dataset packaged as a BDBag. It provides methods to access dataset contents, metadata, and associated files from the local filesystem.</p> <p>SQLite-backed dataset access for downloaded BDBags.</p> <p>This module provides the DatasetBag class, which allows querying and navigating downloaded dataset bags using SQLite. When a dataset is downloaded from a Deriva catalog, it is stored as a BDBag (Big Data Bag) containing:</p> <ul> <li>CSV files with table data</li> <li>Asset files (images, documents, etc.)</li> <li>A schema.json describing the catalog structure</li> <li>A fetch.txt manifest of referenced files</li> </ul> <p>The DatasetBag class provides a read-only interface to this data, mirroring the Dataset class API where possible. This allows code to work uniformly with both live catalog datasets and downloaded bags.</p> <p>Key concepts: - DatasetBag wraps a single dataset within a downloaded bag - A bag may contain multiple datasets (nested/hierarchical) - All operations are read-only (bags are immutable snapshots) - Queries use SQLite via SQLAlchemy ORM - Table-level access (get_table_as_dict, lookup_term) is on the catalog (DerivaMLDatabase)</p> Typical usage"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag--download-a-dataset-from-a-catalog","title":"Download a dataset from a catalog","text":"<p>bag = ml.download_dataset_bag(dataset_spec)</p>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag--list-dataset-members-by-type","title":"List dataset members by type","text":"<p>members = bag.list_dataset_members(recurse=True) for image in members.get(\"Image\", []): ...     print(image[\"Filename\"])</p>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag","title":"DatasetBag","text":"<p>Read-only interface to a downloaded dataset bag.</p> <p>DatasetBag manages access to a materialized BDBag (Big Data Bag) that contains a snapshot of dataset data from a Deriva catalog. It provides methods for:</p> <ul> <li>Listing dataset members and their attributes</li> <li>Navigating dataset relationships (parents, children)</li> <li>Accessing feature values</li> <li>Denormalizing data across related tables</li> </ul> <p>A bag may contain multiple datasets when nested datasets are involved. Each DatasetBag instance represents a single dataset within the bag - use list_dataset_children() to navigate to nested datasets.</p> <p>For catalog-level operations like querying arbitrary tables or looking up vocabulary terms, use the DerivaMLDatabase class instead.</p> <p>The class implements the DatasetLike protocol, providing the same read interface as the Dataset class. This allows code to work with both live catalogs and downloaded bags interchangeably.</p> <p>Attributes:</p> Name Type Description <code>dataset_rid</code> <code>RID</code> <p>The unique Resource Identifier for this dataset.</p> <code>dataset_types</code> <code>list[str]</code> <p>List of vocabulary terms describing the dataset type.</p> <code>description</code> <code>str</code> <p>Human-readable description of the dataset.</p> <code>execution_rid</code> <code>RID | None</code> <p>RID of the execution associated with this dataset version, if any.</p> <code>model</code> <code>DatabaseModel</code> <p>The DatabaseModel providing SQLite access to bag data.</p> <code>engine</code> <code>Engine</code> <p>SQLAlchemy engine for database queries.</p> <code>metadata</code> <code>MetaData</code> <p>SQLAlchemy metadata with table definitions.</p> Example Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>class DatasetBag:\n    \"\"\"Read-only interface to a downloaded dataset bag.\n\n    DatasetBag manages access to a materialized BDBag (Big Data Bag) that contains\n    a snapshot of dataset data from a Deriva catalog. It provides methods for:\n\n    - Listing dataset members and their attributes\n    - Navigating dataset relationships (parents, children)\n    - Accessing feature values\n    - Denormalizing data across related tables\n\n    A bag may contain multiple datasets when nested datasets are involved. Each\n    DatasetBag instance represents a single dataset within the bag - use\n    list_dataset_children() to navigate to nested datasets.\n\n    For catalog-level operations like querying arbitrary tables or looking up\n    vocabulary terms, use the DerivaMLDatabase class instead.\n\n    The class implements the DatasetLike protocol, providing the same read interface\n    as the Dataset class. This allows code to work with both live catalogs and\n    downloaded bags interchangeably.\n\n    Attributes:\n        dataset_rid (RID): The unique Resource Identifier for this dataset.\n        dataset_types (list[str]): List of vocabulary terms describing the dataset type.\n        description (str): Human-readable description of the dataset.\n        execution_rid (RID | None): RID of the execution associated with this dataset version, if any.\n        model (DatabaseModel): The DatabaseModel providing SQLite access to bag data.\n        engine (Engine): SQLAlchemy engine for database queries.\n        metadata (MetaData): SQLAlchemy metadata with table definitions.\n\n    Example:\n        &gt;&gt;&gt; # Download a dataset\n        &gt;&gt;&gt; bag = dataset.download_dataset_bag(version=\"1.0.0\")\n        &gt;&gt;&gt; # List members by type\n        &gt;&gt;&gt; members = bag.list_dataset_members()\n        &gt;&gt;&gt; for image in members.get(\"Image\", []):\n        ...     print(f\"File: {image['Filename']}\")\n        &gt;&gt;&gt; # Navigate to nested datasets\n        &gt;&gt;&gt; for child in bag.list_dataset_children():\n        ...     print(f\"Nested: {child.dataset_rid}\")\n    \"\"\"\n\n    def __init__(\n        self,\n        catalog: \"DerivaMLDatabase\",\n        dataset_rid: RID | None = None,\n        dataset_types: str | list[str] | None = None,\n        description: str = \"\",\n        execution_rid: RID | None = None,\n    ):\n        \"\"\"Initialize a DatasetBag instance for a dataset within a downloaded bag.\n\n        This mirrors the Dataset class initialization pattern, where both classes\n        take a catalog-like object as their first argument for consistency.\n\n        Args:\n            catalog: The DerivaMLDatabase instance providing access to the bag's data.\n                This implements the DerivaMLCatalog protocol.\n            dataset_rid: The RID of the dataset to wrap. If None, uses the primary\n                dataset RID from the bag.\n            dataset_types: One or more dataset type terms. Can be a single string\n                or list of strings.\n            description: Human-readable description of the dataset.\n            execution_rid: RID of the execution associated with this dataset version.\n                If None, will be looked up from the Dataset_Version table.\n\n        Raises:\n            DerivaMLException: If no dataset_rid is provided and none can be\n                determined from the bag, or if the RID doesn't exist in the bag.\n        \"\"\"\n        # Store reference to the catalog and extract the underlying model\n        self._catalog = catalog\n        self.model = catalog.model\n        self.engine = cast(Engine, self.model.engine)\n        self.metadata = self.model.metadata\n\n        # Use provided RID or fall back to the bag's primary dataset\n        self.dataset_rid = dataset_rid or self.model.dataset_rid\n        self.description = description\n        self.execution_rid = execution_rid or (\n            self.model._get_dataset_execution(self.dataset_rid) or {}\n        ).get(\"Execution\")\n\n        # Normalize dataset_types to always be a list of strings for consistency\n        # with the Dataset class interface\n        if dataset_types is None:\n            self.dataset_types: list[str] = []\n        elif isinstance(dataset_types, str):\n            self.dataset_types: list[str] = [dataset_types]\n        else:\n            self.dataset_types: list[str] = list(dataset_types)\n\n        if not self.dataset_rid:\n            raise DerivaMLException(\"No dataset RID provided\")\n\n        # Validate that this dataset exists in the bag\n        self.model.rid_lookup(self.dataset_rid)\n\n        # Cache the version and dataset table reference\n        self._current_version = self.model.dataset_version(self.dataset_rid)\n        self._dataset_table = self.model.dataset_table\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the DatasetBag for debugging.\"\"\"\n        return (f\"&lt;deriva_ml.DatasetBag object at {hex(id(self))}: rid='{self.dataset_rid}', \"\n                f\"version='{self.current_version}', types={self.dataset_types}&gt;\")\n\n    @property\n    def current_version(self) -&gt; DatasetVersion:\n        \"\"\"Get the version of the dataset at the time the bag was downloaded.\n\n        For a DatasetBag, this is the version that was current when the bag was\n        created. Unlike the live Dataset class, this value is immutable since\n        bags are read-only snapshots.\n\n        Returns:\n            DatasetVersion: The semantic version (major.minor.patch) of this dataset.\n        \"\"\"\n        return self._current_version\n\n    def list_tables(self) -&gt; list[str]:\n        \"\"\"List all tables available in the bag's SQLite database.\n\n        Returns the fully-qualified names of all tables (e.g., \"domain.Image\",\n        \"deriva-ml.Dataset\") that were exported in this bag.\n\n        Returns:\n            list[str]: Table names in \"schema.table\" format, sorted alphabetically.\n        \"\"\"\n        return self.model.list_tables()\n\n    def get_table_as_dict(self, table: str) -&gt; Generator[dict[str, Any], None, None]:\n        \"\"\"Get table contents as dictionaries.\n\n        Convenience method that delegates to the underlying catalog. This provides\n        access to all rows in a table, not just those belonging to this dataset.\n        For dataset-filtered results, use list_dataset_members() instead.\n\n        Args:\n            table: Name of the table to retrieve (e.g., \"Subject\", \"Image\").\n\n        Yields:\n            dict: Dictionary for each row in the table.\n\n        Example:\n            &gt;&gt;&gt; for subject in bag.get_table_as_dict(\"Subject\"):\n            ...     print(subject[\"Name\"])\n        \"\"\"\n        return self._catalog.get_table_as_dict(table)\n\n    @staticmethod\n    def _find_relationship_attr(source, target):\n        \"\"\"Find the SQLAlchemy relationship attribute connecting two ORM classes.\n\n        Searches for a relationship on `source` that points to `target`, which is\n        needed to construct proper JOIN clauses in SQL queries.\n\n        Args:\n            source: Source ORM class or AliasedClass.\n            target: Target ORM class or AliasedClass.\n\n        Returns:\n            InstrumentedAttribute: The relationship attribute on source pointing to target.\n\n        Raises:\n            LookupError: If no relationship exists between the two classes.\n\n        Note:\n            When multiple relationships exist, prefers MANYTOONE direction as this\n            is typically the more natural join direction for denormalization.\n        \"\"\"\n        src_mapper = inspect(source).mapper\n        tgt_mapper = inspect(target).mapper\n\n        # Collect all relationships on the source mapper that point to target\n        candidates: list[RelationshipProperty] = [rel for rel in src_mapper.relationships if rel.mapper is tgt_mapper]\n\n        if not candidates:\n            raise LookupError(f\"No relationship from {src_mapper.class_.__name__} \u2192 {tgt_mapper.class_.__name__}\")\n\n        # Prefer MANYTOONE when multiple paths exist (often best for joins)\n        candidates.sort(key=lambda r: r.direction.name != \"MANYTOONE\")\n        rel = candidates[0]\n\n        # Return the bound attribute (handles AliasedClass properly)\n        return getattr(source, rel.key) if isinstance(source, AliasedClass) else rel.class_attribute\n\n    def _dataset_table_view(self, table: str) -&gt; CompoundSelect[Any]:\n        \"\"\"Build a SQL query for all rows in a table that belong to this dataset.\n\n        Creates a UNION of queries that traverse all possible paths from the\n        Dataset table to the target table, filtering by this dataset's RID\n        (and any nested dataset RIDs).\n\n        This is necessary because table data may be linked to datasets through\n        different relationship paths (e.g., Image might be linked directly to\n        Dataset or through an intermediate Subject table).\n\n        Args:\n            table: Name of the table to query.\n\n        Returns:\n            CompoundSelect: A SQLAlchemy UNION query selecting all matching rows.\n        \"\"\"\n        table_class = self.model.get_orm_class_by_name(table)\n        dataset_table_class = self.model.get_orm_class_by_name(self._dataset_table.name)\n\n        # Include this dataset and all nested datasets in the query\n        dataset_rids = [self.dataset_rid] + [c.dataset_rid for c in self.list_dataset_children(recurse=True)]\n\n        # Find all paths from Dataset to the target table\n        paths = [[t.name for t in p] for p in self.model._schema_to_paths() if p[-1].name == table]\n\n        # Build a SELECT query for each path and UNION them together\n        sql_cmds = []\n        for path in paths:\n            path_sql = select(table_class)\n            last_class = self.model.get_orm_class_by_name(path[0])\n            # Join through each table in the path\n            for t in path[1:]:\n                t_class = self.model.get_orm_class_by_name(t)\n                path_sql = path_sql.join(self._find_relationship_attr(last_class, t_class))\n                last_class = t_class\n            # Filter to only rows belonging to our dataset(s)\n            path_sql = path_sql.where(dataset_table_class.RID.in_(dataset_rids))\n            sql_cmds.append(path_sql)\n        return union(*sql_cmds)\n\n    def dataset_history(self) -&gt; list[DatasetHistory]:\n        \"\"\"Retrieves the version history of a dataset.\n\n        Returns a chronological list of dataset versions, including their version numbers,\n        creation times, and associated metadata.\n\n        Returns:\n            list[DatasetHistory]: List of history entries, each containing:\n                - dataset_version: Version number (major.minor.patch)\n                - minid: Minimal Viable Identifier\n                - snapshot: Catalog snapshot time\n                - dataset_rid: Dataset Resource Identifier\n                - version_rid: Version Resource Identifier\n                - description: Version description\n                - execution_rid: Associated execution RID\n\n        Raises:\n            DerivaMLException: If dataset_rid is not a valid dataset RID.\n\n        Example:\n            &gt;&gt;&gt; history = ml.dataset_history(\"1-abc123\")\n            &gt;&gt;&gt; for entry in history:\n            ...     print(f\"Version {entry.dataset_version}: {entry.description}\")\n        \"\"\"\n        # Query Dataset_Version table directly via the model\n        return [\n            DatasetHistory(\n                dataset_version=DatasetVersion.parse(v[\"Version\"]),\n                minid=v[\"Minid\"],\n                snapshot=v[\"Snapshot\"],\n                dataset_rid=self.dataset_rid,\n                version_rid=v[\"RID\"],\n                description=v[\"Description\"],\n                execution_rid=v[\"Execution\"],\n            )\n            for v in self.model._get_table_contents(\"Dataset_Version\")\n            if v[\"Dataset\"] == self.dataset_rid\n        ]\n\n    def list_dataset_members(\n        self,\n        recurse: bool = False,\n        limit: int | None = None,\n        _visited: set[RID] | None = None,\n        version: Any = None,\n        **kwargs: Any,\n    ) -&gt; dict[str, list[dict[str, Any]]]:\n        \"\"\"Return a list of entities associated with a specific dataset.\n\n        Args:\n            recurse: Whether to include members of nested datasets.\n            limit: Maximum number of members to return per type. None for no limit.\n            _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n            version: Ignored (bags are immutable snapshots).\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Returns:\n            Dictionary mapping member types to lists of member records.\n        \"\"\"\n        # Initialize visited set for recursion guard\n        if _visited is None:\n            _visited = set()\n\n        # Prevent infinite recursion by checking if we've already visited this dataset\n        if self.dataset_rid in _visited:\n            return {}\n        _visited.add(self.dataset_rid)\n\n        # Look at each of the element types that might be in the _dataset_table and get the list of rid for them from\n        # the appropriate association table.\n        members = defaultdict(list)\n\n        dataset_class = self.model.get_orm_class_for_table(self._dataset_table)\n        for element_table in self.model.list_dataset_element_types():\n            element_class = self.model.get_orm_class_for_table(element_table)\n\n            assoc_class, dataset_rel, element_rel = self.model.get_orm_association_class(dataset_class, element_class)\n\n            element_table = inspect(element_class).mapped_table\n            if not self.model.is_domain_schema(element_table.schema) and element_table.name not in [\"Dataset\", \"File\"]:\n                # Look at domain tables and nested datasets.\n                continue\n\n            # Get the names of the columns that we are going to need for linking\n            with Session(self.engine) as session:\n                # For Dataset_Dataset, use Nested_Dataset column to find nested datasets\n                # (similar to how the live catalog does it in Dataset.list_dataset_members)\n                if element_table.name == \"Dataset\":\n                    sql_cmd = (\n                        select(element_class)\n                        .join(assoc_class, element_class.RID == assoc_class.__table__.c[\"Nested_Dataset\"])\n                        .where(self.dataset_rid == assoc_class.__table__.c[\"Dataset\"])\n                    )\n                else:\n                    # For other tables, use the original join via element_rel\n                    sql_cmd = (\n                        select(element_class)\n                        .join(element_rel)\n                        .where(self.dataset_rid == assoc_class.__table__.c[\"Dataset\"])\n                    )\n                if limit is not None:\n                    sql_cmd = sql_cmd.limit(limit)\n                # Get back the list of ORM entities and convert them to dictionaries.\n                element_entities = session.scalars(sql_cmd).all()\n                element_rows = [{c.key: getattr(obj, c.key) for c in obj.__table__.columns} for obj in element_entities]\n            members[element_table.name].extend(element_rows)\n            if recurse and (element_table.name == self._dataset_table.name):\n                # Get the members for all the nested datasets and add to the member list.\n                nested_datasets = [d[\"RID\"] for d in element_rows]\n                for ds in nested_datasets:\n                    nested_dataset = self._catalog.lookup_dataset(ds)\n                    for k, v in nested_dataset.list_dataset_members(recurse=recurse, limit=limit, _visited=_visited).items():\n                        members[k].extend(v)\n        return dict(members)\n\n    def find_features(self, table: str | Table) -&gt; Iterable[Feature]:\n        \"\"\"Find features for a table.\n\n        Args:\n            table: The table to find features for.\n\n        Returns:\n            An iterable of Feature instances.\n        \"\"\"\n        return self.model.find_features(table)\n\n    def list_feature_values(\n        self, table: Table | str, feature_name: str\n    ) -&gt; Iterable[FeatureRecord]:\n        \"\"\"Retrieves all values for a feature as typed FeatureRecord instances.\n\n        Returns an iterator of dynamically-generated FeatureRecord objects for each\n        feature value. Each record is an instance of a Pydantic model specific to\n        this feature, with typed attributes for all columns including the Execution\n        that created the feature value.\n\n        Args:\n            table: The table containing the feature, either as name or Table object.\n            feature_name: Name of the feature to retrieve values for.\n\n        Returns:\n            Iterable[FeatureRecord]: An iterator of FeatureRecord instances.\n                Each instance has:\n                - Execution: RID of the execution that created this feature value\n                - Feature_Name: Name of the feature\n                - All feature-specific columns as typed attributes\n                - model_dump() method to convert back to a dictionary\n\n        Raises:\n            DerivaMLException: If the feature doesn't exist or cannot be accessed.\n\n        Example:\n            &gt;&gt;&gt; # Get typed feature records\n            &gt;&gt;&gt; for record in bag.list_feature_values(\"Image\", \"Quality\"):\n            ...     print(f\"Image {record.Image}: {record.ImageQuality}\")\n            ...     print(f\"Created by execution: {record.Execution}\")\n\n            &gt;&gt;&gt; # Convert records to dictionaries\n            &gt;&gt;&gt; records = list(bag.list_feature_values(\"Image\", \"Quality\"))\n            &gt;&gt;&gt; dicts = [r.model_dump() for r in records]\n        \"\"\"\n        # Get table and feature\n        feature = self.model.lookup_feature(table, feature_name)\n\n        # Get the dynamically-generated FeatureRecord subclass for this feature\n        record_class = feature.feature_record_class()\n\n        # Query raw values from SQLite\n        feature_table = self.model.find_table(feature.feature_table.name)\n        with Session(self.engine) as session:\n            sql_cmd = select(feature_table)\n            result = session.execute(sql_cmd)\n            rows = [dict(row._mapping) for row in result]\n\n        # Convert to typed records\n        for raw_value in rows:\n            # Filter to only include fields that the record class expects\n            field_names = set(record_class.model_fields.keys())\n            filtered_data = {k: v for k, v in raw_value.items() if k in field_names}\n            yield record_class(**filtered_data)\n\n    def list_dataset_element_types(self) -&gt; Iterable[Table]:\n        \"\"\"List the types of elements that can be contained in datasets.\n\n        This method analyzes the dataset and identifies the data types for all\n        elements within it. It is useful for understanding the structure and\n        content of the dataset and allows for better manipulation and usage of its\n        data.\n\n        Returns:\n            list[str]: A list of strings where each string represents a data type\n            of an element found in the dataset.\n\n        \"\"\"\n        return self.model.list_dataset_element_types()\n\n    def list_dataset_children(\n        self,\n        recurse: bool = False,\n        _visited: set[RID] | None = None,\n        version: Any = None,\n        **kwargs: Any,\n    ) -&gt; list[Self]:\n        \"\"\"Get nested datasets.\n\n        Args:\n            recurse: Whether to include children of children.\n            _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n            version: Ignored (bags are immutable snapshots).\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Returns:\n            List of child dataset bags.\n        \"\"\"\n        # Initialize visited set for recursion guard\n        if _visited is None:\n            _visited = set()\n\n        # Prevent infinite recursion by checking if we've already visited this dataset\n        if self.dataset_rid in _visited:\n            return []\n        _visited.add(self.dataset_rid)\n\n        ds_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset\")\n        nds_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset_Dataset\")\n        dv_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset_Version\")\n\n        with Session(self.engine) as session:\n            sql_cmd = (\n                select(nds_table.Nested_Dataset, dv_table.Version)\n                .join_from(ds_table, nds_table, onclause=ds_table.RID == nds_table.Nested_Dataset)\n                .join_from(ds_table, dv_table, onclause=ds_table.Version == dv_table.RID)\n                .where(nds_table.Dataset == self.dataset_rid)\n            )\n            nested = [self._catalog.lookup_dataset(r[0]) for r in session.execute(sql_cmd).all()]\n\n        result = copy(nested)\n        if recurse:\n            for child in nested:\n                result.extend(child.list_dataset_children(recurse=recurse, _visited=_visited))\n        return result\n\n    def list_dataset_parents(\n        self,\n        recurse: bool = False,\n        _visited: set[RID] | None = None,\n        version: Any = None,\n        **kwargs: Any,\n    ) -&gt; list[Self]:\n        \"\"\"Given a dataset_table RID, return a list of RIDs of the parent datasets if this is included in a\n        nested dataset.\n\n        Args:\n            recurse: If True, recursively return all ancestor datasets.\n            _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n            version: Ignored (bags are immutable snapshots).\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Returns:\n            List of parent dataset bags.\n        \"\"\"\n        # Initialize visited set for recursion guard\n        if _visited is None:\n            _visited = set()\n\n        # Prevent infinite recursion by checking if we've already visited this dataset\n        if self.dataset_rid in _visited:\n            return []\n        _visited.add(self.dataset_rid)\n\n        nds_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset_Dataset\")\n\n        with Session(self.engine) as session:\n            sql_cmd = select(nds_table.Dataset).where(nds_table.Nested_Dataset == self.dataset_rid)\n            parents = [self._catalog.lookup_dataset(r[0]) for r in session.execute(sql_cmd).all()]\n\n        if recurse:\n            for parent in parents.copy():\n                parents.extend(parent.list_dataset_parents(recurse=True, _visited=_visited))\n        return parents\n\n    def list_executions(self) -&gt; list[RID]:\n        \"\"\"List all execution RIDs associated with this dataset.\n\n        Returns all executions that used this dataset as input. This is\n        tracked through the Dataset_Execution association table.\n\n        Note:\n            Unlike the live Dataset class which returns Execution objects,\n            DatasetBag returns a list of execution RIDs since the bag is\n            an offline snapshot and cannot look up live execution objects.\n\n        Returns:\n            List of execution RIDs associated with this dataset.\n\n        Example:\n            &gt;&gt;&gt; bag = ml.download_dataset_bag(dataset_spec)\n            &gt;&gt;&gt; execution_rids = bag.list_executions()\n            &gt;&gt;&gt; for rid in execution_rids:\n            ...     print(f\"Associated execution: {rid}\")\n        \"\"\"\n        de_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset_Execution\")\n\n        with Session(self.engine) as session:\n            sql_cmd = select(de_table.Execution).where(de_table.Dataset == self.dataset_rid)\n            return [r[0] for r in session.execute(sql_cmd).all()]\n\n    def _denormalize(self, include_tables: list[str]) -&gt; Select:\n        \"\"\"Build a SQL query that joins multiple tables into a denormalized view.\n\n        This method creates a \"wide table\" by joining related tables together,\n        producing a single query that returns columns from all specified tables.\n        This is useful for machine learning pipelines that need flat data.\n\n        The method:\n        1. Analyzes the schema to find join paths between tables\n        2. Determines the correct join order based on foreign key relationships\n        3. Builds SELECT statements with properly aliased columns\n        4. Creates a UNION if multiple paths exist to the same tables\n\n        Args:\n            include_tables: List of table names to include in the output. Additional\n                tables may be included if they're needed to join the requested tables.\n\n        Returns:\n            Select: A SQLAlchemy query that produces the denormalized result.\n\n        Note:\n            Column names in the result are prefixed with the table name to avoid\n            collisions (e.g., \"Image.Filename\", \"Subject.RID\").\n        \"\"\"\n        # Skip over tables that we don't want to include in the denormalized dataset.\n        # Also, strip off the Dataset/Dataset_X part of the path so we don't include dataset columns in the denormalized\n        # table.\n\n        def find_relationship(table, join_condition):\n            side1 = (join_condition[0].table.name, join_condition[0].name)\n            side2 = (join_condition[1].table.name, join_condition[1].name)\n\n            for relationship in inspect(table).relationships:\n                local_columns = list(relationship.local_columns)[0].table.name, list(relationship.local_columns)[0].name\n                remote_side = list(relationship.remote_side)[0].table.name, list(relationship.remote_side)[0].name\n                if local_columns == side1 and remote_side == side2 or local_columns == side2 and remote_side == side1:\n                    return relationship\n            return None\n\n        join_tables, denormalized_columns = self.model._prepare_wide_table(self, self.dataset_rid, include_tables)\n\n        denormalized_columns = [\n            self.model.get_orm_class_by_name(table_name)\n            .__table__.columns[column_name]\n            .label(f\"{table_name}.{column_name}\")\n            for table_name, column_name in denormalized_columns\n        ]\n        sql_statements = []\n        for key, (path, join_conditions) in join_tables.items():\n            sql_statement = select(*denormalized_columns).select_from(\n                self.model.get_orm_class_for_table(self._dataset_table)\n            )\n            for table_name in path[1:]:  # Skip over dataset table\n                table_class = self.model.get_orm_class_by_name(table_name)\n                on_clause = [\n                    getattr(table_class, r.key)\n                    for on_condition in join_conditions[table_name]\n                    if (r := find_relationship(table_class, on_condition))\n                ]\n                sql_statement = sql_statement.join(table_class, onclause=and_(*on_clause))\n            dataset_rid_list = [self.dataset_rid] + [c.dataset_rid for c in self.list_dataset_children(recurse=True)]\n            dataset_class = self.model.get_orm_class_by_name(self._dataset_table.name)\n            sql_statement = sql_statement.where(dataset_class.RID.in_(dataset_rid_list))\n            sql_statements.append(sql_statement)\n        return union(*sql_statements)\n\n    def _denormalize_from_members(\n        self,\n        include_tables: list[str],\n    ) -&gt; Generator[dict[str, Any], None, None]:\n        \"\"\"Denormalize dataset members by joining related tables.\n\n        This method creates a \"wide table\" view by joining related tables together,\n        using list_dataset_members() as the data source. This ensures consistency\n        with the catalog-based denormalize implementation. The result has outer join\n        semantics - tables without FK relationships are included with NULL values.\n\n        The method:\n        1. Gets the list of dataset members for each included table via list_dataset_members\n        2. For each member in the first table, follows foreign key relationships to\n           get related records from other tables\n        3. Tables without FK connections to the first table are included with NULLs\n        4. Includes nested dataset members recursively\n\n        Args:\n            include_tables: List of table names to include in the output.\n\n        Yields:\n            dict[str, Any]: Rows with column names prefixed by table name (e.g., \"Image.Filename\").\n                Unrelated tables have NULL values for their columns.\n\n        Note:\n            Column names in the result are prefixed with the table name to avoid\n            collisions (e.g., \"Image.Filename\", \"Subject.RID\").\n        \"\"\"\n        # Skip system columns in output\n        skip_columns = {\"RCT\", \"RMT\", \"RCB\", \"RMB\"}\n\n        # Get all members for the included tables (recursively includes nested datasets)\n        members = self.list_dataset_members(recurse=True)\n\n        # Build a lookup of columns for each table\n        table_columns: dict[str, list[str]] = {}\n        for table_name in include_tables:\n            table = self.model.name_to_table(table_name)\n            table_columns[table_name] = [\n                c.name for c in table.columns if c.name not in skip_columns\n            ]\n\n        # Find the primary table (first non-empty table in include_tables)\n        primary_table = None\n        for table_name in include_tables:\n            if table_name in members and members[table_name]:\n                primary_table = table_name\n                break\n\n        if primary_table is None:\n            # No data at all\n            return\n\n        primary_table_obj = self.model.name_to_table(primary_table)\n\n        for member in members[primary_table]:\n            # Build the row with all columns from all tables\n            row: dict[str, Any] = {}\n\n            # Add primary table columns\n            for col_name in table_columns[primary_table]:\n                prefixed_name = f\"{primary_table}.{col_name}\"\n                row[prefixed_name] = member.get(col_name)\n\n            # For each other table, try to join or add NULL values\n            for other_table_name in include_tables:\n                if other_table_name == primary_table:\n                    continue\n\n                other_table = self.model.name_to_table(other_table_name)\n                other_cols = table_columns[other_table_name]\n\n                # Initialize all columns to None (outer join behavior)\n                for col_name in other_cols:\n                    prefixed_name = f\"{other_table_name}.{col_name}\"\n                    row[prefixed_name] = None\n\n                # Try to find FK relationship and join\n                if other_table_name in members:\n                    try:\n                        relationship = self.model._table_relationship(\n                            primary_table_obj, other_table\n                        )\n                        fk_col, pk_col = relationship\n\n                        # Look up the related record\n                        fk_value = member.get(fk_col.name)\n                        if fk_value:\n                            for other_member in members.get(other_table_name, []):\n                                if other_member.get(pk_col.name) == fk_value:\n                                    for col_name in other_cols:\n                                        prefixed_name = f\"{other_table_name}.{col_name}\"\n                                        row[prefixed_name] = other_member.get(col_name)\n                                    break\n                    except DerivaMLException:\n                        # No FK relationship - columns remain NULL (outer join)\n                        pass\n\n            yield row\n\n    def denormalize_as_dataframe(\n        self,\n        include_tables: list[str],\n        version: Any = None,\n        **kwargs: Any,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Denormalize the dataset bag into a single wide table (DataFrame).\n\n        Denormalization transforms normalized relational data into a single \"wide table\"\n        (also called a \"flat table\" or \"denormalized table\") by joining related tables\n        together. This produces a DataFrame where each row contains all related information\n        from multiple source tables, with columns from each table combined side-by-side.\n\n        Wide tables are the standard input format for most machine learning frameworks,\n        which expect all features for a single observation to be in one row. This method\n        bridges the gap between normalized database schemas and ML-ready tabular data.\n\n        **How it works:**\n\n        Tables are joined based on their foreign key relationships stored in the bag's\n        schema. For example, if Image has a foreign key to Subject, denormalizing\n        [\"Subject\", \"Image\"] produces rows where each image appears with its subject's\n        metadata.\n\n        **Column naming:**\n\n        Column names are prefixed with the source table name using dots to avoid\n        collisions (e.g., \"Image.Filename\", \"Subject.RID\"). This differs from the\n        live Dataset class which uses underscores.\n\n        Args:\n            include_tables: List of table names to include in the output. Tables\n                are joined based on their foreign key relationships.\n                Order doesn't matter - the join order is determined automatically.\n            version: Ignored (bags are immutable snapshots of a specific version).\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Returns:\n            pd.DataFrame: Wide table with columns from all included tables.\n\n        Example:\n            Create a training dataset from a downloaded bag::\n\n                &gt;&gt;&gt; # Download and materialize the dataset\n                &gt;&gt;&gt; bag = ml.download_dataset_bag(spec, materialize=True)\n\n                &gt;&gt;&gt; # Denormalize into a wide table\n                &gt;&gt;&gt; df = bag.denormalize_as_dataframe([\"Image\", \"Diagnosis\"])\n                &gt;&gt;&gt; print(df.columns.tolist())\n                ['Image.RID', 'Image.Filename', 'Image.URL', 'Diagnosis.RID',\n                 'Diagnosis.Label', 'Diagnosis.Confidence']\n\n                &gt;&gt;&gt; # Access local file paths for images\n                &gt;&gt;&gt; for _, row in df.iterrows():\n                ...     local_path = bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n                ...     label = row[\"Diagnosis.Label\"]\n                ...     # Train on local_path with label\n\n        See Also:\n            denormalize_as_dict: Generator version for memory-efficient processing.\n        \"\"\"\n        rows = list(self._denormalize_from_members(include_tables=include_tables))\n        return pd.DataFrame(rows)\n\n    def denormalize_as_dict(\n        self,\n        include_tables: list[str],\n        version: Any = None,\n        **kwargs: Any,\n    ) -&gt; Generator[dict[str, Any], None, None]:\n        \"\"\"Denormalize the dataset bag and yield rows as dictionaries.\n\n        This is a memory-efficient alternative to denormalize_as_dataframe() that\n        yields one row at a time as a dictionary instead of loading all data into\n        a DataFrame. Use this when processing large datasets that may not fit in\n        memory, or when you want to process rows incrementally.\n\n        Like denormalize_as_dataframe(), this produces a \"wide table\" representation\n        where each yielded dictionary contains all columns from the joined tables.\n        See denormalize_as_dataframe() for detailed explanation of how denormalization\n        works.\n\n        **Column naming:**\n\n        Column names are prefixed with the source table name using dots to avoid\n        collisions (e.g., \"Image.Filename\", \"Subject.RID\"). This differs from the\n        live Dataset class which uses underscores.\n\n        Args:\n            include_tables: List of table names to include in the output.\n                Tables are joined based on their foreign key relationships.\n            version: Ignored (bags are immutable snapshots of a specific version).\n            **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n        Yields:\n            dict[str, Any]: Dictionary representing one row of the wide table.\n                Keys are column names in \"Table.Column\" format.\n\n        Example:\n            Stream through a large dataset for training::\n\n                &gt;&gt;&gt; bag = ml.download_dataset_bag(spec, materialize=True)\n                &gt;&gt;&gt; for row in bag.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n                ...     # Get local file path for this image\n                ...     local_path = bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n                ...     label = row[\"Diagnosis.Label\"]\n                ...     # Process image and label...\n\n            Build a PyTorch dataset efficiently::\n\n                &gt;&gt;&gt; class BagDataset(torch.utils.data.IterableDataset):\n                ...     def __init__(self, bag, tables):\n                ...         self.bag = bag\n                ...         self.tables = tables\n                ...     def __iter__(self):\n                ...         for row in self.bag.denormalize_as_dict(self.tables):\n                ...             img_path = self.bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n                ...             yield load_image(img_path), row[\"Diagnosis.Label\"]\n\n        See Also:\n            denormalize_as_dataframe: Returns all data as a pandas DataFrame.\n        \"\"\"\n        yield from self._denormalize_from_members(include_tables=include_tables)\n\n\n    # =========================================================================\n    # Asset Restructuring Methods\n    # =========================================================================\n\n    def _build_dataset_type_path_map(\n        self,\n        type_selector: Callable[[list[str]], str] | None = None,\n    ) -&gt; dict[RID, list[str]]:\n        \"\"\"Build a mapping from dataset RID to its type path in the hierarchy.\n\n        Recursively traverses nested datasets to create a mapping where each\n        dataset RID maps to its hierarchical type path (e.g., [\"complete\", \"training\"]).\n\n        Args:\n            type_selector: Function to select type when dataset has multiple types.\n                Receives list of type names, returns selected type name.\n                Defaults to selecting first type or \"unknown\" if no types.\n\n        Returns:\n            Dictionary mapping dataset RID to list of type names from root to leaf.\n            e.g., {\"4-ABC\": [\"complete\", \"training\"], \"4-DEF\": [\"complete\", \"testing\"]}\n        \"\"\"\n        if type_selector is None:\n            type_selector = lambda types: types[0] if types else \"Testing\"\n\n        type_paths: dict[RID, list[str]] = {}\n\n        def traverse(dataset: DatasetBag, parent_path: list[str], visited: set[RID]) -&gt; None:\n            if dataset.dataset_rid in visited:\n                return\n            visited.add(dataset.dataset_rid)\n\n            current_type = type_selector(dataset.dataset_types)\n            current_path = parent_path + [current_type]\n            type_paths[dataset.dataset_rid] = current_path\n\n            for child in dataset.list_dataset_children():\n                traverse(child, current_path, visited)\n\n        traverse(self, [], set())\n        return type_paths\n\n    def _get_asset_dataset_mapping(self, asset_table: str) -&gt; dict[RID, RID]:\n        \"\"\"Map asset RIDs to their containing dataset RID.\n\n        For each asset in the specified table, determines which dataset it belongs to.\n        This uses _dataset_table_view to find assets reachable through any FK path\n        from the dataset, not just directly associated assets.\n\n        Assets are mapped to their most specific (leaf) dataset in the hierarchy.\n        For example, if a Split dataset contains Training and Testing children,\n        and images are members of Training, the images map to Training (not Split).\n\n        Args:\n            asset_table: Name of the asset table (e.g., \"Image\")\n\n        Returns:\n            Dictionary mapping asset RID to the dataset RID that contains it.\n        \"\"\"\n        asset_to_dataset: dict[RID, RID] = {}\n\n        def collect_from_dataset(dataset: DatasetBag, visited: set[RID]) -&gt; None:\n            if dataset.dataset_rid in visited:\n                return\n            visited.add(dataset.dataset_rid)\n\n            # Process children FIRST (depth-first) so leaf datasets get priority\n            # This ensures assets are mapped to their most specific dataset\n            for child in dataset.list_dataset_children():\n                collect_from_dataset(child, visited)\n\n            # Then process this dataset's assets\n            # Only set if not already mapped (child/leaf dataset wins)\n            for asset in dataset._get_reachable_assets(asset_table):\n                if asset[\"RID\"] not in asset_to_dataset:\n                    asset_to_dataset[asset[\"RID\"]] = dataset.dataset_rid\n\n        collect_from_dataset(self, set())\n        return asset_to_dataset\n\n    def _get_reachable_assets(self, asset_table: str) -&gt; list[dict[str, Any]]:\n        \"\"\"Get all assets reachable from this dataset through any FK path.\n\n        Unlike list_dataset_members which only returns directly associated entities,\n        this method traverses foreign key relationships to find assets that are\n        indirectly connected to the dataset. For example, if a dataset contains\n        Subjects, and Subject -&gt; Encounter -&gt; Image, this method will find those\n        Images even though they're not directly in the Dataset_Image association table.\n\n        Args:\n            asset_table: Name of the asset table (e.g., \"Image\")\n\n        Returns:\n            List of asset records as dictionaries.\n        \"\"\"\n        # Use the _dataset_table_view query which traverses all FK paths\n        sql_query = self._dataset_table_view(asset_table)\n\n        with Session(self.engine) as session:\n            result = session.execute(sql_query)\n            # Convert rows to dictionaries\n            rows = [dict(row._mapping) for row in result]\n\n        return rows\n\n    def _load_feature_values_cache(\n        self,\n        asset_table: str,\n        group_keys: list[str],\n        enforce_vocabulary: bool = True,\n        value_selector: Callable[[list[FeatureValueRecord]], FeatureValueRecord] | None = None,\n    ) -&gt; dict[str, dict[RID, Any]]:\n        \"\"\"Load feature values into a cache for efficient lookup.\n\n        Pre-loads feature values for any group_keys that are feature names,\n        organizing them by target entity RID for fast lookup.\n\n        Args:\n            asset_table: The asset table name to find features for.\n            group_keys: List of potential feature names to cache. Supports two formats:\n                - \"FeatureName\": Uses the first term column (default behavior)\n                - \"FeatureName.column_name\": Uses the specified column from the feature table\n            enforce_vocabulary: If True (default), only allow features with\n                controlled vocabulary term columns and raise an error if an\n                asset has multiple values. If False, allow any feature type\n                and use the first value found when multiple exist.\n            value_selector: Optional function to select which feature value to use\n                when an asset has multiple values for the same feature. Receives a\n                list of FeatureValueRecord objects (each with execution_rid for\n                provenance) and returns the selected one. If not provided and\n                multiple values exist, raises DerivaMLException when\n                enforce_vocabulary=True or uses the first value when False.\n\n        Returns:\n            Dictionary mapping group_key -&gt; {target_rid -&gt; feature_value}\n            Only includes entries for keys that are actually features.\n\n        Raises:\n            DerivaMLException: If enforce_vocabulary is True and:\n                - A feature has no term columns (not vocabulary-based), or\n                - An asset has multiple different vocabulary term values for the same feature\n                  and no value_selector is provided.\n        \"\"\"\n        from deriva_ml.core.exceptions import DerivaMLException\n\n        cache: dict[str, dict[RID, Any]] = {}\n        # Store all feature value records for later selection when there are multiples\n        records_cache: dict[str, dict[RID, list[FeatureValueRecord]]] = {}\n        logger = logging.getLogger(\"deriva_ml\")\n\n        # Parse group_keys to extract feature names and optional column specifications\n        # Format: \"FeatureName\" or \"FeatureName.column_name\"\n        feature_column_map: dict[str, str | None] = {}  # group_key -&gt; specific column or None\n        feature_names_to_check: set[str] = set()\n        for key in group_keys:\n            if \".\" in key:\n                parts = key.split(\".\", 1)\n                feature_name = parts[0]\n                column_name = parts[1]\n                feature_column_map[key] = column_name\n                feature_names_to_check.add(feature_name)\n            else:\n                feature_column_map[key] = None\n                feature_names_to_check.add(key)\n\n        def process_feature(feat: Any, table_name: str, group_key: str, specific_column: str | None) -&gt; None:\n            \"\"\"Process a single feature and add its values to the cache.\"\"\"\n            term_cols = [c.name for c in feat.term_columns]\n            value_cols = [c.name for c in feat.value_columns]\n            all_cols = term_cols + value_cols\n\n            # Determine which column to use for the value\n            if specific_column:\n                # User specified a specific column\n                if specific_column not in all_cols:\n                    raise DerivaMLException(\n                        f\"Column '{specific_column}' not found in feature '{feat.feature_name}'. \"\n                        f\"Available columns: {all_cols}\"\n                    )\n                use_column = specific_column\n            elif term_cols:\n                # Use first term column (default behavior)\n                use_column = term_cols[0]\n            elif not enforce_vocabulary and value_cols:\n                # Fall back to value columns if allowed\n                use_column = value_cols[0]\n            else:\n                if enforce_vocabulary:\n                    raise DerivaMLException(\n                        f\"Feature '{feat.feature_name}' on table '{table_name}' has no \"\n                        f\"controlled vocabulary term columns. Only vocabulary-based features \"\n                        f\"can be used for grouping when enforce_vocabulary=True. \"\n                        f\"Set enforce_vocabulary=False to allow non-vocabulary features.\"\n                    )\n                return\n\n            records_cache[group_key] = defaultdict(list)\n            feature_values = self.list_feature_values(table_name, feat.feature_name)\n\n            for fv in feature_values:\n                # Convert FeatureRecord to dict for easier access\n                fv_dict = fv.model_dump()\n                target_col = table_name\n                if target_col not in fv_dict:\n                    continue\n\n                target_rid = fv_dict[target_col]\n\n                # Get the value from the specified column\n                value = fv_dict.get(use_column) if use_column in fv_dict else None\n\n                if value is None:\n                    continue\n\n                # Create a FeatureValueRecord with execution provenance\n                record = FeatureValueRecord(\n                    target_rid=target_rid,\n                    feature_name=feat.feature_name,\n                    value=value,\n                    execution_rid=fv_dict.get(\"Execution\"),\n                    raw_record=fv_dict,\n                )\n                records_cache[group_key][target_rid].append(record)\n\n        # Find all features on tables that this asset table references\n        asset_table_obj = self.model.name_to_table(asset_table)\n\n        # Check features on the asset table itself\n        for feature in self.find_features(asset_table):\n            if feature.feature_name in feature_names_to_check:\n                # Find all group_keys that reference this feature\n                for group_key, specific_col in feature_column_map.items():\n                    # Check if this group_key references this feature\n                    key_feature = group_key.split(\".\")[0] if \".\" in group_key else group_key\n                    if key_feature == feature.feature_name:\n                        try:\n                            process_feature(feature, asset_table, group_key, specific_col)\n                        except DerivaMLException:\n                            raise\n                        except Exception as e:\n                            logger.warning(f\"Could not load feature {feature.feature_name}: {e}\")\n\n        # Also check features on referenced tables (via foreign keys)\n        for fk in asset_table_obj.foreign_keys:\n            target_table = fk.pk_table\n            for feature in self.find_features(target_table):\n                if feature.feature_name in feature_names_to_check:\n                    # Find all group_keys that reference this feature\n                    for group_key, specific_col in feature_column_map.items():\n                        # Check if this group_key references this feature\n                        key_feature = group_key.split(\".\")[0] if \".\" in group_key else group_key\n                        if key_feature == feature.feature_name:\n                            try:\n                                process_feature(feature, target_table.name, group_key, specific_col)\n                            except DerivaMLException:\n                                raise\n                            except Exception as e:\n                                logger.warning(f\"Could not load feature {feature.feature_name}: {e}\")\n\n        # Now resolve multiple values using value_selector or error handling\n        for group_key, target_records in records_cache.items():\n            cache[group_key] = {}\n            for target_rid, records in target_records.items():\n                if len(records) == 1:\n                    # Single value - straightforward\n                    cache[group_key][target_rid] = records[0].value\n                elif len(records) &gt; 1:\n                    # Multiple values - need to resolve\n                    unique_values = set(r.value for r in records)\n                    if len(unique_values) == 1:\n                        # All records have same value, use it\n                        cache[group_key][target_rid] = records[0].value\n                    elif value_selector:\n                        # Use provided selector function\n                        selected = value_selector(records)\n                        cache[group_key][target_rid] = selected.value\n                    elif enforce_vocabulary:\n                        # Multiple different values without selector - error\n                        values_str = \", \".join(f\"'{r.value}' (exec: {r.execution_rid})\" for r in records)\n                        raise DerivaMLException(\n                            f\"Asset '{target_rid}' has multiple different values for \"\n                            f\"feature '{records[0].feature_name}': {values_str}. \"\n                            f\"Provide a value_selector function to choose between values, \"\n                            f\"or set enforce_vocabulary=False to use the first value.\"\n                        )\n                    else:\n                        # Not enforcing - use first value\n                        cache[group_key][target_rid] = records[0].value\n\n        return cache\n\n    def _resolve_grouping_value(\n        self,\n        asset: dict[str, Any],\n        group_key: str,\n        feature_cache: dict[str, dict[RID, Any]],\n    ) -&gt; str:\n        \"\"\"Resolve a grouping value for an asset.\n\n        First checks if group_key is a direct column on the asset record,\n        then checks if it's a feature name in the feature cache.\n\n        Args:\n            asset: The asset record dictionary.\n            group_key: Column name or feature name to group by.\n            feature_cache: Pre-loaded feature values keyed by feature name -&gt; target RID -&gt; value.\n\n        Returns:\n            The resolved value as a string, or \"Unknown\" if not found or None.\n            Uses \"Unknown\" (capitalized) to match vocabulary term naming conventions.\n        \"\"\"\n        # First check if it's a direct column on the asset table\n        if group_key in asset:\n            value = asset[group_key]\n            if value is not None:\n                return str(value)\n            return \"Unknown\"\n\n        # Check if it's a feature name\n        if group_key in feature_cache:\n            feature_values = feature_cache[group_key]\n            # Check each column in the asset that might be a FK to the feature target\n            for column_name, column_value in asset.items():\n                if column_value and column_value in feature_values:\n                    return str(feature_values[column_value])\n            # Also check if the asset's own RID is in the feature values\n            if asset.get(\"RID\") in feature_values:\n                return str(feature_values[asset[\"RID\"]])\n\n        return \"Unknown\"\n\n    def _detect_asset_table(self) -&gt; str | None:\n        \"\"\"Auto-detect the asset table from dataset members.\n\n        Searches for asset tables in the dataset members by examining\n        the schema. Returns the first asset table found, or None if\n        no asset tables are in the dataset.\n\n        Returns:\n            Name of the detected asset table, or None if not found.\n        \"\"\"\n        members = self.list_dataset_members(recurse=True)\n        for table_name in members:\n            if table_name == \"Dataset\":\n                continue\n            # Check if this table is an asset table\n            try:\n                table = self.model.name_to_table(table_name)\n                if self.model.is_asset(table):\n                    return table_name\n            except (KeyError, AttributeError):\n                continue\n        return None\n\n    def _validate_dataset_types(self) -&gt; list[str] | None:\n        \"\"\"Validate that the dataset or its children have Training/Testing types.\n\n        Checks if this dataset is of type Training or Testing, or if it has\n        nested children of those types. Returns the valid types found.\n\n        Returns:\n            List of Training/Testing type names found, or None if validation fails.\n        \"\"\"\n        valid_types = {\"Training\", \"Testing\"}\n        found_types: set[str] = set()\n\n        def check_dataset(ds: DatasetBag, visited: set[RID]) -&gt; None:\n            if ds.dataset_rid in visited:\n                return\n            visited.add(ds.dataset_rid)\n\n            for dtype in ds.dataset_types:\n                if dtype in valid_types:\n                    found_types.add(dtype)\n\n            for child in ds.list_dataset_children():\n                check_dataset(child, visited)\n\n        check_dataset(self, set())\n        return list(found_types) if found_types else None\n\n    def restructure_assets(\n        self,\n        output_dir: Path | str,\n        asset_table: str | None = None,\n        group_by: list[str] | None = None,\n        use_symlinks: bool = True,\n        type_selector: Callable[[list[str]], str] | None = None,\n        type_to_dir_map: dict[str, str] | None = None,\n        enforce_vocabulary: bool = True,\n        value_selector: Callable[[list[FeatureValueRecord]], FeatureValueRecord] | None = None,\n    ) -&gt; Path:\n        \"\"\"Restructure downloaded assets into a directory hierarchy.\n\n        Creates a directory structure organizing assets by dataset types and\n        grouping values. This is useful for ML workflows that expect data\n        organized in conventional folder structures (e.g., PyTorch ImageFolder).\n\n        The dataset should be of type Training or Testing, or have nested\n        children of those types. The top-level directory name is determined\n        by the dataset type (e.g., \"Training\" -&gt; \"training\").\n\n        **Finding assets through foreign key relationships:**\n\n        Assets are found by traversing all foreign key paths from the dataset,\n        not just direct associations. For example, if a dataset contains Subjects,\n        and the schema has Subject -&gt; Encounter -&gt; Image relationships, this method\n        will find all Images reachable through those paths even though they are\n        not directly in a Dataset_Image association table.\n\n        **Handling datasets without types (prediction scenarios):**\n\n        If a dataset has no type defined, it is treated as Testing. This is\n        common for prediction/inference scenarios where you want to apply a\n        trained model to new unlabeled data.\n\n        **Handling missing labels:**\n\n        If an asset doesn't have a value for a group_by key (e.g., no label\n        assigned), it is placed in an \"Unknown\" directory. This allows\n        restructure_assets to work with unlabeled data for prediction.\n\n        Args:\n            output_dir: Base directory for restructured assets.\n            asset_table: Name of the asset table (e.g., \"Image\"). If None,\n                auto-detects from dataset members. Raises DerivaMLException\n                if multiple asset tables are found and none is specified.\n            group_by: Names to group assets by. Each name creates a subdirectory\n                level after the dataset type path. Names can be:\n\n                - **Column names**: Direct columns on the asset table. The column\n                  value becomes the subdirectory name.\n                - **Feature names**: Features defined on the asset table (or tables\n                  it references via foreign keys). The feature's vocabulary term\n                  value becomes the subdirectory name.\n                - **Feature.column**: Specify a particular column from a multi-term\n                  feature (e.g., \"Classification.Label\" to use the Label column).\n\n                Column names are checked first, then feature names. If a value\n                is not found, \"unknown\" is used as the subdirectory name.\n\n            use_symlinks: If True (default), create symlinks to original files.\n                If False, copy files. Symlinks save disk space but require\n                the original bag to remain in place.\n            type_selector: Function to select type when dataset has multiple types.\n                Receives list of type names, returns selected type name.\n                Defaults to selecting first type or \"unknown\" if no types.\n            type_to_dir_map: Optional mapping from dataset type names to directory\n                names. Defaults to {\"Training\": \"training\", \"Testing\": \"testing\",\n                \"Unknown\": \"unknown\"}. Use this to customize directory names or\n                add new type mappings.\n            enforce_vocabulary: If True (default), only allow features that have\n                controlled vocabulary term columns, and raise an error if an asset\n                has multiple different values for the same feature without a\n                value_selector. This ensures clean, unambiguous directory structures.\n                If False, allow any feature type and use the first value found\n                when multiple values exist.\n            value_selector: Optional function to select which feature value to use\n                when an asset has multiple values for the same feature. Receives a\n                list of FeatureValueRecord objects (each containing target_rid,\n                feature_name, value, execution_rid, and raw_record) and returns\n                the selected FeatureValueRecord. Use execution_rid to distinguish\n                between values from different executions.\n\n        Returns:\n            Path to the output directory.\n\n        Raises:\n            DerivaMLException: If asset_table cannot be determined (multiple\n                asset tables exist without specification), if no valid dataset\n                types (Training/Testing) are found, or if enforce_vocabulary\n                is True and a feature has multiple values without value_selector.\n\n        Examples:\n            Basic restructuring with auto-detected asset table::\n\n                bag.restructure_assets(\n                    output_dir=\"./ml_data\",\n                    group_by=[\"Diagnosis\"],\n                )\n                # Creates:\n                # ./ml_data/training/Normal/image1.jpg\n                # ./ml_data/testing/Abnormal/image2.jpg\n\n            Custom type-to-directory mapping::\n\n                bag.restructure_assets(\n                    output_dir=\"./ml_data\",\n                    group_by=[\"Diagnosis\"],\n                    type_to_dir_map={\"Training\": \"train\", \"Testing\": \"test\"},\n                )\n                # Creates:\n                # ./ml_data/train/Normal/image1.jpg\n                # ./ml_data/test/Abnormal/image2.jpg\n\n            Select specific feature column for multi-term features::\n\n                bag.restructure_assets(\n                    output_dir=\"./ml_data\",\n                    group_by=[\"Classification.Label\"],  # Use Label column\n                )\n\n            Handle multiple feature values with a selector::\n\n                def select_latest(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n                    # Select value from most recent execution\n                    return max(records, key=lambda r: r.execution_rid or \"\")\n\n                bag.restructure_assets(\n                    output_dir=\"./ml_data\",\n                    group_by=[\"Diagnosis\"],\n                    value_selector=select_latest,\n                )\n\n            Prediction scenario with unlabeled data::\n\n                # Dataset has no type - treated as Testing\n                # Assets have no labels - placed in Unknown directory\n                bag.restructure_assets(\n                    output_dir=\"./prediction_data\",\n                    group_by=[\"Diagnosis\"],\n                )\n                # Creates:\n                # ./prediction_data/testing/Unknown/image1.jpg\n                # ./prediction_data/testing/Unknown/image2.jpg\n        \"\"\"\n        logger = logging.getLogger(\"deriva_ml\")\n        group_by = group_by or []\n        output_dir = Path(output_dir)\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n        # Default type-to-directory mapping\n        if type_to_dir_map is None:\n            type_to_dir_map = {\"Training\": \"training\", \"Testing\": \"testing\", \"Unknown\": \"unknown\"}\n\n        # Auto-detect asset table if not provided\n        if asset_table is None:\n            asset_table = self._detect_asset_table()\n            if asset_table is None:\n                raise DerivaMLException(\n                    \"Could not auto-detect asset table. No asset tables found in dataset members. \"\n                    \"Specify the asset_table parameter explicitly.\"\n                )\n            logger.info(f\"Auto-detected asset table: {asset_table}\")\n\n        # Step 1: Build dataset type path map with directory name mapping\n        def map_type_to_dir(types: list[str]) -&gt; str:\n            \"\"\"Map dataset types to directory name using type_to_dir_map.\n\n            If dataset has no types, treat it as Testing (prediction use case).\n            \"\"\"\n            if not types:\n                # No types defined - treat as Testing for prediction scenarios\n                return type_to_dir_map.get(\"Testing\", \"testing\")\n            if type_selector:\n                selected_type = type_selector(types)\n            else:\n                selected_type = types[0]\n            return type_to_dir_map.get(selected_type, selected_type.lower())\n\n        type_path_map = self._build_dataset_type_path_map(map_type_to_dir)\n\n        # Step 2: Get asset-to-dataset mapping\n        asset_dataset_map = self._get_asset_dataset_mapping(asset_table)\n\n        # Step 3: Load feature values cache for relevant features\n        feature_cache = self._load_feature_values_cache(\n            asset_table, group_by, enforce_vocabulary, value_selector\n        )\n\n        # Step 4: Get all assets reachable through FK paths\n        # This uses _get_reachable_assets which traverses FK relationships,\n        # so assets connected via Subject -&gt; Encounter -&gt; Image are found\n        # even if the dataset only contains Subjects directly.\n        assets = self._get_reachable_assets(asset_table)\n\n        if not assets:\n            logger.warning(f\"No assets found in table '{asset_table}'\")\n            return output_dir\n\n        # Step 5: Process each asset\n        for asset in assets:\n            # Get source file path\n            filename = asset.get(\"Filename\")\n            if not filename:\n                logger.warning(f\"Asset {asset.get('RID')} has no Filename\")\n                continue\n\n            source_path = Path(filename)\n            if not source_path.exists():\n                logger.warning(f\"Asset file not found: {source_path}\")\n                continue\n\n            # Get dataset type path\n            dataset_rid = asset_dataset_map.get(asset[\"RID\"])\n            type_path = type_path_map.get(dataset_rid, [\"unknown\"])\n\n            # Resolve grouping values\n            group_path = []\n            for key in group_by:\n                value = self._resolve_grouping_value(asset, key, feature_cache)\n                group_path.append(value)\n\n            # Build target directory\n            target_dir = output_dir.joinpath(*type_path, *group_path)\n            target_dir.mkdir(parents=True, exist_ok=True)\n\n            # Create link or copy\n            target_path = target_dir / source_path.name\n\n            # Handle existing files\n            if target_path.exists() or target_path.is_symlink():\n                target_path.unlink()\n\n            if use_symlinks:\n                try:\n                    target_path.symlink_to(source_path.resolve())\n                except OSError as e:\n                    # Fall back to copy on platforms that don't support symlinks\n                    logger.warning(f\"Symlink failed, falling back to copy: {e}\")\n                    shutil.copy2(source_path, target_path)\n            else:\n                shutil.copy2(source_path, target_path)\n\n        return output_dir\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag--download-a-dataset","title":"Download a dataset","text":"<p>bag = dataset.download_dataset_bag(version=\"1.0.0\")</p>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag--list-members-by-type","title":"List members by type","text":"<p>members = bag.list_dataset_members() for image in members.get(\"Image\", []): ...     print(f\"File: {image['Filename']}\")</p>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag--navigate-to-nested-datasets","title":"Navigate to nested datasets","text":"<p>for child in bag.list_dataset_children(): ...     print(f\"Nested: {child.dataset_rid}\")</p>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.current_version","title":"current_version  <code>property</code>","text":"<pre><code>current_version: DatasetVersion\n</code></pre> <p>Get the version of the dataset at the time the bag was downloaded.</p> <p>For a DatasetBag, this is the version that was current when the bag was created. Unlike the live Dataset class, this value is immutable since bags are read-only snapshots.</p> <p>Returns:</p> Name Type Description <code>DatasetVersion</code> <code>DatasetVersion</code> <p>The semantic version (major.minor.patch) of this dataset.</p>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.__init__","title":"__init__","text":"<pre><code>__init__(\n    catalog: \"DerivaMLDatabase\",\n    dataset_rid: RID | None = None,\n    dataset_types: str\n    | list[str]\n    | None = None,\n    description: str = \"\",\n    execution_rid: RID | None = None,\n)\n</code></pre> <p>Initialize a DatasetBag instance for a dataset within a downloaded bag.</p> <p>This mirrors the Dataset class initialization pattern, where both classes take a catalog-like object as their first argument for consistency.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>'DerivaMLDatabase'</code> <p>The DerivaMLDatabase instance providing access to the bag's data. This implements the DerivaMLCatalog protocol.</p> required <code>dataset_rid</code> <code>RID | None</code> <p>The RID of the dataset to wrap. If None, uses the primary dataset RID from the bag.</p> <code>None</code> <code>dataset_types</code> <code>str | list[str] | None</code> <p>One or more dataset type terms. Can be a single string or list of strings.</p> <code>None</code> <code>description</code> <code>str</code> <p>Human-readable description of the dataset.</p> <code>''</code> <code>execution_rid</code> <code>RID | None</code> <p>RID of the execution associated with this dataset version. If None, will be looked up from the Dataset_Version table.</p> <code>None</code> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If no dataset_rid is provided and none can be determined from the bag, or if the RID doesn't exist in the bag.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def __init__(\n    self,\n    catalog: \"DerivaMLDatabase\",\n    dataset_rid: RID | None = None,\n    dataset_types: str | list[str] | None = None,\n    description: str = \"\",\n    execution_rid: RID | None = None,\n):\n    \"\"\"Initialize a DatasetBag instance for a dataset within a downloaded bag.\n\n    This mirrors the Dataset class initialization pattern, where both classes\n    take a catalog-like object as their first argument for consistency.\n\n    Args:\n        catalog: The DerivaMLDatabase instance providing access to the bag's data.\n            This implements the DerivaMLCatalog protocol.\n        dataset_rid: The RID of the dataset to wrap. If None, uses the primary\n            dataset RID from the bag.\n        dataset_types: One or more dataset type terms. Can be a single string\n            or list of strings.\n        description: Human-readable description of the dataset.\n        execution_rid: RID of the execution associated with this dataset version.\n            If None, will be looked up from the Dataset_Version table.\n\n    Raises:\n        DerivaMLException: If no dataset_rid is provided and none can be\n            determined from the bag, or if the RID doesn't exist in the bag.\n    \"\"\"\n    # Store reference to the catalog and extract the underlying model\n    self._catalog = catalog\n    self.model = catalog.model\n    self.engine = cast(Engine, self.model.engine)\n    self.metadata = self.model.metadata\n\n    # Use provided RID or fall back to the bag's primary dataset\n    self.dataset_rid = dataset_rid or self.model.dataset_rid\n    self.description = description\n    self.execution_rid = execution_rid or (\n        self.model._get_dataset_execution(self.dataset_rid) or {}\n    ).get(\"Execution\")\n\n    # Normalize dataset_types to always be a list of strings for consistency\n    # with the Dataset class interface\n    if dataset_types is None:\n        self.dataset_types: list[str] = []\n    elif isinstance(dataset_types, str):\n        self.dataset_types: list[str] = [dataset_types]\n    else:\n        self.dataset_types: list[str] = list(dataset_types)\n\n    if not self.dataset_rid:\n        raise DerivaMLException(\"No dataset RID provided\")\n\n    # Validate that this dataset exists in the bag\n    self.model.rid_lookup(self.dataset_rid)\n\n    # Cache the version and dataset table reference\n    self._current_version = self.model.dataset_version(self.dataset_rid)\n    self._dataset_table = self.model.dataset_table\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Return a string representation of the DatasetBag for debugging.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the DatasetBag for debugging.\"\"\"\n    return (f\"&lt;deriva_ml.DatasetBag object at {hex(id(self))}: rid='{self.dataset_rid}', \"\n            f\"version='{self.current_version}', types={self.dataset_types}&gt;\")\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.dataset_history","title":"dataset_history","text":"<pre><code>dataset_history() -&gt; list[\n    DatasetHistory\n]\n</code></pre> <p>Retrieves the version history of a dataset.</p> <p>Returns a chronological list of dataset versions, including their version numbers, creation times, and associated metadata.</p> <p>Returns:</p> Type Description <code>list[DatasetHistory]</code> <p>list[DatasetHistory]: List of history entries, each containing: - dataset_version: Version number (major.minor.patch) - minid: Minimal Viable Identifier - snapshot: Catalog snapshot time - dataset_rid: Dataset Resource Identifier - version_rid: Version Resource Identifier - description: Version description - execution_rid: Associated execution RID</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If dataset_rid is not a valid dataset RID.</p> Example <p>history = ml.dataset_history(\"1-abc123\") for entry in history: ...     print(f\"Version {entry.dataset_version}: {entry.description}\")</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def dataset_history(self) -&gt; list[DatasetHistory]:\n    \"\"\"Retrieves the version history of a dataset.\n\n    Returns a chronological list of dataset versions, including their version numbers,\n    creation times, and associated metadata.\n\n    Returns:\n        list[DatasetHistory]: List of history entries, each containing:\n            - dataset_version: Version number (major.minor.patch)\n            - minid: Minimal Viable Identifier\n            - snapshot: Catalog snapshot time\n            - dataset_rid: Dataset Resource Identifier\n            - version_rid: Version Resource Identifier\n            - description: Version description\n            - execution_rid: Associated execution RID\n\n    Raises:\n        DerivaMLException: If dataset_rid is not a valid dataset RID.\n\n    Example:\n        &gt;&gt;&gt; history = ml.dataset_history(\"1-abc123\")\n        &gt;&gt;&gt; for entry in history:\n        ...     print(f\"Version {entry.dataset_version}: {entry.description}\")\n    \"\"\"\n    # Query Dataset_Version table directly via the model\n    return [\n        DatasetHistory(\n            dataset_version=DatasetVersion.parse(v[\"Version\"]),\n            minid=v[\"Minid\"],\n            snapshot=v[\"Snapshot\"],\n            dataset_rid=self.dataset_rid,\n            version_rid=v[\"RID\"],\n            description=v[\"Description\"],\n            execution_rid=v[\"Execution\"],\n        )\n        for v in self.model._get_table_contents(\"Dataset_Version\")\n        if v[\"Dataset\"] == self.dataset_rid\n    ]\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.denormalize_as_dataframe","title":"denormalize_as_dataframe","text":"<pre><code>denormalize_as_dataframe(\n    include_tables: list[str],\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; pd.DataFrame\n</code></pre> <p>Denormalize the dataset bag into a single wide table (DataFrame).</p> <p>Denormalization transforms normalized relational data into a single \"wide table\" (also called a \"flat table\" or \"denormalized table\") by joining related tables together. This produces a DataFrame where each row contains all related information from multiple source tables, with columns from each table combined side-by-side.</p> <p>Wide tables are the standard input format for most machine learning frameworks, which expect all features for a single observation to be in one row. This method bridges the gap between normalized database schemas and ML-ready tabular data.</p> <p>How it works:</p> <p>Tables are joined based on their foreign key relationships stored in the bag's schema. For example, if Image has a foreign key to Subject, denormalizing [\"Subject\", \"Image\"] produces rows where each image appears with its subject's metadata.</p> <p>Column naming:</p> <p>Column names are prefixed with the source table name using dots to avoid collisions (e.g., \"Image.Filename\", \"Subject.RID\"). This differs from the live Dataset class which uses underscores.</p> <p>Parameters:</p> Name Type Description Default <code>include_tables</code> <code>list[str]</code> <p>List of table names to include in the output. Tables are joined based on their foreign key relationships. Order doesn't matter - the join order is determined automatically.</p> required <code>version</code> <code>Any</code> <p>Ignored (bags are immutable snapshots of a specific version).</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Wide table with columns from all included tables.</p> Example <p>Create a training dataset from a downloaded bag::</p> <pre><code>&gt;&gt;&gt; # Download and materialize the dataset\n&gt;&gt;&gt; bag = ml.download_dataset_bag(spec, materialize=True)\n\n&gt;&gt;&gt; # Denormalize into a wide table\n&gt;&gt;&gt; df = bag.denormalize_as_dataframe([\"Image\", \"Diagnosis\"])\n&gt;&gt;&gt; print(df.columns.tolist())\n['Image.RID', 'Image.Filename', 'Image.URL', 'Diagnosis.RID',\n 'Diagnosis.Label', 'Diagnosis.Confidence']\n\n&gt;&gt;&gt; # Access local file paths for images\n&gt;&gt;&gt; for _, row in df.iterrows():\n...     local_path = bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n...     label = row[\"Diagnosis.Label\"]\n...     # Train on local_path with label\n</code></pre> See Also <p>denormalize_as_dict: Generator version for memory-efficient processing.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def denormalize_as_dataframe(\n    self,\n    include_tables: list[str],\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; pd.DataFrame:\n    \"\"\"Denormalize the dataset bag into a single wide table (DataFrame).\n\n    Denormalization transforms normalized relational data into a single \"wide table\"\n    (also called a \"flat table\" or \"denormalized table\") by joining related tables\n    together. This produces a DataFrame where each row contains all related information\n    from multiple source tables, with columns from each table combined side-by-side.\n\n    Wide tables are the standard input format for most machine learning frameworks,\n    which expect all features for a single observation to be in one row. This method\n    bridges the gap between normalized database schemas and ML-ready tabular data.\n\n    **How it works:**\n\n    Tables are joined based on their foreign key relationships stored in the bag's\n    schema. For example, if Image has a foreign key to Subject, denormalizing\n    [\"Subject\", \"Image\"] produces rows where each image appears with its subject's\n    metadata.\n\n    **Column naming:**\n\n    Column names are prefixed with the source table name using dots to avoid\n    collisions (e.g., \"Image.Filename\", \"Subject.RID\"). This differs from the\n    live Dataset class which uses underscores.\n\n    Args:\n        include_tables: List of table names to include in the output. Tables\n            are joined based on their foreign key relationships.\n            Order doesn't matter - the join order is determined automatically.\n        version: Ignored (bags are immutable snapshots of a specific version).\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Returns:\n        pd.DataFrame: Wide table with columns from all included tables.\n\n    Example:\n        Create a training dataset from a downloaded bag::\n\n            &gt;&gt;&gt; # Download and materialize the dataset\n            &gt;&gt;&gt; bag = ml.download_dataset_bag(spec, materialize=True)\n\n            &gt;&gt;&gt; # Denormalize into a wide table\n            &gt;&gt;&gt; df = bag.denormalize_as_dataframe([\"Image\", \"Diagnosis\"])\n            &gt;&gt;&gt; print(df.columns.tolist())\n            ['Image.RID', 'Image.Filename', 'Image.URL', 'Diagnosis.RID',\n             'Diagnosis.Label', 'Diagnosis.Confidence']\n\n            &gt;&gt;&gt; # Access local file paths for images\n            &gt;&gt;&gt; for _, row in df.iterrows():\n            ...     local_path = bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n            ...     label = row[\"Diagnosis.Label\"]\n            ...     # Train on local_path with label\n\n    See Also:\n        denormalize_as_dict: Generator version for memory-efficient processing.\n    \"\"\"\n    rows = list(self._denormalize_from_members(include_tables=include_tables))\n    return pd.DataFrame(rows)\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.denormalize_as_dict","title":"denormalize_as_dict","text":"<pre><code>denormalize_as_dict(\n    include_tables: list[str],\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; Generator[\n    dict[str, Any], None, None\n]\n</code></pre> <p>Denormalize the dataset bag and yield rows as dictionaries.</p> <p>This is a memory-efficient alternative to denormalize_as_dataframe() that yields one row at a time as a dictionary instead of loading all data into a DataFrame. Use this when processing large datasets that may not fit in memory, or when you want to process rows incrementally.</p> <p>Like denormalize_as_dataframe(), this produces a \"wide table\" representation where each yielded dictionary contains all columns from the joined tables. See denormalize_as_dataframe() for detailed explanation of how denormalization works.</p> <p>Column naming:</p> <p>Column names are prefixed with the source table name using dots to avoid collisions (e.g., \"Image.Filename\", \"Subject.RID\"). This differs from the live Dataset class which uses underscores.</p> <p>Parameters:</p> Name Type Description Default <code>include_tables</code> <code>list[str]</code> <p>List of table names to include in the output. Tables are joined based on their foreign key relationships.</p> required <code>version</code> <code>Any</code> <p>Ignored (bags are immutable snapshots of a specific version).</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Yields:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary representing one row of the wide table. Keys are column names in \"Table.Column\" format.</p> Example <p>Stream through a large dataset for training::</p> <pre><code>&gt;&gt;&gt; bag = ml.download_dataset_bag(spec, materialize=True)\n&gt;&gt;&gt; for row in bag.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n...     # Get local file path for this image\n...     local_path = bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n...     label = row[\"Diagnosis.Label\"]\n...     # Process image and label...\n</code></pre> <p>Build a PyTorch dataset efficiently::</p> <pre><code>&gt;&gt;&gt; class BagDataset(torch.utils.data.IterableDataset):\n...     def __init__(self, bag, tables):\n...         self.bag = bag\n...         self.tables = tables\n...     def __iter__(self):\n...         for row in self.bag.denormalize_as_dict(self.tables):\n...             img_path = self.bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n...             yield load_image(img_path), row[\"Diagnosis.Label\"]\n</code></pre> See Also <p>denormalize_as_dataframe: Returns all data as a pandas DataFrame.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def denormalize_as_dict(\n    self,\n    include_tables: list[str],\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; Generator[dict[str, Any], None, None]:\n    \"\"\"Denormalize the dataset bag and yield rows as dictionaries.\n\n    This is a memory-efficient alternative to denormalize_as_dataframe() that\n    yields one row at a time as a dictionary instead of loading all data into\n    a DataFrame. Use this when processing large datasets that may not fit in\n    memory, or when you want to process rows incrementally.\n\n    Like denormalize_as_dataframe(), this produces a \"wide table\" representation\n    where each yielded dictionary contains all columns from the joined tables.\n    See denormalize_as_dataframe() for detailed explanation of how denormalization\n    works.\n\n    **Column naming:**\n\n    Column names are prefixed with the source table name using dots to avoid\n    collisions (e.g., \"Image.Filename\", \"Subject.RID\"). This differs from the\n    live Dataset class which uses underscores.\n\n    Args:\n        include_tables: List of table names to include in the output.\n            Tables are joined based on their foreign key relationships.\n        version: Ignored (bags are immutable snapshots of a specific version).\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Yields:\n        dict[str, Any]: Dictionary representing one row of the wide table.\n            Keys are column names in \"Table.Column\" format.\n\n    Example:\n        Stream through a large dataset for training::\n\n            &gt;&gt;&gt; bag = ml.download_dataset_bag(spec, materialize=True)\n            &gt;&gt;&gt; for row in bag.denormalize_as_dict([\"Image\", \"Diagnosis\"]):\n            ...     # Get local file path for this image\n            ...     local_path = bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n            ...     label = row[\"Diagnosis.Label\"]\n            ...     # Process image and label...\n\n        Build a PyTorch dataset efficiently::\n\n            &gt;&gt;&gt; class BagDataset(torch.utils.data.IterableDataset):\n            ...     def __init__(self, bag, tables):\n            ...         self.bag = bag\n            ...         self.tables = tables\n            ...     def __iter__(self):\n            ...         for row in self.bag.denormalize_as_dict(self.tables):\n            ...             img_path = self.bag.get_asset_path(\"Image\", row[\"Image.RID\"])\n            ...             yield load_image(img_path), row[\"Diagnosis.Label\"]\n\n    See Also:\n        denormalize_as_dataframe: Returns all data as a pandas DataFrame.\n    \"\"\"\n    yield from self._denormalize_from_members(include_tables=include_tables)\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.find_features","title":"find_features","text":"<pre><code>find_features(\n    table: str | Table,\n) -&gt; Iterable[Feature]\n</code></pre> <p>Find features for a table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>The table to find features for.</p> required <p>Returns:</p> Type Description <code>Iterable[Feature]</code> <p>An iterable of Feature instances.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def find_features(self, table: str | Table) -&gt; Iterable[Feature]:\n    \"\"\"Find features for a table.\n\n    Args:\n        table: The table to find features for.\n\n    Returns:\n        An iterable of Feature instances.\n    \"\"\"\n    return self.model.find_features(table)\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.get_table_as_dict","title":"get_table_as_dict","text":"<pre><code>get_table_as_dict(\n    table: str,\n) -&gt; Generator[\n    dict[str, Any], None, None\n]\n</code></pre> <p>Get table contents as dictionaries.</p> <p>Convenience method that delegates to the underlying catalog. This provides access to all rows in a table, not just those belonging to this dataset. For dataset-filtered results, use list_dataset_members() instead.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Name of the table to retrieve (e.g., \"Subject\", \"Image\").</p> required <p>Yields:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>Dictionary for each row in the table.</p> Example <p>for subject in bag.get_table_as_dict(\"Subject\"): ...     print(subject[\"Name\"])</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def get_table_as_dict(self, table: str) -&gt; Generator[dict[str, Any], None, None]:\n    \"\"\"Get table contents as dictionaries.\n\n    Convenience method that delegates to the underlying catalog. This provides\n    access to all rows in a table, not just those belonging to this dataset.\n    For dataset-filtered results, use list_dataset_members() instead.\n\n    Args:\n        table: Name of the table to retrieve (e.g., \"Subject\", \"Image\").\n\n    Yields:\n        dict: Dictionary for each row in the table.\n\n    Example:\n        &gt;&gt;&gt; for subject in bag.get_table_as_dict(\"Subject\"):\n        ...     print(subject[\"Name\"])\n    \"\"\"\n    return self._catalog.get_table_as_dict(table)\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_dataset_children","title":"list_dataset_children","text":"<pre><code>list_dataset_children(\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; list[Self]\n</code></pre> <p>Get nested datasets.</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>Whether to include children of children.</p> <code>False</code> <code>_visited</code> <code>set[RID] | None</code> <p>Internal parameter to track visited datasets and prevent infinite recursion.</p> <code>None</code> <code>version</code> <code>Any</code> <p>Ignored (bags are immutable snapshots).</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[Self]</code> <p>List of child dataset bags.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def list_dataset_children(\n    self,\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; list[Self]:\n    \"\"\"Get nested datasets.\n\n    Args:\n        recurse: Whether to include children of children.\n        _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n        version: Ignored (bags are immutable snapshots).\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Returns:\n        List of child dataset bags.\n    \"\"\"\n    # Initialize visited set for recursion guard\n    if _visited is None:\n        _visited = set()\n\n    # Prevent infinite recursion by checking if we've already visited this dataset\n    if self.dataset_rid in _visited:\n        return []\n    _visited.add(self.dataset_rid)\n\n    ds_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset\")\n    nds_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset_Dataset\")\n    dv_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset_Version\")\n\n    with Session(self.engine) as session:\n        sql_cmd = (\n            select(nds_table.Nested_Dataset, dv_table.Version)\n            .join_from(ds_table, nds_table, onclause=ds_table.RID == nds_table.Nested_Dataset)\n            .join_from(ds_table, dv_table, onclause=ds_table.Version == dv_table.RID)\n            .where(nds_table.Dataset == self.dataset_rid)\n        )\n        nested = [self._catalog.lookup_dataset(r[0]) for r in session.execute(sql_cmd).all()]\n\n    result = copy(nested)\n    if recurse:\n        for child in nested:\n            result.extend(child.list_dataset_children(recurse=recurse, _visited=_visited))\n    return result\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_dataset_element_types","title":"list_dataset_element_types","text":"<pre><code>list_dataset_element_types() -&gt; (\n    Iterable[Table]\n)\n</code></pre> <p>List the types of elements that can be contained in datasets.</p> <p>This method analyzes the dataset and identifies the data types for all elements within it. It is useful for understanding the structure and content of the dataset and allows for better manipulation and usage of its data.</p> <p>Returns:</p> Type Description <code>Iterable[Table]</code> <p>list[str]: A list of strings where each string represents a data type</p> <code>Iterable[Table]</code> <p>of an element found in the dataset.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def list_dataset_element_types(self) -&gt; Iterable[Table]:\n    \"\"\"List the types of elements that can be contained in datasets.\n\n    This method analyzes the dataset and identifies the data types for all\n    elements within it. It is useful for understanding the structure and\n    content of the dataset and allows for better manipulation and usage of its\n    data.\n\n    Returns:\n        list[str]: A list of strings where each string represents a data type\n        of an element found in the dataset.\n\n    \"\"\"\n    return self.model.list_dataset_element_types()\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_dataset_members","title":"list_dataset_members","text":"<pre><code>list_dataset_members(\n    recurse: bool = False,\n    limit: int | None = None,\n    _visited: set[RID] | None = None,\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; dict[str, list[dict[str, Any]]]\n</code></pre> <p>Return a list of entities associated with a specific dataset.</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>Whether to include members of nested datasets.</p> <code>False</code> <code>limit</code> <code>int | None</code> <p>Maximum number of members to return per type. None for no limit.</p> <code>None</code> <code>_visited</code> <code>set[RID] | None</code> <p>Internal parameter to track visited datasets and prevent infinite recursion.</p> <code>None</code> <code>version</code> <code>Any</code> <p>Ignored (bags are immutable snapshots).</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, list[dict[str, Any]]]</code> <p>Dictionary mapping member types to lists of member records.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def list_dataset_members(\n    self,\n    recurse: bool = False,\n    limit: int | None = None,\n    _visited: set[RID] | None = None,\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; dict[str, list[dict[str, Any]]]:\n    \"\"\"Return a list of entities associated with a specific dataset.\n\n    Args:\n        recurse: Whether to include members of nested datasets.\n        limit: Maximum number of members to return per type. None for no limit.\n        _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n        version: Ignored (bags are immutable snapshots).\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Returns:\n        Dictionary mapping member types to lists of member records.\n    \"\"\"\n    # Initialize visited set for recursion guard\n    if _visited is None:\n        _visited = set()\n\n    # Prevent infinite recursion by checking if we've already visited this dataset\n    if self.dataset_rid in _visited:\n        return {}\n    _visited.add(self.dataset_rid)\n\n    # Look at each of the element types that might be in the _dataset_table and get the list of rid for them from\n    # the appropriate association table.\n    members = defaultdict(list)\n\n    dataset_class = self.model.get_orm_class_for_table(self._dataset_table)\n    for element_table in self.model.list_dataset_element_types():\n        element_class = self.model.get_orm_class_for_table(element_table)\n\n        assoc_class, dataset_rel, element_rel = self.model.get_orm_association_class(dataset_class, element_class)\n\n        element_table = inspect(element_class).mapped_table\n        if not self.model.is_domain_schema(element_table.schema) and element_table.name not in [\"Dataset\", \"File\"]:\n            # Look at domain tables and nested datasets.\n            continue\n\n        # Get the names of the columns that we are going to need for linking\n        with Session(self.engine) as session:\n            # For Dataset_Dataset, use Nested_Dataset column to find nested datasets\n            # (similar to how the live catalog does it in Dataset.list_dataset_members)\n            if element_table.name == \"Dataset\":\n                sql_cmd = (\n                    select(element_class)\n                    .join(assoc_class, element_class.RID == assoc_class.__table__.c[\"Nested_Dataset\"])\n                    .where(self.dataset_rid == assoc_class.__table__.c[\"Dataset\"])\n                )\n            else:\n                # For other tables, use the original join via element_rel\n                sql_cmd = (\n                    select(element_class)\n                    .join(element_rel)\n                    .where(self.dataset_rid == assoc_class.__table__.c[\"Dataset\"])\n                )\n            if limit is not None:\n                sql_cmd = sql_cmd.limit(limit)\n            # Get back the list of ORM entities and convert them to dictionaries.\n            element_entities = session.scalars(sql_cmd).all()\n            element_rows = [{c.key: getattr(obj, c.key) for c in obj.__table__.columns} for obj in element_entities]\n        members[element_table.name].extend(element_rows)\n        if recurse and (element_table.name == self._dataset_table.name):\n            # Get the members for all the nested datasets and add to the member list.\n            nested_datasets = [d[\"RID\"] for d in element_rows]\n            for ds in nested_datasets:\n                nested_dataset = self._catalog.lookup_dataset(ds)\n                for k, v in nested_dataset.list_dataset_members(recurse=recurse, limit=limit, _visited=_visited).items():\n                    members[k].extend(v)\n    return dict(members)\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_dataset_parents","title":"list_dataset_parents","text":"<pre><code>list_dataset_parents(\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; list[Self]\n</code></pre> <p>Given a dataset_table RID, return a list of RIDs of the parent datasets if this is included in a nested dataset.</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>If True, recursively return all ancestor datasets.</p> <code>False</code> <code>_visited</code> <code>set[RID] | None</code> <p>Internal parameter to track visited datasets and prevent infinite recursion.</p> <code>None</code> <code>version</code> <code>Any</code> <p>Ignored (bags are immutable snapshots).</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments (ignored, for protocol compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[Self]</code> <p>List of parent dataset bags.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def list_dataset_parents(\n    self,\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n    version: Any = None,\n    **kwargs: Any,\n) -&gt; list[Self]:\n    \"\"\"Given a dataset_table RID, return a list of RIDs of the parent datasets if this is included in a\n    nested dataset.\n\n    Args:\n        recurse: If True, recursively return all ancestor datasets.\n        _visited: Internal parameter to track visited datasets and prevent infinite recursion.\n        version: Ignored (bags are immutable snapshots).\n        **kwargs: Additional arguments (ignored, for protocol compatibility).\n\n    Returns:\n        List of parent dataset bags.\n    \"\"\"\n    # Initialize visited set for recursion guard\n    if _visited is None:\n        _visited = set()\n\n    # Prevent infinite recursion by checking if we've already visited this dataset\n    if self.dataset_rid in _visited:\n        return []\n    _visited.add(self.dataset_rid)\n\n    nds_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset_Dataset\")\n\n    with Session(self.engine) as session:\n        sql_cmd = select(nds_table.Dataset).where(nds_table.Nested_Dataset == self.dataset_rid)\n        parents = [self._catalog.lookup_dataset(r[0]) for r in session.execute(sql_cmd).all()]\n\n    if recurse:\n        for parent in parents.copy():\n            parents.extend(parent.list_dataset_parents(recurse=True, _visited=_visited))\n    return parents\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_executions","title":"list_executions","text":"<pre><code>list_executions() -&gt; list[RID]\n</code></pre> <p>List all execution RIDs associated with this dataset.</p> <p>Returns all executions that used this dataset as input. This is tracked through the Dataset_Execution association table.</p> Note <p>Unlike the live Dataset class which returns Execution objects, DatasetBag returns a list of execution RIDs since the bag is an offline snapshot and cannot look up live execution objects.</p> <p>Returns:</p> Type Description <code>list[RID]</code> <p>List of execution RIDs associated with this dataset.</p> Example <p>bag = ml.download_dataset_bag(dataset_spec) execution_rids = bag.list_executions() for rid in execution_rids: ...     print(f\"Associated execution: {rid}\")</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def list_executions(self) -&gt; list[RID]:\n    \"\"\"List all execution RIDs associated with this dataset.\n\n    Returns all executions that used this dataset as input. This is\n    tracked through the Dataset_Execution association table.\n\n    Note:\n        Unlike the live Dataset class which returns Execution objects,\n        DatasetBag returns a list of execution RIDs since the bag is\n        an offline snapshot and cannot look up live execution objects.\n\n    Returns:\n        List of execution RIDs associated with this dataset.\n\n    Example:\n        &gt;&gt;&gt; bag = ml.download_dataset_bag(dataset_spec)\n        &gt;&gt;&gt; execution_rids = bag.list_executions()\n        &gt;&gt;&gt; for rid in execution_rids:\n        ...     print(f\"Associated execution: {rid}\")\n    \"\"\"\n    de_table = self.model.get_orm_class_by_name(f\"{self.model.ml_schema}.Dataset_Execution\")\n\n    with Session(self.engine) as session:\n        sql_cmd = select(de_table.Execution).where(de_table.Dataset == self.dataset_rid)\n        return [r[0] for r in session.execute(sql_cmd).all()]\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_feature_values","title":"list_feature_values","text":"<pre><code>list_feature_values(\n    table: Table | str,\n    feature_name: str,\n) -&gt; Iterable[FeatureRecord]\n</code></pre> <p>Retrieves all values for a feature as typed FeatureRecord instances.</p> <p>Returns an iterator of dynamically-generated FeatureRecord objects for each feature value. Each record is an instance of a Pydantic model specific to this feature, with typed attributes for all columns including the Execution that created the feature value.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>The table containing the feature, either as name or Table object.</p> required <code>feature_name</code> <code>str</code> <p>Name of the feature to retrieve values for.</p> required <p>Returns:</p> Type Description <code>Iterable[FeatureRecord]</code> <p>Iterable[FeatureRecord]: An iterator of FeatureRecord instances. Each instance has: - Execution: RID of the execution that created this feature value - Feature_Name: Name of the feature - All feature-specific columns as typed attributes - model_dump() method to convert back to a dictionary</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the feature doesn't exist or cannot be accessed.</p> Example Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def list_feature_values(\n    self, table: Table | str, feature_name: str\n) -&gt; Iterable[FeatureRecord]:\n    \"\"\"Retrieves all values for a feature as typed FeatureRecord instances.\n\n    Returns an iterator of dynamically-generated FeatureRecord objects for each\n    feature value. Each record is an instance of a Pydantic model specific to\n    this feature, with typed attributes for all columns including the Execution\n    that created the feature value.\n\n    Args:\n        table: The table containing the feature, either as name or Table object.\n        feature_name: Name of the feature to retrieve values for.\n\n    Returns:\n        Iterable[FeatureRecord]: An iterator of FeatureRecord instances.\n            Each instance has:\n            - Execution: RID of the execution that created this feature value\n            - Feature_Name: Name of the feature\n            - All feature-specific columns as typed attributes\n            - model_dump() method to convert back to a dictionary\n\n    Raises:\n        DerivaMLException: If the feature doesn't exist or cannot be accessed.\n\n    Example:\n        &gt;&gt;&gt; # Get typed feature records\n        &gt;&gt;&gt; for record in bag.list_feature_values(\"Image\", \"Quality\"):\n        ...     print(f\"Image {record.Image}: {record.ImageQuality}\")\n        ...     print(f\"Created by execution: {record.Execution}\")\n\n        &gt;&gt;&gt; # Convert records to dictionaries\n        &gt;&gt;&gt; records = list(bag.list_feature_values(\"Image\", \"Quality\"))\n        &gt;&gt;&gt; dicts = [r.model_dump() for r in records]\n    \"\"\"\n    # Get table and feature\n    feature = self.model.lookup_feature(table, feature_name)\n\n    # Get the dynamically-generated FeatureRecord subclass for this feature\n    record_class = feature.feature_record_class()\n\n    # Query raw values from SQLite\n    feature_table = self.model.find_table(feature.feature_table.name)\n    with Session(self.engine) as session:\n        sql_cmd = select(feature_table)\n        result = session.execute(sql_cmd)\n        rows = [dict(row._mapping) for row in result]\n\n    # Convert to typed records\n    for raw_value in rows:\n        # Filter to only include fields that the record class expects\n        field_names = set(record_class.model_fields.keys())\n        filtered_data = {k: v for k, v in raw_value.items() if k in field_names}\n        yield record_class(**filtered_data)\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_feature_values--get-typed-feature-records","title":"Get typed feature records","text":"<p>for record in bag.list_feature_values(\"Image\", \"Quality\"): ...     print(f\"Image {record.Image}: {record.ImageQuality}\") ...     print(f\"Created by execution: {record.Execution}\")</p>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_feature_values--convert-records-to-dictionaries","title":"Convert records to dictionaries","text":"<p>records = list(bag.list_feature_values(\"Image\", \"Quality\")) dicts = [r.model_dump() for r in records]</p>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.list_tables","title":"list_tables","text":"<pre><code>list_tables() -&gt; list[str]\n</code></pre> <p>List all tables available in the bag's SQLite database.</p> <p>Returns the fully-qualified names of all tables (e.g., \"domain.Image\", \"deriva-ml.Dataset\") that were exported in this bag.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: Table names in \"schema.table\" format, sorted alphabetically.</p> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def list_tables(self) -&gt; list[str]:\n    \"\"\"List all tables available in the bag's SQLite database.\n\n    Returns the fully-qualified names of all tables (e.g., \"domain.Image\",\n    \"deriva-ml.Dataset\") that were exported in this bag.\n\n    Returns:\n        list[str]: Table names in \"schema.table\" format, sorted alphabetically.\n    \"\"\"\n    return self.model.list_tables()\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.DatasetBag.restructure_assets","title":"restructure_assets","text":"<pre><code>restructure_assets(\n    output_dir: Path | str,\n    asset_table: str | None = None,\n    group_by: list[str] | None = None,\n    use_symlinks: bool = True,\n    type_selector: Callable[\n        [list[str]], str\n    ]\n    | None = None,\n    type_to_dir_map: dict[str, str]\n    | None = None,\n    enforce_vocabulary: bool = True,\n    value_selector: Callable[\n        [list[FeatureValueRecord]],\n        FeatureValueRecord,\n    ]\n    | None = None,\n) -&gt; Path\n</code></pre> <p>Restructure downloaded assets into a directory hierarchy.</p> <p>Creates a directory structure organizing assets by dataset types and grouping values. This is useful for ML workflows that expect data organized in conventional folder structures (e.g., PyTorch ImageFolder).</p> <p>The dataset should be of type Training or Testing, or have nested children of those types. The top-level directory name is determined by the dataset type (e.g., \"Training\" -&gt; \"training\").</p> <p>Finding assets through foreign key relationships:</p> <p>Assets are found by traversing all foreign key paths from the dataset, not just direct associations. For example, if a dataset contains Subjects, and the schema has Subject -&gt; Encounter -&gt; Image relationships, this method will find all Images reachable through those paths even though they are not directly in a Dataset_Image association table.</p> <p>Handling datasets without types (prediction scenarios):</p> <p>If a dataset has no type defined, it is treated as Testing. This is common for prediction/inference scenarios where you want to apply a trained model to new unlabeled data.</p> <p>Handling missing labels:</p> <p>If an asset doesn't have a value for a group_by key (e.g., no label assigned), it is placed in an \"Unknown\" directory. This allows restructure_assets to work with unlabeled data for prediction.</p> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>Path | str</code> <p>Base directory for restructured assets.</p> required <code>asset_table</code> <code>str | None</code> <p>Name of the asset table (e.g., \"Image\"). If None, auto-detects from dataset members. Raises DerivaMLException if multiple asset tables are found and none is specified.</p> <code>None</code> <code>group_by</code> <code>list[str] | None</code> <p>Names to group assets by. Each name creates a subdirectory level after the dataset type path. Names can be:</p> <ul> <li>Column names: Direct columns on the asset table. The column   value becomes the subdirectory name.</li> <li>Feature names: Features defined on the asset table (or tables   it references via foreign keys). The feature's vocabulary term   value becomes the subdirectory name.</li> <li>Feature.column: Specify a particular column from a multi-term   feature (e.g., \"Classification.Label\" to use the Label column).</li> </ul> <p>Column names are checked first, then feature names. If a value is not found, \"unknown\" is used as the subdirectory name.</p> <code>None</code> <code>use_symlinks</code> <code>bool</code> <p>If True (default), create symlinks to original files. If False, copy files. Symlinks save disk space but require the original bag to remain in place.</p> <code>True</code> <code>type_selector</code> <code>Callable[[list[str]], str] | None</code> <p>Function to select type when dataset has multiple types. Receives list of type names, returns selected type name. Defaults to selecting first type or \"unknown\" if no types.</p> <code>None</code> <code>type_to_dir_map</code> <code>dict[str, str] | None</code> <p>Optional mapping from dataset type names to directory names. Defaults to {\"Training\": \"training\", \"Testing\": \"testing\", \"Unknown\": \"unknown\"}. Use this to customize directory names or add new type mappings.</p> <code>None</code> <code>enforce_vocabulary</code> <code>bool</code> <p>If True (default), only allow features that have controlled vocabulary term columns, and raise an error if an asset has multiple different values for the same feature without a value_selector. This ensures clean, unambiguous directory structures. If False, allow any feature type and use the first value found when multiple values exist.</p> <code>True</code> <code>value_selector</code> <code>Callable[[list[FeatureValueRecord]], FeatureValueRecord] | None</code> <p>Optional function to select which feature value to use when an asset has multiple values for the same feature. Receives a list of FeatureValueRecord objects (each containing target_rid, feature_name, value, execution_rid, and raw_record) and returns the selected FeatureValueRecord. Use execution_rid to distinguish between values from different executions.</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the output directory.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If asset_table cannot be determined (multiple asset tables exist without specification), if no valid dataset types (Training/Testing) are found, or if enforce_vocabulary is True and a feature has multiple values without value_selector.</p> <p>Examples:</p> <p>Basic restructuring with auto-detected asset table::</p> <pre><code>bag.restructure_assets(\n    output_dir=\"./ml_data\",\n    group_by=[\"Diagnosis\"],\n)\n# Creates:\n# ./ml_data/training/Normal/image1.jpg\n# ./ml_data/testing/Abnormal/image2.jpg\n</code></pre> <p>Custom type-to-directory mapping::</p> <pre><code>bag.restructure_assets(\n    output_dir=\"./ml_data\",\n    group_by=[\"Diagnosis\"],\n    type_to_dir_map={\"Training\": \"train\", \"Testing\": \"test\"},\n)\n# Creates:\n# ./ml_data/train/Normal/image1.jpg\n# ./ml_data/test/Abnormal/image2.jpg\n</code></pre> <p>Select specific feature column for multi-term features::</p> <pre><code>bag.restructure_assets(\n    output_dir=\"./ml_data\",\n    group_by=[\"Classification.Label\"],  # Use Label column\n)\n</code></pre> <p>Handle multiple feature values with a selector::</p> <pre><code>def select_latest(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n    # Select value from most recent execution\n    return max(records, key=lambda r: r.execution_rid or \"\")\n\nbag.restructure_assets(\n    output_dir=\"./ml_data\",\n    group_by=[\"Diagnosis\"],\n    value_selector=select_latest,\n)\n</code></pre> <p>Prediction scenario with unlabeled data::</p> <pre><code># Dataset has no type - treated as Testing\n# Assets have no labels - placed in Unknown directory\nbag.restructure_assets(\n    output_dir=\"./prediction_data\",\n    group_by=[\"Diagnosis\"],\n)\n# Creates:\n# ./prediction_data/testing/Unknown/image1.jpg\n# ./prediction_data/testing/Unknown/image2.jpg\n</code></pre> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>def restructure_assets(\n    self,\n    output_dir: Path | str,\n    asset_table: str | None = None,\n    group_by: list[str] | None = None,\n    use_symlinks: bool = True,\n    type_selector: Callable[[list[str]], str] | None = None,\n    type_to_dir_map: dict[str, str] | None = None,\n    enforce_vocabulary: bool = True,\n    value_selector: Callable[[list[FeatureValueRecord]], FeatureValueRecord] | None = None,\n) -&gt; Path:\n    \"\"\"Restructure downloaded assets into a directory hierarchy.\n\n    Creates a directory structure organizing assets by dataset types and\n    grouping values. This is useful for ML workflows that expect data\n    organized in conventional folder structures (e.g., PyTorch ImageFolder).\n\n    The dataset should be of type Training or Testing, or have nested\n    children of those types. The top-level directory name is determined\n    by the dataset type (e.g., \"Training\" -&gt; \"training\").\n\n    **Finding assets through foreign key relationships:**\n\n    Assets are found by traversing all foreign key paths from the dataset,\n    not just direct associations. For example, if a dataset contains Subjects,\n    and the schema has Subject -&gt; Encounter -&gt; Image relationships, this method\n    will find all Images reachable through those paths even though they are\n    not directly in a Dataset_Image association table.\n\n    **Handling datasets without types (prediction scenarios):**\n\n    If a dataset has no type defined, it is treated as Testing. This is\n    common for prediction/inference scenarios where you want to apply a\n    trained model to new unlabeled data.\n\n    **Handling missing labels:**\n\n    If an asset doesn't have a value for a group_by key (e.g., no label\n    assigned), it is placed in an \"Unknown\" directory. This allows\n    restructure_assets to work with unlabeled data for prediction.\n\n    Args:\n        output_dir: Base directory for restructured assets.\n        asset_table: Name of the asset table (e.g., \"Image\"). If None,\n            auto-detects from dataset members. Raises DerivaMLException\n            if multiple asset tables are found and none is specified.\n        group_by: Names to group assets by. Each name creates a subdirectory\n            level after the dataset type path. Names can be:\n\n            - **Column names**: Direct columns on the asset table. The column\n              value becomes the subdirectory name.\n            - **Feature names**: Features defined on the asset table (or tables\n              it references via foreign keys). The feature's vocabulary term\n              value becomes the subdirectory name.\n            - **Feature.column**: Specify a particular column from a multi-term\n              feature (e.g., \"Classification.Label\" to use the Label column).\n\n            Column names are checked first, then feature names. If a value\n            is not found, \"unknown\" is used as the subdirectory name.\n\n        use_symlinks: If True (default), create symlinks to original files.\n            If False, copy files. Symlinks save disk space but require\n            the original bag to remain in place.\n        type_selector: Function to select type when dataset has multiple types.\n            Receives list of type names, returns selected type name.\n            Defaults to selecting first type or \"unknown\" if no types.\n        type_to_dir_map: Optional mapping from dataset type names to directory\n            names. Defaults to {\"Training\": \"training\", \"Testing\": \"testing\",\n            \"Unknown\": \"unknown\"}. Use this to customize directory names or\n            add new type mappings.\n        enforce_vocabulary: If True (default), only allow features that have\n            controlled vocabulary term columns, and raise an error if an asset\n            has multiple different values for the same feature without a\n            value_selector. This ensures clean, unambiguous directory structures.\n            If False, allow any feature type and use the first value found\n            when multiple values exist.\n        value_selector: Optional function to select which feature value to use\n            when an asset has multiple values for the same feature. Receives a\n            list of FeatureValueRecord objects (each containing target_rid,\n            feature_name, value, execution_rid, and raw_record) and returns\n            the selected FeatureValueRecord. Use execution_rid to distinguish\n            between values from different executions.\n\n    Returns:\n        Path to the output directory.\n\n    Raises:\n        DerivaMLException: If asset_table cannot be determined (multiple\n            asset tables exist without specification), if no valid dataset\n            types (Training/Testing) are found, or if enforce_vocabulary\n            is True and a feature has multiple values without value_selector.\n\n    Examples:\n        Basic restructuring with auto-detected asset table::\n\n            bag.restructure_assets(\n                output_dir=\"./ml_data\",\n                group_by=[\"Diagnosis\"],\n            )\n            # Creates:\n            # ./ml_data/training/Normal/image1.jpg\n            # ./ml_data/testing/Abnormal/image2.jpg\n\n        Custom type-to-directory mapping::\n\n            bag.restructure_assets(\n                output_dir=\"./ml_data\",\n                group_by=[\"Diagnosis\"],\n                type_to_dir_map={\"Training\": \"train\", \"Testing\": \"test\"},\n            )\n            # Creates:\n            # ./ml_data/train/Normal/image1.jpg\n            # ./ml_data/test/Abnormal/image2.jpg\n\n        Select specific feature column for multi-term features::\n\n            bag.restructure_assets(\n                output_dir=\"./ml_data\",\n                group_by=[\"Classification.Label\"],  # Use Label column\n            )\n\n        Handle multiple feature values with a selector::\n\n            def select_latest(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n                # Select value from most recent execution\n                return max(records, key=lambda r: r.execution_rid or \"\")\n\n            bag.restructure_assets(\n                output_dir=\"./ml_data\",\n                group_by=[\"Diagnosis\"],\n                value_selector=select_latest,\n            )\n\n        Prediction scenario with unlabeled data::\n\n            # Dataset has no type - treated as Testing\n            # Assets have no labels - placed in Unknown directory\n            bag.restructure_assets(\n                output_dir=\"./prediction_data\",\n                group_by=[\"Diagnosis\"],\n            )\n            # Creates:\n            # ./prediction_data/testing/Unknown/image1.jpg\n            # ./prediction_data/testing/Unknown/image2.jpg\n    \"\"\"\n    logger = logging.getLogger(\"deriva_ml\")\n    group_by = group_by or []\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Default type-to-directory mapping\n    if type_to_dir_map is None:\n        type_to_dir_map = {\"Training\": \"training\", \"Testing\": \"testing\", \"Unknown\": \"unknown\"}\n\n    # Auto-detect asset table if not provided\n    if asset_table is None:\n        asset_table = self._detect_asset_table()\n        if asset_table is None:\n            raise DerivaMLException(\n                \"Could not auto-detect asset table. No asset tables found in dataset members. \"\n                \"Specify the asset_table parameter explicitly.\"\n            )\n        logger.info(f\"Auto-detected asset table: {asset_table}\")\n\n    # Step 1: Build dataset type path map with directory name mapping\n    def map_type_to_dir(types: list[str]) -&gt; str:\n        \"\"\"Map dataset types to directory name using type_to_dir_map.\n\n        If dataset has no types, treat it as Testing (prediction use case).\n        \"\"\"\n        if not types:\n            # No types defined - treat as Testing for prediction scenarios\n            return type_to_dir_map.get(\"Testing\", \"testing\")\n        if type_selector:\n            selected_type = type_selector(types)\n        else:\n            selected_type = types[0]\n        return type_to_dir_map.get(selected_type, selected_type.lower())\n\n    type_path_map = self._build_dataset_type_path_map(map_type_to_dir)\n\n    # Step 2: Get asset-to-dataset mapping\n    asset_dataset_map = self._get_asset_dataset_mapping(asset_table)\n\n    # Step 3: Load feature values cache for relevant features\n    feature_cache = self._load_feature_values_cache(\n        asset_table, group_by, enforce_vocabulary, value_selector\n    )\n\n    # Step 4: Get all assets reachable through FK paths\n    # This uses _get_reachable_assets which traverses FK relationships,\n    # so assets connected via Subject -&gt; Encounter -&gt; Image are found\n    # even if the dataset only contains Subjects directly.\n    assets = self._get_reachable_assets(asset_table)\n\n    if not assets:\n        logger.warning(f\"No assets found in table '{asset_table}'\")\n        return output_dir\n\n    # Step 5: Process each asset\n    for asset in assets:\n        # Get source file path\n        filename = asset.get(\"Filename\")\n        if not filename:\n            logger.warning(f\"Asset {asset.get('RID')} has no Filename\")\n            continue\n\n        source_path = Path(filename)\n        if not source_path.exists():\n            logger.warning(f\"Asset file not found: {source_path}\")\n            continue\n\n        # Get dataset type path\n        dataset_rid = asset_dataset_map.get(asset[\"RID\"])\n        type_path = type_path_map.get(dataset_rid, [\"unknown\"])\n\n        # Resolve grouping values\n        group_path = []\n        for key in group_by:\n            value = self._resolve_grouping_value(asset, key, feature_cache)\n            group_path.append(value)\n\n        # Build target directory\n        target_dir = output_dir.joinpath(*type_path, *group_path)\n        target_dir.mkdir(parents=True, exist_ok=True)\n\n        # Create link or copy\n        target_path = target_dir / source_path.name\n\n        # Handle existing files\n        if target_path.exists() or target_path.is_symlink():\n            target_path.unlink()\n\n        if use_symlinks:\n            try:\n                target_path.symlink_to(source_path.resolve())\n            except OSError as e:\n                # Fall back to copy on platforms that don't support symlinks\n                logger.warning(f\"Symlink failed, falling back to copy: {e}\")\n                shutil.copy2(source_path, target_path)\n        else:\n            shutil.copy2(source_path, target_path)\n\n    return output_dir\n</code></pre>"},{"location":"code-docs/dataset_bag/#deriva_ml.dataset.dataset_bag.FeatureValueRecord","title":"FeatureValueRecord  <code>dataclass</code>","text":"<p>A feature value record with execution provenance.</p> <p>This class represents a single feature value assigned to an asset, including the execution that created it. Used by restructure_assets when a value_selector function needs to choose between multiple feature values for the same asset.</p> <p>The raw_record attribute contains the complete feature table row as a dictionary, which can be used to access all columns including any additional metadata or columns beyond the primary value.</p> <p>Attributes:</p> Name Type Description <code>target_rid</code> <code>RID</code> <p>RID of the asset/entity this feature value applies to.</p> <code>feature_name</code> <code>str</code> <p>Name of the feature.</p> <code>value</code> <code>Any</code> <p>The feature value (typically a vocabulary term name).</p> <code>execution_rid</code> <code>RID | None</code> <p>RID of the execution that created this feature value, if any. Use this to distinguish between values from different executions.</p> <code>raw_record</code> <code>dict[str, Any]</code> <p>The complete raw record from the feature table as a dictionary. Access all columns via dict keys, e.g., record.raw_record[\"MyColumn\"].</p> Example <p>Using a value_selector to choose the most recent feature value::</p> <pre><code>def select_by_execution(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n    # Select value from most recent execution (assuming RIDs are sortable)\n    return max(records, key=lambda r: r.execution_rid or \"\")\n\nbag.restructure_assets(\n    output_dir=\"./ml_data\",\n    group_by=[\"Diagnosis\"],\n    value_selector=select_by_execution,\n)\n</code></pre> <p>Accessing raw record data::</p> <pre><code>def select_by_confidence(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n    # Select value with highest confidence score from raw record\n    return max(records, key=lambda r: r.raw_record.get(\"Confidence\", 0))\n</code></pre> Source code in <code>src/deriva_ml/dataset/dataset_bag.py</code> <pre><code>@dataclass\nclass FeatureValueRecord:\n    \"\"\"A feature value record with execution provenance.\n\n    This class represents a single feature value assigned to an asset,\n    including the execution that created it. Used by restructure_assets\n    when a value_selector function needs to choose between multiple\n    feature values for the same asset.\n\n    The raw_record attribute contains the complete feature table row as\n    a dictionary, which can be used to access all columns including any\n    additional metadata or columns beyond the primary value.\n\n    Attributes:\n        target_rid: RID of the asset/entity this feature value applies to.\n        feature_name: Name of the feature.\n        value: The feature value (typically a vocabulary term name).\n        execution_rid: RID of the execution that created this feature value, if any.\n            Use this to distinguish between values from different executions.\n        raw_record: The complete raw record from the feature table as a dictionary.\n            Access all columns via dict keys, e.g., record.raw_record[\"MyColumn\"].\n\n    Example:\n        Using a value_selector to choose the most recent feature value::\n\n            def select_by_execution(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n                # Select value from most recent execution (assuming RIDs are sortable)\n                return max(records, key=lambda r: r.execution_rid or \"\")\n\n            bag.restructure_assets(\n                output_dir=\"./ml_data\",\n                group_by=[\"Diagnosis\"],\n                value_selector=select_by_execution,\n            )\n\n        Accessing raw record data::\n\n            def select_by_confidence(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n                # Select value with highest confidence score from raw record\n                return max(records, key=lambda r: r.raw_record.get(\"Confidence\", 0))\n    \"\"\"\n    target_rid: RID\n    feature_name: str\n    value: Any\n    execution_rid: RID | None = None\n    raw_record: dict[str, Any] = field(default_factory=dict)\n\n    def __repr__(self) -&gt; str:\n        return (f\"FeatureValueRecord(target_rid='{self.target_rid}', \"\n                f\"feature_name='{self.feature_name}', value='{self.value}', \"\n                f\"execution_rid='{self.execution_rid}')\")\n</code></pre>"},{"location":"code-docs/dataset_split/","title":"Dataset Splitting","text":"<p>Functions for splitting DerivaML datasets into training and testing subsets with full provenance tracking. Supports random, stratified, and custom selection strategies.</p> <p>Generic dataset splitting for DerivaML.</p> <p>This module provides functions to split a DerivaML dataset into training and testing subsets with full provenance tracking. It works with any DerivaML catalog and any registered element type.</p> <p>The splitting API follows scikit-learn conventions (<code>test_size</code>, <code>train_size</code>, <code>shuffle</code>, <code>seed</code>, <code>stratify</code>) while integrating with DerivaML's dataset hierarchy, execution provenance, and versioning.</p> Splitting Strategies <p>Random (default):     Shuffles members and splits at the train_size boundary.     No denormalization required.</p> <p>Stratified:     Maintains class distribution across splits using scikit-learn's     stratified splitting. Requires specifying a column to stratify by     from the denormalized DataFrame.</p> <p>Custom:     Users can provide a <code>SelectionFunction</code> callable for arbitrary     selection logic (balanced labels, filtered subsets, etc.).</p> Example <p>Simple random 80/20 split::</p> <pre><code>from deriva_ml import DerivaML\nfrom deriva_ml.dataset.split import split_dataset\n\nml = DerivaML(\"localhost\", \"9\")\nresult = split_dataset(ml, \"28D0\", test_size=0.2, seed=42)\n</code></pre> <p>Stratified split::</p> <pre><code>result = split_dataset(\n    ml, \"28D0\",\n    test_size=0.2,\n    stratify_by_column=\"Image_Classification_Image_Class\",\n    include_tables=[\"Image\", \"Image_Classification\"],\n)\n</code></pre> <p>Custom selection function::</p> <pre><code>def my_selector(df, train_size, test_size, seed):\n    # Custom logic...\n    return train_indices, test_indices\n\nresult = split_dataset(\n    ml, \"28D0\",\n    test_size=100,\n    selection_fn=my_selector,\n    include_tables=[\"Image\", \"Image_Classification\"],\n)\n</code></pre> See Also <ul> <li><code>sklearn.model_selection.train_test_split</code></li> <li><code>Dataset.denormalize_as_dataframe</code></li> <li><code>Dataset.list_dataset_members</code></li> </ul>"},{"location":"code-docs/dataset_split/#deriva_ml.dataset.split.SelectionFunction","title":"SelectionFunction","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for custom train/test selection functions.</p> <p>A selection function receives the denormalized dataset DataFrame and returns a tuple of <code>(train_indices, test_indices)</code> as integer arrays indexing into the DataFrame rows.</p> <p>The function is responsible for:</p> <ul> <li>Deciding which records go into training vs testing</li> <li>Ensuring the sizes match the requested train_size/test_size</li> <li>Implementing any balancing or stratification logic</li> </ul> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>Denormalized DataFrame from <code>dataset.denormalize_as_dataframe()</code>. Columns are prefixed with table names (e.g., <code>Image_RID</code>, <code>Image_Classification_Image_Class</code>).</p> required <code>train_size</code> <p>Number of records for the training set.</p> required <code>test_size</code> <p>Number of records for the testing set.</p> required <code>seed</code> <p>Random seed for reproducibility.</p> required <p>Returns:</p> Type Description <p>Tuple of <code>(train_indices, test_indices)</code> as numpy arrays of</p> <p>integer indices into the DataFrame.</p> Example <p>def balanced_selector(df, train_size, test_size, seed): ...     rng = np.random.default_rng(seed) ...     # ... balance classes ... ...     return train_indices, test_indices</p> Source code in <code>src/deriva_ml/dataset/split.py</code> <pre><code>@runtime_checkable\nclass SelectionFunction(Protocol):\n    \"\"\"Protocol for custom train/test selection functions.\n\n    A selection function receives the denormalized dataset DataFrame and\n    returns a tuple of ``(train_indices, test_indices)`` as integer arrays\n    indexing into the DataFrame rows.\n\n    The function is responsible for:\n\n    - Deciding which records go into training vs testing\n    - Ensuring the sizes match the requested train_size/test_size\n    - Implementing any balancing or stratification logic\n\n    Args:\n        df: Denormalized DataFrame from ``dataset.denormalize_as_dataframe()``.\n            Columns are prefixed with table names (e.g., ``Image_RID``,\n            ``Image_Classification_Image_Class``).\n        train_size: Number of records for the training set.\n        test_size: Number of records for the testing set.\n        seed: Random seed for reproducibility.\n\n    Returns:\n        Tuple of ``(train_indices, test_indices)`` as numpy arrays of\n        integer indices into the DataFrame.\n\n    Example:\n        &gt;&gt;&gt; def balanced_selector(df, train_size, test_size, seed):\n        ...     rng = np.random.default_rng(seed)\n        ...     # ... balance classes ...\n        ...     return train_indices, test_indices\n    \"\"\"\n\n    def __call__(\n        self,\n        df: pd.DataFrame,\n        train_size: int,\n        test_size: int,\n        seed: int,\n    ) -&gt; tuple[np.ndarray, np.ndarray]: ...\n</code></pre>"},{"location":"code-docs/dataset_split/#deriva_ml.dataset.split.main","title":"main","text":"<pre><code>main() -&gt; int\n</code></pre> <p>CLI entry point for <code>deriva-ml-split-dataset</code>.</p> <p>Parses command-line arguments, connects to a DerivaML catalog, and splits the specified dataset into training and testing subsets.</p> <p>Returns:</p> Type Description <code>int</code> <p>Exit code: 0 for success, 1 for failure.</p> Source code in <code>src/deriva_ml/dataset/split.py</code> <pre><code>def main() -&gt; int:\n    \"\"\"CLI entry point for ``deriva-ml-split-dataset``.\n\n    Parses command-line arguments, connects to a DerivaML catalog, and\n    splits the specified dataset into training and testing subsets.\n\n    Returns:\n        Exit code: 0 for success, 1 for failure.\n    \"\"\"\n    import argparse\n    import sys\n    import textwrap\n\n    parser = argparse.ArgumentParser(\n        description=\"Split a DerivaML dataset into training/testing subsets\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=textwrap.dedent(\"\"\"\\\n        Examples:\n            # Simple random 80/20 split\n            deriva-ml-split-dataset --hostname localhost --catalog-id 9 \\\\\n                --dataset-rid 28D0\n\n            # Stratified split by class label\n            deriva-ml-split-dataset --hostname localhost --catalog-id 9 \\\\\n                --dataset-rid 28D0 \\\\\n                --stratify-by-column Image_Classification_Image_Class \\\\\n                --include-tables Image,Image_Classification\n\n            # Fixed-count split\n            deriva-ml-split-dataset --hostname localhost --catalog-id 9 \\\\\n                --dataset-rid 28D0 --train-size 400 --test-size 100\n\n            # Dry run (show plan without modifying catalog)\n            deriva-ml-split-dataset --hostname localhost --catalog-id 9 \\\\\n                --dataset-rid 28D0 --dry-run\n\n        For more information, see:\n            https://github.com/informatics-isi-edu/deriva-ml\n        \"\"\"),\n    )\n\n    # Connection parameters\n    parser.add_argument(\n        \"--hostname\", required=True,\n        help=\"Deriva server hostname (e.g., localhost, ml.derivacloud.org)\",\n    )\n    parser.add_argument(\n        \"--catalog-id\", required=True,\n        help=\"Catalog ID to connect to\",\n    )\n    parser.add_argument(\n        \"--domain-schema\",\n        help=\"Domain schema name (auto-detected if not provided)\",\n    )\n\n    # Source dataset\n    parser.add_argument(\n        \"--dataset-rid\", required=True,\n        help=\"RID of the source dataset to split\",\n    )\n\n    # Split parameters (scikit-learn conventions)\n    parser.add_argument(\n        \"--test-size\", type=float, default=0.2,\n        help=\"Test set size as fraction (0-1) or absolute count (default: 0.2)\",\n    )\n    parser.add_argument(\n        \"--train-size\", type=float, default=None,\n        help=\"Train set size as fraction (0-1) or absolute count \"\n        \"(default: complement of test-size)\",\n    )\n    parser.add_argument(\n        \"--no-shuffle\", action=\"store_true\",\n        help=\"Do not shuffle before splitting\",\n    )\n    parser.add_argument(\n        \"--seed\", type=int, default=42,\n        help=\"Random seed for reproducibility (default: 42)\",\n    )\n    parser.add_argument(\n        \"--stratify-by-column\",\n        help=\"Column name in denormalized DataFrame for stratified splitting \"\n        \"(e.g., Image_Classification_Image_Class). Requires --include-tables.\",\n    )\n\n    # DerivaML parameters\n    parser.add_argument(\n        \"--element-table\",\n        help=\"Element table to split (e.g., Image). Auto-detected if omitted.\",\n    )\n    parser.add_argument(\n        \"--include-tables\",\n        help=\"Comma-separated tables for denormalization \"\n        \"(e.g., Image,Image_Classification). Required for stratified splitting.\",\n    )\n    parser.add_argument(\n        \"--training-types\", default=\"Labeled\",\n        help=\"Comma-separated additional dataset types for training set \"\n        \"(default: Labeled)\",\n    )\n    parser.add_argument(\n        \"--testing-types\", default=\"Labeled\",\n        help=\"Comma-separated additional dataset types for testing set \"\n        \"(default: Labeled)\",\n    )\n    parser.add_argument(\n        \"--description\", default=\"\",\n        help=\"Description for the parent split dataset\",\n    )\n    parser.add_argument(\n        \"--workflow-type\", default=\"Dataset_Split\",\n        help=\"Workflow type vocabulary term (default: Dataset_Split)\",\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Print plan without modifying catalog\",\n    )\n    parser.add_argument(\n        \"--show-urls\", action=\"store_true\",\n        help=\"Show Chaise web interface URLs for created datasets\",\n    )\n\n    args = parser.parse_args()\n\n    # Configure logging\n    handler = logging.StreamHandler(sys.stderr)\n    handler.setLevel(logging.INFO)\n    handler.setFormatter(\n        logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n    )\n    logging.getLogger(\"deriva_ml\").addHandler(handler)\n    logging.getLogger(\"deriva_ml\").setLevel(logging.INFO)\n\n    sys.stdout.reconfigure(line_buffering=True)\n    sys.stderr.reconfigure(line_buffering=True)\n\n    try:\n        from deriva_ml import DerivaML\n\n        # Connect\n        logger.info(f\"Connecting to {args.hostname}, catalog {args.catalog_id}\")\n        ml = DerivaML(\n            hostname=args.hostname,\n            catalog_id=str(args.catalog_id),\n            domain_schemas={args.domain_schema} if args.domain_schema else None,\n            check_auth=True,\n        )\n        logger.info(f\"Connected, domain schema: {ml.default_schema}\")\n\n        # Parse comma-separated lists\n        include_tables = (\n            [t.strip() for t in args.include_tables.split(\",\")]\n            if args.include_tables else None\n        )\n        training_types = (\n            [t.strip() for t in args.training_types.split(\",\")]\n            if args.training_types else None\n        )\n        testing_types = (\n            [t.strip() for t in args.testing_types.split(\",\")]\n            if args.testing_types else None\n        )\n\n        # Run the split\n        result = split_dataset(\n            ml=ml,\n            source_dataset_rid=args.dataset_rid,\n            test_size=args.test_size,\n            train_size=args.train_size,\n            shuffle=not args.no_shuffle,\n            seed=args.seed,\n            stratify_by_column=args.stratify_by_column,\n            split_description=args.description,\n            training_types=training_types,\n            testing_types=testing_types,\n            element_table=args.element_table,\n            include_tables=include_tables,\n            workflow_type=args.workflow_type,\n            dry_run=args.dry_run,\n        )\n\n        # Print summary\n        if args.dry_run:\n            print(f\"\\n{'='*60}\")\n            print(\"  DRY RUN - No changes will be made\")\n            print(f\"{'='*60}\")\n            print(f\"  Source dataset:  {result['source']}\")\n            print(f\"  Element table:   {result.get('element_table', 'auto-detect')}\")\n            print(f\"  Strategy:        {result.get('strategy', 'random')}\")\n            print(f\"  Seed:            {args.seed}\")\n            print(f\"  Training size:   {result['train_count']}\")\n            print(f\"  Testing size:    {result['test_count']}\")\n            print(f\"{'='*60}\\n\")\n        else:\n            print(f\"\\n{'='*60}\")\n            print(\"  SPLIT COMPLETE\")\n            print(f\"{'='*60}\")\n            print(f\"  Source dataset:  {result['source']}\")\n            print(f\"  Split dataset:   {result['split']} (v{result['split_version']})\")\n            print(f\"  Training:        {result['training']} (v{result['training_version']})\")\n            print(f\"  Testing:         {result['testing']} (v{result['testing_version']})\")\n\n            if args.show_urls:\n                print()\n                print(\"  Chaise URLs:\")\n                for name in [\"split\", \"training\", \"testing\"]:\n                    try:\n                        url = ml.cite(result[name], current=True)\n                        print(f\"    {name}: {url}\")\n                    except Exception:\n                        pass\n\n            print(f\"{'='*60}\\n\")\n\n        return 0\n\n    except Exception as e:\n        logger.error(f\"Split failed: {e}\")\n        return 1\n</code></pre>"},{"location":"code-docs/dataset_split/#deriva_ml.dataset.split.random_split","title":"random_split","text":"<pre><code>random_split(\n    df: DataFrame,\n    train_size: int,\n    test_size: int,\n    seed: int,\n) -&gt; tuple[np.ndarray, np.ndarray]\n</code></pre> <p>Random train/test split.</p> <p>Shuffles the DataFrame indices and splits at the train_size boundary.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Source DataFrame.</p> required <code>train_size</code> <code>int</code> <p>Number of training records.</p> required <code>test_size</code> <code>int</code> <p>Number of testing records.</p> required <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>Tuple of <code>(train_indices, test_indices)</code>.</p> Source code in <code>src/deriva_ml/dataset/split.py</code> <pre><code>def random_split(\n    df: pd.DataFrame,\n    train_size: int,\n    test_size: int,\n    seed: int,\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Random train/test split.\n\n    Shuffles the DataFrame indices and splits at the train_size boundary.\n\n    Args:\n        df: Source DataFrame.\n        train_size: Number of training records.\n        test_size: Number of testing records.\n        seed: Random seed for reproducibility.\n\n    Returns:\n        Tuple of ``(train_indices, test_indices)``.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    total_needed = train_size + test_size\n    indices = np.arange(len(df))\n    rng.shuffle(indices)\n    indices = indices[:total_needed]\n    return indices[:train_size], indices[train_size : train_size + test_size]\n</code></pre>"},{"location":"code-docs/dataset_split/#deriva_ml.dataset.split.split_dataset","title":"split_dataset","text":"<pre><code>split_dataset(\n    ml: DerivaML,\n    source_dataset_rid: str,\n    *,\n    test_size: float | int = 0.2,\n    train_size: float\n    | int\n    | None = None,\n    shuffle: bool = True,\n    seed: int = 42,\n    stratify_by_column: str\n    | None = None,\n    split_description: str = \"\",\n    training_types: list[str]\n    | None = None,\n    testing_types: list[str]\n    | None = None,\n    element_table: str | None = None,\n    include_tables: list[str]\n    | None = None,\n    selection_fn: SelectionFunction\n    | None = None,\n    workflow_type: str = \"Dataset_Split\",\n    dry_run: bool = False,\n) -&gt; dict[str, str]\n</code></pre> <p>Split a DerivaML dataset into training and testing subsets.</p> <p>Creates a new dataset hierarchy in the catalog::</p> <pre><code>Split (parent, type: \"Split\")\n+-- Training (child, type: \"Training\", + training_types)\n+-- Testing (child, type: \"Testing\", + testing_types)\n</code></pre> <p>All operations are performed within an execution context for full provenance tracking.</p> <p>This function is generic and works with any DerivaML dataset that has registered element types.</p> <p>Parameters:</p> Name Type Description Default <code>ml</code> <code>DerivaML</code> <p>Connected DerivaML instance.</p> required <code>source_dataset_rid</code> <code>str</code> <p>RID of the source dataset to split.</p> required <code>test_size</code> <code>float | int</code> <p>If float (0-1), fraction of data for testing. If int, absolute number of test samples. Default: 0.2.</p> <code>0.2</code> <code>train_size</code> <code>float | int | None</code> <p>If float (0-1), fraction of data for training. If int, absolute number of training samples. If None, complement of test_size. Default: None.</p> <code>None</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle before splitting. Default: True. Ignored when using stratified or custom selection functions (they handle their own shuffling).</p> <code>True</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Default: 42.</p> <code>42</code> <code>stratify_by_column</code> <code>str | None</code> <p>Column name for stratified splitting. Must be a column in the denormalized DataFrame (prefixed with table name, e.g., <code>Image_Classification_Image_Class</code>). Mutually exclusive with <code>selection_fn</code>.</p> <code>None</code> <code>split_description</code> <code>str</code> <p>Description for the parent Split dataset.</p> <code>''</code> <code>training_types</code> <code>list[str] | None</code> <p>Additional dataset types for the training set beyond \"Training\" (e.g., <code>[\"Labeled\"]</code>). Default: None.</p> <code>None</code> <code>testing_types</code> <code>list[str] | None</code> <p>Additional dataset types for the testing set beyond \"Testing\" (e.g., <code>[\"Labeled\"]</code>). Default: None.</p> <code>None</code> <code>element_table</code> <code>str | None</code> <p>Name of the element table to split (e.g., \"Image\"). If None, auto-detected from the source dataset's members.</p> <code>None</code> <code>include_tables</code> <code>list[str] | None</code> <p>Tables to include when denormalizing for the selection function. Required when using <code>stratify_by_column</code> or a custom <code>selection_fn</code>.</p> <code>None</code> <code>selection_fn</code> <code>SelectionFunction | None</code> <p>Custom selection function conforming to the <code>SelectionFunction</code> protocol. Mutually exclusive with <code>stratify_by_column</code>.</p> <code>None</code> <code>workflow_type</code> <code>str</code> <p>Workflow type vocabulary term. Default: \"Dataset_Split\".</p> <code>'Dataset_Split'</code> <code>dry_run</code> <code>bool</code> <p>If True, return what would happen without modifying catalog.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary with keys:</p> <code>dict[str, str]</code> <ul> <li><code>split</code>: RID of the parent Split dataset</li> </ul> <code>dict[str, str]</code> <ul> <li><code>split_version</code>: Version string of the Split dataset</li> </ul> <code>dict[str, str]</code> <ul> <li><code>training</code>: RID of the Training dataset</li> </ul> <code>dict[str, str]</code> <ul> <li><code>training_version</code>: Version string of the Training dataset</li> </ul> <code>dict[str, str]</code> <ul> <li><code>testing</code>: RID of the Testing dataset</li> </ul> <code>dict[str, str]</code> <ul> <li><code>testing_version</code>: Version string of the Testing dataset</li> </ul> <code>dict[str, str]</code> <ul> <li><code>source</code>: RID of the source dataset</li> </ul> <code>dict[str, str]</code> <ul> <li><code>train_count</code>: Number of training samples</li> </ul> <code>dict[str, str]</code> <ul> <li><code>test_count</code>: Number of testing samples</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If sizes are invalid, dataset has no members, or parameters conflict.</p> Example <p>Simple random 80/20 split::</p> <pre><code>from deriva_ml import DerivaML\nfrom deriva_ml.dataset.split import split_dataset\n\nml = DerivaML(\"localhost\", \"9\")\nresult = split_dataset(ml, \"28D0\", test_size=0.2, seed=42)\nprint(f\"Training: {result['training']} ({result['train_count']} samples)\")\nprint(f\"Testing:  {result['testing']} ({result['test_count']} samples)\")\n</code></pre> <p>Fixed-count split with labeled types::</p> <pre><code>result = split_dataset(\n    ml, \"28D0\",\n    test_size=100,\n    train_size=400,\n    seed=42,\n    training_types=[\"Labeled\"],\n    testing_types=[\"Labeled\"],\n)\n</code></pre> <p>Stratified split preserving class distribution::</p> <pre><code>result = split_dataset(\n    ml, \"28D0\",\n    test_size=0.2,\n    stratify_by_column=\"Image_Classification_Image_Class\",\n    include_tables=[\"Image\", \"Image_Classification\"],\n)\n</code></pre> <p>Custom selection function for balanced sampling::</p> <pre><code>import numpy as np\n\ndef balanced_selector(df, train_size, test_size, seed):\n    rng = np.random.default_rng(seed)\n    label_col = \"Image_Classification_Image_Class\"\n    classes = df[label_col].unique()\n    train_idx, test_idx = [], []\n    for cls in classes:\n        cls_indices = df.index[df[label_col] == cls].to_numpy()\n        rng.shuffle(cls_indices)\n        per_class_train = train_size // len(classes)\n        per_class_test = test_size // len(classes)\n        train_idx.extend(cls_indices[:per_class_train])\n        test_idx.extend(cls_indices[per_class_train:per_class_train + per_class_test])\n    return np.array(train_idx), np.array(test_idx)\n\nresult = split_dataset(\n    ml, \"28D0\",\n    test_size=100,\n    selection_fn=balanced_selector,\n    include_tables=[\"Image\", \"Image_Classification\"],\n)\n</code></pre> <p>Dry run to preview the split plan without modifying the catalog::</p> <pre><code>result = split_dataset(\n    ml, \"28D0\",\n    test_size=0.2,\n    dry_run=True,\n)\nprint(f\"Would create: {result['train_count']} train, \"\n      f\"{result['test_count']} test\")\n</code></pre> <p>Use returned RIDs to create a hydra-zen configuration::</p> <pre><code>from deriva_ml.dataset import DatasetSpecConfig\n\nresult = split_dataset(ml, \"28D0\", test_size=0.2, seed=42)\n# Use the split dataset in a configuration\nsplit_config = DatasetSpecConfig(\n    rid=result[\"split\"],\n    version=result[\"split_version\"],\n)\n</code></pre> Source code in <code>src/deriva_ml/dataset/split.py</code> <pre><code>def split_dataset(\n    ml: DerivaML,\n    source_dataset_rid: str,\n    *,\n    # scikit-learn compatible parameters\n    test_size: float | int = 0.2,\n    train_size: float | int | None = None,\n    shuffle: bool = True,\n    seed: int = 42,\n    stratify_by_column: str | None = None,\n    # DerivaML-specific parameters\n    split_description: str = \"\",\n    training_types: list[str] | None = None,\n    testing_types: list[str] | None = None,\n    element_table: str | None = None,\n    include_tables: list[str] | None = None,\n    selection_fn: SelectionFunction | None = None,\n    workflow_type: str = \"Dataset_Split\",\n    dry_run: bool = False,\n) -&gt; dict[str, str]:\n    \"\"\"Split a DerivaML dataset into training and testing subsets.\n\n    Creates a new dataset hierarchy in the catalog::\n\n        Split (parent, type: \"Split\")\n        +-- Training (child, type: \"Training\", + training_types)\n        +-- Testing (child, type: \"Testing\", + testing_types)\n\n    All operations are performed within an execution context for\n    full provenance tracking.\n\n    This function is generic and works with any DerivaML dataset\n    that has registered element types.\n\n    Args:\n        ml: Connected DerivaML instance.\n        source_dataset_rid: RID of the source dataset to split.\n        test_size: If float (0-1), fraction of data for testing.\n            If int, absolute number of test samples. Default: 0.2.\n        train_size: If float (0-1), fraction of data for training.\n            If int, absolute number of training samples.\n            If None, complement of test_size. Default: None.\n        shuffle: Whether to shuffle before splitting. Default: True.\n            Ignored when using stratified or custom selection functions\n            (they handle their own shuffling).\n        seed: Random seed for reproducibility. Default: 42.\n        stratify_by_column: Column name for stratified splitting.\n            Must be a column in the denormalized DataFrame (prefixed\n            with table name, e.g., ``Image_Classification_Image_Class``).\n            Mutually exclusive with ``selection_fn``.\n        split_description: Description for the parent Split dataset.\n        training_types: Additional dataset types for the training set\n            beyond \"Training\" (e.g., ``[\"Labeled\"]``). Default: None.\n        testing_types: Additional dataset types for the testing set\n            beyond \"Testing\" (e.g., ``[\"Labeled\"]``). Default: None.\n        element_table: Name of the element table to split (e.g., \"Image\").\n            If None, auto-detected from the source dataset's members.\n        include_tables: Tables to include when denormalizing for the\n            selection function. Required when using ``stratify_by_column``\n            or a custom ``selection_fn``.\n        selection_fn: Custom selection function conforming to the\n            ``SelectionFunction`` protocol. Mutually exclusive with\n            ``stratify_by_column``.\n        workflow_type: Workflow type vocabulary term. Default: \"Dataset_Split\".\n        dry_run: If True, return what would happen without modifying catalog.\n\n    Returns:\n        Dictionary with keys:\n\n        - ``split``: RID of the parent Split dataset\n        - ``split_version``: Version string of the Split dataset\n        - ``training``: RID of the Training dataset\n        - ``training_version``: Version string of the Training dataset\n        - ``testing``: RID of the Testing dataset\n        - ``testing_version``: Version string of the Testing dataset\n        - ``source``: RID of the source dataset\n        - ``train_count``: Number of training samples\n        - ``test_count``: Number of testing samples\n\n    Raises:\n        ValueError: If sizes are invalid, dataset has no members, or\n            parameters conflict.\n\n    Example:\n        Simple random 80/20 split::\n\n            from deriva_ml import DerivaML\n            from deriva_ml.dataset.split import split_dataset\n\n            ml = DerivaML(\"localhost\", \"9\")\n            result = split_dataset(ml, \"28D0\", test_size=0.2, seed=42)\n            print(f\"Training: {result['training']} ({result['train_count']} samples)\")\n            print(f\"Testing:  {result['testing']} ({result['test_count']} samples)\")\n\n        Fixed-count split with labeled types::\n\n            result = split_dataset(\n                ml, \"28D0\",\n                test_size=100,\n                train_size=400,\n                seed=42,\n                training_types=[\"Labeled\"],\n                testing_types=[\"Labeled\"],\n            )\n\n        Stratified split preserving class distribution::\n\n            result = split_dataset(\n                ml, \"28D0\",\n                test_size=0.2,\n                stratify_by_column=\"Image_Classification_Image_Class\",\n                include_tables=[\"Image\", \"Image_Classification\"],\n            )\n\n        Custom selection function for balanced sampling::\n\n            import numpy as np\n\n            def balanced_selector(df, train_size, test_size, seed):\n                rng = np.random.default_rng(seed)\n                label_col = \"Image_Classification_Image_Class\"\n                classes = df[label_col].unique()\n                train_idx, test_idx = [], []\n                for cls in classes:\n                    cls_indices = df.index[df[label_col] == cls].to_numpy()\n                    rng.shuffle(cls_indices)\n                    per_class_train = train_size // len(classes)\n                    per_class_test = test_size // len(classes)\n                    train_idx.extend(cls_indices[:per_class_train])\n                    test_idx.extend(cls_indices[per_class_train:per_class_train + per_class_test])\n                return np.array(train_idx), np.array(test_idx)\n\n            result = split_dataset(\n                ml, \"28D0\",\n                test_size=100,\n                selection_fn=balanced_selector,\n                include_tables=[\"Image\", \"Image_Classification\"],\n            )\n\n        Dry run to preview the split plan without modifying the catalog::\n\n            result = split_dataset(\n                ml, \"28D0\",\n                test_size=0.2,\n                dry_run=True,\n            )\n            print(f\"Would create: {result['train_count']} train, \"\n                  f\"{result['test_count']} test\")\n\n        Use returned RIDs to create a hydra-zen configuration::\n\n            from deriva_ml.dataset import DatasetSpecConfig\n\n            result = split_dataset(ml, \"28D0\", test_size=0.2, seed=42)\n            # Use the split dataset in a configuration\n            split_config = DatasetSpecConfig(\n                rid=result[\"split\"],\n                version=result[\"split_version\"],\n            )\n    \"\"\"\n    # -------------------------------------------------------------------------\n    # Validate inputs\n    # -------------------------------------------------------------------------\n    if stratify_by_column and selection_fn:\n        raise ValueError(\n            \"stratify_by_column and selection_fn are mutually exclusive. \"\n            \"Use one or the other.\"\n        )\n\n    if stratify_by_column and not include_tables:\n        raise ValueError(\n            \"include_tables is required when using stratify_by_column. \"\n            \"Specify the tables needed for denormalization \"\n            \"(e.g., include_tables=['Image', 'Image_Classification']).\"\n        )\n\n    if selection_fn and not include_tables:\n        raise ValueError(\n            \"include_tables is required when using a custom selection_fn. \"\n            \"Specify the tables needed for denormalization.\"\n        )\n\n    # -------------------------------------------------------------------------\n    # Look up source dataset and get members\n    # -------------------------------------------------------------------------\n    logger.info(f\"Looking up source dataset: {source_dataset_rid}\")\n    source_ds = ml.lookup_dataset(source_dataset_rid)\n\n    logger.info(\"Listing dataset members...\")\n    members = source_ds.list_dataset_members(recurse=True)\n\n    # Auto-detect element table if not specified\n    if element_table is None:\n        candidate_tables = [\n            table_name\n            for table_name, records in members.items()\n            if table_name != \"Dataset\" and len(records) &gt; 0\n        ]\n        if not candidate_tables:\n            raise ValueError(\n                f\"Source dataset {source_dataset_rid} has no members. \"\n                \"Cannot split an empty dataset.\"\n            )\n        if len(candidate_tables) &gt; 1:\n            raise ValueError(\n                f\"Source dataset has members in multiple tables: {candidate_tables}. \"\n                \"Specify element_table to choose which one to split.\"\n            )\n        element_table = candidate_tables[0]\n\n    if element_table not in members or not members[element_table]:\n        raise ValueError(\n            f\"Source dataset {source_dataset_rid} has no members in \"\n            f\"table '{element_table}'. Available tables with members: \"\n            f\"{[t for t, r in members.items() if r and t != 'Dataset']}\"\n        )\n\n    member_records = members[element_table]\n    total = len(member_records)\n    logger.info(f\"Found {total} members in table '{element_table}'\")\n\n    # -------------------------------------------------------------------------\n    # Compute absolute sizes\n    # -------------------------------------------------------------------------\n    train_count, test_count = _resolve_sizes(total, test_size, train_size)\n    logger.info(f\"Split sizes: train={train_count}, test={test_count} (total={total})\")\n\n    # -------------------------------------------------------------------------\n    # Determine selection strategy and get train/test RIDs\n    # -------------------------------------------------------------------------\n    use_denormalization = stratify_by_column is not None or selection_fn is not None\n\n    if use_denormalization:\n        logger.info(f\"Denormalizing dataset with tables: {include_tables}\")\n        df = source_ds.denormalize_as_dataframe(include_tables)\n        logger.info(\n            f\"Denormalized DataFrame: {len(df)} rows, {len(df.columns)} columns\"\n        )\n\n        if stratify_by_column:\n            logger.info(f\"Using stratified split on column: {stratify_by_column}\")\n            selector = stratified_split(stratify_by_column)\n        else:\n            logger.info(\"Using custom selection function\")\n            selector = selection_fn\n\n        train_indices, test_indices = selector(df, train_count, test_count, seed)\n\n        # Map indices back to RIDs\n        rid_column = f\"{element_table}_RID\"\n        if rid_column not in df.columns:\n            rid_column = \"RID\"\n            if rid_column not in df.columns:\n                raise ValueError(\n                    f\"Cannot find RID column. Tried '{element_table}_RID' and 'RID'. \"\n                    f\"Available columns: {list(df.columns)}\"\n                )\n\n        train_rids = df.iloc[train_indices][rid_column].tolist()\n        test_rids = df.iloc[test_indices][rid_column].tolist()\n\n    else:\n        all_rids = [record[\"RID\"] for record in member_records]\n\n        if shuffle:\n            rng = np.random.default_rng(seed)\n            indices = np.arange(len(all_rids))\n            rng.shuffle(indices)\n            all_rids = [all_rids[i] for i in indices]\n\n        train_rids = all_rids[:train_count]\n        test_rids = all_rids[train_count : train_count + test_count]\n\n    logger.info(\n        f\"Selected {len(train_rids)} training and {len(test_rids)} testing RIDs\"\n    )\n\n    # -------------------------------------------------------------------------\n    # Dry run\n    # -------------------------------------------------------------------------\n    if dry_run:\n        strategy = (\n            f\"stratified by {stratify_by_column}\" if stratify_by_column else \"random\"\n        )\n        if selection_fn:\n            strategy = \"custom selection function\"\n        return {\n            \"split\": \"(dry run)\",\n            \"split_version\": \"(dry run)\",\n            \"training\": \"(dry run)\",\n            \"training_version\": \"(dry run)\",\n            \"testing\": \"(dry run)\",\n            \"testing_version\": \"(dry run)\",\n            \"source\": source_dataset_rid,\n            \"train_count\": train_count,\n            \"test_count\": test_count,\n            \"strategy\": strategy,\n            \"element_table\": element_table,\n        }\n\n    # -------------------------------------------------------------------------\n    # Ensure vocabulary terms exist\n    # -------------------------------------------------------------------------\n    _ensure_workflow_type(ml, workflow_type)\n    _ensure_dataset_types(ml)\n\n    # -------------------------------------------------------------------------\n    # Create execution and dataset hierarchy\n    # -------------------------------------------------------------------------\n    strategy_desc = (\n        f\"stratified by {stratify_by_column}\" if stratify_by_column else \"random\"\n    )\n    if selection_fn:\n        strategy_desc = \"custom selection function\"\n\n    auto_description = (\n        f\"Train/test split of dataset {source_dataset_rid} \"\n        f\"({strategy_desc}, train={train_count}, test={test_count}, seed={seed})\"\n    )\n\n    logger.info(\"Creating workflow and execution...\")\n    workflow = ml.create_workflow(\n        name=f\"Dataset Split: {source_dataset_rid}\",\n        workflow_type=workflow_type,\n        description=\"Split dataset into training and testing subsets\",\n    )\n\n    config = ExecutionConfiguration(\n        workflow=workflow,\n        description=split_description or auto_description,\n    )\n\n    train_types = [\"Training\"] + (training_types or [])\n    test_types = [\"Testing\"] + (testing_types or [])\n\n    with ml.create_execution(config) as exe:\n        logger.info(f\"  Execution RID: {exe.execution_rid}\")\n\n        # Save split parameters as config artifact\n        split_params = {\n            \"source_dataset_rid\": source_dataset_rid,\n            \"test_size\": test_size,\n            \"train_size\": train_size,\n            \"train_count\": train_count,\n            \"test_count\": test_count,\n            \"shuffle\": shuffle,\n            \"seed\": seed,\n            \"stratify_by_column\": stratify_by_column,\n            \"element_table\": element_table,\n            \"include_tables\": include_tables,\n            \"training_types\": train_types,\n            \"testing_types\": test_types,\n            \"strategy\": strategy_desc,\n        }\n        params_file = Path(exe.working_dir) / \"split_config.json\"\n        params_file.write_text(json.dumps(split_params, indent=2))\n        logger.info(f\"  Saved split parameters to {params_file}\")\n\n        # Create parent Split dataset\n        split_ds = exe.create_dataset(\n            description=split_description or auto_description,\n            dataset_types=[\"Split\"],\n        )\n        logger.info(f\"  Created Split dataset: {split_ds.dataset_rid}\")\n\n        # Create Training dataset\n        training_ds = exe.create_dataset(\n            description=(\n                f\"Training subset ({train_count} samples) of {source_dataset_rid} \"\n                f\"({strategy_desc}, seed={seed})\"\n            ),\n            dataset_types=train_types,\n        )\n        logger.info(f\"  Created Training dataset: {training_ds.dataset_rid}\")\n\n        # Create Testing dataset\n        testing_ds = exe.create_dataset(\n            description=(\n                f\"Testing subset ({test_count} samples) of {source_dataset_rid} \"\n                f\"({strategy_desc}, seed={seed})\"\n            ),\n            dataset_types=test_types,\n        )\n        logger.info(f\"  Created Testing dataset: {testing_ds.dataset_rid}\")\n\n        # Link children to parent\n        split_ds.add_dataset_members(\n            [training_ds.dataset_rid, testing_ds.dataset_rid], validate=False\n        )\n        logger.info(\"  Linked Training and Testing to Split dataset\")\n\n        # Add members to training dataset\n        logger.info(f\"  Adding {len(train_rids)} members to Training dataset...\")\n        batch_size = 500\n        for i in range(0, len(train_rids), batch_size):\n            batch = train_rids[i : i + batch_size]\n            training_ds.add_dataset_members({element_table: batch}, validate=False)\n            added = min(i + batch_size, len(train_rids))\n            if added % 2000 == 0 or added &gt;= len(train_rids):\n                logger.info(f\"    Added {added}/{len(train_rids)}\")\n\n        # Add members to testing dataset\n        logger.info(f\"  Adding {len(test_rids)} members to Testing dataset...\")\n        for i in range(0, len(test_rids), batch_size):\n            batch = test_rids[i : i + batch_size]\n            testing_ds.add_dataset_members({element_table: batch}, validate=False)\n            added = min(i + batch_size, len(test_rids))\n            if added % 2000 == 0 or added &gt;= len(test_rids):\n                logger.info(f\"    Added {added}/{len(test_rids)}\")\n\n    # Upload execution outputs (after context manager exits)\n    logger.info(\"Uploading execution outputs...\")\n    exe.upload_execution_outputs(clean_folder=True)\n\n    # -------------------------------------------------------------------------\n    # Build result with versions\n    # -------------------------------------------------------------------------\n    split_ds_info = ml.lookup_dataset(split_ds.dataset_rid)\n    training_ds_info = ml.lookup_dataset(training_ds.dataset_rid)\n    testing_ds_info = ml.lookup_dataset(testing_ds.dataset_rid)\n\n    return {\n        \"split\": split_ds.dataset_rid,\n        \"split_version\": str(split_ds_info.current_version),\n        \"training\": training_ds.dataset_rid,\n        \"training_version\": str(training_ds_info.current_version),\n        \"testing\": testing_ds.dataset_rid,\n        \"testing_version\": str(testing_ds_info.current_version),\n        \"source\": source_dataset_rid,\n        \"train_count\": train_count,\n        \"test_count\": test_count,\n    }\n</code></pre>"},{"location":"code-docs/dataset_split/#deriva_ml.dataset.split.stratified_split","title":"stratified_split","text":"<pre><code>stratified_split(\n    stratify_column: str,\n) -&gt; SelectionFunction\n</code></pre> <p>Create a stratified selection function.</p> <p>Returns a selection function that maintains the class distribution of the specified column across train and test sets. Delegates to scikit-learn's <code>train_test_split</code> for the actual stratification.</p> <p>Parameters:</p> Name Type Description Default <code>stratify_column</code> <code>str</code> <p>Column name in the denormalized DataFrame to stratify by (e.g., <code>Image_Classification_Image_Class</code>).</p> required <p>Returns:</p> Type Description <code>SelectionFunction</code> <p>A <code>SelectionFunction</code> that performs stratified splitting.</p> Example <p>selector = stratified_split(\"Image_Classification_Image_Class\") train_idx, test_idx = selector(df, 400, 100, seed=42)</p> Source code in <code>src/deriva_ml/dataset/split.py</code> <pre><code>def stratified_split(stratify_column: str) -&gt; SelectionFunction:\n    \"\"\"Create a stratified selection function.\n\n    Returns a selection function that maintains the class distribution\n    of the specified column across train and test sets. Delegates to\n    scikit-learn's ``train_test_split`` for the actual stratification.\n\n    Args:\n        stratify_column: Column name in the denormalized DataFrame to\n            stratify by (e.g., ``Image_Classification_Image_Class``).\n\n    Returns:\n        A ``SelectionFunction`` that performs stratified splitting.\n\n    Example:\n        &gt;&gt;&gt; selector = stratified_split(\"Image_Classification_Image_Class\")\n        &gt;&gt;&gt; train_idx, test_idx = selector(df, 400, 100, seed=42)\n    \"\"\"\n\n    def _stratified_split(\n        df: pd.DataFrame,\n        train_size: int,\n        test_size: int,\n        seed: int,\n    ) -&gt; tuple[np.ndarray, np.ndarray]:\n        from sklearn.model_selection import train_test_split as sklearn_split\n\n        total_needed = train_size + test_size\n        if total_needed &gt; len(df):\n            raise ValueError(\n                f\"Requested {total_needed} samples but dataset has {len(df)} records\"\n            )\n\n        if stratify_column not in df.columns:\n            available = [c for c in df.columns if not c.startswith(\"_\")]\n            raise ValueError(\n                f\"Column '{stratify_column}' not found in denormalized DataFrame. \"\n                f\"Available columns: {available}\"\n            )\n\n        indices = np.arange(len(df))\n\n        # If we need a subset of the data, first do a stratified sample\n        if total_needed &lt; len(df):\n            _, subset_indices = sklearn_split(\n                indices,\n                test_size=total_needed,\n                stratify=df[stratify_column].values,\n                random_state=seed,\n            )\n            sub_df = df.iloc[subset_indices]\n        else:\n            subset_indices = indices\n            sub_df = df\n\n        # Split the subset into train/test with stratification\n        test_fraction = test_size / total_needed\n        train_idx, test_idx = sklearn_split(\n            np.arange(len(sub_df)),\n            test_size=test_fraction,\n            stratify=sub_df[stratify_column].values,\n            random_state=seed,\n        )\n\n        return subset_indices[train_idx], subset_indices[test_idx]\n\n    return _stratified_split\n</code></pre>"},{"location":"code-docs/deriva_definitions/","title":"Definitions &amp; Types","text":"<p>Core type definitions, enums, and constants used throughout DerivaML. This includes vocabulary types, status enums, column definitions, and other foundational types.</p> <p>Shared definitions for DerivaML modules.</p> <p>This module serves as the central location for type definitions, constants, enums, and data models used throughout DerivaML. It re-exports symbols from specialized submodules for convenience and backwards compatibility.</p> The module consolidates <ul> <li>Constants: Schema names, RID patterns, column definitions</li> <li>Enums: Status codes, upload states, built-in types, vocabulary identifiers</li> <li>Models: Dataclass-based models for ERMrest structures (tables, columns, keys)</li> <li>Utilities: FileSpec for file metadata handling</li> </ul> <p>Core definition classes (ColumnDef, KeyDef, ForeignKeyDef, TableDef) are provided by <code>deriva.core.typed</code> and re-exported here. Legacy aliases (ColumnDefinition, etc.) are maintained for backwards compatibility.</p> This is the recommended import location for most DerivaML type definitions <p>from deriva_ml.core.definitions import RID, MLVocab, TableDef</p> <p>For more specialized imports, you can import directly from submodules:     &gt;&gt;&gt; from deriva_ml.core.constants import ML_SCHEMA     &gt;&gt;&gt; from deriva_ml.core.enums import Status     &gt;&gt;&gt; from deriva.core.typed import ColumnDef</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.BuiltinTypes","title":"BuiltinTypes  <code>module-attribute</code>","text":"<pre><code>BuiltinTypes = BuiltinType\n</code></pre> <p>Alias for BuiltinType from deriva.core.typed.</p> <p>This maintains backwards compatibility with existing DerivaML code that uses the plural form 'BuiltinTypes'. New code should use BuiltinType directly.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.ColumnDefinition","title":"ColumnDefinition  <code>module-attribute</code>","text":"<pre><code>ColumnDefinition = ColumnDef\n</code></pre> <p>Alias for ColumnDef from deriva.core.typed.</p> <p>This maintains backwards compatibility with existing DerivaML code. New code should use ColumnDef directly.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.ForeignKeyDefinition","title":"ForeignKeyDefinition  <code>module-attribute</code>","text":"<pre><code>ForeignKeyDefinition = ForeignKeyDef\n</code></pre> <p>Alias for ForeignKeyDef from deriva.core.typed.</p> <p>This maintains backwards compatibility with existing DerivaML code. New code should use ForeignKeyDef directly.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.KeyDefinition","title":"KeyDefinition  <code>module-attribute</code>","text":"<pre><code>KeyDefinition = KeyDef\n</code></pre> <p>Alias for KeyDef from deriva.core.typed.</p> <p>This maintains backwards compatibility with existing DerivaML code. New code should use KeyDef directly.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.TableDefinition","title":"TableDefinition  <code>module-attribute</code>","text":"<pre><code>TableDefinition = TableDef\n</code></pre> <p>Alias for TableDef from deriva.core.typed.</p> <p>This maintains backwards compatibility with existing DerivaML code. New code should use TableDef directly.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.BaseStrEnum","title":"BaseStrEnum","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Base class for string-based enumerations.</p> <p>Extends both str and Enum to create string enums that are both string-like and enumerated. This provides type safety while maintaining string compatibility.</p> Example <p>class MyEnum(BaseStrEnum): ...     VALUE = \"value\" isinstance(MyEnum.VALUE, str)  # True isinstance(MyEnum.VALUE, Enum)  # True</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class BaseStrEnum(str, Enum):\n    \"\"\"Base class for string-based enumerations.\n\n    Extends both str and Enum to create string enums that are both string-like and enumerated.\n    This provides type safety while maintaining string compatibility.\n\n    Example:\n        &gt;&gt;&gt; class MyEnum(BaseStrEnum):\n        ...     VALUE = \"value\"\n        &gt;&gt;&gt; isinstance(MyEnum.VALUE, str)  # True\n        &gt;&gt;&gt; isinstance(MyEnum.VALUE, Enum)  # True\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLAuthenticationError","title":"DerivaMLAuthenticationError","text":"<p>               Bases: <code>DerivaMLConfigurationError</code></p> <p>Exception raised for authentication failures.</p> <p>Raised when authentication with the catalog fails or credentials are invalid.</p> Example <p>raise DerivaMLAuthenticationError(\"Failed to authenticate with catalog\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLAuthenticationError(DerivaMLConfigurationError):\n    \"\"\"Exception raised for authentication failures.\n\n    Raised when authentication with the catalog fails or credentials are invalid.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLAuthenticationError(\"Failed to authenticate with catalog\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLConfigurationError","title":"DerivaMLConfigurationError","text":"<p>               Bases: <code>DerivaMLException</code></p> <p>Exception raised for configuration and initialization errors.</p> <p>Raised when there are issues with DerivaML configuration, catalog initialization, or schema setup.</p> Example <p>raise DerivaMLConfigurationError(\"Invalid catalog configuration\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLConfigurationError(DerivaMLException):\n    \"\"\"Exception raised for configuration and initialization errors.\n\n    Raised when there are issues with DerivaML configuration, catalog\n    initialization, or schema setup.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLConfigurationError(\"Invalid catalog configuration\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLCycleError","title":"DerivaMLCycleError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when a cycle is detected in relationships.</p> <p>Raised when creating dataset hierarchies or other relationships that would result in a circular dependency.</p> <p>Parameters:</p> Name Type Description Default <code>cycle_nodes</code> <code>list[str]</code> <p>List of nodes involved in the cycle.</p> required <code>msg</code> <code>str</code> <p>Additional context. Defaults to \"Cycle detected\".</p> <code>'Cycle detected'</code> Example <p>raise DerivaMLCycleError([\"Dataset1\", \"Dataset2\", \"Dataset1\"])</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLCycleError(DerivaMLDataError):\n    \"\"\"Exception raised when a cycle is detected in relationships.\n\n    Raised when creating dataset hierarchies or other relationships that\n    would result in a circular dependency.\n\n    Args:\n        cycle_nodes: List of nodes involved in the cycle.\n        msg: Additional context. Defaults to \"Cycle detected\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLCycleError([\"Dataset1\", \"Dataset2\", \"Dataset1\"])\n    \"\"\"\n\n    def __init__(self, cycle_nodes: list[str], msg: str = \"Cycle detected\") -&gt; None:\n        super().__init__(f\"{msg}: {cycle_nodes}\")\n        self.cycle_nodes = cycle_nodes\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLDataError","title":"DerivaMLDataError","text":"<p>               Bases: <code>DerivaMLException</code></p> <p>Exception raised for data access and validation issues.</p> <p>Base class for errors related to data lookup, validation, and integrity.</p> Example <p>raise DerivaMLDataError(\"Invalid data format\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLDataError(DerivaMLException):\n    \"\"\"Exception raised for data access and validation issues.\n\n    Base class for errors related to data lookup, validation, and integrity.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLDataError(\"Invalid data format\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLDatasetNotFound","title":"DerivaMLDatasetNotFound","text":"<p>               Bases: <code>DerivaMLNotFoundError</code></p> <p>Exception raised when a dataset cannot be found.</p> <p>Raised when attempting to look up a dataset that doesn't exist in the catalog or downloaded bag.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_rid</code> <code>str</code> <p>The RID of the dataset that was not found.</p> required <code>msg</code> <code>str</code> <p>Additional context. Defaults to \"Dataset not found\".</p> <code>'Dataset not found'</code> Example <p>raise DerivaMLDatasetNotFound(\"1-ABC\") DerivaMLDatasetNotFound: Dataset 1-ABC not found</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLDatasetNotFound(DerivaMLNotFoundError):\n    \"\"\"Exception raised when a dataset cannot be found.\n\n    Raised when attempting to look up a dataset that doesn't exist in the\n    catalog or downloaded bag.\n\n    Args:\n        dataset_rid: The RID of the dataset that was not found.\n        msg: Additional context. Defaults to \"Dataset not found\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLDatasetNotFound(\"1-ABC\")\n        DerivaMLDatasetNotFound: Dataset 1-ABC not found\n    \"\"\"\n\n    def __init__(self, dataset_rid: str, msg: str = \"Dataset not found\") -&gt; None:\n        super().__init__(f\"{msg}: {dataset_rid}\")\n        self.dataset_rid = dataset_rid\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLException","title":"DerivaMLException","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for all DerivaML errors.</p> <p>This is the root exception for all DerivaML-specific errors. Catching this exception will catch any error raised by the DerivaML library.</p> <p>Attributes:</p> Name Type Description <code>_msg</code> <p>The error message stored for later access.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>Descriptive error message. Defaults to empty string.</p> <code>''</code> Example <p>raise DerivaMLException(\"Failed to connect to catalog\") DerivaMLException: Failed to connect to catalog</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLException(Exception):\n    \"\"\"Base exception class for all DerivaML errors.\n\n    This is the root exception for all DerivaML-specific errors. Catching this\n    exception will catch any error raised by the DerivaML library.\n\n    Attributes:\n        _msg: The error message stored for later access.\n\n    Args:\n        msg: Descriptive error message. Defaults to empty string.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLException(\"Failed to connect to catalog\")\n        DerivaMLException: Failed to connect to catalog\n    \"\"\"\n\n    def __init__(self, msg: str = \"\") -&gt; None:\n        super().__init__(msg)\n        self._msg = msg\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLExecutionError","title":"DerivaMLExecutionError","text":"<p>               Bases: <code>DerivaMLException</code></p> <p>Exception raised for execution lifecycle issues.</p> <p>Base class for errors related to workflow execution, asset management, and provenance tracking.</p> Example <p>raise DerivaMLExecutionError(\"Execution failed to initialize\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLExecutionError(DerivaMLException):\n    \"\"\"Exception raised for execution lifecycle issues.\n\n    Base class for errors related to workflow execution, asset management,\n    and provenance tracking.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLExecutionError(\"Execution failed to initialize\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLInvalidTerm","title":"DerivaMLInvalidTerm","text":"<p>               Bases: <code>DerivaMLNotFoundError</code></p> <p>Exception raised when a vocabulary term is not found or invalid.</p> <p>Raised when attempting to look up or use a term that doesn't exist in a controlled vocabulary table, or when a term name/synonym cannot be resolved.</p> <p>Parameters:</p> Name Type Description Default <code>vocabulary</code> <code>str</code> <p>Name of the vocabulary table being searched.</p> required <code>term</code> <code>str</code> <p>The term name that was not found.</p> required <code>msg</code> <code>str</code> <p>Additional context about the error. Defaults to \"Term doesn't exist\".</p> <code>\"Term doesn't exist\"</code> Example <p>raise DerivaMLInvalidTerm(\"Diagnosis\", \"unknown_condition\") DerivaMLInvalidTerm: Invalid term unknown_condition in vocabulary Diagnosis: Term doesn't exist.</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLInvalidTerm(DerivaMLNotFoundError):\n    \"\"\"Exception raised when a vocabulary term is not found or invalid.\n\n    Raised when attempting to look up or use a term that doesn't exist in\n    a controlled vocabulary table, or when a term name/synonym cannot be resolved.\n\n    Args:\n        vocabulary: Name of the vocabulary table being searched.\n        term: The term name that was not found.\n        msg: Additional context about the error. Defaults to \"Term doesn't exist\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLInvalidTerm(\"Diagnosis\", \"unknown_condition\")\n        DerivaMLInvalidTerm: Invalid term unknown_condition in vocabulary Diagnosis: Term doesn't exist.\n    \"\"\"\n\n    def __init__(self, vocabulary: str, term: str, msg: str = \"Term doesn't exist\") -&gt; None:\n        super().__init__(f\"Invalid term {term} in vocabulary {vocabulary}: {msg}.\")\n        self.vocabulary = vocabulary\n        self.term = term\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLNotFoundError","title":"DerivaMLNotFoundError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when an entity cannot be found.</p> <p>Raised when a lookup operation fails to find the requested entity (dataset, table, term, etc.) in the catalog or bag.</p> Example <p>raise DerivaMLNotFoundError(\"Entity '1-ABC' not found in catalog\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLNotFoundError(DerivaMLDataError):\n    \"\"\"Exception raised when an entity cannot be found.\n\n    Raised when a lookup operation fails to find the requested entity\n    (dataset, table, term, etc.) in the catalog or bag.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLNotFoundError(\"Entity '1-ABC' not found in catalog\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLReadOnlyError","title":"DerivaMLReadOnlyError","text":"<p>               Bases: <code>DerivaMLException</code></p> <p>Exception raised when attempting write operations on read-only resources.</p> <p>Raised when attempting to modify data in a downloaded bag or other read-only context where write operations are not supported.</p> Example <p>raise DerivaMLReadOnlyError(\"Cannot create datasets in a downloaded bag\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLReadOnlyError(DerivaMLException):\n    \"\"\"Exception raised when attempting write operations on read-only resources.\n\n    Raised when attempting to modify data in a downloaded bag or other\n    read-only context where write operations are not supported.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLReadOnlyError(\"Cannot create datasets in a downloaded bag\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLSchemaError","title":"DerivaMLSchemaError","text":"<p>               Bases: <code>DerivaMLConfigurationError</code></p> <p>Exception raised for schema or catalog structure issues.</p> <p>Raised when the catalog schema is invalid, missing required tables, or has structural problems that prevent normal operation.</p> Example <p>raise DerivaMLSchemaError(\"Ambiguous domain schema: ['Schema1', 'Schema2']\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLSchemaError(DerivaMLConfigurationError):\n    \"\"\"Exception raised for schema or catalog structure issues.\n\n    Raised when the catalog schema is invalid, missing required tables,\n    or has structural problems that prevent normal operation.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLSchemaError(\"Ambiguous domain schema: ['Schema1', 'Schema2']\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLTableNotFound","title":"DerivaMLTableNotFound","text":"<p>               Bases: <code>DerivaMLNotFoundError</code></p> <p>Exception raised when a table cannot be found.</p> <p>Raised when attempting to access a table that doesn't exist in the catalog schema or downloaded bag.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table that was not found.</p> required <code>msg</code> <code>str</code> <p>Additional context. Defaults to \"Table not found\".</p> <code>'Table not found'</code> Example <p>raise DerivaMLTableNotFound(\"MyTable\") DerivaMLTableNotFound: Table not found: MyTable</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLTableNotFound(DerivaMLNotFoundError):\n    \"\"\"Exception raised when a table cannot be found.\n\n    Raised when attempting to access a table that doesn't exist in the\n    catalog schema or downloaded bag.\n\n    Args:\n        table_name: The name of the table that was not found.\n        msg: Additional context. Defaults to \"Table not found\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLTableNotFound(\"MyTable\")\n        DerivaMLTableNotFound: Table not found: MyTable\n    \"\"\"\n\n    def __init__(self, table_name: str, msg: str = \"Table not found\") -&gt; None:\n        super().__init__(f\"{msg}: {table_name}\")\n        self.table_name = table_name\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLTableTypeError","title":"DerivaMLTableTypeError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when a RID or table is not of the expected type.</p> <p>Raised when an operation requires a specific table type (e.g., Dataset, Execution) but receives a RID or table reference of a different type.</p> <p>Parameters:</p> Name Type Description Default <code>table_type</code> <code>str</code> <p>The expected table type (e.g., \"Dataset\", \"Execution\").</p> required <code>table</code> <code>str</code> <p>The actual table name or RID that was provided.</p> required Example <p>raise DerivaMLTableTypeError(\"Dataset\", \"1-ABC123\") DerivaMLTableTypeError: Table 1-ABC123 is not of type Dataset.</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLTableTypeError(DerivaMLDataError):\n    \"\"\"Exception raised when a RID or table is not of the expected type.\n\n    Raised when an operation requires a specific table type (e.g., Dataset,\n    Execution) but receives a RID or table reference of a different type.\n\n    Args:\n        table_type: The expected table type (e.g., \"Dataset\", \"Execution\").\n        table: The actual table name or RID that was provided.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLTableTypeError(\"Dataset\", \"1-ABC123\")\n        DerivaMLTableTypeError: Table 1-ABC123 is not of type Dataset.\n    \"\"\"\n\n    def __init__(self, table_type: str, table: str) -&gt; None:\n        super().__init__(f\"Table {table} is not of type {table_type}.\")\n        self.table_type = table_type\n        self.table = table\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLUploadError","title":"DerivaMLUploadError","text":"<p>               Bases: <code>DerivaMLExecutionError</code></p> <p>Exception raised for asset upload failures.</p> <p>Raised when uploading assets to the catalog fails, including file uploads, metadata insertion, and provenance recording.</p> Example <p>raise DerivaMLUploadError(\"Failed to upload execution assets\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLUploadError(DerivaMLExecutionError):\n    \"\"\"Exception raised for asset upload failures.\n\n    Raised when uploading assets to the catalog fails, including file\n    uploads, metadata insertion, and provenance recording.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLUploadError(\"Failed to upload execution assets\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLValidationError","title":"DerivaMLValidationError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when data validation fails.</p> <p>Raised when input data fails validation, such as invalid RID format, mismatched metadata, or constraint violations.</p> Example <p>raise DerivaMLValidationError(\"Invalid RID format: ABC\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLValidationError(DerivaMLDataError):\n    \"\"\"Exception raised when data validation fails.\n\n    Raised when input data fails validation, such as invalid RID format,\n    mismatched metadata, or constraint violations.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLValidationError(\"Invalid RID format: ABC\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.DerivaMLWorkflowError","title":"DerivaMLWorkflowError","text":"<p>               Bases: <code>DerivaMLExecutionError</code></p> <p>Exception raised for workflow-related issues.</p> <p>Raised when there are problems with workflow lookup, creation, or Git integration for workflow tracking.</p> Example <p>raise DerivaMLWorkflowError(\"Not executing in a Git repository\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLWorkflowError(DerivaMLExecutionError):\n    \"\"\"Exception raised for workflow-related issues.\n\n    Raised when there are problems with workflow lookup, creation, or\n    Git integration for workflow tracking.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLWorkflowError(\"Not executing in a Git repository\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.ExecAssetType","title":"ExecAssetType","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Execution asset type identifiers.</p> <p>Defines the types of assets that can be produced or consumed during an execution. These types are used to categorize files associated with workflow runs.</p> <p>Attributes:</p> Name Type Description <code>input_file</code> <code>str</code> <p>Input file consumed by the execution.</p> <code>output_file</code> <code>str</code> <p>Output file produced by the execution.</p> <code>notebook_output</code> <code>str</code> <p>Jupyter notebook output from the execution.</p> <code>model_file</code> <code>str</code> <p>Machine learning model file (e.g., .pkl, .h5, .pt).</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class ExecAssetType(BaseStrEnum):\n    \"\"\"Execution asset type identifiers.\n\n    Defines the types of assets that can be produced or consumed during an execution.\n    These types are used to categorize files associated with workflow runs.\n\n    Attributes:\n        input_file (str): Input file consumed by the execution.\n        output_file (str): Output file produced by the execution.\n        notebook_output (str): Jupyter notebook output from the execution.\n        model_file (str): Machine learning model file (e.g., .pkl, .h5, .pt).\n    \"\"\"\n\n    input_file = \"Input_File\"\n    output_file = \"Output_File\"\n    notebook_output = \"Notebook_Output\"\n    model_file = \"Model_File\"\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.ExecMetadataType","title":"ExecMetadataType","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Execution metadata type identifiers.</p> <p>Defines the types of metadata that can be associated with an execution.</p> <p>Attributes:</p> Name Type Description <code>execution_config</code> <code>str</code> <p>General execution configuration data.</p> <code>runtime_env</code> <code>str</code> <p>Runtime environment information.</p> <code>hydra_config</code> <code>str</code> <p>Hydra YAML configuration files (config.yaml, overrides.yaml).</p> <code>deriva_config</code> <code>str</code> <p>DerivaML execution configuration (configuration.json).</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class ExecMetadataType(BaseStrEnum):\n    \"\"\"Execution metadata type identifiers.\n\n    Defines the types of metadata that can be associated with an execution.\n\n    Attributes:\n        execution_config (str): General execution configuration data.\n        runtime_env (str): Runtime environment information.\n        hydra_config (str): Hydra YAML configuration files (config.yaml, overrides.yaml).\n        deriva_config (str): DerivaML execution configuration (configuration.json).\n    \"\"\"\n\n    execution_config = \"Execution_Config\"\n    runtime_env = \"Runtime_Env\"\n    hydra_config = \"Hydra_Config\"\n    deriva_config = \"Deriva_Config\"\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.FileSpec","title":"FileSpec","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specification for a file to be added to the Deriva catalog.</p> <p>Represents file metadata required for creating entries in the File table. Handles URL normalization, ensuring local file paths are converted to tag URIs that uniquely identify the file's origin.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>File location as URL or local path. Local paths are converted to tag URIs.</p> <code>md5</code> <code>str</code> <p>MD5 checksum for integrity verification.</p> <code>length</code> <code>int</code> <p>File size in bytes.</p> <code>description</code> <code>str | None</code> <p>Optional description of the file's contents or purpose.</p> <code>file_types</code> <code>list[str] | None</code> <p>List of file type classifications from the Asset_Type vocabulary.</p> Note <p>The 'File' type is automatically added to file_types if not present when using create_filespecs().</p> Example <p>spec = FileSpec( ...     url=\"/data/results.csv\", ...     md5=\"d41d8cd98f00b204e9800998ecf8427e\", ...     length=1024, ...     description=\"Analysis results\", ...     file_types=[\"CSV\", \"Data\"] ... )</p> Source code in <code>src/deriva_ml/core/filespec.py</code> <pre><code>class FileSpec(BaseModel):\n    \"\"\"Specification for a file to be added to the Deriva catalog.\n\n    Represents file metadata required for creating entries in the File table.\n    Handles URL normalization, ensuring local file paths are converted to\n    tag URIs that uniquely identify the file's origin.\n\n    Attributes:\n        url: File location as URL or local path. Local paths are converted to tag URIs.\n        md5: MD5 checksum for integrity verification.\n        length: File size in bytes.\n        description: Optional description of the file's contents or purpose.\n        file_types: List of file type classifications from the Asset_Type vocabulary.\n\n    Note:\n        The 'File' type is automatically added to file_types if not present when\n        using create_filespecs().\n\n    Example:\n        &gt;&gt;&gt; spec = FileSpec(\n        ...     url=\"/data/results.csv\",\n        ...     md5=\"d41d8cd98f00b204e9800998ecf8427e\",\n        ...     length=1024,\n        ...     description=\"Analysis results\",\n        ...     file_types=[\"CSV\", \"Data\"]\n        ... )\n    \"\"\"\n\n    model_config = {\"populate_by_name\": True}\n\n    url: str = Field(alias=\"URL\")\n    md5: str = Field(alias=\"MD5\")\n    length: int = Field(alias=\"Length\")\n    description: str | None = Field(default=\"\", alias=\"Description\")\n    file_types: list[str] | None = Field(default_factory=list)\n\n    @field_validator(\"url\")\n    @classmethod\n    def validate_file_url(cls, url: str) -&gt; str:\n        \"\"\"Examine the provided URL. If it's a local path, convert it into a tag URL.\n\n        Args:\n            url: The URL to validate and potentially convert\n\n        Returns:\n            The validated/converted URL\n\n        Raises:\n            ValidationError: If the URL is not a file URL\n        \"\"\"\n        url_parts = urlparse(url)\n        if url_parts.scheme == \"tag\":\n            # Already a tag URL, so just return it.\n            return url\n        elif (not url_parts.scheme) or url_parts.scheme == \"file\":\n            # There is no scheme part of the URL, or it is a file URL, so it is a local file path.\n            # Convert to a tag URL.\n            return f\"tag://{gethostname()},{date.today()}:file://{url_parts.path}\"\n        else:\n            raise ValueError(\"url is not a file URL\")\n\n    @classmethod\n    def create_filespecs(\n        cls, path: Path | str, description: str, file_types: list[str] | Callable[[Path], list[str]] | None = None\n    ) -&gt; Generator[FileSpec, None, None]:\n        \"\"\"Generate FileSpec objects for a file or directory.\n\n        Creates FileSpec objects with computed MD5 checksums for each file found.\n        For directories, recursively processes all files. The 'File' type is\n        automatically prepended to file_types if not already present.\n\n        Args:\n            path: Path to a file or directory. If directory, all files are processed recursively.\n            description: Description to apply to all generated FileSpecs.\n            file_types: Either a static list of file types, or a callable that takes a Path\n                and returns a list of types for that specific file. Allows dynamic type\n                assignment based on file extension, content, etc.\n\n        Yields:\n            FileSpec: A specification for each file with computed checksums and metadata.\n\n        Example:\n            Static file types:\n                &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data/images\", \"Images\", [\"Image\"])\n\n            Dynamic file types based on extension:\n                &gt;&gt;&gt; def get_types(path):\n                ...     ext = path.suffix.lower()\n                ...     return {\"png\": [\"PNG\", \"Image\"], \".jpg\": [\"JPEG\", \"Image\"]}.get(ext, [])\n                &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data\", \"Mixed files\", get_types)\n        \"\"\"\n        path = Path(path)\n        file_types = file_types or []\n        # Convert static list to callable for uniform handling\n        file_types_fn = file_types if callable(file_types) else lambda _x: file_types\n\n        def create_spec(file_path: Path) -&gt; FileSpec:\n            \"\"\"Create a FileSpec for a single file with computed hashes.\"\"\"\n            hashes = hash_utils.compute_file_hashes(file_path, hashes=frozenset([\"md5\", \"sha256\"]))\n            md5 = hashes[\"md5\"][0]\n            type_list = file_types_fn(file_path)\n            return FileSpec(\n                length=path.stat().st_size,\n                md5=md5,\n                description=description,\n                url=file_path.as_posix(),\n                # Ensure 'File' type is always included\n                file_types=type_list if \"File\" in type_list else [\"File\"] + type_list,\n            )\n\n        # Handle both single files and directories (recursive)\n        files = [path] if path.is_file() else [f for f in Path(path).rglob(\"*\") if f.is_file()]\n        return (create_spec(file) for file in files)\n\n    @staticmethod\n    def read_filespec(path: Path | str) -&gt; Generator[FileSpec, None, None]:\n        \"\"\"Read FileSpec objects from a JSON Lines file.\n\n        Parses a JSONL file where each line is a JSON object representing a FileSpec.\n        Empty lines are skipped. This is useful for batch processing pre-computed\n        file specifications.\n\n        Args:\n            path: Path to the .jsonl file containing FileSpec data.\n\n        Yields:\n            FileSpec: Parsed FileSpec object for each valid line.\n\n        Example:\n            &gt;&gt;&gt; for spec in FileSpec.read_filespec(\"files.jsonl\"):\n            ...     print(f\"{spec.url}: {spec.md5}\")\n        \"\"\"\n        path = Path(path)\n        with path.open(\"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                line = line.strip()\n                if not line:\n                    continue\n                yield FileSpec(**json.loads(line))\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.FileSpec.create_filespecs","title":"create_filespecs  <code>classmethod</code>","text":"<pre><code>create_filespecs(\n    path: Path | str,\n    description: str,\n    file_types: list[str]\n    | Callable[[Path], list[str]]\n    | None = None,\n) -&gt; Generator[FileSpec, None, None]\n</code></pre> <p>Generate FileSpec objects for a file or directory.</p> <p>Creates FileSpec objects with computed MD5 checksums for each file found. For directories, recursively processes all files. The 'File' type is automatically prepended to file_types if not already present.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to a file or directory. If directory, all files are processed recursively.</p> required <code>description</code> <code>str</code> <p>Description to apply to all generated FileSpecs.</p> required <code>file_types</code> <code>list[str] | Callable[[Path], list[str]] | None</code> <p>Either a static list of file types, or a callable that takes a Path and returns a list of types for that specific file. Allows dynamic type assignment based on file extension, content, etc.</p> <code>None</code> <p>Yields:</p> Name Type Description <code>FileSpec</code> <code>FileSpec</code> <p>A specification for each file with computed checksums and metadata.</p> Example <p>Static file types:     &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data/images\", \"Images\", [\"Image\"])</p> <p>Dynamic file types based on extension:     &gt;&gt;&gt; def get_types(path):     ...     ext = path.suffix.lower()     ...     return {\"png\": [\"PNG\", \"Image\"], \".jpg\": [\"JPEG\", \"Image\"]}.get(ext, [])     &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data\", \"Mixed files\", get_types)</p> Source code in <code>src/deriva_ml/core/filespec.py</code> <pre><code>@classmethod\ndef create_filespecs(\n    cls, path: Path | str, description: str, file_types: list[str] | Callable[[Path], list[str]] | None = None\n) -&gt; Generator[FileSpec, None, None]:\n    \"\"\"Generate FileSpec objects for a file or directory.\n\n    Creates FileSpec objects with computed MD5 checksums for each file found.\n    For directories, recursively processes all files. The 'File' type is\n    automatically prepended to file_types if not already present.\n\n    Args:\n        path: Path to a file or directory. If directory, all files are processed recursively.\n        description: Description to apply to all generated FileSpecs.\n        file_types: Either a static list of file types, or a callable that takes a Path\n            and returns a list of types for that specific file. Allows dynamic type\n            assignment based on file extension, content, etc.\n\n    Yields:\n        FileSpec: A specification for each file with computed checksums and metadata.\n\n    Example:\n        Static file types:\n            &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data/images\", \"Images\", [\"Image\"])\n\n        Dynamic file types based on extension:\n            &gt;&gt;&gt; def get_types(path):\n            ...     ext = path.suffix.lower()\n            ...     return {\"png\": [\"PNG\", \"Image\"], \".jpg\": [\"JPEG\", \"Image\"]}.get(ext, [])\n            &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data\", \"Mixed files\", get_types)\n    \"\"\"\n    path = Path(path)\n    file_types = file_types or []\n    # Convert static list to callable for uniform handling\n    file_types_fn = file_types if callable(file_types) else lambda _x: file_types\n\n    def create_spec(file_path: Path) -&gt; FileSpec:\n        \"\"\"Create a FileSpec for a single file with computed hashes.\"\"\"\n        hashes = hash_utils.compute_file_hashes(file_path, hashes=frozenset([\"md5\", \"sha256\"]))\n        md5 = hashes[\"md5\"][0]\n        type_list = file_types_fn(file_path)\n        return FileSpec(\n            length=path.stat().st_size,\n            md5=md5,\n            description=description,\n            url=file_path.as_posix(),\n            # Ensure 'File' type is always included\n            file_types=type_list if \"File\" in type_list else [\"File\"] + type_list,\n        )\n\n    # Handle both single files and directories (recursive)\n    files = [path] if path.is_file() else [f for f in Path(path).rglob(\"*\") if f.is_file()]\n    return (create_spec(file) for file in files)\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.FileSpec.read_filespec","title":"read_filespec  <code>staticmethod</code>","text":"<pre><code>read_filespec(\n    path: Path | str,\n) -&gt; Generator[FileSpec, None, None]\n</code></pre> <p>Read FileSpec objects from a JSON Lines file.</p> <p>Parses a JSONL file where each line is a JSON object representing a FileSpec. Empty lines are skipped. This is useful for batch processing pre-computed file specifications.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to the .jsonl file containing FileSpec data.</p> required <p>Yields:</p> Name Type Description <code>FileSpec</code> <code>FileSpec</code> <p>Parsed FileSpec object for each valid line.</p> Example <p>for spec in FileSpec.read_filespec(\"files.jsonl\"): ...     print(f\"{spec.url}: {spec.md5}\")</p> Source code in <code>src/deriva_ml/core/filespec.py</code> <pre><code>@staticmethod\ndef read_filespec(path: Path | str) -&gt; Generator[FileSpec, None, None]:\n    \"\"\"Read FileSpec objects from a JSON Lines file.\n\n    Parses a JSONL file where each line is a JSON object representing a FileSpec.\n    Empty lines are skipped. This is useful for batch processing pre-computed\n    file specifications.\n\n    Args:\n        path: Path to the .jsonl file containing FileSpec data.\n\n    Yields:\n        FileSpec: Parsed FileSpec object for each valid line.\n\n    Example:\n        &gt;&gt;&gt; for spec in FileSpec.read_filespec(\"files.jsonl\"):\n        ...     print(f\"{spec.url}: {spec.md5}\")\n    \"\"\"\n    path = Path(path)\n    with path.open(\"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            yield FileSpec(**json.loads(line))\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.FileSpec.validate_file_url","title":"validate_file_url  <code>classmethod</code>","text":"<pre><code>validate_file_url(url: str) -&gt; str\n</code></pre> <p>Examine the provided URL. If it's a local path, convert it into a tag URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to validate and potentially convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>The validated/converted URL</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the URL is not a file URL</p> Source code in <code>src/deriva_ml/core/filespec.py</code> <pre><code>@field_validator(\"url\")\n@classmethod\ndef validate_file_url(cls, url: str) -&gt; str:\n    \"\"\"Examine the provided URL. If it's a local path, convert it into a tag URL.\n\n    Args:\n        url: The URL to validate and potentially convert\n\n    Returns:\n        The validated/converted URL\n\n    Raises:\n        ValidationError: If the URL is not a file URL\n    \"\"\"\n    url_parts = urlparse(url)\n    if url_parts.scheme == \"tag\":\n        # Already a tag URL, so just return it.\n        return url\n    elif (not url_parts.scheme) or url_parts.scheme == \"file\":\n        # There is no scheme part of the URL, or it is a file URL, so it is a local file path.\n        # Convert to a tag URL.\n        return f\"tag://{gethostname()},{date.today()}:file://{url_parts.path}\"\n    else:\n        raise ValueError(\"url is not a file URL\")\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.FileUploadState","title":"FileUploadState","text":"<p>               Bases: <code>BaseModel</code></p> <p>Tracks the state and result of a file upload operation.</p> <p>Attributes:</p> Name Type Description <code>state</code> <code>UploadState</code> <p>Current state of the upload (success, failed, etc.).</p> <code>status</code> <code>str</code> <p>Detailed status message.</p> <code>result</code> <code>Any</code> <p>Upload result data, if any.</p> Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>class FileUploadState(BaseModel):\n    \"\"\"Tracks the state and result of a file upload operation.\n\n    Attributes:\n        state (UploadState): Current state of the upload (success, failed, etc.).\n        status (str): Detailed status message.\n        result (Any): Upload result data, if any.\n    \"\"\"\n    state: UploadState\n    status: str\n    result: Any\n\n    @computed_field\n    @property\n    def rid(self) -&gt; RID | None:\n        return self.result and self.result[\"RID\"]\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.MLAsset","title":"MLAsset","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Asset type identifiers.</p> <p>Defines the types of assets that can be associated with executions.</p> <p>Attributes:</p> Name Type Description <code>execution_metadata</code> <code>str</code> <p>Metadata about an execution.</p> <code>execution_asset</code> <code>str</code> <p>Asset produced by an execution.</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class MLAsset(BaseStrEnum):\n    \"\"\"Asset type identifiers.\n\n    Defines the types of assets that can be associated with executions.\n\n    Attributes:\n        execution_metadata (str): Metadata about an execution.\n        execution_asset (str): Asset produced by an execution.\n    \"\"\"\n\n    execution_metadata = \"Execution_Metadata\"\n    execution_asset = \"Execution_Asset\"\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.MLTable","title":"MLTable","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Core ML schema table identifiers.</p> <p>Defines the names of the core tables in the deriva-ml schema. These tables form the backbone of the ML workflow tracking system.</p> <p>Attributes:</p> Name Type Description <code>dataset</code> <code>str</code> <p>Dataset table for versioned data collections.</p> <code>workflow</code> <code>str</code> <p>Workflow table for computational pipeline definitions.</p> <code>file</code> <code>str</code> <p>File table for tracking individual files.</p> <code>asset</code> <code>str</code> <p>Asset table for domain-specific file types.</p> <code>execution</code> <code>str</code> <p>Execution table for workflow run tracking.</p> <code>execution_execution</code> <code>str</code> <p>Execution_Execution table for nested executions.</p> <code>dataset_version</code> <code>str</code> <p>Dataset_Version table for version history.</p> <code>execution_metadata</code> <code>str</code> <p>Execution_Metadata table for run metadata.</p> <code>execution_asset</code> <code>str</code> <p>Execution_Asset table for run outputs.</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class MLTable(BaseStrEnum):\n    \"\"\"Core ML schema table identifiers.\n\n    Defines the names of the core tables in the deriva-ml schema. These tables\n    form the backbone of the ML workflow tracking system.\n\n    Attributes:\n        dataset (str): Dataset table for versioned data collections.\n        workflow (str): Workflow table for computational pipeline definitions.\n        file (str): File table for tracking individual files.\n        asset (str): Asset table for domain-specific file types.\n        execution (str): Execution table for workflow run tracking.\n        execution_execution (str): Execution_Execution table for nested executions.\n        dataset_version (str): Dataset_Version table for version history.\n        execution_metadata (str): Execution_Metadata table for run metadata.\n        execution_asset (str): Execution_Asset table for run outputs.\n    \"\"\"\n\n    dataset = \"Dataset\"\n    workflow = \"Workflow\"\n    file = \"File\"\n    asset = \"Asset\"\n    execution = \"Execution\"\n    execution_execution = \"Execution_Execution\"\n    dataset_version = \"Dataset_Version\"\n    execution_metadata = \"Execution_Metadata\"\n    execution_asset = \"Execution_Asset\"\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.MLVocab","title":"MLVocab","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Controlled vocabulary table identifiers.</p> <p>Defines the names of controlled vocabulary tables used in DerivaML. These tables store standardized terms with descriptions and synonyms for consistent data classification across the catalog.</p> <p>Attributes:</p> Name Type Description <code>dataset_type</code> <code>str</code> <p>Dataset classification vocabulary (e.g., \"Training\", \"Test\").</p> <code>workflow_type</code> <code>str</code> <p>Workflow classification vocabulary (e.g., \"Python\", \"Notebook\").</p> <code>asset_type</code> <code>str</code> <p>Asset/file type classification vocabulary (e.g., \"Image\", \"CSV\").</p> <code>asset_role</code> <code>str</code> <p>Asset role vocabulary for execution relationships (e.g., \"Input\", \"Output\").</p> <code>feature_name</code> <code>str</code> <p>Feature name vocabulary for ML feature definitions.</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class MLVocab(BaseStrEnum):\n    \"\"\"Controlled vocabulary table identifiers.\n\n    Defines the names of controlled vocabulary tables used in DerivaML. These tables\n    store standardized terms with descriptions and synonyms for consistent data\n    classification across the catalog.\n\n    Attributes:\n        dataset_type (str): Dataset classification vocabulary (e.g., \"Training\", \"Test\").\n        workflow_type (str): Workflow classification vocabulary (e.g., \"Python\", \"Notebook\").\n        asset_type (str): Asset/file type classification vocabulary (e.g., \"Image\", \"CSV\").\n        asset_role (str): Asset role vocabulary for execution relationships (e.g., \"Input\", \"Output\").\n        feature_name (str): Feature name vocabulary for ML feature definitions.\n    \"\"\"\n\n    dataset_type = \"Dataset_Type\"\n    workflow_type = \"Workflow_Type\"\n    asset_type = \"Asset_Type\"\n    asset_role = \"Asset_Role\"\n    feature_name = \"Feature_Name\"\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.Status","title":"Status","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Execution status values.</p> <p>Represents the various states an execution can be in throughout its lifecycle.</p> <p>Attributes:</p> Name Type Description <code>initializing</code> <code>str</code> <p>Initial setup is in progress.</p> <code>created</code> <code>str</code> <p>Execution record has been created.</p> <code>pending</code> <code>str</code> <p>Execution is queued.</p> <code>running</code> <code>str</code> <p>Execution is in progress.</p> <code>aborted</code> <code>str</code> <p>Execution was manually stopped.</p> <code>completed</code> <code>str</code> <p>Execution finished successfully.</p> <code>failed</code> <code>str</code> <p>Execution encountered an error.</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class Status(BaseStrEnum):\n    \"\"\"Execution status values.\n\n    Represents the various states an execution can be in throughout its lifecycle.\n\n    Attributes:\n        initializing (str): Initial setup is in progress.\n        created (str): Execution record has been created.\n        pending (str): Execution is queued.\n        running (str): Execution is in progress.\n        aborted (str): Execution was manually stopped.\n        completed (str): Execution finished successfully.\n        failed (str): Execution encountered an error.\n    \"\"\"\n\n    initializing = \"Initializing\"\n    created = \"Created\"\n    pending = \"Pending\"\n    running = \"Running\"\n    aborted = \"Aborted\"\n    completed = \"Completed\"\n    failed = \"Failed\"\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.UploadCallback","title":"UploadCallback","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for upload progress callbacks.</p> <p>Implement this protocol to receive progress updates during file uploads. The callback is invoked with an UploadProgress object containing current upload state information.</p> Example <p>def my_callback(progress: UploadProgress) -&gt; None: ...     print(f\"Uploading {progress.file_name}: {progress.percent_complete:.1f}%\") ... execution.upload_execution_outputs(progress_callback=my_callback)</p> Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>class UploadCallback(Protocol):\n    \"\"\"Protocol for upload progress callbacks.\n\n    Implement this protocol to receive progress updates during file uploads.\n    The callback is invoked with an UploadProgress object containing current\n    upload state information.\n\n    Example:\n        &gt;&gt;&gt; def my_callback(progress: UploadProgress) -&gt; None:\n        ...     print(f\"Uploading {progress.file_name}: {progress.percent_complete:.1f}%\")\n        ...\n        &gt;&gt;&gt; execution.upload_execution_outputs(progress_callback=my_callback)\n    \"\"\"\n    def __call__(self, progress: UploadProgress) -&gt; None:\n        \"\"\"Called with upload progress information.\n\n        Args:\n            progress: Current upload progress state.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.UploadCallback.__call__","title":"__call__","text":"<pre><code>__call__(\n    progress: UploadProgress,\n) -&gt; None\n</code></pre> <p>Called with upload progress information.</p> <p>Parameters:</p> Name Type Description Default <code>progress</code> <code>UploadProgress</code> <p>Current upload progress state.</p> required Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>def __call__(self, progress: UploadProgress) -&gt; None:\n    \"\"\"Called with upload progress information.\n\n    Args:\n        progress: Current upload progress state.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.UploadProgress","title":"UploadProgress  <code>dataclass</code>","text":"<p>Progress information for file uploads.</p> <p>This dataclass is passed to upload callbacks to report progress during file upload operations.</p> <p>Attributes:</p> Name Type Description <code>file_path</code> <code>str</code> <p>Path to the file being uploaded.</p> <code>file_name</code> <code>str</code> <p>Name of the file being uploaded.</p> <code>bytes_completed</code> <code>int</code> <p>Number of bytes uploaded so far.</p> <code>bytes_total</code> <code>int</code> <p>Total number of bytes to upload.</p> <code>percent_complete</code> <code>float</code> <p>Percentage of upload completed (0-100).</p> <code>phase</code> <code>str</code> <p>Current phase of the upload operation.</p> <code>message</code> <code>str</code> <p>Human-readable status message.</p> Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>@dataclass\nclass UploadProgress:\n    \"\"\"Progress information for file uploads.\n\n    This dataclass is passed to upload callbacks to report progress during\n    file upload operations.\n\n    Attributes:\n        file_path: Path to the file being uploaded.\n        file_name: Name of the file being uploaded.\n        bytes_completed: Number of bytes uploaded so far.\n        bytes_total: Total number of bytes to upload.\n        percent_complete: Percentage of upload completed (0-100).\n        phase: Current phase of the upload operation.\n        message: Human-readable status message.\n    \"\"\"\n    file_path: str = \"\"\n    file_name: str = \"\"\n    bytes_completed: int = 0\n    bytes_total: int = 0\n    percent_complete: float = 0.0\n    phase: str = \"\"\n    message: str = \"\"\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.UploadState","title":"UploadState","text":"<p>               Bases: <code>Enum</code></p> <p>File upload operation states.</p> <p>Represents the various states a file upload operation can be in, from initiation to completion.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>int</code> <p>Upload completed successfully.</p> <code>failed</code> <code>int</code> <p>Upload failed.</p> <code>pending</code> <code>int</code> <p>Upload is queued.</p> <code>running</code> <code>int</code> <p>Upload is in progress.</p> <code>paused</code> <code>int</code> <p>Upload is temporarily paused.</p> <code>aborted</code> <code>int</code> <p>Upload was aborted.</p> <code>cancelled</code> <code>int</code> <p>Upload was cancelled.</p> <code>timeout</code> <code>int</code> <p>Upload timed out.</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class UploadState(Enum):\n    \"\"\"File upload operation states.\n\n    Represents the various states a file upload operation can be in, from initiation to completion.\n\n    Attributes:\n        success (int): Upload completed successfully.\n        failed (int): Upload failed.\n        pending (int): Upload is queued.\n        running (int): Upload is in progress.\n        paused (int): Upload is temporarily paused.\n        aborted (int): Upload was aborted.\n        cancelled (int): Upload was cancelled.\n        timeout (int): Upload timed out.\n    \"\"\"\n\n    success = 0\n    failed = 1\n    pending = 2\n    running = 3\n    paused = 4\n    aborted = 5\n    cancelled = 6\n    timeout = 7\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTerm","title":"VocabularyTerm","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a term in a controlled vocabulary.</p> <p>A vocabulary term is a standardized entry in a controlled vocabulary table. Each term has a primary name, optional synonyms, and identifiers for cross-referencing.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Primary name of the term.</p> <code>synonyms</code> <code>list[str] | None</code> <p>Alternative names for the term.</p> <code>id</code> <code>str</code> <p>CURIE (Compact URI) identifier.</p> <code>uri</code> <code>str</code> <p>Full URI for the term.</p> <code>description</code> <code>str</code> <p>Explanation of the term's meaning.</p> <code>rid</code> <code>str</code> <p>Resource identifier in the catalog.</p> Example <p>term = VocabularyTerm( ...     Name=\"epithelial\", ...     Synonyms=[\"epithelium\"], ...     ID=\"tissue:0001\", ...     URI=\"http://example.org/tissue/0001\", ...     Description=\"Epithelial tissue type\", ...     RID=\"1-abc123\" ... )</p> Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>class VocabularyTerm(BaseModel):\n    \"\"\"Represents a term in a controlled vocabulary.\n\n    A vocabulary term is a standardized entry in a controlled vocabulary table. Each term has\n    a primary name, optional synonyms, and identifiers for cross-referencing.\n\n    Attributes:\n        name (str): Primary name of the term.\n        synonyms (list[str] | None): Alternative names for the term.\n        id (str): CURIE (Compact URI) identifier.\n        uri (str): Full URI for the term.\n        description (str): Explanation of the term's meaning.\n        rid (str): Resource identifier in the catalog.\n\n    Example:\n        &gt;&gt;&gt; term = VocabularyTerm(\n        ...     Name=\"epithelial\",\n        ...     Synonyms=[\"epithelium\"],\n        ...     ID=\"tissue:0001\",\n        ...     URI=\"http://example.org/tissue/0001\",\n        ...     Description=\"Epithelial tissue type\",\n        ...     RID=\"1-abc123\"\n        ... )\n    \"\"\"\n    _name: str = PrivateAttr()\n    _synonyms: list[str] | None = PrivateAttr()\n    _description: str = PrivateAttr()\n    id: str = Field(validation_alias=AliasChoices(\"ID\", \"id\"))\n    uri: str = Field(validation_alias=AliasChoices(\"URI\", \"uri\"))\n    rid: str = Field(validation_alias=AliasChoices(\"RID\", \"rid\"))\n\n    def __init__(self, **data):\n        # Extract fields that will be private attrs before calling super\n        name = data.pop(\"Name\", None) or data.pop(\"name\", None)\n        synonyms = data.pop(\"Synonyms\", None) or data.pop(\"synonyms\", None)\n        description = data.pop(\"Description\", None) or data.pop(\"description\", None)\n        super().__init__(**data)\n        self._name = name\n        self._synonyms = synonyms\n        self._description = description\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Primary name of the term.\"\"\"\n        return self._name\n\n    @property\n    def synonyms(self) -&gt; tuple[str, ...]:\n        \"\"\"Alternative names for the term (immutable).\"\"\"\n        return tuple(self._synonyms or [])\n\n    @property\n    def description(self) -&gt; str:\n        \"\"\"Explanation of the term's meaning.\"\"\"\n        return self._description\n\n    class Config:\n        extra = \"ignore\"\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTerm.description","title":"description  <code>property</code>","text":"<pre><code>description: str\n</code></pre> <p>Explanation of the term's meaning.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTerm.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Primary name of the term.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTerm.synonyms","title":"synonyms  <code>property</code>","text":"<pre><code>synonyms: tuple[str, ...]\n</code></pre> <p>Alternative names for the term (immutable).</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTermHandle","title":"VocabularyTermHandle","text":"<p>               Bases: <code>VocabularyTerm</code></p> <p>A VocabularyTerm with methods to modify it in the catalog.</p> <p>This class extends VocabularyTerm to provide mutable access to vocabulary terms. Changes made through property setters are persisted to the catalog.</p> <p>The <code>synonyms</code> property returns a tuple (immutable) to prevent accidental modification without catalog update. To modify synonyms, assign a new tuple/list to the property.</p> Example <p>term = ml.lookup_term(\"Dataset_Type\", \"Training\") term.description = \"Data used for model training\" term.synonyms = (\"Train\", \"TrainingData\") term.delete()</p> Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>class VocabularyTermHandle(VocabularyTerm):\n    \"\"\"A VocabularyTerm with methods to modify it in the catalog.\n\n    This class extends VocabularyTerm to provide mutable access to vocabulary\n    terms. Changes made through property setters are persisted to the catalog.\n\n    The `synonyms` property returns a tuple (immutable) to prevent accidental\n    modification without catalog update. To modify synonyms, assign a new\n    tuple/list to the property.\n\n    Attributes:\n        Inherits all attributes from VocabularyTerm.\n\n    Example:\n        &gt;&gt;&gt; term = ml.lookup_term(\"Dataset_Type\", \"Training\")\n        &gt;&gt;&gt; term.description = \"Data used for model training\"\n        &gt;&gt;&gt; term.synonyms = (\"Train\", \"TrainingData\")\n        &gt;&gt;&gt; term.delete()\n    \"\"\"\n\n    _ml: Any = PrivateAttr()\n    _table: str = PrivateAttr()\n\n    def __init__(self, ml: Any, table: str, **data):\n        \"\"\"Initialize a VocabularyTermHandle.\n\n        Args:\n            ml: DerivaML instance for catalog operations.\n            table: Name of the vocabulary table containing this term.\n            **data: Term data (Name, Synonyms, Description, ID, URI, RID).\n        \"\"\"\n        super().__init__(**data)\n        self._ml = ml\n        self._table = table\n\n    @property\n    def description(self) -&gt; str:\n        \"\"\"Explanation of the term's meaning.\"\"\"\n        return self._description\n\n    @description.setter\n    def description(self, value: str) -&gt; None:\n        \"\"\"Update the term's description in the catalog.\n\n        Args:\n            value: New description for the term.\n        \"\"\"\n        self._ml._update_term_description(self._table, self.name, value)\n        self._description = value\n\n    @property\n    def synonyms(self) -&gt; tuple[str, ...]:\n        \"\"\"Alternative names for the term (immutable).\n\n        Returns a tuple to prevent accidental modification without catalog update.\n        To modify synonyms, assign a new tuple/list to this property.\n        \"\"\"\n        return tuple(self._synonyms or [])\n\n    @synonyms.setter\n    def synonyms(self, value: list[str] | tuple[str, ...]) -&gt; None:\n        \"\"\"Replace all synonyms for this term in the catalog.\n\n        Args:\n            value: New list of synonyms (replaces all existing synonyms).\n        \"\"\"\n        new_synonyms = list(value)\n        self._ml._update_term_synonyms(self._table, self.name, new_synonyms)\n        self._synonyms = new_synonyms\n\n    def delete(self) -&gt; None:\n        \"\"\"Delete this term from the vocabulary.\n\n        Raises:\n            DerivaMLException: If the term is currently in use by other records.\n        \"\"\"\n        self._ml.delete_term(self._table, self.name)\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTermHandle.description","title":"description  <code>property</code> <code>writable</code>","text":"<pre><code>description: str\n</code></pre> <p>Explanation of the term's meaning.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTermHandle.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Primary name of the term.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTermHandle.synonyms","title":"synonyms  <code>property</code> <code>writable</code>","text":"<pre><code>synonyms: tuple[str, ...]\n</code></pre> <p>Alternative names for the term (immutable).</p> <p>Returns a tuple to prevent accidental modification without catalog update. To modify synonyms, assign a new tuple/list to this property.</p>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTermHandle.__init__","title":"__init__","text":"<pre><code>__init__(ml: Any, table: str, **data)\n</code></pre> <p>Initialize a VocabularyTermHandle.</p> <p>Parameters:</p> Name Type Description Default <code>ml</code> <code>Any</code> <p>DerivaML instance for catalog operations.</p> required <code>table</code> <code>str</code> <p>Name of the vocabulary table containing this term.</p> required <code>**data</code> <p>Term data (Name, Synonyms, Description, ID, URI, RID).</p> <code>{}</code> Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>def __init__(self, ml: Any, table: str, **data):\n    \"\"\"Initialize a VocabularyTermHandle.\n\n    Args:\n        ml: DerivaML instance for catalog operations.\n        table: Name of the vocabulary table containing this term.\n        **data: Term data (Name, Synonyms, Description, ID, URI, RID).\n    \"\"\"\n    super().__init__(**data)\n    self._ml = ml\n    self._table = table\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.VocabularyTermHandle.delete","title":"delete","text":"<pre><code>delete() -&gt; None\n</code></pre> <p>Delete this term from the vocabulary.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the term is currently in use by other records.</p> Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>def delete(self) -&gt; None:\n    \"\"\"Delete this term from the vocabulary.\n\n    Raises:\n        DerivaMLException: If the term is currently in use by other records.\n    \"\"\"\n    self._ml.delete_term(self._table, self.name)\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.get_domain_schemas","title":"get_domain_schemas","text":"<pre><code>get_domain_schemas(\n    all_schemas: set[str] | list[str],\n    ml_schema: str = ML_SCHEMA,\n) -&gt; frozenset[str]\n</code></pre> <p>Return all domain schemas from a collection of schema names.</p> <p>Filters out system schemas (public, www, WWW) and the ML schema to return only user-defined domain schemas.</p> <p>Parameters:</p> Name Type Description Default <code>all_schemas</code> <code>set[str] | list[str]</code> <p>Collection of schema names to filter.</p> required <code>ml_schema</code> <code>str</code> <p>Name of the ML schema to exclude (default: 'deriva-ml').</p> <code>ML_SCHEMA</code> <p>Returns:</p> Type Description <code>frozenset[str]</code> <p>Frozen set of domain schema names.</p> Example <p>get_domain_schemas([\"public\", \"deriva-ml\", \"my_project\", \"www\"]) frozenset({'my_project'})</p> Source code in <code>src/deriva_ml/core/constants.py</code> <pre><code>def get_domain_schemas(all_schemas: set[str] | list[str], ml_schema: str = ML_SCHEMA) -&gt; frozenset[str]:\n    \"\"\"Return all domain schemas from a collection of schema names.\n\n    Filters out system schemas (public, www, WWW) and the ML schema to return\n    only user-defined domain schemas.\n\n    Args:\n        all_schemas: Collection of schema names to filter.\n        ml_schema: Name of the ML schema to exclude (default: 'deriva-ml').\n\n    Returns:\n        Frozen set of domain schema names.\n\n    Example:\n        &gt;&gt;&gt; get_domain_schemas([\"public\", \"deriva-ml\", \"my_project\", \"www\"])\n        frozenset({'my_project'})\n    \"\"\"\n    return frozenset(s for s in all_schemas if not is_system_schema(s, ml_schema))\n</code></pre>"},{"location":"code-docs/deriva_definitions/#deriva_ml.core.definitions.is_system_schema","title":"is_system_schema","text":"<pre><code>is_system_schema(\n    schema_name: str,\n    ml_schema: str = ML_SCHEMA,\n) -&gt; bool\n</code></pre> <p>Check if a schema is a system or ML schema (not a domain schema).</p> <p>System schemas are Deriva infrastructure schemas (public, www, WWW) and the ML schema (deriva-ml by default). Domain schemas are user-defined schemas containing business logic tables.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Name of the schema to check.</p> required <code>ml_schema</code> <code>str</code> <p>Name of the ML schema (default: 'deriva-ml').</p> <code>ML_SCHEMA</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the schema is a system or ML schema, False if it's a domain schema.</p> Example <p>is_system_schema(\"public\") True is_system_schema(\"deriva-ml\") True is_system_schema(\"my_project\") False</p> Source code in <code>src/deriva_ml/core/constants.py</code> <pre><code>def is_system_schema(schema_name: str, ml_schema: str = ML_SCHEMA) -&gt; bool:\n    \"\"\"Check if a schema is a system or ML schema (not a domain schema).\n\n    System schemas are Deriva infrastructure schemas (public, www, WWW) and the\n    ML schema (deriva-ml by default). Domain schemas are user-defined schemas\n    containing business logic tables.\n\n    Args:\n        schema_name: Name of the schema to check.\n        ml_schema: Name of the ML schema (default: 'deriva-ml').\n\n    Returns:\n        True if the schema is a system or ML schema, False if it's a domain schema.\n\n    Example:\n        &gt;&gt;&gt; is_system_schema(\"public\")\n        True\n        &gt;&gt;&gt; is_system_schema(\"deriva-ml\")\n        True\n        &gt;&gt;&gt; is_system_schema(\"my_project\")\n        False\n    \"\"\"\n    return schema_name.lower() in {s.lower() for s in SYSTEM_SCHEMAS} or schema_name == ml_schema\n</code></pre>"},{"location":"code-docs/deriva_ml_base/","title":"<code>DerivaML</code> Class","text":"<p>The DerivaML class provides a range of methods to interact with a Deriva catalog. These methods assume tha tthe catalog contains a <code>deriva-ml</code> and a domain schema.</p> <p>Data Catalog: The catalog must include both the domain schema and a standard ML schema for effective data management.</p> <p></p> <ul> <li>Domain schema: The domain schema includes the data collected or generated by domain-specific experiments or systems.</li> <li>ML schema: Each entity in the ML schema is designed to capture details of the ML development process. It including the following tables<ul> <li>A Dataset represents a data collection, such as aggregation identified for training, validation, and testing purposes.</li> <li>A Workflow represents a specific sequence of computational steps or human interactions.</li> <li>An Execution is an instance of a workflow that a user instantiates at a specific time. </li> <li>An Execution Asset is an output file that results from the execution of a workflow.</li> <li>An Execution Metadata is an asset entity for saving metadata files referencing a given execution.</li> </ul> </li> </ul> <p>Core module for DerivaML.</p> <p>This module provides the primary public interface to DerivaML functionality. It exports the main DerivaML class along with configuration, definitions, and exceptions needed for interacting with Deriva-based ML catalogs.</p> Key exports <ul> <li>DerivaML: Main class for catalog operations and ML workflow management.</li> <li>DerivaMLConfig: Configuration class for DerivaML instances.</li> <li>Exceptions: DerivaMLException and specialized exception types.</li> <li>Definitions: Type definitions, enums, and constants used throughout the package.</li> </ul> Example <p>from deriva_ml.core import DerivaML, DerivaMLConfig ml = DerivaML('deriva.example.org', 'my_catalog') datasets = ml.find_datasets()</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.BuiltinTypes","title":"BuiltinTypes  <code>module-attribute</code>","text":"<pre><code>BuiltinTypes = BuiltinType\n</code></pre> <p>Alias for BuiltinType from deriva.core.typed.</p> <p>This maintains backwards compatibility with existing DerivaML code that uses the plural form 'BuiltinTypes'. New code should use BuiltinType directly.</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.ColumnDefinition","title":"ColumnDefinition  <code>module-attribute</code>","text":"<pre><code>ColumnDefinition = ColumnDef\n</code></pre> <p>Alias for ColumnDef from deriva.core.typed.</p> <p>This maintains backwards compatibility with existing DerivaML code. New code should use ColumnDef directly.</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.TableDefinition","title":"TableDefinition  <code>module-attribute</code>","text":"<pre><code>TableDefinition = TableDef\n</code></pre> <p>Alias for TableDef from deriva.core.typed.</p> <p>This maintains backwards compatibility with existing DerivaML code. New code should use TableDef directly.</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML","title":"DerivaML","text":"<p>               Bases: <code>PathBuilderMixin</code>, <code>RidResolutionMixin</code>, <code>VocabularyMixin</code>, <code>WorkflowMixin</code>, <code>FeatureMixin</code>, <code>DatasetMixin</code>, <code>AssetMixin</code>, <code>ExecutionMixin</code>, <code>FileMixin</code>, <code>AnnotationMixin</code>, <code>DerivaMLCatalog</code></p> <p>Core class for machine learning operations on a Deriva catalog.</p> <p>This class provides core functionality for managing ML workflows, features, and datasets in a Deriva catalog. It handles data versioning, feature management, vocabulary control, and execution tracking.</p> <p>Attributes:</p> Name Type Description <code>host_name</code> <code>str</code> <p>Hostname of the Deriva server (e.g., 'deriva.example.org').</p> <code>catalog_id</code> <code>Union[str, int]</code> <p>Catalog identifier or name.</p> <code>domain_schema</code> <code>str</code> <p>Schema name for domain-specific tables and relationships.</p> <code>model</code> <code>DerivaModel</code> <p>ERMRest model for the catalog.</p> <code>working_dir</code> <code>Path</code> <p>Directory for storing computation data and results.</p> <code>cache_dir</code> <code>Path</code> <p>Directory for caching downloaded datasets.</p> <code>ml_schema</code> <code>str</code> <p>Schema name for ML-specific tables (default: 'deriva_ml').</p> <code>configuration</code> <code>ExecutionConfiguration</code> <p>Current execution configuration.</p> <code>project_name</code> <code>str</code> <p>Name of the current project.</p> <code>start_time</code> <code>datetime</code> <p>Timestamp when this instance was created.</p> <code>status</code> <code>str</code> <p>Current status of operations.</p> Example <p>ml = DerivaML('deriva.example.org', 'my_catalog') ml.create_feature('my_table', 'new_feature') ml.add_term('vocabulary_table', 'new_term', description='Description of term')</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>class DerivaML(\n    PathBuilderMixin,\n    RidResolutionMixin,\n    VocabularyMixin,\n    WorkflowMixin,\n    FeatureMixin,\n    DatasetMixin,\n    AssetMixin,\n    ExecutionMixin,\n    FileMixin,\n    AnnotationMixin,\n    DerivaMLCatalog,\n):\n    \"\"\"Core class for machine learning operations on a Deriva catalog.\n\n    This class provides core functionality for managing ML workflows, features, and datasets in a Deriva catalog.\n    It handles data versioning, feature management, vocabulary control, and execution tracking.\n\n    Attributes:\n        host_name (str): Hostname of the Deriva server (e.g., 'deriva.example.org').\n        catalog_id (Union[str, int]): Catalog identifier or name.\n        domain_schema (str): Schema name for domain-specific tables and relationships.\n        model (DerivaModel): ERMRest model for the catalog.\n        working_dir (Path): Directory for storing computation data and results.\n        cache_dir (Path): Directory for caching downloaded datasets.\n        ml_schema (str): Schema name for ML-specific tables (default: 'deriva_ml').\n        configuration (ExecutionConfiguration): Current execution configuration.\n        project_name (str): Name of the current project.\n        start_time (datetime): Timestamp when this instance was created.\n        status (str): Current status of operations.\n\n    Example:\n        &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n        &gt;&gt;&gt; ml.create_feature('my_table', 'new_feature')\n        &gt;&gt;&gt; ml.add_term('vocabulary_table', 'new_term', description='Description of term')\n    \"\"\"\n\n    # Class-level type annotations for DerivaMLCatalog protocol compliance\n    ml_schema: str\n    domain_schemas: frozenset[str]\n    default_schema: str | None\n    model: DerivaModel\n    cache_dir: Path\n    working_dir: Path\n    catalog: ErmrestCatalog | ErmrestSnapshot\n    catalog_id: str | int\n\n    @classmethod\n    def instantiate(cls, config: DerivaMLConfig) -&gt; Self:\n        \"\"\"Create a DerivaML instance from a configuration object.\n\n        This method is the preferred way to instantiate DerivaML when using hydra-zen\n        for configuration management. It accepts a DerivaMLConfig (Pydantic model) and\n        unpacks it to create the instance.\n\n        This pattern allows hydra-zen's `instantiate()` to work with DerivaML:\n\n        Example with hydra-zen:\n            &gt;&gt;&gt; from hydra_zen import builds, instantiate\n            &gt;&gt;&gt; from deriva_ml import DerivaML\n            &gt;&gt;&gt; from deriva_ml.core.config import DerivaMLConfig\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create a structured config using hydra-zen\n            &gt;&gt;&gt; DerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Configure for your environment\n            &gt;&gt;&gt; conf = DerivaMLConf(\n            ...     hostname='deriva.example.org',\n            ...     catalog_id='42',\n            ...     domain_schema='my_domain',\n            ... )\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Instantiate the config to get a DerivaMLConfig object\n            &gt;&gt;&gt; config = instantiate(conf)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create the DerivaML instance\n            &gt;&gt;&gt; ml = DerivaML.instantiate(config)\n\n        Args:\n            config: A DerivaMLConfig object containing all configuration parameters.\n\n        Returns:\n            A new DerivaML instance configured according to the config object.\n\n        Note:\n            The DerivaMLConfig class integrates with Hydra's configuration system\n            and registers custom resolvers for computing working directories.\n            See `deriva_ml.core.config` for details on configuration options.\n        \"\"\"\n        return cls(**config.model_dump())\n\n    def __init__(\n        self,\n        hostname: str,\n        catalog_id: str | int,\n        domain_schemas: str | set[str] | None = None,\n        default_schema: str | None = None,\n        project_name: str | None = None,\n        cache_dir: str | Path | None = None,\n        working_dir: str | Path | None = None,\n        hydra_runtime_output_dir: str | Path | None = None,\n        ml_schema: str = ML_SCHEMA,\n        logging_level: int = logging.WARNING,\n        deriva_logging_level: int = logging.WARNING,\n        credential: dict | None = None,\n        s3_bucket: str | None = None,\n        use_minid: bool | None = None,\n        check_auth: bool = True,\n        clean_execution_dir: bool = True,\n    ) -&gt; None:\n        \"\"\"Initializes a DerivaML instance.\n\n        This method will connect to a catalog and initialize local configuration for the ML execution.\n        This class is intended to be used as a base class on which domain-specific interfaces are built.\n\n        Args:\n            hostname: Hostname of the Deriva server.\n            catalog_id: Catalog ID. Either an identifier or a catalog name.\n            domain_schemas: Optional set of domain schema names. If None, auto-detects all\n                non-system schemas. Use this when working with catalogs that have multiple\n                user-defined schemas.\n            default_schema: The default schema for table creation operations. If None and\n                there is exactly one domain schema, that schema is used. If there are multiple\n                domain schemas, this must be specified for table creation to work without\n                explicit schema parameters.\n            ml_schema: Schema name for ML schema. Used if you have a non-standard configuration of deriva-ml.\n            project_name: Project name. Defaults to name of default_schema.\n            cache_dir: Directory path for caching data downloaded from the Deriva server as bdbag. If not provided,\n                will default to working_dir.\n            working_dir: Directory path for storing data used by or generated by any computations. If no value is\n                provided, will default to  ${HOME}/deriva_ml\n            s3_bucket: S3 bucket URL for dataset bag storage (e.g., 's3://my-bucket'). If provided,\n                enables MINID creation and S3 upload for dataset exports. If None, MINID functionality\n                is disabled regardless of use_minid setting.\n            use_minid: Use the MINID service when downloading dataset bags. Only effective when\n                s3_bucket is configured. If None (default), automatically set to True when s3_bucket\n                is provided, False otherwise.\n            check_auth: Check if the user has access to the catalog.\n            clean_execution_dir: Whether to automatically clean up execution working directories\n                after successful upload. Defaults to True. Set to False to retain local copies.\n        \"\"\"\n        # Get or use provided credentials for server access\n        self.credential = credential or get_credential(hostname)\n\n        # Initialize server connection and catalog access\n        server = DerivaServer(\n            \"https\",\n            hostname,\n            credentials=self.credential,\n            session_config=self._get_session_config(),\n        )\n        try:\n            if check_auth and server.get_authn_session():\n                pass\n        except Exception:\n            raise DerivaMLException(\n                \"You are not authorized to access this catalog. \"\n                \"Please check your credentials and make sure you have logged in.\"\n            )\n        self.catalog = server.connect_ermrest(catalog_id)\n        # Import here to avoid circular imports\n        from deriva_ml.model.catalog import DerivaModel\n        self.model = DerivaModel(\n            self.catalog.getCatalogModel(),\n            ml_schema=ml_schema,\n            domain_schemas=domain_schemas,\n            default_schema=default_schema,\n        )\n\n        # Store S3 bucket configuration and resolve use_minid\n        self.s3_bucket = s3_bucket\n        if use_minid is None:\n            # Auto mode: enable MINID if s3_bucket is configured\n            self.use_minid = s3_bucket is not None\n        elif use_minid and s3_bucket is None:\n            # User requested MINID but no S3 bucket configured - disable MINID\n            self.use_minid = False\n        else:\n            self.use_minid = use_minid\n\n        # Set up working and cache directories\n        # If working_dir is already provided (e.g. from DerivaMLConfig.instantiate()),\n        # use it directly; otherwise compute the default path.\n        if working_dir is not None:\n            self.working_dir = Path(working_dir).absolute()\n        else:\n            self.working_dir = DerivaMLConfig.compute_workdir(None, catalog_id, hostname)\n        self.working_dir.mkdir(parents=True, exist_ok=True)\n        self.hydra_runtime_output_dir = hydra_runtime_output_dir\n\n        self.cache_dir = Path(cache_dir) if cache_dir else self.working_dir / \"cache\"\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n\n        # Set up logging using centralized configuration\n        # This configures deriva_ml, Hydra, and deriva-py loggers without\n        # affecting the root logger or calling basicConfig()\n        self._logger = configure_logging(\n            level=logging_level,\n            deriva_level=deriva_logging_level,\n        )\n        self._logging_level = logging_level\n        self._deriva_logging_level = deriva_logging_level\n\n        # Apply deriva's default logger overrides for fine-grained control\n        apply_logger_overrides(DEFAULT_LOGGER_OVERRIDES)\n\n        # Store instance configuration\n        self.host_name = hostname\n        self.catalog_id = catalog_id\n        self.ml_schema = ml_schema\n        self.configuration = None\n        self._execution: Execution | None = None\n        self.domain_schemas = self.model.domain_schemas\n        self.default_schema = self.model.default_schema\n        self.project_name = project_name or self.default_schema or \"deriva-ml\"\n        self.start_time = datetime.now()\n        self.status = Status.pending.value\n        self.clean_execution_dir = clean_execution_dir\n\n    def __del__(self) -&gt; None:\n        \"\"\"Cleanup method to handle incomplete executions.\"\"\"\n        try:\n            # Mark execution as aborted if not completed\n            if self._execution and self._execution.status != Status.completed:\n                self._execution.update_status(Status.aborted, \"Execution Aborted\")\n        except (AttributeError, requests.HTTPError):\n            pass\n\n    @staticmethod\n    def _get_session_config() -&gt; dict:\n        \"\"\"Returns customized HTTP session configuration.\n\n        Configures retry behavior and connection settings for HTTP requests to the Deriva server. Settings include:\n        - Idempotent retry behavior for all HTTP methods\n        - Increased retry attempts for read and connect operations\n        - Exponential backoff for retries\n\n        Returns:\n            dict: Session configuration dictionary with retry and connection settings.\n\n        Example:\n            &gt;&gt;&gt; config = DerivaML._get_session_config()\n            &gt;&gt;&gt; print(config['retry_read']) # 8\n        \"\"\"\n        # Start with a default configuration\n        session_config = DEFAULT_SESSION_CONFIG.copy()\n\n        # Customize retry behavior for robustness\n        session_config.update(\n            {\n                # Allow retries for all HTTP methods (PUT/POST are idempotent)\n                \"allow_retry_on_all_methods\": True,\n                # Increase retry attempts for better reliability\n                \"retry_read\": 8,\n                \"retry_connect\": 5,\n                # Use exponential backoff for retries\n                \"retry_backoff_factor\": 5,\n            }\n        )\n        return session_config\n\n    def is_snapshot(self) -&gt; bool:\n        return hasattr(self.catalog, \"_snaptime\")\n\n    def catalog_snapshot(self, version_snapshot: str) -&gt; Self:\n        \"\"\"Returns a DerivaML instance for a specific snapshot of the catalog.\"\"\"\n        return DerivaML(\n            self.host_name,\n            version_snapshot,\n            logging_level=self._logging_level,\n            deriva_logging_level=self._deriva_logging_level,\n        )\n\n    @property\n    def _dataset_table(self) -&gt; Table:\n        return self.model.schemas[self.model.ml_schema].tables[\"Dataset\"]\n\n    # pathBuilder, domain_path, table_path moved to PathBuilderMixin\n\n    def download_dir(self, cached: bool = False) -&gt; Path:\n        \"\"\"Returns the appropriate download directory.\n\n        Provides the appropriate directory path for storing downloaded files, either in the cache or working directory.\n\n        Args:\n            cached: If True, returns the cache directory path. If False, returns the working directory path.\n\n        Returns:\n            Path: Directory path where downloaded files should be stored.\n\n        Example:\n            &gt;&gt;&gt; cache_dir = ml.download_dir(cached=True)\n            &gt;&gt;&gt; work_dir = ml.download_dir(cached=False)\n        \"\"\"\n        # Return cache directory if cached=True, otherwise working directory\n        return self.cache_dir if cached else self.working_dir\n\n    @staticmethod\n    def globus_login(host: str) -&gt; None:\n        \"\"\"Authenticates with Globus for accessing Deriva services.\n\n        Performs authentication using Globus Auth to access Deriva services. If already logged in, notifies the user.\n        Uses non-interactive authentication flow without a browser or local server.\n\n        Args:\n            host: The hostname of the Deriva server to authenticate with (e.g., 'deriva.example.org').\n\n        Example:\n            &gt;&gt;&gt; DerivaML.globus_login('deriva.example.org')\n            'Login Successful'\n        \"\"\"\n        gnl = GlobusNativeLogin(host=host)\n        if gnl.is_logged_in([host]):\n            print(\"You are already logged in.\")\n        else:\n            gnl.login(\n                [host],\n                no_local_server=True,\n                no_browser=True,\n                refresh_tokens=True,\n                update_bdbag_keychain=True,\n            )\n            print(\"Login Successful\")\n\n    def chaise_url(self, table: RID | Table | str) -&gt; str:\n        \"\"\"Generates Chaise web interface URL.\n\n        Chaise is Deriva's web interface for data exploration. This method creates a URL that directly links to\n        the specified table or record.\n\n        Args:\n            table: Table to generate URL for (name, Table object, or RID).\n\n        Returns:\n            str: URL in format: https://{host}/chaise/recordset/#{catalog}/{schema}:{table}\n\n        Raises:\n            DerivaMLException: If table or RID cannot be found.\n\n        Examples:\n            Using table name:\n                &gt;&gt;&gt; ml.chaise_url(\"experiment_table\")\n                'https://deriva.org/chaise/recordset/#1/schema:experiment_table'\n\n            Using RID:\n                &gt;&gt;&gt; ml.chaise_url(\"1-abc123\")\n        \"\"\"\n        # Get the table object and build base URI\n        table_obj = self.model.name_to_table(table)\n        try:\n            uri = self.catalog.get_server_uri().replace(\"ermrest/catalog/\", \"chaise/recordset/#\")\n        except DerivaMLException:\n            # Handle RID case\n            uri = self.cite(cast(str, table))\n        return f\"{uri}/{urlquote(table_obj.schema.name)}:{urlquote(table_obj.name)}\"\n\n    def cite(self, entity: Dict[str, Any] | str, current: bool = False) -&gt; str:\n        \"\"\"Generates citation URL for an entity.\n\n        Creates a URL that can be used to reference a specific entity in the catalog.\n        By default, includes the catalog snapshot time to ensure version stability\n        (permanent citation). With current=True, returns a URL to the current state.\n\n        Args:\n            entity: Either a RID string or a dictionary containing entity data with a 'RID' key.\n            current: If True, return URL to current catalog state (no snapshot).\n                     If False (default), return permanent citation URL with snapshot time.\n\n        Returns:\n            str: Citation URL. Format depends on `current` parameter:\n                - current=False: https://{host}/id/{catalog}/{rid}@{snapshot_time}\n                - current=True: https://{host}/id/{catalog}/{rid}\n\n        Raises:\n            DerivaMLException: If an entity doesn't exist or lacks a RID.\n\n        Examples:\n            Permanent citation (default):\n                &gt;&gt;&gt; url = ml.cite(\"1-abc123\")\n                &gt;&gt;&gt; print(url)\n                'https://deriva.org/id/1/1-abc123@2024-01-01T12:00:00'\n\n            Current catalog URL:\n                &gt;&gt;&gt; url = ml.cite(\"1-abc123\", current=True)\n                &gt;&gt;&gt; print(url)\n                'https://deriva.org/id/1/1-abc123'\n\n            Using a dictionary:\n                &gt;&gt;&gt; url = ml.cite({\"RID\": \"1-abc123\"})\n        \"\"\"\n        # Return if already a citation URL\n        if isinstance(entity, str) and entity.startswith(f\"https://{self.host_name}/id/{self.catalog_id}/\"):\n            return entity\n\n        try:\n            # Resolve RID and create citation URL\n            self.resolve_rid(rid := entity if isinstance(entity, str) else entity[\"RID\"])\n            base_url = f\"https://{self.host_name}/id/{self.catalog_id}/{rid}\"\n            if current:\n                return base_url\n            return f\"{base_url}@{self.catalog.latest_snapshot().snaptime}\"\n        except KeyError as e:\n            raise DerivaMLException(f\"Entity {e} does not have RID column\")\n        except DerivaMLException as _e:\n            raise DerivaMLException(\"Entity RID does not exist\")\n\n    @property\n    def catalog_provenance(self) -&gt; \"CatalogProvenance | None\":\n        \"\"\"Get the provenance information for this catalog.\n\n        Returns provenance information if the catalog has it set. This includes\n        information about how the catalog was created (clone, create, schema),\n        who created it, when, and any workflow information.\n\n        For cloned catalogs, additional details about the clone operation are\n        available in the `clone_details` attribute.\n\n        Returns:\n            CatalogProvenance if available, None otherwise.\n\n        Example:\n            &gt;&gt;&gt; ml = DerivaML('localhost', '45')\n            &gt;&gt;&gt; prov = ml.catalog_provenance\n            &gt;&gt;&gt; if prov:\n            ...     print(f\"Created: {prov.created_at} by {prov.created_by}\")\n            ...     print(f\"Method: {prov.creation_method.value}\")\n            ...     if prov.is_clone:\n            ...         print(f\"Cloned from: {prov.clone_details.source_hostname}\")\n        \"\"\"\n        from deriva_ml.catalog.clone import get_catalog_provenance\n\n        return get_catalog_provenance(self.catalog)\n\n    def user_list(self) -&gt; List[Dict[str, str]]:\n        \"\"\"Returns catalog user list.\n\n        Retrieves basic information about all users who have access to the catalog, including their\n        identifiers and full names.\n\n        Returns:\n            List[Dict[str, str]]: List of user information dictionaries, each containing:\n                - 'ID': User identifier\n                - 'Full_Name': User's full name\n\n        Examples:\n\n            &gt;&gt;&gt; users = ml.user_list()\n            &gt;&gt;&gt; for user in users:\n            ...     print(f\"{user['Full_Name']} ({user['ID']})\")\n        \"\"\"\n        # Get the user table path and fetch basic user info\n        user_path = self.pathBuilder().public.ERMrest_Client.path\n        return [{\"ID\": u[\"ID\"], \"Full_Name\": u[\"Full_Name\"]} for u in user_path.entities().fetch()]\n\n    # resolve_rid, retrieve_rid moved to RidResolutionMixin\n\n    def apply_catalog_annotations(\n        self,\n        navbar_brand_text: str = \"ML Data Browser\",\n        head_title: str = \"Catalog ML\",\n    ) -&gt; None:\n        \"\"\"Apply catalog-level annotations including the navigation bar and display settings.\n\n        This method configures the Chaise web interface for the catalog. Chaise is Deriva's\n        web-based data browser that provides a user-friendly interface for exploring and\n        managing catalog data. This method sets up annotations that control how Chaise\n        displays and organizes the catalog.\n\n        **Navigation Bar Structure**:\n        The method creates a navigation bar with the following menus:\n        - **User Info**: Links to Users, Groups, and RID Lease tables\n        - **Deriva-ML**: Core ML tables (Workflow, Execution, Dataset, Dataset_Version, etc.)\n        - **WWW**: Web content tables (Page, File)\n        - **{Domain Schema}**: All domain-specific tables (excludes vocabularies and associations)\n        - **Vocabulary**: All controlled vocabulary tables from both ML and domain schemas\n        - **Assets**: All asset tables from both ML and domain schemas\n        - **Features**: All feature tables with entries named \"TableName:FeatureName\"\n        - **Catalog Registry**: Link to the ermrest registry\n        - **Documentation**: Links to ML notebook instructions and Deriva-ML docs\n\n        **Display Settings**:\n        - Underscores in table/column names displayed as spaces\n        - System columns (RID) shown in compact and entry views\n        - Default table set to Dataset\n        - Faceting and record deletion enabled\n        - Export configurations available to all users\n\n        **Bulk Upload Configuration**:\n        Configures upload patterns for asset tables, enabling drag-and-drop file uploads\n        through the Chaise interface.\n\n        Call this after creating the domain schema and all tables to initialize the catalog's\n        web interface. The navigation menus are dynamically built based on the current schema\n        structure, automatically organizing tables into appropriate categories.\n\n        Args:\n            navbar_brand_text: Text displayed in the navigation bar brand area.\n            head_title: Title displayed in the browser tab.\n\n        Example:\n            &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n            &gt;&gt;&gt; # After creating domain schema and tables...\n            &gt;&gt;&gt; ml.apply_catalog_annotations()\n            &gt;&gt;&gt; # Or with custom branding:\n            &gt;&gt;&gt; ml.apply_catalog_annotations(\"My Project Browser\", \"My ML Project\")\n        \"\"\"\n        catalog_id = self.model.catalog.catalog_id\n        ml_schema = self.ml_schema\n\n        # Build domain schema menu items (one menu per domain schema)\n        domain_schema_menus = []\n        for domain_schema in sorted(self.domain_schemas):\n            if domain_schema not in self.model.schemas:\n                continue\n            domain_schema_menus.append({\n                \"name\": domain_schema,\n                \"children\": [\n                    {\n                        \"name\": tname,\n                        \"url\": f\"/chaise/recordset/#{catalog_id}/{domain_schema}:{tname}\",\n                    }\n                    for tname in self.model.schemas[domain_schema].tables\n                    # Don't include controlled vocabularies, association tables, or feature tables.\n                    if not (\n                        self.model.is_vocabulary(tname)\n                        or self.model.is_association(tname, pure=False, max_arity=3)\n                    )\n                ],\n            })\n\n        # Build vocabulary menu items (ML schema + all domain schemas)\n        vocab_children = [{\"name\": f\"{ml_schema} Vocabularies\", \"header\": True}]\n        vocab_children.extend([\n            {\n                \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:{tname}\",\n                \"name\": tname,\n            }\n            for tname in self.model.schemas[ml_schema].tables\n            if self.model.is_vocabulary(tname)\n        ])\n        for domain_schema in sorted(self.domain_schemas):\n            if domain_schema not in self.model.schemas:\n                continue\n            vocab_children.append({\"name\": f\"{domain_schema} Vocabularies\", \"header\": True})\n            vocab_children.extend([\n                {\n                    \"url\": f\"/chaise/recordset/#{catalog_id}/{domain_schema}:{tname}\",\n                    \"name\": tname,\n                }\n                for tname in self.model.schemas[domain_schema].tables\n                if self.model.is_vocabulary(tname)\n            ])\n\n        # Build asset menu items (ML schema + all domain schemas)\n        asset_children = [\n            {\n                \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:{tname}\",\n                \"name\": tname,\n            }\n            for tname in self.model.schemas[ml_schema].tables\n            if self.model.is_asset(tname)\n        ]\n        for domain_schema in sorted(self.domain_schemas):\n            if domain_schema not in self.model.schemas:\n                continue\n            asset_children.extend([\n                {\n                    \"url\": f\"/chaise/recordset/#{catalog_id}/{domain_schema}:{tname}\",\n                    \"name\": tname,\n                }\n                for tname in self.model.schemas[domain_schema].tables\n                if self.model.is_asset(tname)\n            ])\n\n        catalog_annotation = {\n            deriva_tags.display: {\"name_style\": {\"underline_space\": True}},\n            deriva_tags.chaise_config: {\n                \"headTitle\": head_title,\n                \"navbarBrandText\": navbar_brand_text,\n                \"systemColumnsDisplayEntry\": [\"RID\"],\n                \"systemColumnsDisplayCompact\": [\"RID\"],\n                \"defaultTable\": {\"table\": \"Dataset\", \"schema\": \"deriva-ml\"},\n                \"deleteRecord\": True,\n                \"showFaceting\": True,\n                \"shareCiteAcls\": True,\n                \"exportConfigsSubmenu\": {\"acls\": {\"show\": [\"*\"], \"enable\": [\"*\"]}},\n                \"resolverImplicitCatalog\": False,\n                \"navbarMenu\": {\n                    \"newTab\": False,\n                    \"children\": [\n                        {\n                            \"name\": \"User Info\",\n                            \"children\": [\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/public:ERMrest_Client\",\n                                    \"name\": \"Users\",\n                                },\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/public:ERMrest_Group\",\n                                    \"name\": \"Groups\",\n                                },\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/public:ERMrest_RID_Lease\",\n                                    \"name\": \"ERMrest RID Lease\",\n                                },\n                            ],\n                        },\n                        {  # All the primary tables in deriva-ml schema.\n                            \"name\": \"Deriva-ML\",\n                            \"children\": [\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Workflow\",\n                                    \"name\": \"Workflow\",\n                                },\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Execution\",\n                                    \"name\": \"Execution\",\n                                },\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Execution_Metadata\",\n                                    \"name\": \"Execution Metadata\",\n                                },\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Execution_Asset\",\n                                    \"name\": \"Execution Asset\",\n                                },\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Dataset\",\n                                    \"name\": \"Dataset\",\n                                },\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Dataset_Version\",\n                                    \"name\": \"Dataset Version\",\n                                },\n                            ],\n                        },\n                        {  # WWW schema tables.\n                            \"name\": \"WWW\",\n                            \"children\": [\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/WWW:Page\",\n                                    \"name\": \"Page\",\n                                },\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/WWW:File\",\n                                    \"name\": \"File\",\n                                },\n                            ],\n                        },\n                        *domain_schema_menus,  # One menu per domain schema\n                        {  # Vocabulary menu with all controlled vocabularies.\n                            \"name\": \"Vocabulary\",\n                            \"children\": vocab_children,\n                        },\n                        {  # List of all asset tables.\n                            \"name\": \"Assets\",\n                            \"children\": asset_children,\n                        },\n                        {  # List of all feature tables in the catalog.\n                            \"name\": \"Features\",\n                            \"children\": [\n                                {\n                                    \"url\": f\"/chaise/recordset/#{catalog_id}/{f.feature_table.schema.name}:{f.feature_table.name}\",\n                                    \"name\": f\"{f.target_table.name}:{f.feature_name}\",\n                                }\n                                for f in self.model.find_features()\n                            ],\n                        },\n                        {\n                            \"url\": \"/chaise/recordset/#0/ermrest:registry@sort(RID)\",\n                            \"name\": \"Catalog Registry\",\n                        },\n                        {\n                            \"name\": \"Documentation\",\n                            \"children\": [\n                                {\n                                    \"url\": \"https://github.com/informatics-isi-edu/deriva-ml/blob/main/docs/ml_workflow_instruction.md\",\n                                    \"name\": \"ML Notebook Instruction\",\n                                },\n                                {\n                                    \"url\": \"https://informatics-isi-edu.github.io/deriva-ml/\",\n                                    \"name\": \"Deriva-ML Documentation\",\n                                },\n                            ],\n                        },\n                    ],\n                },\n            },\n            deriva_tags.bulk_upload: bulk_upload_configuration(model=self.model),\n        }\n        self.model.annotations.update(catalog_annotation)\n        self.model.apply()\n\n    def add_page(self, title: str, content: str) -&gt; None:\n        \"\"\"Adds page to web interface.\n\n        Creates a new page in the catalog's web interface with the specified title and content. The page will be\n        accessible through the catalog's navigation system.\n\n        Args:\n            title: The title of the page to be displayed in navigation and headers.\n            content: The main content of the page can include HTML markup.\n\n        Raises:\n            DerivaMLException: If the page creation fails or the user lacks necessary permissions.\n\n        Example:\n            &gt;&gt;&gt; ml.add_page(\n            ...     title=\"Analysis Results\",\n            ...     content=\"&lt;h1&gt;Results&lt;/h1&gt;&lt;p&gt;Analysis completed successfully...&lt;/p&gt;\"\n            ... )\n        \"\"\"\n        # Insert page into www tables with title and content\n        # Use default schema or first domain schema for www tables\n        schema = self.default_schema or (sorted(self.domain_schemas)[0] if self.domain_schemas else None)\n        if schema is None:\n            raise DerivaMLException(\"No domain schema available for adding pages\")\n        self.pathBuilder().www.tables[schema].insert([{\"Title\": title, \"Content\": content}])\n\n    def create_vocabulary(\n        self, vocab_name: str, comment: str = \"\", schema: str | None = None, update_navbar: bool = True\n    ) -&gt; Table:\n        \"\"\"Creates a controlled vocabulary table.\n\n        A controlled vocabulary table maintains a list of standardized terms and their definitions. Each term can have\n        synonyms and descriptions to ensure consistent terminology usage across the dataset.\n\n        Args:\n            vocab_name: Name for the new vocabulary table. Must be a valid SQL identifier.\n            comment: Description of the vocabulary's purpose and usage. Defaults to empty string.\n            schema: Schema name to create the table in. If None, uses domain_schema.\n            update_navbar: If True (default), automatically updates the navigation bar to include\n                the new vocabulary table. Set to False during batch table creation to avoid\n                redundant updates, then call apply_catalog_annotations() once at the end.\n\n        Returns:\n            Table: ERMRest table object representing the newly created vocabulary table.\n\n        Raises:\n            DerivaMLException: If vocab_name is invalid or already exists.\n\n        Examples:\n            Create a vocabulary for tissue types:\n\n                &gt;&gt;&gt; table = ml.create_vocabulary(\n                ...     vocab_name=\"tissue_types\",\n                ...     comment=\"Standard tissue classifications\",\n                ...     schema=\"bio_schema\"\n                ... )\n\n            Create multiple vocabularies without updating navbar until the end:\n\n                &gt;&gt;&gt; ml.create_vocabulary(\"Species\", update_navbar=False)\n                &gt;&gt;&gt; ml.create_vocabulary(\"Tissue_Type\", update_navbar=False)\n                &gt;&gt;&gt; ml.apply_catalog_annotations()  # Update navbar once\n        \"\"\"\n        # Use default schema if none specified\n        schema = schema or self.model._require_default_schema()\n\n        # Create and return vocabulary table with RID-based URI pattern\n        try:\n            vocab_table = self.model.schemas[schema].create_table(\n                VocabularyTableDef(\n                    name=vocab_name,\n                    curie_template=f\"{self.project_name}:{{RID}}\",\n                    comment=comment,\n                )\n            )\n        except ValueError:\n            raise DerivaMLException(f\"Table {vocab_name} already exist\")\n\n        # Update navbar to include the new vocabulary table\n        if update_navbar:\n            self.apply_catalog_annotations()\n\n        return vocab_table\n\n    def create_table(self, table: TableDefinition, schema: str | None = None, update_navbar: bool = True) -&gt; Table:\n        \"\"\"Creates a new table in the domain schema.\n\n        Creates a table using the provided TableDefinition object, which specifies the table structure\n        including columns, keys, and foreign key relationships. The table is created in the domain\n        schema associated with this DerivaML instance.\n\n        **Required Classes**:\n        Import the following classes from deriva_ml to define tables:\n\n        - ``TableDefinition``: Defines the complete table structure\n        - ``ColumnDefinition``: Defines individual columns with types and constraints\n        - ``KeyDefinition``: Defines unique key constraints (optional)\n        - ``ForeignKeyDefinition``: Defines foreign key relationships to other tables (optional)\n        - ``BuiltinTypes``: Enum of available column data types\n\n        **Available Column Types** (BuiltinTypes enum):\n        ``text``, ``int2``, ``int4``, ``int8``, ``float4``, ``float8``, ``boolean``,\n        ``date``, ``timestamp``, ``timestamptz``, ``json``, ``jsonb``, ``markdown``,\n        ``ermrest_uri``, ``ermrest_rid``, ``ermrest_rcb``, ``ermrest_rmb``,\n        ``ermrest_rct``, ``ermrest_rmt``\n\n        Args:\n            table: A TableDefinition object containing the complete specification of the table to create.\n            update_navbar: If True (default), automatically updates the navigation bar to include\n                the new table. Set to False during batch table creation to avoid redundant updates,\n                then call apply_catalog_annotations() once at the end.\n\n        Returns:\n            Table: The newly created ERMRest table object.\n\n        Raises:\n            DerivaMLException: If table creation fails or the definition is invalid.\n\n        Examples:\n            **Simple table with basic columns**:\n\n                &gt;&gt;&gt; from deriva_ml import TableDefinition, ColumnDefinition, BuiltinTypes\n                &gt;&gt;&gt;\n                &gt;&gt;&gt; table_def = TableDefinition(\n                ...     name=\"Experiment\",\n                ...     column_defs=[\n                ...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n                ...         ColumnDefinition(name=\"Date\", type=BuiltinTypes.date),\n                ...         ColumnDefinition(name=\"Description\", type=BuiltinTypes.markdown),\n                ...         ColumnDefinition(name=\"Score\", type=BuiltinTypes.float4),\n                ...     ],\n                ...     comment=\"Records of experimental runs\"\n                ... )\n                &gt;&gt;&gt; experiment_table = ml.create_table(table_def)\n\n            **Table with foreign key to another table**:\n\n                &gt;&gt;&gt; from deriva_ml import (\n                ...     TableDefinition, ColumnDefinition, ForeignKeyDefinition, BuiltinTypes\n                ... )\n                &gt;&gt;&gt;\n                &gt;&gt;&gt; # Create a Sample table that references Subject\n                &gt;&gt;&gt; sample_def = TableDefinition(\n                ...     name=\"Sample\",\n                ...     column_defs=[\n                ...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n                ...         ColumnDefinition(name=\"Subject\", type=BuiltinTypes.text, nullok=False),\n                ...         ColumnDefinition(name=\"Collection_Date\", type=BuiltinTypes.date),\n                ...     ],\n                ...     fkey_defs=[\n                ...         ForeignKeyDefinition(\n                ...             colnames=[\"Subject\"],\n                ...             pk_sname=ml.default_schema,  # Schema of referenced table\n                ...             pk_tname=\"Subject\",          # Name of referenced table\n                ...             pk_colnames=[\"RID\"],         # Column(s) in referenced table\n                ...             on_delete=\"CASCADE\",         # Delete samples when subject deleted\n                ...         )\n                ...     ],\n                ...     comment=\"Biological samples collected from subjects\"\n                ... )\n                &gt;&gt;&gt; sample_table = ml.create_table(sample_def)\n\n            **Table with unique key constraint**:\n\n                &gt;&gt;&gt; from deriva_ml import (\n                ...     TableDefinition, ColumnDefinition, KeyDefinition, BuiltinTypes\n                ... )\n                &gt;&gt;&gt;\n                &gt;&gt;&gt; protocol_def = TableDefinition(\n                ...     name=\"Protocol\",\n                ...     column_defs=[\n                ...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n                ...         ColumnDefinition(name=\"Version\", type=BuiltinTypes.text, nullok=False),\n                ...         ColumnDefinition(name=\"Description\", type=BuiltinTypes.markdown),\n                ...     ],\n                ...     key_defs=[\n                ...         KeyDefinition(\n                ...             colnames=[\"Name\", \"Version\"],\n                ...             constraint_names=[[\"myschema\", \"Protocol_Name_Version_key\"]],\n                ...             comment=\"Each protocol name+version must be unique\"\n                ...         )\n                ...     ],\n                ...     comment=\"Experimental protocols with versioning\"\n                ... )\n                &gt;&gt;&gt; protocol_table = ml.create_table(protocol_def)\n\n            **Batch creation without navbar updates**:\n\n                &gt;&gt;&gt; ml.create_table(table1_def, update_navbar=False)\n                &gt;&gt;&gt; ml.create_table(table2_def, update_navbar=False)\n                &gt;&gt;&gt; ml.create_table(table3_def, update_navbar=False)\n                &gt;&gt;&gt; ml.apply_catalog_annotations()  # Update navbar once at the end\n        \"\"\"\n        # Use default schema if none specified\n        schema = schema or self.model._require_default_schema()\n\n        # Create table in domain schema using provided definition\n        # Handle both TableDefinition (dataclass with to_dict) and plain dicts\n        table_dict = table.to_dict() if hasattr(table, 'to_dict') else table\n        new_table = self.model.schemas[schema].create_table(table_dict)\n\n        # Update navbar to include the new table\n        if update_navbar:\n            self.apply_catalog_annotations()\n\n        return new_table\n\n    # =========================================================================\n    # Cache and Directory Management\n    # =========================================================================\n\n    def clear_cache(self, older_than_days: int | None = None) -&gt; dict[str, int]:\n        \"\"\"Clear the dataset cache directory.\n\n        Removes cached dataset bags from the cache directory. Can optionally filter\n        by age to only remove old cache entries.\n\n        Args:\n            older_than_days: If provided, only remove cache entries older than this\n                many days. If None, removes all cache entries.\n\n        Returns:\n            dict with keys:\n                - 'files_removed': Number of files removed\n                - 'dirs_removed': Number of directories removed\n                - 'bytes_freed': Total bytes freed\n                - 'errors': Number of removal errors\n\n        Example:\n            &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n            &gt;&gt;&gt; # Clear all cache\n            &gt;&gt;&gt; result = ml.clear_cache()\n            &gt;&gt;&gt; print(f\"Freed {result['bytes_freed'] / 1e6:.1f} MB\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Clear cache older than 7 days\n            &gt;&gt;&gt; result = ml.clear_cache(older_than_days=7)\n        \"\"\"\n        import shutil\n        import time\n\n        stats = {'files_removed': 0, 'dirs_removed': 0, 'bytes_freed': 0, 'errors': 0}\n\n        if not self.cache_dir.exists():\n            return stats\n\n        cutoff_time = None\n        if older_than_days is not None:\n            cutoff_time = time.time() - (older_than_days * 24 * 60 * 60)\n\n        try:\n            for entry in self.cache_dir.iterdir():\n                try:\n                    # Check age if filtering\n                    if cutoff_time is not None:\n                        entry_mtime = entry.stat().st_mtime\n                        if entry_mtime &gt; cutoff_time:\n                            continue  # Skip recent entries\n\n                    # Calculate size before removal\n                    if entry.is_dir():\n                        entry_size = sum(f.stat().st_size for f in entry.rglob('*') if f.is_file())\n                        shutil.rmtree(entry)\n                        stats['dirs_removed'] += 1\n                    else:\n                        entry_size = entry.stat().st_size\n                        entry.unlink()\n                        stats['files_removed'] += 1\n\n                    stats['bytes_freed'] += entry_size\n                except (OSError, PermissionError) as e:\n                    self._logger.warning(f\"Failed to remove cache entry {entry}: {e}\")\n                    stats['errors'] += 1\n\n        except OSError as e:\n            self._logger.error(f\"Failed to iterate cache directory: {e}\")\n            stats['errors'] += 1\n\n        return stats\n\n    def get_cache_size(self) -&gt; dict[str, int | float]:\n        \"\"\"Get the current size of the cache directory.\n\n        Returns:\n            dict with keys:\n                - 'total_bytes': Total size in bytes\n                - 'total_mb': Total size in megabytes\n                - 'file_count': Number of files\n                - 'dir_count': Number of directories\n\n        Example:\n            &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n            &gt;&gt;&gt; size = ml.get_cache_size()\n            &gt;&gt;&gt; print(f\"Cache size: {size['total_mb']:.1f} MB ({size['file_count']} files)\")\n        \"\"\"\n        stats = {'total_bytes': 0, 'total_mb': 0.0, 'file_count': 0, 'dir_count': 0}\n\n        if not self.cache_dir.exists():\n            return stats\n\n        for entry in self.cache_dir.rglob('*'):\n            if entry.is_file():\n                stats['total_bytes'] += entry.stat().st_size\n                stats['file_count'] += 1\n            elif entry.is_dir():\n                stats['dir_count'] += 1\n\n        stats['total_mb'] = stats['total_bytes'] / (1024 * 1024)\n        return stats\n\n    def list_execution_dirs(self) -&gt; list[dict[str, any]]:\n        \"\"\"List execution working directories.\n\n        Returns information about each execution directory in the working directory,\n        useful for identifying orphaned or incomplete execution outputs.\n\n        Returns:\n            List of dicts, each containing:\n                - 'execution_rid': The execution RID (directory name)\n                - 'path': Full path to the directory\n                - 'size_bytes': Total size in bytes\n                - 'size_mb': Total size in megabytes\n                - 'modified': Last modification time (datetime)\n                - 'file_count': Number of files\n\n        Example:\n            &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n            &gt;&gt;&gt; dirs = ml.list_execution_dirs()\n            &gt;&gt;&gt; for d in dirs:\n            ...     print(f\"{d['execution_rid']}: {d['size_mb']:.1f} MB\")\n        \"\"\"\n        from datetime import datetime\n\n        from deriva_ml.dataset.upload import upload_root\n\n        results = []\n        exec_root = upload_root(self.working_dir) / \"execution\"\n\n        if not exec_root.exists():\n            return results\n\n        for entry in exec_root.iterdir():\n            if entry.is_dir():\n                size_bytes = sum(f.stat().st_size for f in entry.rglob('*') if f.is_file())\n                file_count = sum(1 for f in entry.rglob('*') if f.is_file())\n                mtime = datetime.fromtimestamp(entry.stat().st_mtime)\n\n                results.append({\n                    'execution_rid': entry.name,\n                    'path': str(entry),\n                    'size_bytes': size_bytes,\n                    'size_mb': size_bytes / (1024 * 1024),\n                    'modified': mtime,\n                    'file_count': file_count,\n                })\n\n        return sorted(results, key=lambda x: x['modified'], reverse=True)\n\n    def clean_execution_dirs(\n        self,\n        older_than_days: int | None = None,\n        exclude_rids: list[str] | None = None,\n    ) -&gt; dict[str, int]:\n        \"\"\"Clean up execution working directories.\n\n        Removes execution output directories from the local working directory.\n        Use this to free up disk space from completed or orphaned executions.\n\n        Args:\n            older_than_days: If provided, only remove directories older than this\n                many days. If None, removes all execution directories (except excluded).\n            exclude_rids: List of execution RIDs to preserve (never remove).\n\n        Returns:\n            dict with keys:\n                - 'dirs_removed': Number of directories removed\n                - 'bytes_freed': Total bytes freed\n                - 'errors': Number of removal errors\n\n        Example:\n            &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n            &gt;&gt;&gt; # Clean all execution dirs older than 30 days\n            &gt;&gt;&gt; result = ml.clean_execution_dirs(older_than_days=30)\n            &gt;&gt;&gt; print(f\"Freed {result['bytes_freed'] / 1e9:.2f} GB\")\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Clean all except specific executions\n            &gt;&gt;&gt; result = ml.clean_execution_dirs(exclude_rids=['1-ABC', '1-DEF'])\n        \"\"\"\n        import shutil\n        import time\n\n        from deriva_ml.dataset.upload import upload_root\n\n        stats = {'dirs_removed': 0, 'bytes_freed': 0, 'errors': 0}\n        exclude_rids = set(exclude_rids or [])\n\n        exec_root = upload_root(self.working_dir) / \"execution\"\n        if not exec_root.exists():\n            return stats\n\n        cutoff_time = None\n        if older_than_days is not None:\n            cutoff_time = time.time() - (older_than_days * 24 * 60 * 60)\n\n        for entry in exec_root.iterdir():\n            if not entry.is_dir():\n                continue\n\n            # Skip excluded RIDs\n            if entry.name in exclude_rids:\n                continue\n\n            try:\n                # Check age if filtering\n                if cutoff_time is not None:\n                    entry_mtime = entry.stat().st_mtime\n                    if entry_mtime &gt; cutoff_time:\n                        continue\n\n                # Calculate size before removal\n                entry_size = sum(f.stat().st_size for f in entry.rglob('*') if f.is_file())\n                shutil.rmtree(entry)\n                stats['dirs_removed'] += 1\n                stats['bytes_freed'] += entry_size\n\n            except (OSError, PermissionError) as e:\n                self._logger.warning(f\"Failed to remove execution dir {entry}: {e}\")\n                stats['errors'] += 1\n\n        return stats\n\n    def get_storage_summary(self) -&gt; dict[str, any]:\n        \"\"\"Get a summary of local storage usage.\n\n        Returns:\n            dict with keys:\n                - 'working_dir': Path to working directory\n                - 'cache_dir': Path to cache directory\n                - 'cache_size_mb': Cache size in MB\n                - 'cache_file_count': Number of files in cache\n                - 'execution_dir_count': Number of execution directories\n                - 'execution_size_mb': Total size of execution directories in MB\n                - 'total_size_mb': Combined size in MB\n\n        Example:\n            &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n            &gt;&gt;&gt; summary = ml.get_storage_summary()\n            &gt;&gt;&gt; print(f\"Total storage: {summary['total_size_mb']:.1f} MB\")\n            &gt;&gt;&gt; print(f\"  Cache: {summary['cache_size_mb']:.1f} MB\")\n            &gt;&gt;&gt; print(f\"  Executions: {summary['execution_size_mb']:.1f} MB\")\n        \"\"\"\n        cache_stats = self.get_cache_size()\n        exec_dirs = self.list_execution_dirs()\n\n        exec_size_mb = sum(d['size_mb'] for d in exec_dirs)\n\n        return {\n            'working_dir': str(self.working_dir),\n            'cache_dir': str(self.cache_dir),\n            'cache_size_mb': cache_stats['total_mb'],\n            'cache_file_count': cache_stats['file_count'],\n            'execution_dir_count': len(exec_dirs),\n            'execution_size_mb': exec_size_mb,\n            'total_size_mb': cache_stats['total_mb'] + exec_size_mb,\n        }\n\n    # =========================================================================\n    # Schema Validation\n    # =========================================================================\n\n    def validate_schema(self, strict: bool = False) -&gt; \"SchemaValidationReport\":\n        \"\"\"Validate that the catalog's ML schema matches the expected structure.\n\n        This method inspects the catalog schema and verifies that it contains all\n        the required tables, columns, vocabulary terms, and relationships that are\n        created by the ML schema initialization routines in create_schema.py.\n\n        The validation checks:\n        - All required ML tables exist (Dataset, Execution, Workflow, etc.)\n        - All required columns exist with correct types\n        - All required vocabulary tables exist (Asset_Type, Dataset_Type, etc.)\n        - All required vocabulary terms are initialized\n        - All association tables exist for relationships\n\n        In strict mode, the validator also reports errors for:\n        - Extra tables not in the expected schema\n        - Extra columns not in the expected table definitions\n\n        Args:\n            strict: If True, extra tables and columns are reported as errors.\n                   If False (default), they are reported as informational items.\n                   Use strict=True to verify a clean ML catalog matches exactly.\n                   Use strict=False to validate a catalog that may have domain extensions.\n\n        Returns:\n            SchemaValidationReport with validation results. Key attributes:\n                - is_valid: True if no errors were found\n                - errors: List of error-level issues\n                - warnings: List of warning-level issues\n                - info: List of informational items\n                - to_text(): Human-readable report\n                - to_dict(): JSON-serializable dictionary\n\n        Example:\n            &gt;&gt;&gt; ml = DerivaML('localhost', 'my_catalog')\n            &gt;&gt;&gt; report = ml.validate_schema(strict=False)\n            &gt;&gt;&gt; if report.is_valid:\n            ...     print(\"Schema is valid!\")\n            ... else:\n            ...     print(report.to_text())\n\n            &gt;&gt;&gt; # Strict validation for a fresh ML catalog\n            &gt;&gt;&gt; report = ml.validate_schema(strict=True)\n            &gt;&gt;&gt; print(f\"Found {len(report.errors)} errors, {len(report.warnings)} warnings\")\n\n            &gt;&gt;&gt; # Get report as dictionary for JSON/logging\n            &gt;&gt;&gt; import json\n            &gt;&gt;&gt; print(json.dumps(report.to_dict(), indent=2))\n\n        Note:\n            This method validates the ML schema (typically 'deriva-ml'), not the\n            domain schema. Domain-specific tables and columns are not checked\n            unless they are part of the ML schema itself.\n\n        See Also:\n            - deriva_ml.schema.validation.SchemaValidationReport\n            - deriva_ml.schema.validation.validate_ml_schema\n        \"\"\"\n        from deriva_ml.schema.validation import validate_ml_schema\n        return validate_ml_schema(self, strict=strict)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.catalog_provenance","title":"catalog_provenance  <code>property</code>","text":"<pre><code>catalog_provenance: (\n    \"CatalogProvenance | None\"\n)\n</code></pre> <p>Get the provenance information for this catalog.</p> <p>Returns provenance information if the catalog has it set. This includes information about how the catalog was created (clone, create, schema), who created it, when, and any workflow information.</p> <p>For cloned catalogs, additional details about the clone operation are available in the <code>clone_details</code> attribute.</p> <p>Returns:</p> Type Description <code>'CatalogProvenance | None'</code> <p>CatalogProvenance if available, None otherwise.</p> Example <p>ml = DerivaML('localhost', '45') prov = ml.catalog_provenance if prov: ...     print(f\"Created: {prov.created_at} by {prov.created_by}\") ...     print(f\"Method: {prov.creation_method.value}\") ...     if prov.is_clone: ...         print(f\"Cloned from: {prov.clone_details.source_hostname}\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.__del__","title":"__del__","text":"<pre><code>__del__() -&gt; None\n</code></pre> <p>Cleanup method to handle incomplete executions.</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def __del__(self) -&gt; None:\n    \"\"\"Cleanup method to handle incomplete executions.\"\"\"\n    try:\n        # Mark execution as aborted if not completed\n        if self._execution and self._execution.status != Status.completed:\n            self._execution.update_status(Status.aborted, \"Execution Aborted\")\n    except (AttributeError, requests.HTTPError):\n        pass\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.__init__","title":"__init__","text":"<pre><code>__init__(\n    hostname: str,\n    catalog_id: str | int,\n    domain_schemas: str\n    | set[str]\n    | None = None,\n    default_schema: str | None = None,\n    project_name: str | None = None,\n    cache_dir: str | Path | None = None,\n    working_dir: str\n    | Path\n    | None = None,\n    hydra_runtime_output_dir: str\n    | Path\n    | None = None,\n    ml_schema: str = ML_SCHEMA,\n    logging_level: int = logging.WARNING,\n    deriva_logging_level: int = logging.WARNING,\n    credential: dict | None = None,\n    s3_bucket: str | None = None,\n    use_minid: bool | None = None,\n    check_auth: bool = True,\n    clean_execution_dir: bool = True,\n) -&gt; None\n</code></pre> <p>Initializes a DerivaML instance.</p> <p>This method will connect to a catalog and initialize local configuration for the ML execution. This class is intended to be used as a base class on which domain-specific interfaces are built.</p> <p>Parameters:</p> Name Type Description Default <code>hostname</code> <code>str</code> <p>Hostname of the Deriva server.</p> required <code>catalog_id</code> <code>str | int</code> <p>Catalog ID. Either an identifier or a catalog name.</p> required <code>domain_schemas</code> <code>str | set[str] | None</code> <p>Optional set of domain schema names. If None, auto-detects all non-system schemas. Use this when working with catalogs that have multiple user-defined schemas.</p> <code>None</code> <code>default_schema</code> <code>str | None</code> <p>The default schema for table creation operations. If None and there is exactly one domain schema, that schema is used. If there are multiple domain schemas, this must be specified for table creation to work without explicit schema parameters.</p> <code>None</code> <code>ml_schema</code> <code>str</code> <p>Schema name for ML schema. Used if you have a non-standard configuration of deriva-ml.</p> <code>ML_SCHEMA</code> <code>project_name</code> <code>str | None</code> <p>Project name. Defaults to name of default_schema.</p> <code>None</code> <code>cache_dir</code> <code>str | Path | None</code> <p>Directory path for caching data downloaded from the Deriva server as bdbag. If not provided, will default to working_dir.</p> <code>None</code> <code>working_dir</code> <code>str | Path | None</code> <p>Directory path for storing data used by or generated by any computations. If no value is provided, will default to  ${HOME}/deriva_ml</p> <code>None</code> <code>s3_bucket</code> <code>str | None</code> <p>S3 bucket URL for dataset bag storage (e.g., 's3://my-bucket'). If provided, enables MINID creation and S3 upload for dataset exports. If None, MINID functionality is disabled regardless of use_minid setting.</p> <code>None</code> <code>use_minid</code> <code>bool | None</code> <p>Use the MINID service when downloading dataset bags. Only effective when s3_bucket is configured. If None (default), automatically set to True when s3_bucket is provided, False otherwise.</p> <code>None</code> <code>check_auth</code> <code>bool</code> <p>Check if the user has access to the catalog.</p> <code>True</code> <code>clean_execution_dir</code> <code>bool</code> <p>Whether to automatically clean up execution working directories after successful upload. Defaults to True. Set to False to retain local copies.</p> <code>True</code> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def __init__(\n    self,\n    hostname: str,\n    catalog_id: str | int,\n    domain_schemas: str | set[str] | None = None,\n    default_schema: str | None = None,\n    project_name: str | None = None,\n    cache_dir: str | Path | None = None,\n    working_dir: str | Path | None = None,\n    hydra_runtime_output_dir: str | Path | None = None,\n    ml_schema: str = ML_SCHEMA,\n    logging_level: int = logging.WARNING,\n    deriva_logging_level: int = logging.WARNING,\n    credential: dict | None = None,\n    s3_bucket: str | None = None,\n    use_minid: bool | None = None,\n    check_auth: bool = True,\n    clean_execution_dir: bool = True,\n) -&gt; None:\n    \"\"\"Initializes a DerivaML instance.\n\n    This method will connect to a catalog and initialize local configuration for the ML execution.\n    This class is intended to be used as a base class on which domain-specific interfaces are built.\n\n    Args:\n        hostname: Hostname of the Deriva server.\n        catalog_id: Catalog ID. Either an identifier or a catalog name.\n        domain_schemas: Optional set of domain schema names. If None, auto-detects all\n            non-system schemas. Use this when working with catalogs that have multiple\n            user-defined schemas.\n        default_schema: The default schema for table creation operations. If None and\n            there is exactly one domain schema, that schema is used. If there are multiple\n            domain schemas, this must be specified for table creation to work without\n            explicit schema parameters.\n        ml_schema: Schema name for ML schema. Used if you have a non-standard configuration of deriva-ml.\n        project_name: Project name. Defaults to name of default_schema.\n        cache_dir: Directory path for caching data downloaded from the Deriva server as bdbag. If not provided,\n            will default to working_dir.\n        working_dir: Directory path for storing data used by or generated by any computations. If no value is\n            provided, will default to  ${HOME}/deriva_ml\n        s3_bucket: S3 bucket URL for dataset bag storage (e.g., 's3://my-bucket'). If provided,\n            enables MINID creation and S3 upload for dataset exports. If None, MINID functionality\n            is disabled regardless of use_minid setting.\n        use_minid: Use the MINID service when downloading dataset bags. Only effective when\n            s3_bucket is configured. If None (default), automatically set to True when s3_bucket\n            is provided, False otherwise.\n        check_auth: Check if the user has access to the catalog.\n        clean_execution_dir: Whether to automatically clean up execution working directories\n            after successful upload. Defaults to True. Set to False to retain local copies.\n    \"\"\"\n    # Get or use provided credentials for server access\n    self.credential = credential or get_credential(hostname)\n\n    # Initialize server connection and catalog access\n    server = DerivaServer(\n        \"https\",\n        hostname,\n        credentials=self.credential,\n        session_config=self._get_session_config(),\n    )\n    try:\n        if check_auth and server.get_authn_session():\n            pass\n    except Exception:\n        raise DerivaMLException(\n            \"You are not authorized to access this catalog. \"\n            \"Please check your credentials and make sure you have logged in.\"\n        )\n    self.catalog = server.connect_ermrest(catalog_id)\n    # Import here to avoid circular imports\n    from deriva_ml.model.catalog import DerivaModel\n    self.model = DerivaModel(\n        self.catalog.getCatalogModel(),\n        ml_schema=ml_schema,\n        domain_schemas=domain_schemas,\n        default_schema=default_schema,\n    )\n\n    # Store S3 bucket configuration and resolve use_minid\n    self.s3_bucket = s3_bucket\n    if use_minid is None:\n        # Auto mode: enable MINID if s3_bucket is configured\n        self.use_minid = s3_bucket is not None\n    elif use_minid and s3_bucket is None:\n        # User requested MINID but no S3 bucket configured - disable MINID\n        self.use_minid = False\n    else:\n        self.use_minid = use_minid\n\n    # Set up working and cache directories\n    # If working_dir is already provided (e.g. from DerivaMLConfig.instantiate()),\n    # use it directly; otherwise compute the default path.\n    if working_dir is not None:\n        self.working_dir = Path(working_dir).absolute()\n    else:\n        self.working_dir = DerivaMLConfig.compute_workdir(None, catalog_id, hostname)\n    self.working_dir.mkdir(parents=True, exist_ok=True)\n    self.hydra_runtime_output_dir = hydra_runtime_output_dir\n\n    self.cache_dir = Path(cache_dir) if cache_dir else self.working_dir / \"cache\"\n    self.cache_dir.mkdir(parents=True, exist_ok=True)\n\n    # Set up logging using centralized configuration\n    # This configures deriva_ml, Hydra, and deriva-py loggers without\n    # affecting the root logger or calling basicConfig()\n    self._logger = configure_logging(\n        level=logging_level,\n        deriva_level=deriva_logging_level,\n    )\n    self._logging_level = logging_level\n    self._deriva_logging_level = deriva_logging_level\n\n    # Apply deriva's default logger overrides for fine-grained control\n    apply_logger_overrides(DEFAULT_LOGGER_OVERRIDES)\n\n    # Store instance configuration\n    self.host_name = hostname\n    self.catalog_id = catalog_id\n    self.ml_schema = ml_schema\n    self.configuration = None\n    self._execution: Execution | None = None\n    self.domain_schemas = self.model.domain_schemas\n    self.default_schema = self.model.default_schema\n    self.project_name = project_name or self.default_schema or \"deriva-ml\"\n    self.start_time = datetime.now()\n    self.status = Status.pending.value\n    self.clean_execution_dir = clean_execution_dir\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.add_dataset_element_type","title":"add_dataset_element_type","text":"<pre><code>add_dataset_element_type(\n    element: str | Table,\n) -&gt; Table\n</code></pre> <p>Makes it possible to add objects from the specified table to a dataset.</p> <p>A dataset is a heterogeneous collection of objects, each of which comes from a different table. This routine adds the specified table as a valid element type for datasets.</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>str | Table</code> <p>Name of the table or table object that is to be added to the dataset.</p> required <p>Returns:</p> Type Description <code>Table</code> <p>The table object that was added to the dataset.</p> Source code in <code>src/deriva_ml/core/mixins/dataset.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef add_dataset_element_type(self, element: str | Table) -&gt; Table:\n    \"\"\"Makes it possible to add objects from the specified table to a dataset.\n\n    A dataset is a heterogeneous collection of objects, each of which comes from a different table.\n    This routine adds the specified table as a valid element type for datasets.\n\n    Args:\n        element: Name of the table or table object that is to be added to the dataset.\n\n    Returns:\n        The table object that was added to the dataset.\n    \"\"\"\n    # Import here to avoid circular imports\n    from deriva_ml.dataset.catalog_graph import CatalogGraph\n\n    # Add table to map\n    element_table = self.model.name_to_table(element)\n    atable_def = Table.define_association([self._dataset_table, element_table])\n    try:\n        table = self.model.create_table(atable_def)\n    except ValueError as e:\n        if \"already exists\" in str(e):\n            table = self.model.name_to_table(atable_def[\"table_name\"])\n        else:\n            raise e\n\n    # self.model = self.catalog.getCatalogModel()\n    annotations = CatalogGraph(self, s3_bucket=self.s3_bucket, use_minid=self.use_minid).generate_dataset_download_annotations()  # type: ignore[arg-type]\n    self._dataset_table.annotations.update(annotations)\n    self.model.model.apply()\n    return table\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.add_files","title":"add_files","text":"<pre><code>add_files(\n    files: Iterable[FileSpec],\n    execution_rid: RID,\n    dataset_types: str\n    | list[str]\n    | None = None,\n    description: str = \"\",\n) -&gt; \"Dataset\"\n</code></pre> <p>Adds files to the catalog with their metadata.</p> <p>Registers files in the catalog along with their metadata (MD5, length, URL) and associates them with specified file types. Links files to the specified execution record for provenance tracking.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>Iterable[FileSpec]</code> <p>File specifications containing MD5 checksum, length, and URL.</p> required <code>execution_rid</code> <code>RID</code> <p>Execution RID to associate files with (required for provenance).</p> required <code>dataset_types</code> <code>str | list[str] | None</code> <p>One or more dataset type terms from File_Type vocabulary.</p> <code>None</code> <code>description</code> <code>str</code> <p>Description of the files.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>'Dataset'</code> <p>Dataset that represents the newly added files.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If file_types are invalid or execution_rid is not an execution record.</p> <p>Examples:</p> <p>Add files via an execution:     &gt;&gt;&gt; with ml.create_execution(config) as exe:     ...     files = [FileSpec(url=\"path/to/file.txt\", md5=\"abc123\", length=1000)]     ...     dataset = exe.add_files(files, dataset_types=\"text\")</p> Source code in <code>src/deriva_ml/core/mixins/file.py</code> <pre><code>def add_files(\n    self,\n    files: Iterable[FileSpec],\n    execution_rid: RID,\n    dataset_types: str | list[str] | None = None,\n    description: str = \"\",\n) -&gt; \"Dataset\":\n    \"\"\"Adds files to the catalog with their metadata.\n\n    Registers files in the catalog along with their metadata (MD5, length, URL) and associates them with\n    specified file types. Links files to the specified execution record for provenance tracking.\n\n    Args:\n        files: File specifications containing MD5 checksum, length, and URL.\n        execution_rid: Execution RID to associate files with (required for provenance).\n        dataset_types: One or more dataset type terms from File_Type vocabulary.\n        description: Description of the files.\n\n    Returns:\n        Dataset: Dataset that represents the newly added files.\n\n    Raises:\n        DerivaMLException: If file_types are invalid or execution_rid is not an execution record.\n\n    Examples:\n        Add files via an execution:\n            &gt;&gt;&gt; with ml.create_execution(config) as exe:\n            ...     files = [FileSpec(url=\"path/to/file.txt\", md5=\"abc123\", length=1000)]\n            ...     dataset = exe.add_files(files, dataset_types=\"text\")\n    \"\"\"\n    # Import here to avoid circular imports\n    from deriva_ml.dataset.dataset import Dataset\n\n    if self.resolve_rid(execution_rid).table.name != \"Execution\":\n        raise DerivaMLTableTypeError(\"Execution\", execution_rid)\n\n    filespec_list = list(files)\n\n    # Get a list of all defined file types and their synonyms.\n    defined_types = set(\n        chain.from_iterable([[t.name] + list(t.synonyms or []) for t in self.list_vocabulary_terms(MLVocab.asset_type)])\n    )\n\n    # Get a list of all of the file types used in the filespec_list\n    spec_types = set(chain.from_iterable(filespec.file_types for filespec in filespec_list))\n\n    # Now make sure that all of the file types and dataset_types in the spec list are defined.\n    if spec_types - defined_types:\n        raise DerivaMLInvalidTerm(MLVocab.asset_type.name, f\"{spec_types - defined_types}\")\n\n    # Normalize dataset_types, make sure File type is included.\n    if isinstance(dataset_types, list):\n        dataset_types = [\"File\"] + dataset_types if \"File\" not in dataset_types else dataset_types\n    else:\n        dataset_types = [\"File\", dataset_types] if dataset_types else [\"File\"]\n    for ds_type in dataset_types:\n        self.lookup_term(MLVocab.dataset_type, ds_type)\n\n    # Add files to the file table, and collect up the resulting entries by directory name.\n    pb = self.pathBuilder()\n    file_records = list(\n        pb.schemas[self.ml_schema].tables[\"File\"].insert([f.model_dump(by_alias=True) for f in filespec_list])\n    )\n\n    # Get the name of the association table between file_table and file_type and add file_type records\n    atable = self.model.find_association(MLTable.file, MLVocab.asset_type)[0].name\n    # Need to get a link between file record and file_types.\n    type_map = {\n        file_spec.md5: file_spec.file_types + ([] if \"File\" in file_spec.file_types else [])\n        for file_spec in filespec_list\n    }\n    file_type_records = [\n        {MLVocab.asset_type.value: file_type, \"File\": file_record[\"RID\"]}\n        for file_record in file_records\n        for file_type in type_map[file_record[\"MD5\"]]\n    ]\n    pb.schemas[self.ml_schema].tables[atable].insert(file_type_records)\n\n    # Link files to the execution for provenance tracking.\n    pb.schemas[self.ml_schema].File_Execution.insert(\n        [\n            {\"File\": file_record[\"RID\"], \"Execution\": execution_rid, \"Asset_Role\": \"Output\"}\n            for file_record in file_records\n        ]\n    )\n\n    # Now create datasets to capture the original directory structure of the files.\n    dir_rid_map = defaultdict(list)\n    for e in file_records:\n        dir_rid_map[Path(urlsplit(e[\"URL\"]).path).parent].append(e[\"RID\"])\n\n    nested_datasets = []\n    path_length = 0\n    dataset = None\n    # Start with the longest path so we get subdirectories first.\n    for p, rids in sorted(dir_rid_map.items(), key=lambda kv: len(kv[0].parts), reverse=True):\n        dataset = Dataset.create_dataset(\n            self,  # type: ignore[arg-type]\n            dataset_types=dataset_types,\n            execution_rid=execution_rid,\n            description=description,\n        )\n        members = rids\n        if len(p.parts) &lt; path_length:\n            # Going up one level in directory, so Create nested dataset\n            members = [m.dataset_rid for m in nested_datasets] + rids\n            nested_datasets = []\n        dataset.add_dataset_members(members=members, execution_rid=execution_rid)\n        nested_datasets.append(dataset)\n        path_length = len(p.parts)\n\n    return dataset\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.add_page","title":"add_page","text":"<pre><code>add_page(\n    title: str, content: str\n) -&gt; None\n</code></pre> <p>Adds page to web interface.</p> <p>Creates a new page in the catalog's web interface with the specified title and content. The page will be accessible through the catalog's navigation system.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>The title of the page to be displayed in navigation and headers.</p> required <code>content</code> <code>str</code> <p>The main content of the page can include HTML markup.</p> required <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the page creation fails or the user lacks necessary permissions.</p> Example <p>ml.add_page( ...     title=\"Analysis Results\", ...     content=\"Results<p>Analysis completed successfully...</p>\" ... )</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def add_page(self, title: str, content: str) -&gt; None:\n    \"\"\"Adds page to web interface.\n\n    Creates a new page in the catalog's web interface with the specified title and content. The page will be\n    accessible through the catalog's navigation system.\n\n    Args:\n        title: The title of the page to be displayed in navigation and headers.\n        content: The main content of the page can include HTML markup.\n\n    Raises:\n        DerivaMLException: If the page creation fails or the user lacks necessary permissions.\n\n    Example:\n        &gt;&gt;&gt; ml.add_page(\n        ...     title=\"Analysis Results\",\n        ...     content=\"&lt;h1&gt;Results&lt;/h1&gt;&lt;p&gt;Analysis completed successfully...&lt;/p&gt;\"\n        ... )\n    \"\"\"\n    # Insert page into www tables with title and content\n    # Use default schema or first domain schema for www tables\n    schema = self.default_schema or (sorted(self.domain_schemas)[0] if self.domain_schemas else None)\n    if schema is None:\n        raise DerivaMLException(\"No domain schema available for adding pages\")\n    self.pathBuilder().www.tables[schema].insert([{\"Title\": title, \"Content\": content}])\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.add_term","title":"add_term","text":"<pre><code>add_term(\n    table: str | Table,\n    term_name: str,\n    description: str,\n    synonyms: list[str] | None = None,\n    exists_ok: bool = True,\n) -&gt; VocabularyTermHandle\n</code></pre> <p>Adds a term to a vocabulary table.</p> <p>Creates a new standardized term with description and optional synonyms in a vocabulary table. Can either create a new term or return an existing one if it already exists.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Vocabulary table to add term to (name or Table object).</p> required <code>term_name</code> <code>str</code> <p>Primary name of the term (must be unique within vocabulary).</p> required <code>description</code> <code>str</code> <p>Explanation of term's meaning and usage.</p> required <code>synonyms</code> <code>list[str] | None</code> <p>Alternative names for the term.</p> <code>None</code> <code>exists_ok</code> <code>bool</code> <p>If True, return the existing term if found. If False, raise error.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>VocabularyTermHandle</code> <code>VocabularyTermHandle</code> <p>Object representing the created or existing term, with methods to modify it in the catalog.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If a term exists and exists_ok=False, or if the table is not a vocabulary table.</p> <p>Examples:</p> <p>Add a new tissue type:     &gt;&gt;&gt; term = ml.add_term(     ...     table=\"tissue_types\",     ...     term_name=\"epithelial\",     ...     description=\"Epithelial tissue type\",     ...     synonyms=[\"epithelium\"]     ... )     &gt;&gt;&gt; # Modify the term     &gt;&gt;&gt; term.description = \"Updated description\"     &gt;&gt;&gt; term.synonyms = (\"epithelium\", \"epithelial_tissue\")</p> <p>Attempt to add an existing term:     &gt;&gt;&gt; term = ml.add_term(\"tissue_types\", \"epithelial\", \"...\", exists_ok=True)</p> Source code in <code>src/deriva_ml/core/mixins/vocabulary.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef add_term(\n    self,\n    table: str | Table,\n    term_name: str,\n    description: str,\n    synonyms: list[str] | None = None,\n    exists_ok: bool = True,\n) -&gt; VocabularyTermHandle:\n    \"\"\"Adds a term to a vocabulary table.\n\n    Creates a new standardized term with description and optional synonyms in a vocabulary table.\n    Can either create a new term or return an existing one if it already exists.\n\n    Args:\n        table: Vocabulary table to add term to (name or Table object).\n        term_name: Primary name of the term (must be unique within vocabulary).\n        description: Explanation of term's meaning and usage.\n        synonyms: Alternative names for the term.\n        exists_ok: If True, return the existing term if found. If False, raise error.\n\n    Returns:\n        VocabularyTermHandle: Object representing the created or existing term, with\n            methods to modify it in the catalog.\n\n    Raises:\n        DerivaMLException: If a term exists and exists_ok=False, or if the table is not a vocabulary table.\n\n    Examples:\n        Add a new tissue type:\n            &gt;&gt;&gt; term = ml.add_term(\n            ...     table=\"tissue_types\",\n            ...     term_name=\"epithelial\",\n            ...     description=\"Epithelial tissue type\",\n            ...     synonyms=[\"epithelium\"]\n            ... )\n            &gt;&gt;&gt; # Modify the term\n            &gt;&gt;&gt; term.description = \"Updated description\"\n            &gt;&gt;&gt; term.synonyms = (\"epithelium\", \"epithelial_tissue\")\n\n        Attempt to add an existing term:\n            &gt;&gt;&gt; term = ml.add_term(\"tissue_types\", \"epithelial\", \"...\", exists_ok=True)\n    \"\"\"\n    # Initialize an empty synonyms list if None\n    synonyms = synonyms or []\n\n    # Get table reference and validate if it is a vocabulary table\n    vocab_table = self.model.name_to_table(table)\n    pb = self.pathBuilder()\n    if not (self.model.is_vocabulary(vocab_table)):\n        raise DerivaMLTableTypeError(\"vocabulary\", vocab_table.name)\n\n    # Get schema and table names for path building\n    schema_name = vocab_table.schema.name\n    table_name = vocab_table.name\n    cols = self.model.vocab_columns(vocab_table)\n\n    try:\n        # Attempt to insert a new term\n        term_data = pb.schemas[schema_name].tables[table_name].insert(\n            [\n                {\n                    cols[\"Name\"]: term_name,\n                    cols[\"Description\"]: description,\n                    cols[\"Synonyms\"]: synonyms,\n                }\n            ],\n            defaults={cols[\"ID\"], cols[\"URI\"]},\n        )[0]\n        term_handle = VocabularyTermHandle(ml=self, table=table_name, **term_data)\n        # Invalidate cache for this vocabulary since we added a new term\n        self.clear_vocabulary_cache(vocab_table)\n        return term_handle\n    except DataPathException as e:\n        # Insert failed \u2014 check if it's because the term already exists\n        # or because of some other database error (permissions, schema, etc.)\n        try:\n            existing_term = self.lookup_term(vocab_table, term_name)\n        except DerivaMLInvalidTerm:\n            # Term doesn't exist \u2014 the insert failed for another reason\n            raise DerivaMLException(\n                f\"Failed to insert term '{term_name}' into {vocab_table.name}: {e}\"\n            ) from e\n        # Term does exist \u2014 either return it or raise depending on exists_ok\n        if not exists_ok:\n            raise DerivaMLInvalidTerm(vocab_table.name, term_name, msg=\"term already exists\")\n        return existing_term\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.add_visible_column","title":"add_visible_column","text":"<pre><code>add_visible_column(\n    table: str | Table,\n    context: str,\n    column: str\n    | list[str]\n    | dict[str, Any],\n    position: int | None = None,\n) -&gt; list[Any]\n</code></pre> <p>Add a column to the visible-columns list for a specific context.</p> <p>Convenience method for adding columns without replacing the entire visible-columns annotation. Changes are staged until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>context</code> <code>str</code> <p>The context to modify (e.g., \"compact\", \"detailed\", \"entry\").</p> required <code>column</code> <code>str | list[str] | dict[str, Any]</code> <p>Column to add. Can be: - String: column name (e.g., \"Filename\") - List: foreign key reference (e.g., [\"schema\", \"fkey_name\"]) - Dict: pseudo-column definition</p> required <code>position</code> <code>int | None</code> <p>Position to insert at (0-indexed). If None, appends to end.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Any]</code> <p>The updated column list for the context.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If context references another context.</p> Example <p>ml.add_visible_column(\"Image\", \"compact\", \"Description\") ml.add_visible_column(\"Image\", \"detailed\", [\"domain\", \"Image_Subject_fkey\"], 1) ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef add_visible_column(\n    self,\n    table: str | Table,\n    context: str,\n    column: str | list[str] | dict[str, Any],\n    position: int | None = None,\n) -&gt; list[Any]:\n    \"\"\"Add a column to the visible-columns list for a specific context.\n\n    Convenience method for adding columns without replacing the entire\n    visible-columns annotation. Changes are staged until apply_annotations()\n    is called.\n\n    Args:\n        table: Table name or Table object.\n        context: The context to modify (e.g., \"compact\", \"detailed\", \"entry\").\n        column: Column to add. Can be:\n            - String: column name (e.g., \"Filename\")\n            - List: foreign key reference (e.g., [\"schema\", \"fkey_name\"])\n            - Dict: pseudo-column definition\n        position: Position to insert at (0-indexed). If None, appends to end.\n\n    Returns:\n        The updated column list for the context.\n\n    Raises:\n        DerivaMLException: If context references another context.\n\n    Example:\n        &gt;&gt;&gt; ml.add_visible_column(\"Image\", \"compact\", \"Description\")\n        &gt;&gt;&gt; ml.add_visible_column(\"Image\", \"detailed\", [\"domain\", \"Image_Subject_fkey\"], 1)\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    # Get or create visible_columns annotation\n    visible_cols = table_obj.annotations.get(VISIBLE_COLUMNS_TAG, {})\n    if visible_cols is None:\n        visible_cols = {}\n\n    # Get or create the context list\n    context_list = visible_cols.get(context, [])\n    if isinstance(context_list, str):\n        raise DerivaMLException(\n            f\"Context '{context}' references another context '{context_list}'. \"\n            \"Set it explicitly first with set_visible_columns().\"\n        )\n\n    # Make a copy to avoid modifying in place\n    context_list = list(context_list)\n\n    # Insert at position or append\n    if position is not None:\n        context_list.insert(position, column)\n    else:\n        context_list.append(column)\n\n    # Update the annotation\n    visible_cols[context] = context_list\n    table_obj.annotations[VISIBLE_COLUMNS_TAG] = visible_cols\n\n    return context_list\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.add_visible_foreign_key","title":"add_visible_foreign_key","text":"<pre><code>add_visible_foreign_key(\n    table: str | Table,\n    context: str,\n    foreign_key: list[str]\n    | dict[str, Any],\n    position: int | None = None,\n) -&gt; list[Any]\n</code></pre> <p>Add a foreign key to the visible-foreign-keys list for a specific context.</p> <p>Convenience method for adding related tables without replacing the entire visible-foreign-keys annotation. Changes are staged until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>context</code> <code>str</code> <p>The context to modify (typically \"detailed\" or \"*\").</p> required <code>foreign_key</code> <code>list[str] | dict[str, Any]</code> <p>Foreign key to add. Can be: - List: inbound foreign key reference (e.g., [\"schema\", \"Other_Table_fkey\"]) - Dict: pseudo-column definition for complex relationships</p> required <code>position</code> <code>int | None</code> <p>Position to insert at (0-indexed). If None, appends to end.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Any]</code> <p>The updated foreign key list for the context.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If context references another context.</p> Example <p>ml.add_visible_foreign_key(\"Subject\", \"detailed\", [\"domain\", \"Image_Subject_fkey\"]) ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef add_visible_foreign_key(\n    self,\n    table: str | Table,\n    context: str,\n    foreign_key: list[str] | dict[str, Any],\n    position: int | None = None,\n) -&gt; list[Any]:\n    \"\"\"Add a foreign key to the visible-foreign-keys list for a specific context.\n\n    Convenience method for adding related tables without replacing the entire\n    visible-foreign-keys annotation. Changes are staged until apply_annotations()\n    is called.\n\n    Args:\n        table: Table name or Table object.\n        context: The context to modify (typically \"detailed\" or \"*\").\n        foreign_key: Foreign key to add. Can be:\n            - List: inbound foreign key reference (e.g., [\"schema\", \"Other_Table_fkey\"])\n            - Dict: pseudo-column definition for complex relationships\n        position: Position to insert at (0-indexed). If None, appends to end.\n\n    Returns:\n        The updated foreign key list for the context.\n\n    Raises:\n        DerivaMLException: If context references another context.\n\n    Example:\n        &gt;&gt;&gt; ml.add_visible_foreign_key(\"Subject\", \"detailed\", [\"domain\", \"Image_Subject_fkey\"])\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    # Get or create visible_foreign_keys annotation\n    visible_fkeys = table_obj.annotations.get(VISIBLE_FOREIGN_KEYS_TAG, {})\n    if visible_fkeys is None:\n        visible_fkeys = {}\n\n    # Get or create the context list\n    context_list = visible_fkeys.get(context, [])\n    if isinstance(context_list, str):\n        raise DerivaMLException(\n            f\"Context '{context}' references another context '{context_list}'. \"\n            \"Set it explicitly first with set_visible_foreign_keys().\"\n        )\n\n    # Make a copy to avoid modifying in place\n    context_list = list(context_list)\n\n    # Insert at position or append\n    if position is not None:\n        context_list.insert(position, foreign_key)\n    else:\n        context_list.append(foreign_key)\n\n    # Update the annotation\n    visible_fkeys[context] = context_list\n    table_obj.annotations[VISIBLE_FOREIGN_KEYS_TAG] = visible_fkeys\n\n    return context_list\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.add_workflow","title":"add_workflow","text":"<pre><code>add_workflow(workflow: Workflow) -&gt; RID\n</code></pre> <p>Adds a workflow to the catalog.</p> <p>Registers a new workflow in the catalog or returns the RID of an existing workflow with the same URL or checksum.</p> <p>Each workflow represents a specific computational process or analysis pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>workflow</code> <code>Workflow</code> <p>Workflow object containing name, URL, type, version, and description.</p> required <p>Returns:</p> Name Type Description <code>RID</code> <code>RID</code> <p>Resource Identifier of the added or existing workflow.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If workflow insertion fails or required fields are missing.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; workflow = Workflow(\n...     name=\"Gene Analysis\",\n...     url=\"https://github.com/org/repo/workflows/gene_analysis.py\",\n...     workflow_type=\"python_script\",\n...     version=\"1.0.0\",\n...     description=\"Analyzes gene expression patterns\"\n... )\n&gt;&gt;&gt; workflow_rid = ml.add_workflow(workflow)\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/workflow.py</code> <pre><code>def add_workflow(self, workflow: Workflow) -&gt; RID:\n    \"\"\"Adds a workflow to the catalog.\n\n    Registers a new workflow in the catalog or returns the RID of an existing workflow with the same\n    URL or checksum.\n\n    Each workflow represents a specific computational process or analysis pipeline.\n\n    Args:\n        workflow: Workflow object containing name, URL, type, version, and description.\n\n    Returns:\n        RID: Resource Identifier of the added or existing workflow.\n\n    Raises:\n        DerivaMLException: If workflow insertion fails or required fields are missing.\n\n    Examples:\n        &gt;&gt;&gt; workflow = Workflow(\n        ...     name=\"Gene Analysis\",\n        ...     url=\"https://github.com/org/repo/workflows/gene_analysis.py\",\n        ...     workflow_type=\"python_script\",\n        ...     version=\"1.0.0\",\n        ...     description=\"Analyzes gene expression patterns\"\n        ... )\n        &gt;&gt;&gt; workflow_rid = ml.add_workflow(workflow)\n    \"\"\"\n    # Check if a workflow already exists by URL or checksum\n    if workflow_rid := self._find_workflow_rid_by_url(workflow.checksum or workflow.url):\n        return workflow_rid\n\n    # Get an ML schema path for the workflow table\n    ml_schema_path = self.pathBuilder().schemas[self.ml_schema]\n\n    try:\n        # Create a workflow record\n        workflow_record = {\n            \"URL\": workflow.url,\n            \"Name\": workflow.name,\n            \"Description\": workflow.description,\n            \"Checksum\": workflow.checksum,\n            \"Version\": workflow.version,\n            MLVocab.workflow_type: self.lookup_term(MLVocab.workflow_type, workflow.workflow_type).name,\n        }\n        # Insert a workflow and get its RID\n        workflow_rid = ml_schema_path.Workflow.insert([workflow_record])[0][\"RID\"]\n    except Exception as e:\n        error = format_exception(e)\n        raise DerivaMLException(f\"Failed to insert workflow. Error: {error}\")\n    return workflow_rid\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.apply_annotations","title":"apply_annotations","text":"<pre><code>apply_annotations() -&gt; None\n</code></pre> <p>Apply all staged annotation changes to the catalog.</p> <p>Commits any annotation changes made via set_display_annotation, set_visible_columns, set_visible_foreign_keys, set_table_display, or set_column_display to the remote catalog.</p> Example <p>ml.set_display_annotation(\"Image\", {\"name\": \"Images\"}) ml.set_visible_columns(\"Image\", {\"compact\": [\"RID\", \"Filename\"]}) ml.apply_annotations()  # Commit all changes</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>def apply_annotations(self) -&gt; None:\n    \"\"\"Apply all staged annotation changes to the catalog.\n\n    Commits any annotation changes made via set_display_annotation,\n    set_visible_columns, set_visible_foreign_keys, set_table_display,\n    or set_column_display to the remote catalog.\n\n    Example:\n        &gt;&gt;&gt; ml.set_display_annotation(\"Image\", {\"name\": \"Images\"})\n        &gt;&gt;&gt; ml.set_visible_columns(\"Image\", {\"compact\": [\"RID\", \"Filename\"]})\n        &gt;&gt;&gt; ml.apply_annotations()  # Commit all changes\n    \"\"\"\n    self.model.apply()\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.apply_catalog_annotations","title":"apply_catalog_annotations","text":"<pre><code>apply_catalog_annotations(\n    navbar_brand_text: str = \"ML Data Browser\",\n    head_title: str = \"Catalog ML\",\n) -&gt; None\n</code></pre> <p>Apply catalog-level annotations including the navigation bar and display settings.</p> <p>This method configures the Chaise web interface for the catalog. Chaise is Deriva's web-based data browser that provides a user-friendly interface for exploring and managing catalog data. This method sets up annotations that control how Chaise displays and organizes the catalog.</p> <p>Navigation Bar Structure: The method creates a navigation bar with the following menus: - User Info: Links to Users, Groups, and RID Lease tables - Deriva-ML: Core ML tables (Workflow, Execution, Dataset, Dataset_Version, etc.) - WWW: Web content tables (Page, File) - {Domain Schema}: All domain-specific tables (excludes vocabularies and associations) - Vocabulary: All controlled vocabulary tables from both ML and domain schemas - Assets: All asset tables from both ML and domain schemas - Features: All feature tables with entries named \"TableName:FeatureName\" - Catalog Registry: Link to the ermrest registry - Documentation: Links to ML notebook instructions and Deriva-ML docs</p> <p>Display Settings: - Underscores in table/column names displayed as spaces - System columns (RID) shown in compact and entry views - Default table set to Dataset - Faceting and record deletion enabled - Export configurations available to all users</p> <p>Bulk Upload Configuration: Configures upload patterns for asset tables, enabling drag-and-drop file uploads through the Chaise interface.</p> <p>Call this after creating the domain schema and all tables to initialize the catalog's web interface. The navigation menus are dynamically built based on the current schema structure, automatically organizing tables into appropriate categories.</p> <p>Parameters:</p> Name Type Description Default <code>navbar_brand_text</code> <code>str</code> <p>Text displayed in the navigation bar brand area.</p> <code>'ML Data Browser'</code> <code>head_title</code> <code>str</code> <p>Title displayed in the browser tab.</p> <code>'Catalog ML'</code> Example <p>ml = DerivaML('deriva.example.org', 'my_catalog')</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def apply_catalog_annotations(\n    self,\n    navbar_brand_text: str = \"ML Data Browser\",\n    head_title: str = \"Catalog ML\",\n) -&gt; None:\n    \"\"\"Apply catalog-level annotations including the navigation bar and display settings.\n\n    This method configures the Chaise web interface for the catalog. Chaise is Deriva's\n    web-based data browser that provides a user-friendly interface for exploring and\n    managing catalog data. This method sets up annotations that control how Chaise\n    displays and organizes the catalog.\n\n    **Navigation Bar Structure**:\n    The method creates a navigation bar with the following menus:\n    - **User Info**: Links to Users, Groups, and RID Lease tables\n    - **Deriva-ML**: Core ML tables (Workflow, Execution, Dataset, Dataset_Version, etc.)\n    - **WWW**: Web content tables (Page, File)\n    - **{Domain Schema}**: All domain-specific tables (excludes vocabularies and associations)\n    - **Vocabulary**: All controlled vocabulary tables from both ML and domain schemas\n    - **Assets**: All asset tables from both ML and domain schemas\n    - **Features**: All feature tables with entries named \"TableName:FeatureName\"\n    - **Catalog Registry**: Link to the ermrest registry\n    - **Documentation**: Links to ML notebook instructions and Deriva-ML docs\n\n    **Display Settings**:\n    - Underscores in table/column names displayed as spaces\n    - System columns (RID) shown in compact and entry views\n    - Default table set to Dataset\n    - Faceting and record deletion enabled\n    - Export configurations available to all users\n\n    **Bulk Upload Configuration**:\n    Configures upload patterns for asset tables, enabling drag-and-drop file uploads\n    through the Chaise interface.\n\n    Call this after creating the domain schema and all tables to initialize the catalog's\n    web interface. The navigation menus are dynamically built based on the current schema\n    structure, automatically organizing tables into appropriate categories.\n\n    Args:\n        navbar_brand_text: Text displayed in the navigation bar brand area.\n        head_title: Title displayed in the browser tab.\n\n    Example:\n        &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n        &gt;&gt;&gt; # After creating domain schema and tables...\n        &gt;&gt;&gt; ml.apply_catalog_annotations()\n        &gt;&gt;&gt; # Or with custom branding:\n        &gt;&gt;&gt; ml.apply_catalog_annotations(\"My Project Browser\", \"My ML Project\")\n    \"\"\"\n    catalog_id = self.model.catalog.catalog_id\n    ml_schema = self.ml_schema\n\n    # Build domain schema menu items (one menu per domain schema)\n    domain_schema_menus = []\n    for domain_schema in sorted(self.domain_schemas):\n        if domain_schema not in self.model.schemas:\n            continue\n        domain_schema_menus.append({\n            \"name\": domain_schema,\n            \"children\": [\n                {\n                    \"name\": tname,\n                    \"url\": f\"/chaise/recordset/#{catalog_id}/{domain_schema}:{tname}\",\n                }\n                for tname in self.model.schemas[domain_schema].tables\n                # Don't include controlled vocabularies, association tables, or feature tables.\n                if not (\n                    self.model.is_vocabulary(tname)\n                    or self.model.is_association(tname, pure=False, max_arity=3)\n                )\n            ],\n        })\n\n    # Build vocabulary menu items (ML schema + all domain schemas)\n    vocab_children = [{\"name\": f\"{ml_schema} Vocabularies\", \"header\": True}]\n    vocab_children.extend([\n        {\n            \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:{tname}\",\n            \"name\": tname,\n        }\n        for tname in self.model.schemas[ml_schema].tables\n        if self.model.is_vocabulary(tname)\n    ])\n    for domain_schema in sorted(self.domain_schemas):\n        if domain_schema not in self.model.schemas:\n            continue\n        vocab_children.append({\"name\": f\"{domain_schema} Vocabularies\", \"header\": True})\n        vocab_children.extend([\n            {\n                \"url\": f\"/chaise/recordset/#{catalog_id}/{domain_schema}:{tname}\",\n                \"name\": tname,\n            }\n            for tname in self.model.schemas[domain_schema].tables\n            if self.model.is_vocabulary(tname)\n        ])\n\n    # Build asset menu items (ML schema + all domain schemas)\n    asset_children = [\n        {\n            \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:{tname}\",\n            \"name\": tname,\n        }\n        for tname in self.model.schemas[ml_schema].tables\n        if self.model.is_asset(tname)\n    ]\n    for domain_schema in sorted(self.domain_schemas):\n        if domain_schema not in self.model.schemas:\n            continue\n        asset_children.extend([\n            {\n                \"url\": f\"/chaise/recordset/#{catalog_id}/{domain_schema}:{tname}\",\n                \"name\": tname,\n            }\n            for tname in self.model.schemas[domain_schema].tables\n            if self.model.is_asset(tname)\n        ])\n\n    catalog_annotation = {\n        deriva_tags.display: {\"name_style\": {\"underline_space\": True}},\n        deriva_tags.chaise_config: {\n            \"headTitle\": head_title,\n            \"navbarBrandText\": navbar_brand_text,\n            \"systemColumnsDisplayEntry\": [\"RID\"],\n            \"systemColumnsDisplayCompact\": [\"RID\"],\n            \"defaultTable\": {\"table\": \"Dataset\", \"schema\": \"deriva-ml\"},\n            \"deleteRecord\": True,\n            \"showFaceting\": True,\n            \"shareCiteAcls\": True,\n            \"exportConfigsSubmenu\": {\"acls\": {\"show\": [\"*\"], \"enable\": [\"*\"]}},\n            \"resolverImplicitCatalog\": False,\n            \"navbarMenu\": {\n                \"newTab\": False,\n                \"children\": [\n                    {\n                        \"name\": \"User Info\",\n                        \"children\": [\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/public:ERMrest_Client\",\n                                \"name\": \"Users\",\n                            },\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/public:ERMrest_Group\",\n                                \"name\": \"Groups\",\n                            },\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/public:ERMrest_RID_Lease\",\n                                \"name\": \"ERMrest RID Lease\",\n                            },\n                        ],\n                    },\n                    {  # All the primary tables in deriva-ml schema.\n                        \"name\": \"Deriva-ML\",\n                        \"children\": [\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Workflow\",\n                                \"name\": \"Workflow\",\n                            },\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Execution\",\n                                \"name\": \"Execution\",\n                            },\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Execution_Metadata\",\n                                \"name\": \"Execution Metadata\",\n                            },\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Execution_Asset\",\n                                \"name\": \"Execution Asset\",\n                            },\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Dataset\",\n                                \"name\": \"Dataset\",\n                            },\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/{ml_schema}:Dataset_Version\",\n                                \"name\": \"Dataset Version\",\n                            },\n                        ],\n                    },\n                    {  # WWW schema tables.\n                        \"name\": \"WWW\",\n                        \"children\": [\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/WWW:Page\",\n                                \"name\": \"Page\",\n                            },\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/WWW:File\",\n                                \"name\": \"File\",\n                            },\n                        ],\n                    },\n                    *domain_schema_menus,  # One menu per domain schema\n                    {  # Vocabulary menu with all controlled vocabularies.\n                        \"name\": \"Vocabulary\",\n                        \"children\": vocab_children,\n                    },\n                    {  # List of all asset tables.\n                        \"name\": \"Assets\",\n                        \"children\": asset_children,\n                    },\n                    {  # List of all feature tables in the catalog.\n                        \"name\": \"Features\",\n                        \"children\": [\n                            {\n                                \"url\": f\"/chaise/recordset/#{catalog_id}/{f.feature_table.schema.name}:{f.feature_table.name}\",\n                                \"name\": f\"{f.target_table.name}:{f.feature_name}\",\n                            }\n                            for f in self.model.find_features()\n                        ],\n                    },\n                    {\n                        \"url\": \"/chaise/recordset/#0/ermrest:registry@sort(RID)\",\n                        \"name\": \"Catalog Registry\",\n                    },\n                    {\n                        \"name\": \"Documentation\",\n                        \"children\": [\n                            {\n                                \"url\": \"https://github.com/informatics-isi-edu/deriva-ml/blob/main/docs/ml_workflow_instruction.md\",\n                                \"name\": \"ML Notebook Instruction\",\n                            },\n                            {\n                                \"url\": \"https://informatics-isi-edu.github.io/deriva-ml/\",\n                                \"name\": \"Deriva-ML Documentation\",\n                            },\n                        ],\n                    },\n                ],\n            },\n        },\n        deriva_tags.bulk_upload: bulk_upload_configuration(model=self.model),\n    }\n    self.model.annotations.update(catalog_annotation)\n    self.model.apply()\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.apply_catalog_annotations--after-creating-domain-schema-and-tables","title":"After creating domain schema and tables...","text":"<p>ml.apply_catalog_annotations()</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.apply_catalog_annotations--or-with-custom-branding","title":"Or with custom branding:","text":"<p>ml.apply_catalog_annotations(\"My Project Browser\", \"My ML Project\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.catalog_snapshot","title":"catalog_snapshot","text":"<pre><code>catalog_snapshot(\n    version_snapshot: str,\n) -&gt; Self\n</code></pre> <p>Returns a DerivaML instance for a specific snapshot of the catalog.</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def catalog_snapshot(self, version_snapshot: str) -&gt; Self:\n    \"\"\"Returns a DerivaML instance for a specific snapshot of the catalog.\"\"\"\n    return DerivaML(\n        self.host_name,\n        version_snapshot,\n        logging_level=self._logging_level,\n        deriva_logging_level=self._deriva_logging_level,\n    )\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.chaise_url","title":"chaise_url","text":"<pre><code>chaise_url(\n    table: RID | Table | str,\n) -&gt; str\n</code></pre> <p>Generates Chaise web interface URL.</p> <p>Chaise is Deriva's web interface for data exploration. This method creates a URL that directly links to the specified table or record.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>RID | Table | str</code> <p>Table to generate URL for (name, Table object, or RID).</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>URL in format: https://{host}/chaise/recordset/#{catalog}/{schema}:{table}</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If table or RID cannot be found.</p> <p>Examples:</p> <p>Using table name:     &gt;&gt;&gt; ml.chaise_url(\"experiment_table\")     'https://deriva.org/chaise/recordset/#1/schema:experiment_table'</p> <p>Using RID:     &gt;&gt;&gt; ml.chaise_url(\"1-abc123\")</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def chaise_url(self, table: RID | Table | str) -&gt; str:\n    \"\"\"Generates Chaise web interface URL.\n\n    Chaise is Deriva's web interface for data exploration. This method creates a URL that directly links to\n    the specified table or record.\n\n    Args:\n        table: Table to generate URL for (name, Table object, or RID).\n\n    Returns:\n        str: URL in format: https://{host}/chaise/recordset/#{catalog}/{schema}:{table}\n\n    Raises:\n        DerivaMLException: If table or RID cannot be found.\n\n    Examples:\n        Using table name:\n            &gt;&gt;&gt; ml.chaise_url(\"experiment_table\")\n            'https://deriva.org/chaise/recordset/#1/schema:experiment_table'\n\n        Using RID:\n            &gt;&gt;&gt; ml.chaise_url(\"1-abc123\")\n    \"\"\"\n    # Get the table object and build base URI\n    table_obj = self.model.name_to_table(table)\n    try:\n        uri = self.catalog.get_server_uri().replace(\"ermrest/catalog/\", \"chaise/recordset/#\")\n    except DerivaMLException:\n        # Handle RID case\n        uri = self.cite(cast(str, table))\n    return f\"{uri}/{urlquote(table_obj.schema.name)}:{urlquote(table_obj.name)}\"\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.cite","title":"cite","text":"<pre><code>cite(\n    entity: Dict[str, Any] | str,\n    current: bool = False,\n) -&gt; str\n</code></pre> <p>Generates citation URL for an entity.</p> <p>Creates a URL that can be used to reference a specific entity in the catalog. By default, includes the catalog snapshot time to ensure version stability (permanent citation). With current=True, returns a URL to the current state.</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> <code>Dict[str, Any] | str</code> <p>Either a RID string or a dictionary containing entity data with a 'RID' key.</p> required <code>current</code> <code>bool</code> <p>If True, return URL to current catalog state (no snapshot).      If False (default), return permanent citation URL with snapshot time.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Citation URL. Format depends on <code>current</code> parameter: - current=False: https://{host}/id/{catalog}/{rid}@{snapshot_time} - current=True: https://{host}/id/{catalog}/{rid}</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If an entity doesn't exist or lacks a RID.</p> <p>Examples:</p> <p>Permanent citation (default):     &gt;&gt;&gt; url = ml.cite(\"1-abc123\")     &gt;&gt;&gt; print(url)     'https://deriva.org/id/1/1-abc123@2024-01-01T12:00:00'</p> <p>Current catalog URL:     &gt;&gt;&gt; url = ml.cite(\"1-abc123\", current=True)     &gt;&gt;&gt; print(url)     'https://deriva.org/id/1/1-abc123'</p> <p>Using a dictionary:     &gt;&gt;&gt; url = ml.cite({\"RID\": \"1-abc123\"})</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def cite(self, entity: Dict[str, Any] | str, current: bool = False) -&gt; str:\n    \"\"\"Generates citation URL for an entity.\n\n    Creates a URL that can be used to reference a specific entity in the catalog.\n    By default, includes the catalog snapshot time to ensure version stability\n    (permanent citation). With current=True, returns a URL to the current state.\n\n    Args:\n        entity: Either a RID string or a dictionary containing entity data with a 'RID' key.\n        current: If True, return URL to current catalog state (no snapshot).\n                 If False (default), return permanent citation URL with snapshot time.\n\n    Returns:\n        str: Citation URL. Format depends on `current` parameter:\n            - current=False: https://{host}/id/{catalog}/{rid}@{snapshot_time}\n            - current=True: https://{host}/id/{catalog}/{rid}\n\n    Raises:\n        DerivaMLException: If an entity doesn't exist or lacks a RID.\n\n    Examples:\n        Permanent citation (default):\n            &gt;&gt;&gt; url = ml.cite(\"1-abc123\")\n            &gt;&gt;&gt; print(url)\n            'https://deriva.org/id/1/1-abc123@2024-01-01T12:00:00'\n\n        Current catalog URL:\n            &gt;&gt;&gt; url = ml.cite(\"1-abc123\", current=True)\n            &gt;&gt;&gt; print(url)\n            'https://deriva.org/id/1/1-abc123'\n\n        Using a dictionary:\n            &gt;&gt;&gt; url = ml.cite({\"RID\": \"1-abc123\"})\n    \"\"\"\n    # Return if already a citation URL\n    if isinstance(entity, str) and entity.startswith(f\"https://{self.host_name}/id/{self.catalog_id}/\"):\n        return entity\n\n    try:\n        # Resolve RID and create citation URL\n        self.resolve_rid(rid := entity if isinstance(entity, str) else entity[\"RID\"])\n        base_url = f\"https://{self.host_name}/id/{self.catalog_id}/{rid}\"\n        if current:\n            return base_url\n        return f\"{base_url}@{self.catalog.latest_snapshot().snaptime}\"\n    except KeyError as e:\n        raise DerivaMLException(f\"Entity {e} does not have RID column\")\n    except DerivaMLException as _e:\n        raise DerivaMLException(\"Entity RID does not exist\")\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.clean_execution_dirs","title":"clean_execution_dirs","text":"<pre><code>clean_execution_dirs(\n    older_than_days: int | None = None,\n    exclude_rids: list[str]\n    | None = None,\n) -&gt; dict[str, int]\n</code></pre> <p>Clean up execution working directories.</p> <p>Removes execution output directories from the local working directory. Use this to free up disk space from completed or orphaned executions.</p> <p>Parameters:</p> Name Type Description Default <code>older_than_days</code> <code>int | None</code> <p>If provided, only remove directories older than this many days. If None, removes all execution directories (except excluded).</p> <code>None</code> <code>exclude_rids</code> <code>list[str] | None</code> <p>List of execution RIDs to preserve (never remove).</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>dict with keys: - 'dirs_removed': Number of directories removed - 'bytes_freed': Total bytes freed - 'errors': Number of removal errors</p> Example <p>ml = DerivaML('deriva.example.org', 'my_catalog')</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def clean_execution_dirs(\n    self,\n    older_than_days: int | None = None,\n    exclude_rids: list[str] | None = None,\n) -&gt; dict[str, int]:\n    \"\"\"Clean up execution working directories.\n\n    Removes execution output directories from the local working directory.\n    Use this to free up disk space from completed or orphaned executions.\n\n    Args:\n        older_than_days: If provided, only remove directories older than this\n            many days. If None, removes all execution directories (except excluded).\n        exclude_rids: List of execution RIDs to preserve (never remove).\n\n    Returns:\n        dict with keys:\n            - 'dirs_removed': Number of directories removed\n            - 'bytes_freed': Total bytes freed\n            - 'errors': Number of removal errors\n\n    Example:\n        &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n        &gt;&gt;&gt; # Clean all execution dirs older than 30 days\n        &gt;&gt;&gt; result = ml.clean_execution_dirs(older_than_days=30)\n        &gt;&gt;&gt; print(f\"Freed {result['bytes_freed'] / 1e9:.2f} GB\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Clean all except specific executions\n        &gt;&gt;&gt; result = ml.clean_execution_dirs(exclude_rids=['1-ABC', '1-DEF'])\n    \"\"\"\n    import shutil\n    import time\n\n    from deriva_ml.dataset.upload import upload_root\n\n    stats = {'dirs_removed': 0, 'bytes_freed': 0, 'errors': 0}\n    exclude_rids = set(exclude_rids or [])\n\n    exec_root = upload_root(self.working_dir) / \"execution\"\n    if not exec_root.exists():\n        return stats\n\n    cutoff_time = None\n    if older_than_days is not None:\n        cutoff_time = time.time() - (older_than_days * 24 * 60 * 60)\n\n    for entry in exec_root.iterdir():\n        if not entry.is_dir():\n            continue\n\n        # Skip excluded RIDs\n        if entry.name in exclude_rids:\n            continue\n\n        try:\n            # Check age if filtering\n            if cutoff_time is not None:\n                entry_mtime = entry.stat().st_mtime\n                if entry_mtime &gt; cutoff_time:\n                    continue\n\n            # Calculate size before removal\n            entry_size = sum(f.stat().st_size for f in entry.rglob('*') if f.is_file())\n            shutil.rmtree(entry)\n            stats['dirs_removed'] += 1\n            stats['bytes_freed'] += entry_size\n\n        except (OSError, PermissionError) as e:\n            self._logger.warning(f\"Failed to remove execution dir {entry}: {e}\")\n            stats['errors'] += 1\n\n    return stats\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.clean_execution_dirs--clean-all-execution-dirs-older-than-30-days","title":"Clean all execution dirs older than 30 days","text":"<p>result = ml.clean_execution_dirs(older_than_days=30) print(f\"Freed {result['bytes_freed'] / 1e9:.2f} GB\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.clean_execution_dirs--clean-all-except-specific-executions","title":"Clean all except specific executions","text":"<p>result = ml.clean_execution_dirs(exclude_rids=['1-ABC', '1-DEF'])</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache(\n    older_than_days: int | None = None,\n) -&gt; dict[str, int]\n</code></pre> <p>Clear the dataset cache directory.</p> <p>Removes cached dataset bags from the cache directory. Can optionally filter by age to only remove old cache entries.</p> <p>Parameters:</p> Name Type Description Default <code>older_than_days</code> <code>int | None</code> <p>If provided, only remove cache entries older than this many days. If None, removes all cache entries.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>dict with keys: - 'files_removed': Number of files removed - 'dirs_removed': Number of directories removed - 'bytes_freed': Total bytes freed - 'errors': Number of removal errors</p> Example <p>ml = DerivaML('deriva.example.org', 'my_catalog')</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def clear_cache(self, older_than_days: int | None = None) -&gt; dict[str, int]:\n    \"\"\"Clear the dataset cache directory.\n\n    Removes cached dataset bags from the cache directory. Can optionally filter\n    by age to only remove old cache entries.\n\n    Args:\n        older_than_days: If provided, only remove cache entries older than this\n            many days. If None, removes all cache entries.\n\n    Returns:\n        dict with keys:\n            - 'files_removed': Number of files removed\n            - 'dirs_removed': Number of directories removed\n            - 'bytes_freed': Total bytes freed\n            - 'errors': Number of removal errors\n\n    Example:\n        &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n        &gt;&gt;&gt; # Clear all cache\n        &gt;&gt;&gt; result = ml.clear_cache()\n        &gt;&gt;&gt; print(f\"Freed {result['bytes_freed'] / 1e6:.1f} MB\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Clear cache older than 7 days\n        &gt;&gt;&gt; result = ml.clear_cache(older_than_days=7)\n    \"\"\"\n    import shutil\n    import time\n\n    stats = {'files_removed': 0, 'dirs_removed': 0, 'bytes_freed': 0, 'errors': 0}\n\n    if not self.cache_dir.exists():\n        return stats\n\n    cutoff_time = None\n    if older_than_days is not None:\n        cutoff_time = time.time() - (older_than_days * 24 * 60 * 60)\n\n    try:\n        for entry in self.cache_dir.iterdir():\n            try:\n                # Check age if filtering\n                if cutoff_time is not None:\n                    entry_mtime = entry.stat().st_mtime\n                    if entry_mtime &gt; cutoff_time:\n                        continue  # Skip recent entries\n\n                # Calculate size before removal\n                if entry.is_dir():\n                    entry_size = sum(f.stat().st_size for f in entry.rglob('*') if f.is_file())\n                    shutil.rmtree(entry)\n                    stats['dirs_removed'] += 1\n                else:\n                    entry_size = entry.stat().st_size\n                    entry.unlink()\n                    stats['files_removed'] += 1\n\n                stats['bytes_freed'] += entry_size\n            except (OSError, PermissionError) as e:\n                self._logger.warning(f\"Failed to remove cache entry {entry}: {e}\")\n                stats['errors'] += 1\n\n    except OSError as e:\n        self._logger.error(f\"Failed to iterate cache directory: {e}\")\n        stats['errors'] += 1\n\n    return stats\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.clear_cache--clear-all-cache","title":"Clear all cache","text":"<p>result = ml.clear_cache() print(f\"Freed {result['bytes_freed'] / 1e6:.1f} MB\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.clear_cache--clear-cache-older-than-7-days","title":"Clear cache older than 7 days","text":"<p>result = ml.clear_cache(older_than_days=7)</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.clear_vocabulary_cache","title":"clear_vocabulary_cache","text":"<pre><code>clear_vocabulary_cache(\n    table: str | Table | None = None,\n) -&gt; None\n</code></pre> <p>Clear the vocabulary term cache.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table | None</code> <p>If provided, only clear cache for this specific vocabulary table.    If None, clear the entire cache.</p> <code>None</code> Source code in <code>src/deriva_ml/core/mixins/vocabulary.py</code> <pre><code>def clear_vocabulary_cache(self, table: str | Table | None = None) -&gt; None:\n    \"\"\"Clear the vocabulary term cache.\n\n    Args:\n        table: If provided, only clear cache for this specific vocabulary table.\n               If None, clear the entire cache.\n    \"\"\"\n    cache = self._get_vocab_cache()\n    if table is None:\n        cache.clear()\n    else:\n        vocab_table = self.model.name_to_table(table)\n        cache_key = (vocab_table.schema.name, vocab_table.name)\n        cache.pop(cache_key, None)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.create_asset","title":"create_asset","text":"<pre><code>create_asset(\n    asset_name: str,\n    column_defs: Iterable[\n        ColumnDefinition\n    ]\n    | None = None,\n    fkey_defs: Iterable[\n        ColumnDefinition\n    ]\n    | None = None,\n    referenced_tables: Iterable[Table]\n    | None = None,\n    comment: str = \"\",\n    schema: str | None = None,\n    update_navbar: bool = True,\n) -&gt; Table\n</code></pre> <p>Creates an asset table.</p> <p>Parameters:</p> Name Type Description Default <code>asset_name</code> <code>str</code> <p>Name of the asset table.</p> required <code>column_defs</code> <code>Iterable[ColumnDefinition] | None</code> <p>Iterable of ColumnDefinition objects to provide additional metadata for asset.</p> <code>None</code> <code>fkey_defs</code> <code>Iterable[ColumnDefinition] | None</code> <p>Iterable of ForeignKeyDefinition objects to provide additional metadata for asset.</p> <code>None</code> <code>referenced_tables</code> <code>Iterable[Table] | None</code> <p>Iterable of Table objects to which asset should provide foreign-key references to.</p> <code>None</code> <code>comment</code> <code>str</code> <p>Description of the asset table. (Default value = '')</p> <code>''</code> <code>schema</code> <code>str | None</code> <p>Schema in which to create the asset table.  Defaults to domain_schema.</p> <code>None</code> <code>update_navbar</code> <code>bool</code> <p>If True (default), automatically updates the navigation bar to include the new asset table. Set to False during batch asset creation to avoid redundant updates, then call apply_catalog_annotations() once at the end.</p> <code>True</code> <p>Returns:</p> Type Description <code>Table</code> <p>Table object for the asset table.</p> Source code in <code>src/deriva_ml/core/mixins/asset.py</code> <pre><code>def create_asset(\n    self,\n    asset_name: str,\n    column_defs: Iterable[ColumnDefinition] | None = None,\n    fkey_defs: Iterable[ColumnDefinition] | None = None,\n    referenced_tables: Iterable[Table] | None = None,\n    comment: str = \"\",\n    schema: str | None = None,\n    update_navbar: bool = True,\n) -&gt; Table:\n    \"\"\"Creates an asset table.\n\n    Args:\n        asset_name: Name of the asset table.\n        column_defs: Iterable of ColumnDefinition objects to provide additional metadata for asset.\n        fkey_defs: Iterable of ForeignKeyDefinition objects to provide additional metadata for asset.\n        referenced_tables: Iterable of Table objects to which asset should provide foreign-key references to.\n        comment: Description of the asset table. (Default value = '')\n        schema: Schema in which to create the asset table.  Defaults to domain_schema.\n        update_navbar: If True (default), automatically updates the navigation bar to include\n            the new asset table. Set to False during batch asset creation to avoid redundant\n            updates, then call apply_catalog_annotations() once at the end.\n\n    Returns:\n        Table object for the asset table.\n    \"\"\"\n    # Initialize empty collections if None provided\n    column_defs = column_defs or []\n    fkey_defs = fkey_defs or []\n    referenced_tables = referenced_tables or []\n    schema = schema or self.model._require_default_schema()\n\n    # Add an asset type to vocabulary\n    self.add_term(MLVocab.asset_type, asset_name, description=f\"A {asset_name} asset\")\n\n    # Create the main asset table\n    # Note: column_defs and fkey_defs should be ColumnDef/ForeignKeyDef objects\n    asset_table = self.model.schemas[schema].create_table(\n        AssetTableDef(\n            schema_name=schema,\n            name=asset_name,\n            columns=list(column_defs),\n            foreign_keys=list(fkey_defs),\n            comment=comment,\n        )\n    )\n\n    # Create an association table between asset and asset type\n    self.model.create_table(\n        Table.define_association(\n            [\n                (asset_table.name, asset_table),\n                (\"Asset_Type\", self.model.name_to_table(\"Asset_Type\")),\n            ]\n        ),\n        schema=schema,\n    )\n\n    # Create references to other tables if specified\n    for t in referenced_tables:\n        asset_table.create_reference(self.model.name_to_table(t))\n\n    # Create an association table for tracking execution\n    atable = self.model.create_table(\n        Table.define_association(\n            [\n                (asset_name, asset_table),\n                (\n                    \"Execution\",\n                    self.model.schemas[self.ml_schema].tables[\"Execution\"],\n                ),\n            ]\n        ),\n        schema=schema,\n    )\n    atable.create_reference(self.model.name_to_table(\"Asset_Role\"))\n\n    # Add asset annotations\n    asset_annotation(asset_table)\n\n    # Update navbar to include the new asset table\n    if update_navbar:\n        self.apply_catalog_annotations()\n\n    return asset_table\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.create_execution","title":"create_execution","text":"<pre><code>create_execution(\n    configuration: ExecutionConfiguration,\n    workflow: \"Workflow | RID | None\" = None,\n    dry_run: bool = False,\n) -&gt; \"Execution\"\n</code></pre> <p>Create an execution environment.</p> <p>Initializes a local compute environment for executing an ML or analytic routine. This has several side effects:</p> <ol> <li>Downloads datasets specified in the configuration to the cache directory.    If no version is specified, creates a new minor version for the dataset.</li> <li>Downloads any execution assets to the working directory.</li> <li>Creates an execution record in the catalog (unless dry_run=True).</li> </ol> <p>Parameters:</p> Name Type Description Default <code>configuration</code> <code>ExecutionConfiguration</code> <p>ExecutionConfiguration specifying execution parameters.</p> required <code>workflow</code> <code>'Workflow | RID | None'</code> <p>Optional Workflow object or RID if not present in configuration.</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>If True, skip creating catalog records and uploading results.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Execution</code> <code>'Execution'</code> <p>An execution object for managing the execution lifecycle.</p> Example <p>config = ExecutionConfiguration( ...     workflow=workflow, ...     description=\"Process samples\", ...     datasets=[DatasetSpec(rid=\"4HM\")], ... ) with ml.create_execution(config) as execution: ...     # Run analysis ...     pass execution.upload_execution_outputs()</p> Source code in <code>src/deriva_ml/core/mixins/execution.py</code> <pre><code>def create_execution(\n    self, configuration: ExecutionConfiguration, workflow: \"Workflow | RID | None\" = None, dry_run: bool = False\n) -&gt; \"Execution\":\n    \"\"\"Create an execution environment.\n\n    Initializes a local compute environment for executing an ML or analytic routine.\n    This has several side effects:\n\n    1. Downloads datasets specified in the configuration to the cache directory.\n       If no version is specified, creates a new minor version for the dataset.\n    2. Downloads any execution assets to the working directory.\n    3. Creates an execution record in the catalog (unless dry_run=True).\n\n    Args:\n        configuration: ExecutionConfiguration specifying execution parameters.\n        workflow: Optional Workflow object or RID if not present in configuration.\n        dry_run: If True, skip creating catalog records and uploading results.\n\n    Returns:\n        Execution: An execution object for managing the execution lifecycle.\n\n    Example:\n        &gt;&gt;&gt; config = ExecutionConfiguration(\n        ...     workflow=workflow,\n        ...     description=\"Process samples\",\n        ...     datasets=[DatasetSpec(rid=\"4HM\")],\n        ... )\n        &gt;&gt;&gt; with ml.create_execution(config) as execution:\n        ...     # Run analysis\n        ...     pass\n        &gt;&gt;&gt; execution.upload_execution_outputs()\n    \"\"\"\n    # Import here to avoid circular dependency\n    from deriva_ml.execution.execution import Execution\n\n    # Create and store an execution instance\n    self._execution = Execution(configuration, self, workflow=workflow, dry_run=dry_run)  # type: ignore[arg-type]\n    return self._execution\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.create_feature","title":"create_feature","text":"<pre><code>create_feature(\n    target_table: Table | str,\n    feature_name: str,\n    terms: list[Table | str]\n    | None = None,\n    assets: list[Table | str]\n    | None = None,\n    metadata: list[\n        ColumnDefinition\n        | Table\n        | Key\n        | str\n    ]\n    | None = None,\n    optional: list[str] | None = None,\n    comment: str = \"\",\n    update_navbar: bool = True,\n) -&gt; type[FeatureRecord]\n</code></pre> <p>Creates a new feature definition.</p> <p>A feature represents a measurable property or characteristic that can be associated with records in the target table. Features can include vocabulary terms, asset references, and additional metadata.</p> <p>Side Effects: This method dynamically creates: 1. A new association table in the domain schema to store feature values 2. A Pydantic model class (subclass of FeatureRecord) for creating validated feature instances</p> <p>The returned Pydantic model class provides type-safe construction of feature records with automatic validation of values against the feature's definition (vocabulary terms, asset references, etc.). Use this class to create feature instances that can be inserted into the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>target_table</code> <code>Table | str</code> <p>Table to associate the feature with (name or Table object).</p> required <code>feature_name</code> <code>str</code> <p>Unique name for the feature within the target table.</p> required <code>terms</code> <code>list[Table | str] | None</code> <p>Optional vocabulary tables/names whose terms can be used as feature values.</p> <code>None</code> <code>assets</code> <code>list[Table | str] | None</code> <p>Optional asset tables/names that can be referenced by this feature.</p> <code>None</code> <code>metadata</code> <code>list[ColumnDefinition | Table | Key | str] | None</code> <p>Optional columns, tables, or keys to include in a feature definition.</p> <code>None</code> <code>optional</code> <code>list[str] | None</code> <p>Column names that are not required when creating feature instances.</p> <code>None</code> <code>comment</code> <code>str</code> <p>Description of the feature's purpose and usage.</p> <code>''</code> <code>update_navbar</code> <code>bool</code> <p>If True (default), automatically updates the navigation bar to include the new feature table. Set to False during batch feature creation to avoid redundant updates, then call apply_catalog_annotations() once at the end.</p> <code>True</code> <p>Returns:</p> Type Description <code>type[FeatureRecord]</code> <p>type[FeatureRecord]: A dynamically generated Pydantic model class for creating validated feature instances. The class has fields corresponding to the feature's terms, assets, and metadata columns.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If a feature definition is invalid or conflicts with existing features.</p> <p>Examples:</p> <p>Create a feature with confidence score:     &gt;&gt;&gt; DiagnosisFeature = ml.create_feature(     ...     target_table=\"Image\",     ...     feature_name=\"Diagnosis\",     ...     terms=[\"Diagnosis_Type\"],     ...     metadata=[ColumnDefinition(name=\"confidence\", type=BuiltinTypes.float4)],     ...     comment=\"Clinical diagnosis label\"     ... )     &gt;&gt;&gt; # Use the returned class to create validated feature instances     &gt;&gt;&gt; record = DiagnosisFeature(     ...     Image=\"1-ABC\",  # Target record RID     ...     Diagnosis_Type=\"Normal\",  # Vocabulary term     ...     confidence=0.95,     ...     Execution=\"2-XYZ\"  # Execution that produced this value     ... )</p> Source code in <code>src/deriva_ml/core/mixins/feature.py</code> <pre><code>def create_feature(\n    self,\n    target_table: Table | str,\n    feature_name: str,\n    terms: list[Table | str] | None = None,\n    assets: list[Table | str] | None = None,\n    metadata: list[ColumnDefinition | Table | Key | str] | None = None,\n    optional: list[str] | None = None,\n    comment: str = \"\",\n    update_navbar: bool = True,\n) -&gt; type[FeatureRecord]:\n    \"\"\"Creates a new feature definition.\n\n    A feature represents a measurable property or characteristic that can be associated with records in the target\n    table. Features can include vocabulary terms, asset references, and additional metadata.\n\n    **Side Effects**:\n    This method dynamically creates:\n    1. A new association table in the domain schema to store feature values\n    2. A Pydantic model class (subclass of FeatureRecord) for creating validated feature instances\n\n    The returned Pydantic model class provides type-safe construction of feature records with\n    automatic validation of values against the feature's definition (vocabulary terms, asset\n    references, etc.). Use this class to create feature instances that can be inserted into\n    the catalog.\n\n    Args:\n        target_table: Table to associate the feature with (name or Table object).\n        feature_name: Unique name for the feature within the target table.\n        terms: Optional vocabulary tables/names whose terms can be used as feature values.\n        assets: Optional asset tables/names that can be referenced by this feature.\n        metadata: Optional columns, tables, or keys to include in a feature definition.\n        optional: Column names that are not required when creating feature instances.\n        comment: Description of the feature's purpose and usage.\n        update_navbar: If True (default), automatically updates the navigation bar to include\n            the new feature table. Set to False during batch feature creation to avoid\n            redundant updates, then call apply_catalog_annotations() once at the end.\n\n    Returns:\n        type[FeatureRecord]: A dynamically generated Pydantic model class for creating\n            validated feature instances. The class has fields corresponding to the feature's\n            terms, assets, and metadata columns.\n\n    Raises:\n        DerivaMLException: If a feature definition is invalid or conflicts with existing features.\n\n    Examples:\n        Create a feature with confidence score:\n            &gt;&gt;&gt; DiagnosisFeature = ml.create_feature(\n            ...     target_table=\"Image\",\n            ...     feature_name=\"Diagnosis\",\n            ...     terms=[\"Diagnosis_Type\"],\n            ...     metadata=[ColumnDefinition(name=\"confidence\", type=BuiltinTypes.float4)],\n            ...     comment=\"Clinical diagnosis label\"\n            ... )\n            &gt;&gt;&gt; # Use the returned class to create validated feature instances\n            &gt;&gt;&gt; record = DiagnosisFeature(\n            ...     Image=\"1-ABC\",  # Target record RID\n            ...     Diagnosis_Type=\"Normal\",  # Vocabulary term\n            ...     confidence=0.95,\n            ...     Execution=\"2-XYZ\"  # Execution that produced this value\n            ... )\n    \"\"\"\n    # Initialize empty collections if None provided\n    terms = terms or []\n    assets = assets or []\n    metadata = metadata or []\n    optional = optional or []\n\n    def normalize_metadata(m: Key | Table | ColumnDefinition | str | dict) -&gt; Key | Table | dict:\n        \"\"\"Helper function to normalize metadata references.\n\n        Handles:\n        - str: Table name, converted to Table object\n        - ColumnDefinition: Dataclass with to_dict() method\n        - dict: Already in dict format (from Column.define())\n        - Key/Table: Passed through unchanged\n        \"\"\"\n        if isinstance(m, str):\n            return self.model.name_to_table(m)\n        elif isinstance(m, dict):\n            # Already a dict (e.g., from Column.define())\n            return m\n        elif hasattr(m, 'to_dict'):\n            # ColumnDefinition or similar dataclass\n            return m.to_dict()\n        else:\n            return m\n\n    # Validate asset and term tables\n    if not all(map(self.model.is_asset, assets)):\n        raise DerivaMLException(\"Invalid create_feature asset table.\")\n    if not all(map(self.model.is_vocabulary, terms)):\n        raise DerivaMLException(\"Invalid create_feature asset table.\")\n\n    # Get references to required tables\n    target_table = self.model.name_to_table(target_table)\n    execution = self.model.schemas[self.ml_schema].tables[\"Execution\"]\n    feature_name_table = self.model.schemas[self.ml_schema].tables[\"Feature_Name\"]\n\n    # Add feature name to vocabulary\n    feature_name_term = self.add_term(\"Feature_Name\", feature_name, description=comment)\n    atable_name = f\"Execution_{target_table.name}_{feature_name_term.name}\"\n    # Create an association table implementing the feature\n    atable = self.model.create_table(\n        target_table.define_association(\n            table_name=atable_name,\n            associates=[execution, target_table, feature_name_table],\n            metadata=[normalize_metadata(m) for m in chain(assets, terms, metadata)],\n            comment=comment,\n        )\n    )\n    # Configure optional columns and default feature name\n    for c in optional:\n        atable.columns[c].alter(nullok=True)\n    atable.columns[\"Feature_Name\"].alter(default=feature_name_term.name)\n\n    # Update navbar to include the new feature table\n    if update_navbar:\n        self.apply_catalog_annotations()\n\n    # Return feature record class for creating instances\n    return self.feature_record_class(target_table, feature_name)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.create_table","title":"create_table","text":"<pre><code>create_table(\n    table: TableDefinition,\n    schema: str | None = None,\n    update_navbar: bool = True,\n) -&gt; Table\n</code></pre> <p>Creates a new table in the domain schema.</p> <p>Creates a table using the provided TableDefinition object, which specifies the table structure including columns, keys, and foreign key relationships. The table is created in the domain schema associated with this DerivaML instance.</p> <p>Required Classes: Import the following classes from deriva_ml to define tables:</p> <ul> <li><code>TableDefinition</code>: Defines the complete table structure</li> <li><code>ColumnDefinition</code>: Defines individual columns with types and constraints</li> <li><code>KeyDefinition</code>: Defines unique key constraints (optional)</li> <li><code>ForeignKeyDefinition</code>: Defines foreign key relationships to other tables (optional)</li> <li><code>BuiltinTypes</code>: Enum of available column data types</li> </ul> <p>Available Column Types (BuiltinTypes enum): <code>text</code>, <code>int2</code>, <code>int4</code>, <code>int8</code>, <code>float4</code>, <code>float8</code>, <code>boolean</code>, <code>date</code>, <code>timestamp</code>, <code>timestamptz</code>, <code>json</code>, <code>jsonb</code>, <code>markdown</code>, <code>ermrest_uri</code>, <code>ermrest_rid</code>, <code>ermrest_rcb</code>, <code>ermrest_rmb</code>, <code>ermrest_rct</code>, <code>ermrest_rmt</code></p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>TableDefinition</code> <p>A TableDefinition object containing the complete specification of the table to create.</p> required <code>update_navbar</code> <code>bool</code> <p>If True (default), automatically updates the navigation bar to include the new table. Set to False during batch table creation to avoid redundant updates, then call apply_catalog_annotations() once at the end.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The newly created ERMRest table object.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If table creation fails or the definition is invalid.</p> <p>Examples:</p> <p>Simple table with basic columns:</p> <pre><code>&gt;&gt;&gt; from deriva_ml import TableDefinition, ColumnDefinition, BuiltinTypes\n&gt;&gt;&gt;\n&gt;&gt;&gt; table_def = TableDefinition(\n...     name=\"Experiment\",\n...     column_defs=[\n...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n...         ColumnDefinition(name=\"Date\", type=BuiltinTypes.date),\n...         ColumnDefinition(name=\"Description\", type=BuiltinTypes.markdown),\n...         ColumnDefinition(name=\"Score\", type=BuiltinTypes.float4),\n...     ],\n...     comment=\"Records of experimental runs\"\n... )\n&gt;&gt;&gt; experiment_table = ml.create_table(table_def)\n</code></pre> <p>Table with foreign key to another table:</p> <pre><code>&gt;&gt;&gt; from deriva_ml import (\n...     TableDefinition, ColumnDefinition, ForeignKeyDefinition, BuiltinTypes\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create a Sample table that references Subject\n&gt;&gt;&gt; sample_def = TableDefinition(\n...     name=\"Sample\",\n...     column_defs=[\n...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n...         ColumnDefinition(name=\"Subject\", type=BuiltinTypes.text, nullok=False),\n...         ColumnDefinition(name=\"Collection_Date\", type=BuiltinTypes.date),\n...     ],\n...     fkey_defs=[\n...         ForeignKeyDefinition(\n...             colnames=[\"Subject\"],\n...             pk_sname=ml.default_schema,  # Schema of referenced table\n...             pk_tname=\"Subject\",          # Name of referenced table\n...             pk_colnames=[\"RID\"],         # Column(s) in referenced table\n...             on_delete=\"CASCADE\",         # Delete samples when subject deleted\n...         )\n...     ],\n...     comment=\"Biological samples collected from subjects\"\n... )\n&gt;&gt;&gt; sample_table = ml.create_table(sample_def)\n</code></pre> <p>Table with unique key constraint:</p> <pre><code>&gt;&gt;&gt; from deriva_ml import (\n...     TableDefinition, ColumnDefinition, KeyDefinition, BuiltinTypes\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; protocol_def = TableDefinition(\n...     name=\"Protocol\",\n...     column_defs=[\n...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n...         ColumnDefinition(name=\"Version\", type=BuiltinTypes.text, nullok=False),\n...         ColumnDefinition(name=\"Description\", type=BuiltinTypes.markdown),\n...     ],\n...     key_defs=[\n...         KeyDefinition(\n...             colnames=[\"Name\", \"Version\"],\n...             constraint_names=[[\"myschema\", \"Protocol_Name_Version_key\"]],\n...             comment=\"Each protocol name+version must be unique\"\n...         )\n...     ],\n...     comment=\"Experimental protocols with versioning\"\n... )\n&gt;&gt;&gt; protocol_table = ml.create_table(protocol_def)\n</code></pre> <p>Batch creation without navbar updates:</p> <pre><code>&gt;&gt;&gt; ml.create_table(table1_def, update_navbar=False)\n&gt;&gt;&gt; ml.create_table(table2_def, update_navbar=False)\n&gt;&gt;&gt; ml.create_table(table3_def, update_navbar=False)\n&gt;&gt;&gt; ml.apply_catalog_annotations()  # Update navbar once at the end\n</code></pre> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def create_table(self, table: TableDefinition, schema: str | None = None, update_navbar: bool = True) -&gt; Table:\n    \"\"\"Creates a new table in the domain schema.\n\n    Creates a table using the provided TableDefinition object, which specifies the table structure\n    including columns, keys, and foreign key relationships. The table is created in the domain\n    schema associated with this DerivaML instance.\n\n    **Required Classes**:\n    Import the following classes from deriva_ml to define tables:\n\n    - ``TableDefinition``: Defines the complete table structure\n    - ``ColumnDefinition``: Defines individual columns with types and constraints\n    - ``KeyDefinition``: Defines unique key constraints (optional)\n    - ``ForeignKeyDefinition``: Defines foreign key relationships to other tables (optional)\n    - ``BuiltinTypes``: Enum of available column data types\n\n    **Available Column Types** (BuiltinTypes enum):\n    ``text``, ``int2``, ``int4``, ``int8``, ``float4``, ``float8``, ``boolean``,\n    ``date``, ``timestamp``, ``timestamptz``, ``json``, ``jsonb``, ``markdown``,\n    ``ermrest_uri``, ``ermrest_rid``, ``ermrest_rcb``, ``ermrest_rmb``,\n    ``ermrest_rct``, ``ermrest_rmt``\n\n    Args:\n        table: A TableDefinition object containing the complete specification of the table to create.\n        update_navbar: If True (default), automatically updates the navigation bar to include\n            the new table. Set to False during batch table creation to avoid redundant updates,\n            then call apply_catalog_annotations() once at the end.\n\n    Returns:\n        Table: The newly created ERMRest table object.\n\n    Raises:\n        DerivaMLException: If table creation fails or the definition is invalid.\n\n    Examples:\n        **Simple table with basic columns**:\n\n            &gt;&gt;&gt; from deriva_ml import TableDefinition, ColumnDefinition, BuiltinTypes\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; table_def = TableDefinition(\n            ...     name=\"Experiment\",\n            ...     column_defs=[\n            ...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n            ...         ColumnDefinition(name=\"Date\", type=BuiltinTypes.date),\n            ...         ColumnDefinition(name=\"Description\", type=BuiltinTypes.markdown),\n            ...         ColumnDefinition(name=\"Score\", type=BuiltinTypes.float4),\n            ...     ],\n            ...     comment=\"Records of experimental runs\"\n            ... )\n            &gt;&gt;&gt; experiment_table = ml.create_table(table_def)\n\n        **Table with foreign key to another table**:\n\n            &gt;&gt;&gt; from deriva_ml import (\n            ...     TableDefinition, ColumnDefinition, ForeignKeyDefinition, BuiltinTypes\n            ... )\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create a Sample table that references Subject\n            &gt;&gt;&gt; sample_def = TableDefinition(\n            ...     name=\"Sample\",\n            ...     column_defs=[\n            ...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n            ...         ColumnDefinition(name=\"Subject\", type=BuiltinTypes.text, nullok=False),\n            ...         ColumnDefinition(name=\"Collection_Date\", type=BuiltinTypes.date),\n            ...     ],\n            ...     fkey_defs=[\n            ...         ForeignKeyDefinition(\n            ...             colnames=[\"Subject\"],\n            ...             pk_sname=ml.default_schema,  # Schema of referenced table\n            ...             pk_tname=\"Subject\",          # Name of referenced table\n            ...             pk_colnames=[\"RID\"],         # Column(s) in referenced table\n            ...             on_delete=\"CASCADE\",         # Delete samples when subject deleted\n            ...         )\n            ...     ],\n            ...     comment=\"Biological samples collected from subjects\"\n            ... )\n            &gt;&gt;&gt; sample_table = ml.create_table(sample_def)\n\n        **Table with unique key constraint**:\n\n            &gt;&gt;&gt; from deriva_ml import (\n            ...     TableDefinition, ColumnDefinition, KeyDefinition, BuiltinTypes\n            ... )\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; protocol_def = TableDefinition(\n            ...     name=\"Protocol\",\n            ...     column_defs=[\n            ...         ColumnDefinition(name=\"Name\", type=BuiltinTypes.text, nullok=False),\n            ...         ColumnDefinition(name=\"Version\", type=BuiltinTypes.text, nullok=False),\n            ...         ColumnDefinition(name=\"Description\", type=BuiltinTypes.markdown),\n            ...     ],\n            ...     key_defs=[\n            ...         KeyDefinition(\n            ...             colnames=[\"Name\", \"Version\"],\n            ...             constraint_names=[[\"myschema\", \"Protocol_Name_Version_key\"]],\n            ...             comment=\"Each protocol name+version must be unique\"\n            ...         )\n            ...     ],\n            ...     comment=\"Experimental protocols with versioning\"\n            ... )\n            &gt;&gt;&gt; protocol_table = ml.create_table(protocol_def)\n\n        **Batch creation without navbar updates**:\n\n            &gt;&gt;&gt; ml.create_table(table1_def, update_navbar=False)\n            &gt;&gt;&gt; ml.create_table(table2_def, update_navbar=False)\n            &gt;&gt;&gt; ml.create_table(table3_def, update_navbar=False)\n            &gt;&gt;&gt; ml.apply_catalog_annotations()  # Update navbar once at the end\n    \"\"\"\n    # Use default schema if none specified\n    schema = schema or self.model._require_default_schema()\n\n    # Create table in domain schema using provided definition\n    # Handle both TableDefinition (dataclass with to_dict) and plain dicts\n    table_dict = table.to_dict() if hasattr(table, 'to_dict') else table\n    new_table = self.model.schemas[schema].create_table(table_dict)\n\n    # Update navbar to include the new table\n    if update_navbar:\n        self.apply_catalog_annotations()\n\n    return new_table\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.create_vocabulary","title":"create_vocabulary","text":"<pre><code>create_vocabulary(\n    vocab_name: str,\n    comment: str = \"\",\n    schema: str | None = None,\n    update_navbar: bool = True,\n) -&gt; Table\n</code></pre> <p>Creates a controlled vocabulary table.</p> <p>A controlled vocabulary table maintains a list of standardized terms and their definitions. Each term can have synonyms and descriptions to ensure consistent terminology usage across the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>vocab_name</code> <code>str</code> <p>Name for the new vocabulary table. Must be a valid SQL identifier.</p> required <code>comment</code> <code>str</code> <p>Description of the vocabulary's purpose and usage. Defaults to empty string.</p> <code>''</code> <code>schema</code> <code>str | None</code> <p>Schema name to create the table in. If None, uses domain_schema.</p> <code>None</code> <code>update_navbar</code> <code>bool</code> <p>If True (default), automatically updates the navigation bar to include the new vocabulary table. Set to False during batch table creation to avoid redundant updates, then call apply_catalog_annotations() once at the end.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>ERMRest table object representing the newly created vocabulary table.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If vocab_name is invalid or already exists.</p> <p>Examples:</p> <p>Create a vocabulary for tissue types:</p> <pre><code>&gt;&gt;&gt; table = ml.create_vocabulary(\n...     vocab_name=\"tissue_types\",\n...     comment=\"Standard tissue classifications\",\n...     schema=\"bio_schema\"\n... )\n</code></pre> <p>Create multiple vocabularies without updating navbar until the end:</p> <pre><code>&gt;&gt;&gt; ml.create_vocabulary(\"Species\", update_navbar=False)\n&gt;&gt;&gt; ml.create_vocabulary(\"Tissue_Type\", update_navbar=False)\n&gt;&gt;&gt; ml.apply_catalog_annotations()  # Update navbar once\n</code></pre> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def create_vocabulary(\n    self, vocab_name: str, comment: str = \"\", schema: str | None = None, update_navbar: bool = True\n) -&gt; Table:\n    \"\"\"Creates a controlled vocabulary table.\n\n    A controlled vocabulary table maintains a list of standardized terms and their definitions. Each term can have\n    synonyms and descriptions to ensure consistent terminology usage across the dataset.\n\n    Args:\n        vocab_name: Name for the new vocabulary table. Must be a valid SQL identifier.\n        comment: Description of the vocabulary's purpose and usage. Defaults to empty string.\n        schema: Schema name to create the table in. If None, uses domain_schema.\n        update_navbar: If True (default), automatically updates the navigation bar to include\n            the new vocabulary table. Set to False during batch table creation to avoid\n            redundant updates, then call apply_catalog_annotations() once at the end.\n\n    Returns:\n        Table: ERMRest table object representing the newly created vocabulary table.\n\n    Raises:\n        DerivaMLException: If vocab_name is invalid or already exists.\n\n    Examples:\n        Create a vocabulary for tissue types:\n\n            &gt;&gt;&gt; table = ml.create_vocabulary(\n            ...     vocab_name=\"tissue_types\",\n            ...     comment=\"Standard tissue classifications\",\n            ...     schema=\"bio_schema\"\n            ... )\n\n        Create multiple vocabularies without updating navbar until the end:\n\n            &gt;&gt;&gt; ml.create_vocabulary(\"Species\", update_navbar=False)\n            &gt;&gt;&gt; ml.create_vocabulary(\"Tissue_Type\", update_navbar=False)\n            &gt;&gt;&gt; ml.apply_catalog_annotations()  # Update navbar once\n    \"\"\"\n    # Use default schema if none specified\n    schema = schema or self.model._require_default_schema()\n\n    # Create and return vocabulary table with RID-based URI pattern\n    try:\n        vocab_table = self.model.schemas[schema].create_table(\n            VocabularyTableDef(\n                name=vocab_name,\n                curie_template=f\"{self.project_name}:{{RID}}\",\n                comment=comment,\n            )\n        )\n    except ValueError:\n        raise DerivaMLException(f\"Table {vocab_name} already exist\")\n\n    # Update navbar to include the new vocabulary table\n    if update_navbar:\n        self.apply_catalog_annotations()\n\n    return vocab_table\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.create_workflow","title":"create_workflow","text":"<pre><code>create_workflow(\n    name: str,\n    workflow_type: str,\n    description: str = \"\",\n) -&gt; Workflow\n</code></pre> <p>Creates a new workflow definition.</p> <p>Creates a Workflow object that represents a computational process or analysis pipeline. The workflow type must be a term from the controlled vocabulary. This method is typically used to define new analysis workflows before execution.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the workflow.</p> required <code>workflow_type</code> <code>str</code> <p>Type of workflow (must exist in workflow_type vocabulary).</p> required <code>description</code> <code>str</code> <p>Description of what the workflow does.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>Workflow</code> <code>Workflow</code> <p>New workflow object ready for registration.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If workflow_type is not in the vocabulary.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; workflow = ml.create_workflow(\n...     name=\"RNA Analysis\",\n...     workflow_type=\"python_notebook\",\n...     description=\"RNA sequence analysis pipeline\"\n... )\n&gt;&gt;&gt; rid = ml.add_workflow(workflow)\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/workflow.py</code> <pre><code>def create_workflow(self, name: str, workflow_type: str, description: str = \"\") -&gt; Workflow:\n    \"\"\"Creates a new workflow definition.\n\n    Creates a Workflow object that represents a computational process or analysis pipeline. The workflow type\n    must be a term from the controlled vocabulary. This method is typically used to define new analysis\n    workflows before execution.\n\n    Args:\n        name: Name of the workflow.\n        workflow_type: Type of workflow (must exist in workflow_type vocabulary).\n        description: Description of what the workflow does.\n\n    Returns:\n        Workflow: New workflow object ready for registration.\n\n    Raises:\n        DerivaMLException: If workflow_type is not in the vocabulary.\n\n    Examples:\n        &gt;&gt;&gt; workflow = ml.create_workflow(\n        ...     name=\"RNA Analysis\",\n        ...     workflow_type=\"python_notebook\",\n        ...     description=\"RNA sequence analysis pipeline\"\n        ... )\n        &gt;&gt;&gt; rid = ml.add_workflow(workflow)\n    \"\"\"\n    # Validate workflow type exists in vocabulary\n    self.lookup_term(MLVocab.workflow_type, workflow_type)\n\n    # Create and return a new workflow object\n    return Workflow(name=name, workflow_type=workflow_type, description=description)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.delete_dataset","title":"delete_dataset","text":"<pre><code>delete_dataset(\n    dataset: \"Dataset\",\n    recurse: bool = False,\n) -&gt; None\n</code></pre> <p>Delete a dataset from the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>'Dataset'</code> <p>The dataset to delete.</p> required <code>recurse</code> <code>bool</code> <p>If True, delete the dataset along with any nested datasets. (Default value = False)</p> <code>False</code> Source code in <code>src/deriva_ml/core/mixins/dataset.py</code> <pre><code>def delete_dataset(self, dataset: \"Dataset\", recurse: bool = False) -&gt; None:\n    \"\"\"Delete a dataset from the catalog.\n\n    Args:\n        dataset: The dataset to delete.\n        recurse: If True, delete the dataset along with any nested datasets. (Default value = False)\n    \"\"\"\n    # Get association table entries for this dataset_table\n    # Delete association table entries\n    dataset_rid = dataset.dataset_rid\n    if not self.model.is_dataset_rid(dataset.dataset_rid):\n        raise DerivaMLException(\"Dataset_rid is not a dataset.\")\n\n    if parents := dataset.list_dataset_parents():\n        raise DerivaMLException(f'Dataset \"{dataset}\" is in a nested dataset: {parents}.')\n\n    pb = self.pathBuilder()\n    dataset_path = pb.schemas[self._dataset_table.schema.name].tables[self._dataset_table.name]\n\n    # list_dataset_children returns Dataset objects, so extract their RIDs\n    child_rids = [ds.dataset_rid for ds in dataset.list_dataset_children()] if recurse else []\n    rid_list = [dataset_rid] + child_rids\n    dataset_path.update([{\"RID\": r, \"Deleted\": True} for r in rid_list])\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.delete_feature","title":"delete_feature","text":"<pre><code>delete_feature(\n    table: Table | str,\n    feature_name: str,\n) -&gt; bool\n</code></pre> <p>Removes a feature definition and its data.</p> <p>Deletes the feature and its implementation table from the catalog. This operation cannot be undone and will remove all feature values associated with this feature.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>The table containing the feature, either as name or Table object.</p> required <code>feature_name</code> <code>str</code> <p>Name of the feature to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the feature was successfully deleted, False if it didn't exist.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If deletion fails due to constraints or permissions.</p> Example <p>success = ml.delete_feature(\"samples\", \"obsolete_feature\") print(\"Deleted\" if success else \"Not found\")</p> Source code in <code>src/deriva_ml/core/mixins/feature.py</code> <pre><code>def delete_feature(self, table: Table | str, feature_name: str) -&gt; bool:\n    \"\"\"Removes a feature definition and its data.\n\n    Deletes the feature and its implementation table from the catalog. This operation cannot be undone and\n    will remove all feature values associated with this feature.\n\n    Args:\n        table: The table containing the feature, either as name or Table object.\n        feature_name: Name of the feature to delete.\n\n    Returns:\n        bool: True if the feature was successfully deleted, False if it didn't exist.\n\n    Raises:\n        DerivaMLException: If deletion fails due to constraints or permissions.\n\n    Example:\n        &gt;&gt;&gt; success = ml.delete_feature(\"samples\", \"obsolete_feature\")\n        &gt;&gt;&gt; print(\"Deleted\" if success else \"Not found\")\n    \"\"\"\n    # Get table reference and find feature\n    table = self.model.name_to_table(table)\n    try:\n        # Find and delete the feature's implementation table\n        feature = next(f for f in self.model.find_features(table) if f.feature_name == feature_name)\n        feature.feature_table.drop()\n        return True\n    except StopIteration:\n        return False\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.delete_term","title":"delete_term","text":"<pre><code>delete_term(\n    table: str | Table, term_name: str\n) -&gt; None\n</code></pre> <p>Delete a term from a vocabulary table.</p> <p>Removes a term from the vocabulary. The term must not be in use by any records in the catalog (e.g., no datasets using this dataset type, no assets using this asset type).</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Vocabulary table containing the term (name or Table object).</p> required <code>term_name</code> <code>str</code> <p>Primary name of the term to delete.</p> required <p>Raises:</p> Type Description <code>DerivaMLInvalidTerm</code> <p>If the term doesn't exist in the vocabulary.</p> <code>DerivaMLException</code> <p>If the term is currently in use by other records.</p> Example <p>ml.delete_term(\"Dataset_Type\", \"Obsolete_Type\")</p> Source code in <code>src/deriva_ml/core/mixins/vocabulary.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef delete_term(self, table: str | Table, term_name: str) -&gt; None:\n    \"\"\"Delete a term from a vocabulary table.\n\n    Removes a term from the vocabulary. The term must not be in use by any\n    records in the catalog (e.g., no datasets using this dataset type, no\n    assets using this asset type).\n\n    Args:\n        table: Vocabulary table containing the term (name or Table object).\n        term_name: Primary name of the term to delete.\n\n    Raises:\n        DerivaMLInvalidTerm: If the term doesn't exist in the vocabulary.\n        DerivaMLException: If the term is currently in use by other records.\n\n    Example:\n        &gt;&gt;&gt; ml.delete_term(\"Dataset_Type\", \"Obsolete_Type\")\n    \"\"\"\n    # Look up the term (validates table and term existence)\n    term = self.lookup_term(table, term_name)\n    vocab_table = self.model.name_to_table(table)\n\n    # Check if the term is in use by examining association tables\n    associations = list(vocab_table.find_associations())\n    pb = self.pathBuilder()\n\n    for assoc in associations:\n        assoc_path = pb.schemas[assoc.schema.name].tables[assoc.name]\n        # Check if any rows reference this term\n        count = len(list(assoc_path.filter(getattr(assoc_path, vocab_table.name) == term.name).entities().fetch()))\n        if count &gt; 0:\n            raise DerivaMLException(\n                f\"Cannot delete term '{term_name}' from {vocab_table.name}: \"\n                f\"it is referenced by {count} record(s) in {assoc.name}\"\n            )\n\n    # No references found - safe to delete\n    table_path = pb.schemas[vocab_table.schema.name].tables[vocab_table.name]\n    table_path.filter(table_path.RID == term.rid).delete()\n\n    # Invalidate cache\n    self.clear_vocabulary_cache(table)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.domain_path","title":"domain_path","text":"<pre><code>domain_path(\n    schema: str | None = None,\n) -&gt; datapath.DataPath\n</code></pre> <p>Returns path builder for a domain schema.</p> <p>Provides a convenient way to access tables and construct queries within a domain-specific schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>str | None</code> <p>Schema name to get path builder for. If None, uses default_schema.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataPath</code> <p>datapath._CatalogWrapper: Path builder object scoped to the specified domain schema.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If no schema specified and default_schema is not set.</p> Example <p>domain = ml.domain_path()  # Uses default schema results = domain.my_table.entities().fetch()</p> Source code in <code>src/deriva_ml/core/mixins/path_builder.py</code> <pre><code>def domain_path(self, schema: str | None = None) -&gt; datapath.DataPath:\n    \"\"\"Returns path builder for a domain schema.\n\n    Provides a convenient way to access tables and construct queries within a domain-specific schema.\n\n    Args:\n        schema: Schema name to get path builder for. If None, uses default_schema.\n\n    Returns:\n        datapath._CatalogWrapper: Path builder object scoped to the specified domain schema.\n\n    Raises:\n        DerivaMLException: If no schema specified and default_schema is not set.\n\n    Example:\n        &gt;&gt;&gt; domain = ml.domain_path()  # Uses default schema\n        &gt;&gt;&gt; results = domain.my_table.entities().fetch()\n        &gt;&gt;&gt; # Or with explicit schema:\n        &gt;&gt;&gt; domain = ml.domain_path(\"my_schema\")\n    \"\"\"\n    schema = schema or self.model._require_default_schema()\n    return self.pathBuilder().schemas[schema]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.domain_path--or-with-explicit-schema","title":"Or with explicit schema:","text":"<p>domain = ml.domain_path(\"my_schema\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.download_dataset_bag","title":"download_dataset_bag","text":"<pre><code>download_dataset_bag(\n    dataset: DatasetSpec,\n) -&gt; \"DatasetBag\"\n</code></pre> <p>Downloads a dataset to the local filesystem.</p> <p>Downloads a dataset specified by DatasetSpec to the local filesystem. If the catalog has s3_bucket configured and use_minid is enabled, the bag will be uploaded to S3 and registered with the MINID service.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DatasetSpec</code> <p>Specification of the dataset to download, including version and materialization options.</p> required <p>Returns:</p> Name Type Description <code>DatasetBag</code> <code>'DatasetBag'</code> <p>Object containing: - path: Local filesystem path to downloaded dataset - rid: Dataset's Resource Identifier - minid: Dataset's Minimal Viable Identifier (if MINID enabled)</p> Note <p>MINID support requires s3_bucket to be configured when creating the DerivaML instance. The catalog's use_minid setting controls whether MINIDs are created.</p> <p>Examples:</p> <p>Download with default options:     &gt;&gt;&gt; spec = DatasetSpec(rid=\"1-abc123\")     &gt;&gt;&gt; bag = ml.download_dataset_bag(dataset=spec)     &gt;&gt;&gt; print(f\"Downloaded to {bag.path}\")</p> Source code in <code>src/deriva_ml/core/mixins/dataset.py</code> <pre><code>def download_dataset_bag(\n    self,\n    dataset: DatasetSpec,\n) -&gt; \"DatasetBag\":\n    \"\"\"Downloads a dataset to the local filesystem.\n\n    Downloads a dataset specified by DatasetSpec to the local filesystem. If the catalog\n    has s3_bucket configured and use_minid is enabled, the bag will be uploaded to S3\n    and registered with the MINID service.\n\n    Args:\n        dataset: Specification of the dataset to download, including version and materialization options.\n\n    Returns:\n        DatasetBag: Object containing:\n            - path: Local filesystem path to downloaded dataset\n            - rid: Dataset's Resource Identifier\n            - minid: Dataset's Minimal Viable Identifier (if MINID enabled)\n\n    Note:\n        MINID support requires s3_bucket to be configured when creating the DerivaML instance.\n        The catalog's use_minid setting controls whether MINIDs are created.\n\n    Examples:\n        Download with default options:\n            &gt;&gt;&gt; spec = DatasetSpec(rid=\"1-abc123\")\n            &gt;&gt;&gt; bag = ml.download_dataset_bag(dataset=spec)\n            &gt;&gt;&gt; print(f\"Downloaded to {bag.path}\")\n    \"\"\"\n    if not self.model.is_dataset_rid(dataset.rid):\n        raise DerivaMLTableTypeError(\"Dataset\", dataset.rid)\n    ds = self.lookup_dataset(dataset)\n    return ds.download_dataset_bag(\n        version=dataset.version,\n        materialize=dataset.materialize,\n        use_minid=self.use_minid,\n        exclude_tables=dataset.exclude_tables,\n    )\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.download_dir","title":"download_dir","text":"<pre><code>download_dir(\n    cached: bool = False,\n) -&gt; Path\n</code></pre> <p>Returns the appropriate download directory.</p> <p>Provides the appropriate directory path for storing downloaded files, either in the cache or working directory.</p> <p>Parameters:</p> Name Type Description Default <code>cached</code> <code>bool</code> <p>If True, returns the cache directory path. If False, returns the working directory path.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Directory path where downloaded files should be stored.</p> Example <p>cache_dir = ml.download_dir(cached=True) work_dir = ml.download_dir(cached=False)</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def download_dir(self, cached: bool = False) -&gt; Path:\n    \"\"\"Returns the appropriate download directory.\n\n    Provides the appropriate directory path for storing downloaded files, either in the cache or working directory.\n\n    Args:\n        cached: If True, returns the cache directory path. If False, returns the working directory path.\n\n    Returns:\n        Path: Directory path where downloaded files should be stored.\n\n    Example:\n        &gt;&gt;&gt; cache_dir = ml.download_dir(cached=True)\n        &gt;&gt;&gt; work_dir = ml.download_dir(cached=False)\n    \"\"\"\n    # Return cache directory if cached=True, otherwise working directory\n    return self.cache_dir if cached else self.working_dir\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.feature_record_class","title":"feature_record_class","text":"<pre><code>feature_record_class(\n    table: str | Table,\n    feature_name: str,\n) -&gt; type[FeatureRecord]\n</code></pre> <p>Returns a dynamically generated Pydantic model class for creating feature records.</p> <p>Each feature has a unique set of columns based on its definition (terms, assets, metadata). This method returns a Pydantic class with fields corresponding to those columns, providing:</p> <ul> <li>Type validation: Values are validated against expected types (str, int, float, Path)</li> <li>Required field checking: Non-nullable columns must be provided</li> <li>Default values: Feature_Name is pre-filled with the feature's name</li> </ul> <p>Field types in the generated class: - <code>{TargetTable}</code> (str): Required. RID of the target record (e.g., Image RID) - <code>Execution</code> (str, optional): RID of the execution for provenance tracking - <code>Feature_Name</code> (str): Pre-filled with the feature name - Term columns (str): Accept vocabulary term names - Asset columns (str | Path): Accept asset RIDs or file paths - Value columns: Accept values matching the column type (int, float, str)</p> <p>Use <code>lookup_feature()</code> to inspect the feature's structure and see what columns are available.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>The table containing the feature, either as name or Table object.</p> required <code>feature_name</code> <code>str</code> <p>Name of the feature to create a record class for.</p> required <p>Returns:</p> Type Description <code>type[FeatureRecord]</code> <p>type[FeatureRecord]: A Pydantic model class for creating validated feature records. The class name follows the pattern <code>{TargetTable}Feature{FeatureName}</code>.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the feature doesn't exist or the table is invalid.</p> Example Source code in <code>src/deriva_ml/core/mixins/feature.py</code> <pre><code>def feature_record_class(self, table: str | Table, feature_name: str) -&gt; type[FeatureRecord]:\n    \"\"\"Returns a dynamically generated Pydantic model class for creating feature records.\n\n    Each feature has a unique set of columns based on its definition (terms, assets, metadata).\n    This method returns a Pydantic class with fields corresponding to those columns, providing:\n\n    - **Type validation**: Values are validated against expected types (str, int, float, Path)\n    - **Required field checking**: Non-nullable columns must be provided\n    - **Default values**: Feature_Name is pre-filled with the feature's name\n\n    **Field types in the generated class:**\n    - `{TargetTable}` (str): Required. RID of the target record (e.g., Image RID)\n    - `Execution` (str, optional): RID of the execution for provenance tracking\n    - `Feature_Name` (str): Pre-filled with the feature name\n    - Term columns (str): Accept vocabulary term names\n    - Asset columns (str | Path): Accept asset RIDs or file paths\n    - Value columns: Accept values matching the column type (int, float, str)\n\n    Use `lookup_feature()` to inspect the feature's structure and see what columns\n    are available.\n\n    Args:\n        table: The table containing the feature, either as name or Table object.\n        feature_name: Name of the feature to create a record class for.\n\n    Returns:\n        type[FeatureRecord]: A Pydantic model class for creating validated feature records.\n            The class name follows the pattern `{TargetTable}Feature{FeatureName}`.\n\n    Raises:\n        DerivaMLException: If the feature doesn't exist or the table is invalid.\n\n    Example:\n        &gt;&gt;&gt; # Get the dynamically generated class\n        &gt;&gt;&gt; DiagnosisFeature = ml.feature_record_class(\"Image\", \"Diagnosis\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create a validated feature record\n        &gt;&gt;&gt; record = DiagnosisFeature(\n        ...     Image=\"1-ABC\",           # Target record RID\n        ...     Diagnosis_Type=\"Normal\", # Vocabulary term\n        ...     confidence=0.95,         # Metadata column\n        ...     Execution=\"2-XYZ\"        # Provenance\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Convert to dict for insertion\n        &gt;&gt;&gt; record.model_dump()\n        {'Image': '1-ABC', 'Diagnosis_Type': 'Normal', 'confidence': 0.95, ...}\n    \"\"\"\n    # Look up a feature and return its record class\n    return self.lookup_feature(table, feature_name).feature_record_class()\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.feature_record_class--get-the-dynamically-generated-class","title":"Get the dynamically generated class","text":"<p>DiagnosisFeature = ml.feature_record_class(\"Image\", \"Diagnosis\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.feature_record_class--create-a-validated-feature-record","title":"Create a validated feature record","text":"<p>record = DiagnosisFeature( ...     Image=\"1-ABC\",           # Target record RID ...     Diagnosis_Type=\"Normal\", # Vocabulary term ...     confidence=0.95,         # Metadata column ...     Execution=\"2-XYZ\"        # Provenance ... )</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.feature_record_class--convert-to-dict-for-insertion","title":"Convert to dict for insertion","text":"<p>record.model_dump() {'Image': '1-ABC', 'Diagnosis_Type': 'Normal', 'confidence': 0.95, ...}</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_assets","title":"find_assets","text":"<pre><code>find_assets(\n    asset_table: Table\n    | str\n    | None = None,\n    asset_type: str | None = None,\n) -&gt; Iterable[\"Asset\"]\n</code></pre> <p>Find assets in the catalog.</p> <p>Returns an iterable of Asset objects matching the specified criteria. If no criteria are specified, returns all assets from all asset tables.</p> <p>Parameters:</p> Name Type Description Default <code>asset_table</code> <code>Table | str | None</code> <p>Optional table or table name to search. If None, searches all asset tables.</p> <code>None</code> <code>asset_type</code> <code>str | None</code> <p>Optional asset type to filter by. Only returns assets with this type.</p> <code>None</code> <p>Returns:</p> Type Description <code>Iterable['Asset']</code> <p>Iterable of Asset objects matching the criteria.</p> Example Source code in <code>src/deriva_ml/core/mixins/asset.py</code> <pre><code>def find_assets(\n    self,\n    asset_table: Table | str | None = None,\n    asset_type: str | None = None,\n) -&gt; Iterable[\"Asset\"]:\n    \"\"\"Find assets in the catalog.\n\n    Returns an iterable of Asset objects matching the specified criteria.\n    If no criteria are specified, returns all assets from all asset tables.\n\n    Args:\n        asset_table: Optional table or table name to search. If None, searches\n            all asset tables.\n        asset_type: Optional asset type to filter by. Only returns assets\n            with this type.\n\n    Returns:\n        Iterable of Asset objects matching the criteria.\n\n    Example:\n        &gt;&gt;&gt; # Find all assets in the Model table\n        &gt;&gt;&gt; models = list(ml.find_assets(asset_table=\"Model\"))\n\n        &gt;&gt;&gt; # Find all assets with type \"Training_Data\"\n        &gt;&gt;&gt; training = list(ml.find_assets(asset_type=\"Training_Data\"))\n\n        &gt;&gt;&gt; # Find all assets across all tables\n        &gt;&gt;&gt; all_assets = list(ml.find_assets())\n    \"\"\"\n    # Determine which tables to search\n    if asset_table is not None:\n        tables = [self.model.name_to_table(asset_table)]\n    else:\n        tables = self.list_asset_tables()\n\n    for table in tables:\n        # Get all assets from this table (now returns Asset objects)\n        for asset in self.list_assets(table):\n            # Filter by asset type if specified\n            if asset_type is not None:\n                if asset_type not in asset.asset_types:\n                    continue\n            yield asset\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_assets--find-all-assets-in-the-model-table","title":"Find all assets in the Model table","text":"<p>models = list(ml.find_assets(asset_table=\"Model\"))</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_assets--find-all-assets-with-type-training_data","title":"Find all assets with type \"Training_Data\"","text":"<p>training = list(ml.find_assets(asset_type=\"Training_Data\"))</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_assets--find-all-assets-across-all-tables","title":"Find all assets across all tables","text":"<p>all_assets = list(ml.find_assets())</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_datasets","title":"find_datasets","text":"<pre><code>find_datasets(\n    deleted: bool = False,\n) -&gt; Iterable[\"Dataset\"]\n</code></pre> <p>List all datasets in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>deleted</code> <code>bool</code> <p>If True, include datasets that have been marked as deleted.</p> <code>False</code> <p>Returns:</p> Type Description <code>Iterable['Dataset']</code> <p>Iterable of Dataset objects.</p> Example <p>datasets = list(ml.find_datasets()) for ds in datasets: ...     print(f\"{ds.dataset_rid}: {ds.description}\")</p> Source code in <code>src/deriva_ml/core/mixins/dataset.py</code> <pre><code>def find_datasets(self, deleted: bool = False) -&gt; Iterable[\"Dataset\"]:\n    \"\"\"List all datasets in the catalog.\n\n    Args:\n        deleted: If True, include datasets that have been marked as deleted.\n\n    Returns:\n        Iterable of Dataset objects.\n\n    Example:\n        &gt;&gt;&gt; datasets = list(ml.find_datasets())\n        &gt;&gt;&gt; for ds in datasets:\n        ...     print(f\"{ds.dataset_rid}: {ds.description}\")\n    \"\"\"\n    # Import here to avoid circular imports\n    from deriva_ml.dataset.dataset import Dataset\n\n    # Get datapath to the Dataset table\n    pb = self.pathBuilder()\n    dataset_path = pb.schemas[self._dataset_table.schema.name].tables[self._dataset_table.name]\n\n    if deleted:\n        filtered_path = dataset_path\n    else:\n        filtered_path = dataset_path.filter(\n            (dataset_path.Deleted == False) | (dataset_path.Deleted == None)  # noqa: E711, E712\n        )\n\n    # Create Dataset objects - dataset_types is now a property that fetches from catalog\n    datasets = []\n    for dataset in filtered_path.entities().fetch():\n        datasets.append(\n            Dataset(\n                self,  # type: ignore[arg-type]\n                dataset_rid=dataset[\"RID\"],\n                description=dataset[\"Description\"],\n            )\n        )\n    return datasets\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_executions","title":"find_executions","text":"<pre><code>find_executions(\n    workflow: \"Workflow | RID | None\" = None,\n    workflow_type: str | None = None,\n    status: Status | None = None,\n) -&gt; Iterable[\"ExecutionRecord\"]\n</code></pre> <p>List all executions in the catalog.</p> <p>Returns ExecutionRecord objects for each execution. These provide access to execution metadata and allow updating mutable properties.</p> <p>Parameters:</p> Name Type Description Default <code>workflow</code> <code>'Workflow | RID | None'</code> <p>Optional Workflow object or RID to filter by.</p> <code>None</code> <code>workflow_type</code> <code>str | None</code> <p>Optional workflow type name to filter by (e.g., \"python_script\"). This filters by the Workflow_Type vocabulary term.</p> <code>None</code> <code>status</code> <code>Status | None</code> <p>Optional status to filter by (e.g., Status.completed).</p> <code>None</code> <p>Returns:</p> Type Description <code>Iterable['ExecutionRecord']</code> <p>Iterable of ExecutionRecord objects.</p> Example <p>List all executions::</p> <pre><code>&gt;&gt;&gt; for record in ml.find_executions():\n...     print(f\"{record.execution_rid}: {record.status}\")\n</code></pre> <p>Filter by status::</p> <pre><code>&gt;&gt;&gt; completed = list(ml.find_executions(status=Status.completed))\n</code></pre> <p>Filter by specific workflow::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; for record in ml.find_executions(workflow=workflow):\n...     print(f\"{record.execution_rid}: {record.description}\")\n</code></pre> <p>Filter by workflow type (all notebooks)::</p> <pre><code>&gt;&gt;&gt; notebooks = list(ml.find_executions(workflow_type=\"python_notebook\"))\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/execution.py</code> <pre><code>def find_executions(\n    self,\n    workflow: \"Workflow | RID | None\" = None,\n    workflow_type: str | None = None,\n    status: Status | None = None,\n) -&gt; Iterable[\"ExecutionRecord\"]:\n    \"\"\"List all executions in the catalog.\n\n    Returns ExecutionRecord objects for each execution. These provide access\n    to execution metadata and allow updating mutable properties.\n\n    Args:\n        workflow: Optional Workflow object or RID to filter by.\n        workflow_type: Optional workflow type name to filter by (e.g., \"python_script\").\n            This filters by the Workflow_Type vocabulary term.\n        status: Optional status to filter by (e.g., Status.completed).\n\n    Returns:\n        Iterable of ExecutionRecord objects.\n\n    Example:\n        List all executions::\n\n            &gt;&gt;&gt; for record in ml.find_executions():\n            ...     print(f\"{record.execution_rid}: {record.status}\")\n\n        Filter by status::\n\n            &gt;&gt;&gt; completed = list(ml.find_executions(status=Status.completed))\n\n        Filter by specific workflow::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; for record in ml.find_executions(workflow=workflow):\n            ...     print(f\"{record.execution_rid}: {record.description}\")\n\n        Filter by workflow type (all notebooks)::\n\n            &gt;&gt;&gt; notebooks = list(ml.find_executions(workflow_type=\"python_notebook\"))\n    \"\"\"\n    # Import for type checking\n    from deriva_ml.execution.workflow import Workflow as WorkflowClass\n\n    # Get datapath to the Execution table\n    pb = self.pathBuilder()\n    execution_path = pb.schemas[self.ml_schema].Execution\n\n    # Apply filters\n    filtered_path = execution_path\n\n    # Filter by specific workflow\n    if workflow:\n        workflow_rid = workflow.rid if isinstance(workflow, WorkflowClass) else workflow\n        filtered_path = filtered_path.filter(execution_path.Workflow == workflow_rid)\n\n    # Filter by workflow type - need to join with Workflow table\n    if workflow_type:\n        workflow_path = pb.schemas[self.ml_schema].Workflow\n        # Link to workflows with matching type\n        filtered_path = (\n            filtered_path\n            .link(workflow_path, on=(execution_path.Workflow == workflow_path.RID))\n            .filter(workflow_path.Workflow_Type == workflow_type)\n        )\n\n    if status:\n        filtered_path = filtered_path.filter(execution_path.Status == status.value)\n\n    # Create ExecutionRecord objects\n    for exec_record in filtered_path.entities().fetch():\n        yield self.lookup_execution(exec_record[\"RID\"])\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_experiments","title":"find_experiments","text":"<pre><code>find_experiments(\n    workflow_rid: RID | None = None,\n    status: Status | None = None,\n) -&gt; Iterable[\"Experiment\"]\n</code></pre> <p>List all experiments (executions with Hydra configuration) in the catalog.</p> <p>Creates Experiment objects for analyzing completed ML model runs. Only returns executions that have Hydra configuration metadata (i.e., a config.yaml file in Execution_Metadata assets).</p> <p>Parameters:</p> Name Type Description Default <code>workflow_rid</code> <code>RID | None</code> <p>Optional workflow RID to filter by.</p> <code>None</code> <code>status</code> <code>Status | None</code> <p>Optional status to filter by (e.g., Status.Completed).</p> <code>None</code> <p>Returns:</p> Type Description <code>Iterable['Experiment']</code> <p>Iterable of Experiment objects for executions with Hydra config.</p> Example <p>experiments = list(ml.find_experiments(status=Status.Completed)) for exp in experiments: ...     print(f\"{exp.name}: {exp.config_choices}\")</p> Source code in <code>src/deriva_ml/core/mixins/execution.py</code> <pre><code>def find_experiments(\n    self,\n    workflow_rid: RID | None = None,\n    status: Status | None = None,\n) -&gt; Iterable[\"Experiment\"]:\n    \"\"\"List all experiments (executions with Hydra configuration) in the catalog.\n\n    Creates Experiment objects for analyzing completed ML model runs.\n    Only returns executions that have Hydra configuration metadata\n    (i.e., a config.yaml file in Execution_Metadata assets).\n\n    Args:\n        workflow_rid: Optional workflow RID to filter by.\n        status: Optional status to filter by (e.g., Status.Completed).\n\n    Returns:\n        Iterable of Experiment objects for executions with Hydra config.\n\n    Example:\n        &gt;&gt;&gt; experiments = list(ml.find_experiments(status=Status.Completed))\n        &gt;&gt;&gt; for exp in experiments:\n        ...     print(f\"{exp.name}: {exp.config_choices}\")\n    \"\"\"\n    import re\n\n    from deriva_ml.experiment import Experiment\n\n    # Get datapath to tables\n    pb = self.pathBuilder()\n    execution_path = pb.schemas[self.ml_schema].Execution\n    metadata_path = pb.schemas[self.ml_schema].Execution_Metadata\n    meta_exec_path = pb.schemas[self.ml_schema].Execution_Metadata_Execution\n\n    # Find executions that have metadata assets with config.yaml files\n    # Query the association table to find executions with hydra config metadata\n    exec_rids_with_config = set()\n\n    # Get all metadata records and filter for config.yaml files in Python\n    # (ERMrest regex support varies by deployment)\n    config_pattern = re.compile(r\".*-config\\.yaml$\")\n    config_metadata_rids = set()\n    for meta in metadata_path.entities().fetch():\n        filename = meta.get(\"Filename\", \"\")\n        if filename and config_pattern.match(filename):\n            config_metadata_rids.add(meta[\"RID\"])\n\n    if config_metadata_rids:\n        # Query the association table to find which executions have these metadata\n        for assoc_record in meta_exec_path.entities().fetch():\n            if assoc_record.get(\"Execution_Metadata\") in config_metadata_rids:\n                exec_rids_with_config.add(assoc_record[\"Execution\"])\n\n    # Apply additional filters and yield Experiment objects\n    filtered_path = execution_path\n    if workflow_rid:\n        filtered_path = filtered_path.filter(execution_path.Workflow == workflow_rid)\n    if status:\n        filtered_path = filtered_path.filter(execution_path.Status == status.value)\n\n    for exec_record in filtered_path.entities().fetch():\n        if exec_record[\"RID\"] in exec_rids_with_config:\n            yield Experiment(self, exec_record[\"RID\"])  # type: ignore[arg-type]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_features","title":"find_features","text":"<pre><code>find_features(\n    table: str | Table | None = None,\n) -&gt; list[Feature]\n</code></pre> <p>Find features in the catalog.</p> <p>Catalog-level operation to find feature definitions. If a table is specified, returns only features for that table. If no table is specified, returns all features across all tables in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table | None</code> <p>Optional table to find features for. If None, returns all features in the catalog.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Feature]</code> <p>A list of Feature instances describing the features.</p> <p>Examples:</p> <p>Find all features in the catalog:     &gt;&gt;&gt; all_features = ml.find_features()     &gt;&gt;&gt; for f in all_features:     ...     print(f\"{f.target_table.name}.{f.feature_name}\")</p> <p>Find features for a specific table:     &gt;&gt;&gt; image_features = ml.find_features(\"Image\")     &gt;&gt;&gt; print([f.feature_name for f in image_features])</p> Source code in <code>src/deriva_ml/core/mixins/feature.py</code> <pre><code>def find_features(self, table: str | Table | None = None) -&gt; list[Feature]:\n    \"\"\"Find features in the catalog.\n\n    Catalog-level operation to find feature definitions. If a table is specified,\n    returns only features for that table. If no table is specified, returns all\n    features across all tables in the catalog.\n\n    Args:\n        table: Optional table to find features for. If None, returns all features\n            in the catalog.\n\n    Returns:\n        A list of Feature instances describing the features.\n\n    Examples:\n        Find all features in the catalog:\n            &gt;&gt;&gt; all_features = ml.find_features()\n            &gt;&gt;&gt; for f in all_features:\n            ...     print(f\"{f.target_table.name}.{f.feature_name}\")\n\n        Find features for a specific table:\n            &gt;&gt;&gt; image_features = ml.find_features(\"Image\")\n            &gt;&gt;&gt; print([f.feature_name for f in image_features])\n    \"\"\"\n    return list(self.model.find_features(table))\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.find_workflows","title":"find_workflows","text":"<pre><code>find_workflows() -&gt; list[Workflow]\n</code></pre> <p>Find all workflows in the catalog.</p> <p>Catalog-level operation to find all workflow definitions, including their names, URLs, types, versions, and descriptions. Each returned Workflow is bound to the catalog, allowing its description to be updated.</p> <p>Returns:</p> Type Description <code>list[Workflow]</code> <p>list[Workflow]: List of workflow objects, each containing: - name: Workflow name - url: Source code URL - workflow_type: Type of workflow - version: Version identifier - description: Workflow description - rid: Resource identifier - checksum: Source code checksum</p> <p>Examples:</p> <p>List all workflows and their descriptions::</p> <pre><code>&gt;&gt;&gt; workflows = ml.find_workflows()\n&gt;&gt;&gt; for w in workflows:\n...     print(f\"{w.name} (v{w.version}): {w.description}\")\n...     print(f\"  Source: {w.url}\")\n</code></pre> <p>Update a workflow's description (workflows are catalog-bound)::</p> <pre><code>&gt;&gt;&gt; workflows = ml.find_workflows()\n&gt;&gt;&gt; workflows[0].description = \"Updated description\"\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/workflow.py</code> <pre><code>def find_workflows(self) -&gt; list[Workflow]:\n    \"\"\"Find all workflows in the catalog.\n\n    Catalog-level operation to find all workflow definitions, including their\n    names, URLs, types, versions, and descriptions. Each returned Workflow\n    is bound to the catalog, allowing its description to be updated.\n\n    Returns:\n        list[Workflow]: List of workflow objects, each containing:\n            - name: Workflow name\n            - url: Source code URL\n            - workflow_type: Type of workflow\n            - version: Version identifier\n            - description: Workflow description\n            - rid: Resource identifier\n            - checksum: Source code checksum\n\n    Examples:\n        List all workflows and their descriptions::\n\n            &gt;&gt;&gt; workflows = ml.find_workflows()\n            &gt;&gt;&gt; for w in workflows:\n            ...     print(f\"{w.name} (v{w.version}): {w.description}\")\n            ...     print(f\"  Source: {w.url}\")\n\n        Update a workflow's description (workflows are catalog-bound)::\n\n            &gt;&gt;&gt; workflows = ml.find_workflows()\n            &gt;&gt;&gt; workflows[0].description = \"Updated description\"\n    \"\"\"\n    # Get a workflow table path and fetch all workflows\n    workflow_path = self.pathBuilder().schemas[self.ml_schema].Workflow\n    workflows = []\n    for w in workflow_path.entities().fetch():\n        workflow = Workflow(\n            name=w[\"Name\"],\n            url=w[\"URL\"],\n            workflow_type=w[\"Workflow_Type\"],\n            version=w[\"Version\"],\n            description=w[\"Description\"],\n            rid=w[\"RID\"],\n            checksum=w[\"Checksum\"],\n        )\n        # Bind the workflow to this catalog instance\n        workflow._ml_instance = self  # type: ignore[assignment]\n        workflows.append(workflow)\n    return workflows\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.get_cache_size","title":"get_cache_size","text":"<pre><code>get_cache_size() -&gt; dict[\n    str, int | float\n]\n</code></pre> <p>Get the current size of the cache directory.</p> <p>Returns:</p> Type Description <code>dict[str, int | float]</code> <p>dict with keys: - 'total_bytes': Total size in bytes - 'total_mb': Total size in megabytes - 'file_count': Number of files - 'dir_count': Number of directories</p> Example <p>ml = DerivaML('deriva.example.org', 'my_catalog') size = ml.get_cache_size() print(f\"Cache size: {size['total_mb']:.1f} MB ({size['file_count']} files)\")</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def get_cache_size(self) -&gt; dict[str, int | float]:\n    \"\"\"Get the current size of the cache directory.\n\n    Returns:\n        dict with keys:\n            - 'total_bytes': Total size in bytes\n            - 'total_mb': Total size in megabytes\n            - 'file_count': Number of files\n            - 'dir_count': Number of directories\n\n    Example:\n        &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n        &gt;&gt;&gt; size = ml.get_cache_size()\n        &gt;&gt;&gt; print(f\"Cache size: {size['total_mb']:.1f} MB ({size['file_count']} files)\")\n    \"\"\"\n    stats = {'total_bytes': 0, 'total_mb': 0.0, 'file_count': 0, 'dir_count': 0}\n\n    if not self.cache_dir.exists():\n        return stats\n\n    for entry in self.cache_dir.rglob('*'):\n        if entry.is_file():\n            stats['total_bytes'] += entry.stat().st_size\n            stats['file_count'] += 1\n        elif entry.is_dir():\n            stats['dir_count'] += 1\n\n    stats['total_mb'] = stats['total_bytes'] / (1024 * 1024)\n    return stats\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.get_column_annotations","title":"get_column_annotations","text":"<pre><code>get_column_annotations(\n    table: str | Table, column_name: str\n) -&gt; dict[str, Any]\n</code></pre> <p>Get all display-related annotations for a column.</p> <p>Returns the current values of display and column-display annotations for the specified column.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object containing the column.</p> required <code>column_name</code> <code>str</code> <p>Name of the column.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with keys: table, column, display, column_display.</p> <code>dict[str, Any]</code> <p>Missing annotations are None.</p> Example <p>annotations = ml.get_column_annotations(\"Image\", \"Filename\") print(annotations[\"display\"])</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef get_column_annotations(self, table: str | Table, column_name: str) -&gt; dict[str, Any]:\n    \"\"\"Get all display-related annotations for a column.\n\n    Returns the current values of display and column-display annotations\n    for the specified column.\n\n    Args:\n        table: Table name or Table object containing the column.\n        column_name: Name of the column.\n\n    Returns:\n        Dictionary with keys: table, column, display, column_display.\n        Missing annotations are None.\n\n    Example:\n        &gt;&gt;&gt; annotations = ml.get_column_annotations(\"Image\", \"Filename\")\n        &gt;&gt;&gt; print(annotations[\"display\"])\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n    column = table_obj.columns[column_name]\n    return {\n        \"table\": table_obj.name,\n        \"column\": column.name,\n        \"display\": column.annotations.get(DISPLAY_TAG),\n        \"column_display\": column.annotations.get(COLUMN_DISPLAY_TAG),\n    }\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.get_handlebars_template_variables","title":"get_handlebars_template_variables","text":"<pre><code>get_handlebars_template_variables(\n    table: str | Table,\n) -&gt; dict[str, Any]\n</code></pre> <p>Get all available template variables for a table.</p> <p>Returns the columns, foreign keys, and special variables that can be used in Handlebars templates (row_markdown_pattern, markdown_pattern, etc.) for the specified table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with columns, foreign_keys, special_variables, and helper_examples.</p> Example <p>vars = ml.get_handlebars_template_variables(\"Image\") for col in vars[\"columns\"]: ...     print(f\"{col['name']}: {col['template']}\")</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef get_handlebars_template_variables(self, table: str | Table) -&gt; dict[str, Any]:\n    \"\"\"Get all available template variables for a table.\n\n    Returns the columns, foreign keys, and special variables that can be\n    used in Handlebars templates (row_markdown_pattern, markdown_pattern, etc.)\n    for the specified table.\n\n    Args:\n        table: Table name or Table object.\n\n    Returns:\n        Dictionary with columns, foreign_keys, special_variables, and helper_examples.\n\n    Example:\n        &gt;&gt;&gt; vars = ml.get_handlebars_template_variables(\"Image\")\n        &gt;&gt;&gt; for col in vars[\"columns\"]:\n        ...     print(f\"{col['name']}: {col['template']}\")\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    # Get columns\n    columns = []\n    for col in table_obj.columns:\n        columns.append({\n            \"name\": col.name,\n            \"type\": str(col.type.typename),\n            \"template\": \"{{{\" + col.name + \"}}}\",\n            \"row_template\": \"{{{_row.\" + col.name + \"}}}\",\n        })\n\n    # Get foreign keys (outbound)\n    foreign_keys = []\n    for fkey in table_obj.foreign_keys:\n        schema_name = fkey.constraint_schema.name\n        constraint_name = fkey.constraint_name\n        fk_path = f\"$fkeys.{schema_name}.{constraint_name}\"\n\n        # Get columns from referenced table\n        ref_columns = [col.name for col in fkey.pk_table.columns]\n\n        foreign_keys.append({\n            \"constraint\": [schema_name, constraint_name],\n            \"from_columns\": [col.name for col in fkey.columns],\n            \"to_table\": fkey.pk_table.name,\n            \"to_columns\": ref_columns,\n            \"values_template\": \"{{{\" + fk_path + \".values.COLUMN}}}\",\n            \"row_name_template\": \"{{{\" + fk_path + \".rowName}}}\",\n            \"example_column_templates\": [\n                \"{{{\" + fk_path + \".values.\" + c + \"}}}\"\n                for c in ref_columns[:3]  # Show first 3 as examples\n            ]\n        })\n\n    return {\n        \"table\": table_obj.name,\n        \"columns\": columns,\n        \"foreign_keys\": foreign_keys,\n        \"special_variables\": {\n            \"_value\": {\n                \"description\": \"Current column value (in column_display)\",\n                \"template\": \"{{{_value}}}\"\n            },\n            \"_row\": {\n                \"description\": \"Object with all row columns\",\n                \"template\": \"{{{_row.column_name}}}\"\n            },\n            \"$catalog.id\": {\n                \"description\": \"Catalog ID\",\n                \"template\": \"{{{$catalog.id}}}\"\n            },\n            \"$catalog.snapshot\": {\n                \"description\": \"Current snapshot ID\",\n                \"template\": \"{{{$catalog.snapshot}}}\"\n            },\n        },\n        \"helper_examples\": {\n            \"conditional\": \"{{#if column}}...{{else}}...{{/if}}\",\n            \"iteration\": \"{{#each array}}{{{this}}}{{/each}}\",\n            \"comparison\": \"{{#ifCond val1 '==' val2}}...{{/ifCond}}\",\n            \"date_format\": \"{{formatDate RCT 'YYYY-MM-DD'}}\",\n            \"json_output\": \"{{toJSON object}}\"\n        }\n    }\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.get_storage_summary","title":"get_storage_summary","text":"<pre><code>get_storage_summary() -&gt; dict[str, any]\n</code></pre> <p>Get a summary of local storage usage.</p> <p>Returns:</p> Type Description <code>dict[str, any]</code> <p>dict with keys: - 'working_dir': Path to working directory - 'cache_dir': Path to cache directory - 'cache_size_mb': Cache size in MB - 'cache_file_count': Number of files in cache - 'execution_dir_count': Number of execution directories - 'execution_size_mb': Total size of execution directories in MB - 'total_size_mb': Combined size in MB</p> Example <p>ml = DerivaML('deriva.example.org', 'my_catalog') summary = ml.get_storage_summary() print(f\"Total storage: {summary['total_size_mb']:.1f} MB\") print(f\"  Cache: {summary['cache_size_mb']:.1f} MB\") print(f\"  Executions: {summary['execution_size_mb']:.1f} MB\")</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def get_storage_summary(self) -&gt; dict[str, any]:\n    \"\"\"Get a summary of local storage usage.\n\n    Returns:\n        dict with keys:\n            - 'working_dir': Path to working directory\n            - 'cache_dir': Path to cache directory\n            - 'cache_size_mb': Cache size in MB\n            - 'cache_file_count': Number of files in cache\n            - 'execution_dir_count': Number of execution directories\n            - 'execution_size_mb': Total size of execution directories in MB\n            - 'total_size_mb': Combined size in MB\n\n    Example:\n        &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n        &gt;&gt;&gt; summary = ml.get_storage_summary()\n        &gt;&gt;&gt; print(f\"Total storage: {summary['total_size_mb']:.1f} MB\")\n        &gt;&gt;&gt; print(f\"  Cache: {summary['cache_size_mb']:.1f} MB\")\n        &gt;&gt;&gt; print(f\"  Executions: {summary['execution_size_mb']:.1f} MB\")\n    \"\"\"\n    cache_stats = self.get_cache_size()\n    exec_dirs = self.list_execution_dirs()\n\n    exec_size_mb = sum(d['size_mb'] for d in exec_dirs)\n\n    return {\n        'working_dir': str(self.working_dir),\n        'cache_dir': str(self.cache_dir),\n        'cache_size_mb': cache_stats['total_mb'],\n        'cache_file_count': cache_stats['file_count'],\n        'execution_dir_count': len(exec_dirs),\n        'execution_size_mb': exec_size_mb,\n        'total_size_mb': cache_stats['total_mb'] + exec_size_mb,\n    }\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.get_table_annotations","title":"get_table_annotations","text":"<pre><code>get_table_annotations(\n    table: str | Table,\n) -&gt; dict[str, Any]\n</code></pre> <p>Get all display-related annotations for a table.</p> <p>Returns the current values of display, visible-columns, visible-foreign-keys, and table-display annotations for the specified table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with keys: table, schema, display, visible_columns,</p> <code>dict[str, Any]</code> <p>visible_foreign_keys, table_display. Missing annotations are None.</p> Example <p>annotations = ml.get_table_annotations(\"Image\") print(annotations[\"visible_columns\"])</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef get_table_annotations(self, table: str | Table) -&gt; dict[str, Any]:\n    \"\"\"Get all display-related annotations for a table.\n\n    Returns the current values of display, visible-columns, visible-foreign-keys,\n    and table-display annotations for the specified table.\n\n    Args:\n        table: Table name or Table object.\n\n    Returns:\n        Dictionary with keys: table, schema, display, visible_columns,\n        visible_foreign_keys, table_display. Missing annotations are None.\n\n    Example:\n        &gt;&gt;&gt; annotations = ml.get_table_annotations(\"Image\")\n        &gt;&gt;&gt; print(annotations[\"visible_columns\"])\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n    return {\n        \"table\": table_obj.name,\n        \"schema\": table_obj.schema.name,\n        \"display\": table_obj.annotations.get(DISPLAY_TAG),\n        \"visible_columns\": table_obj.annotations.get(VISIBLE_COLUMNS_TAG),\n        \"visible_foreign_keys\": table_obj.annotations.get(VISIBLE_FOREIGN_KEYS_TAG),\n        \"table_display\": table_obj.annotations.get(TABLE_DISPLAY_TAG),\n    }\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.get_table_as_dataframe","title":"get_table_as_dataframe","text":"<pre><code>get_table_as_dataframe(\n    table: str,\n) -&gt; pd.DataFrame\n</code></pre> <p>Get table contents as a pandas DataFrame.</p> <p>Retrieves all contents of a table from the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Name of the table to retrieve.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing all table contents.</p> Source code in <code>src/deriva_ml/core/mixins/path_builder.py</code> <pre><code>def get_table_as_dataframe(self, table: str) -&gt; pd.DataFrame:\n    \"\"\"Get table contents as a pandas DataFrame.\n\n    Retrieves all contents of a table from the catalog.\n\n    Args:\n        table: Name of the table to retrieve.\n\n    Returns:\n        DataFrame containing all table contents.\n    \"\"\"\n    return pd.DataFrame(list(self.get_table_as_dict(table)))\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.get_table_as_dict","title":"get_table_as_dict","text":"<pre><code>get_table_as_dict(\n    table: str,\n) -&gt; Iterable[dict[str, Any]]\n</code></pre> <p>Get table contents as dictionaries.</p> <p>Retrieves all contents of a table from the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Name of the table to retrieve.</p> required <p>Returns:</p> Type Description <code>Iterable[dict[str, Any]]</code> <p>Iterable yielding dictionaries for each row.</p> Source code in <code>src/deriva_ml/core/mixins/path_builder.py</code> <pre><code>def get_table_as_dict(self, table: str) -&gt; Iterable[dict[str, Any]]:\n    \"\"\"Get table contents as dictionaries.\n\n    Retrieves all contents of a table from the catalog.\n\n    Args:\n        table: Name of the table to retrieve.\n\n    Returns:\n        Iterable yielding dictionaries for each row.\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n    pb = self.pathBuilder()\n    yield from pb.schemas[table_obj.schema.name].tables[table_obj.name].entities().fetch()\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.globus_login","title":"globus_login  <code>staticmethod</code>","text":"<pre><code>globus_login(host: str) -&gt; None\n</code></pre> <p>Authenticates with Globus for accessing Deriva services.</p> <p>Performs authentication using Globus Auth to access Deriva services. If already logged in, notifies the user. Uses non-interactive authentication flow without a browser or local server.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>The hostname of the Deriva server to authenticate with (e.g., 'deriva.example.org').</p> required Example <p>DerivaML.globus_login('deriva.example.org') 'Login Successful'</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>@staticmethod\ndef globus_login(host: str) -&gt; None:\n    \"\"\"Authenticates with Globus for accessing Deriva services.\n\n    Performs authentication using Globus Auth to access Deriva services. If already logged in, notifies the user.\n    Uses non-interactive authentication flow without a browser or local server.\n\n    Args:\n        host: The hostname of the Deriva server to authenticate with (e.g., 'deriva.example.org').\n\n    Example:\n        &gt;&gt;&gt; DerivaML.globus_login('deriva.example.org')\n        'Login Successful'\n    \"\"\"\n    gnl = GlobusNativeLogin(host=host)\n    if gnl.is_logged_in([host]):\n        print(\"You are already logged in.\")\n    else:\n        gnl.login(\n            [host],\n            no_local_server=True,\n            no_browser=True,\n            refresh_tokens=True,\n            update_bdbag_keychain=True,\n        )\n        print(\"Login Successful\")\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.instantiate","title":"instantiate  <code>classmethod</code>","text":"<pre><code>instantiate(\n    config: DerivaMLConfig,\n) -&gt; Self\n</code></pre> <p>Create a DerivaML instance from a configuration object.</p> <p>This method is the preferred way to instantiate DerivaML when using hydra-zen for configuration management. It accepts a DerivaMLConfig (Pydantic model) and unpacks it to create the instance.</p> <p>This pattern allows hydra-zen's <code>instantiate()</code> to work with DerivaML:</p> Example with hydra-zen <p>from hydra_zen import builds, instantiate from deriva_ml import DerivaML from deriva_ml.core.config import DerivaMLConfig</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>DerivaMLConfig</code> <p>A DerivaMLConfig object containing all configuration parameters.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new DerivaML instance configured according to the config object.</p> Note <p>The DerivaMLConfig class integrates with Hydra's configuration system and registers custom resolvers for computing working directories. See <code>deriva_ml.core.config</code> for details on configuration options.</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>@classmethod\ndef instantiate(cls, config: DerivaMLConfig) -&gt; Self:\n    \"\"\"Create a DerivaML instance from a configuration object.\n\n    This method is the preferred way to instantiate DerivaML when using hydra-zen\n    for configuration management. It accepts a DerivaMLConfig (Pydantic model) and\n    unpacks it to create the instance.\n\n    This pattern allows hydra-zen's `instantiate()` to work with DerivaML:\n\n    Example with hydra-zen:\n        &gt;&gt;&gt; from hydra_zen import builds, instantiate\n        &gt;&gt;&gt; from deriva_ml import DerivaML\n        &gt;&gt;&gt; from deriva_ml.core.config import DerivaMLConfig\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create a structured config using hydra-zen\n        &gt;&gt;&gt; DerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Configure for your environment\n        &gt;&gt;&gt; conf = DerivaMLConf(\n        ...     hostname='deriva.example.org',\n        ...     catalog_id='42',\n        ...     domain_schema='my_domain',\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Instantiate the config to get a DerivaMLConfig object\n        &gt;&gt;&gt; config = instantiate(conf)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create the DerivaML instance\n        &gt;&gt;&gt; ml = DerivaML.instantiate(config)\n\n    Args:\n        config: A DerivaMLConfig object containing all configuration parameters.\n\n    Returns:\n        A new DerivaML instance configured according to the config object.\n\n    Note:\n        The DerivaMLConfig class integrates with Hydra's configuration system\n        and registers custom resolvers for computing working directories.\n        See `deriva_ml.core.config` for details on configuration options.\n    \"\"\"\n    return cls(**config.model_dump())\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.instantiate--create-a-structured-config-using-hydra-zen","title":"Create a structured config using hydra-zen","text":"<p>DerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.instantiate--configure-for-your-environment","title":"Configure for your environment","text":"<p>conf = DerivaMLConf( ...     hostname='deriva.example.org', ...     catalog_id='42', ...     domain_schema='my_domain', ... )</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.instantiate--instantiate-the-config-to-get-a-derivamlconfig-object","title":"Instantiate the config to get a DerivaMLConfig object","text":"<p>config = instantiate(conf)</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.instantiate--create-the-derivaml-instance","title":"Create the DerivaML instance","text":"<p>ml = DerivaML.instantiate(config)</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_asset_executions","title":"list_asset_executions","text":"<pre><code>list_asset_executions(\n    asset_rid: str,\n    asset_role: str | None = None,\n) -&gt; list[\"ExecutionRecord\"]\n</code></pre> <p>List all executions associated with an asset.</p> <p>Given an asset RID, returns a list of executions that created or used the asset, along with the role (Input/Output) in each execution.</p> <p>Parameters:</p> Name Type Description Default <code>asset_rid</code> <code>str</code> <p>The RID of the asset to look up.</p> required <code>asset_role</code> <code>str | None</code> <p>Optional filter for asset role ('Input' or 'Output'). If None, returns all associations.</p> <code>None</code> <p>Returns:</p> Type Description <code>list['ExecutionRecord']</code> <p>list[ExecutionRecord]: List of ExecutionRecord objects for the executions associated with this asset.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the asset RID is not found or not an asset.</p> Example Source code in <code>src/deriva_ml/core/mixins/asset.py</code> <pre><code>def list_asset_executions(\n    self, asset_rid: str, asset_role: str | None = None\n) -&gt; list[\"ExecutionRecord\"]:\n    \"\"\"List all executions associated with an asset.\n\n    Given an asset RID, returns a list of executions that created or used\n    the asset, along with the role (Input/Output) in each execution.\n\n    Args:\n        asset_rid: The RID of the asset to look up.\n        asset_role: Optional filter for asset role ('Input' or 'Output').\n            If None, returns all associations.\n\n    Returns:\n        list[ExecutionRecord]: List of ExecutionRecord objects for the\n            executions associated with this asset.\n\n    Raises:\n        DerivaMLException: If the asset RID is not found or not an asset.\n\n    Example:\n        &gt;&gt;&gt; # Find all executions that created this asset\n        &gt;&gt;&gt; executions = ml.list_asset_executions(\"1-abc123\", asset_role=\"Output\")\n        &gt;&gt;&gt; for exe in executions:\n        ...     print(f\"Created by execution {exe.execution_rid}\")\n\n        &gt;&gt;&gt; # Find all executions that used this asset as input\n        &gt;&gt;&gt; executions = ml.list_asset_executions(\"1-abc123\", asset_role=\"Input\")\n    \"\"\"\n    # Resolve the RID to find which asset table it belongs to\n    rid_info = self.resolve_rid(asset_rid)  # type: ignore[attr-defined]\n    asset_table = rid_info.table\n\n    if not self.model.is_asset(asset_table):\n        raise DerivaMLException(f\"RID {asset_rid} is not an asset (table: {asset_table.name})\")\n\n    # Find the association table between this asset table and Execution\n    asset_exe_table, asset_fk, execution_fk = self.model.find_association(asset_table, \"Execution\")\n\n    # Build the query\n    pb = self.pathBuilder()\n    asset_exe_path = pb.schemas[asset_exe_table.schema.name].tables[asset_exe_table.name]\n\n    # Filter by asset RID\n    query = asset_exe_path.filter(asset_exe_path.columns[asset_fk] == asset_rid)\n\n    # Optionally filter by asset role\n    if asset_role:\n        query = query.filter(asset_exe_path.Asset_Role == asset_role)\n\n    # Convert to ExecutionRecord objects\n    records = list(query.entities().fetch())\n    return [self.lookup_execution(record[\"Execution\"]) for record in records]  # type: ignore[attr-defined]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_asset_executions--find-all-executions-that-created-this-asset","title":"Find all executions that created this asset","text":"<p>executions = ml.list_asset_executions(\"1-abc123\", asset_role=\"Output\") for exe in executions: ...     print(f\"Created by execution {exe.execution_rid}\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_asset_executions--find-all-executions-that-used-this-asset-as-input","title":"Find all executions that used this asset as input","text":"<p>executions = ml.list_asset_executions(\"1-abc123\", asset_role=\"Input\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_asset_tables","title":"list_asset_tables","text":"<pre><code>list_asset_tables() -&gt; list[Table]\n</code></pre> <p>List all asset tables in the catalog.</p> <p>Returns:</p> Type Description <code>list[Table]</code> <p>List of Table objects that are asset tables.</p> Example <p>for table in ml.list_asset_tables(): ...     print(f\"Asset table: {table.name}\")</p> Source code in <code>src/deriva_ml/core/mixins/asset.py</code> <pre><code>def list_asset_tables(self) -&gt; list[Table]:\n    \"\"\"List all asset tables in the catalog.\n\n    Returns:\n        List of Table objects that are asset tables.\n\n    Example:\n        &gt;&gt;&gt; for table in ml.list_asset_tables():\n        ...     print(f\"Asset table: {table.name}\")\n    \"\"\"\n    tables = []\n    # Include asset tables from all domain schemas\n    for domain_schema in self.domain_schemas:\n        if domain_schema in self.model.schemas:\n            tables.extend([\n                t for t in self.model.schemas[domain_schema].tables.values()\n                if self.model.is_asset(t)\n            ])\n    # Also include ML schema asset tables (like Execution_Asset)\n    tables.extend([\n        t for t in self.model.schemas[self.ml_schema].tables.values()\n        if self.model.is_asset(t)\n    ])\n    return tables\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_assets","title":"list_assets","text":"<pre><code>list_assets(\n    asset_table: Table | str,\n) -&gt; list[\"Asset\"]\n</code></pre> <p>Lists contents of an asset table.</p> <p>Returns a list of Asset objects for the specified asset table.</p> <p>Parameters:</p> Name Type Description Default <code>asset_table</code> <code>Table | str</code> <p>Table or name of the asset table to list assets for.</p> required <p>Returns:</p> Type Description <code>list['Asset']</code> <p>list[Asset]: List of Asset objects for the assets in the table.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the table is not an asset table or doesn't exist.</p> Example <p>assets = ml.list_assets(\"Image\") for asset in assets: ...     print(f\"{asset.asset_rid}: {asset.filename}\")</p> Source code in <code>src/deriva_ml/core/mixins/asset.py</code> <pre><code>def list_assets(self, asset_table: Table | str) -&gt; list[\"Asset\"]:\n    \"\"\"Lists contents of an asset table.\n\n    Returns a list of Asset objects for the specified asset table.\n\n    Args:\n        asset_table: Table or name of the asset table to list assets for.\n\n    Returns:\n        list[Asset]: List of Asset objects for the assets in the table.\n\n    Raises:\n        DerivaMLException: If the table is not an asset table or doesn't exist.\n\n    Example:\n        &gt;&gt;&gt; assets = ml.list_assets(\"Image\")\n        &gt;&gt;&gt; for asset in assets:\n        ...     print(f\"{asset.asset_rid}: {asset.filename}\")\n    \"\"\"\n    from deriva_ml.asset.asset import Asset\n\n    # Validate and get asset table reference\n    asset_table_obj = self.model.name_to_table(asset_table)\n    if not self.model.is_asset(asset_table_obj):\n        raise DerivaMLException(f\"Table {asset_table_obj.name} is not an asset\")\n\n    # Get path builders for asset and type tables\n    pb = self.pathBuilder()\n    asset_path = pb.schemas[asset_table_obj.schema.name].tables[asset_table_obj.name]\n    (\n        asset_type_table,\n        _,\n        _,\n    ) = self.model.find_association(asset_table_obj, MLVocab.asset_type)\n    type_path = pb.schemas[asset_type_table.schema.name].tables[asset_type_table.name]\n\n    # Build a list of Asset objects\n    assets = []\n    for asset_record in asset_path.entities().fetch():\n        # Get associated asset types for each asset\n        asset_types = (\n            type_path.filter(type_path.columns[asset_table_obj.name] == asset_record[\"RID\"])\n            .attributes(type_path.Asset_Type)\n            .fetch()\n        )\n        asset_type_list = [asset_type[MLVocab.asset_type.value] for asset_type in asset_types]\n\n        assets.append(Asset(\n            catalog=self,  # type: ignore[arg-type]\n            asset_rid=asset_record[\"RID\"],\n            asset_table=asset_table_obj.name,\n            filename=asset_record.get(\"Filename\", \"\"),\n            url=asset_record.get(\"URL\", \"\"),\n            length=asset_record.get(\"Length\", 0),\n            md5=asset_record.get(\"MD5\", \"\"),\n            description=asset_record.get(\"Description\", \"\"),\n            asset_types=asset_type_list,\n        ))\n    return assets\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_dataset_element_types","title":"list_dataset_element_types","text":"<pre><code>list_dataset_element_types() -&gt; (\n    Iterable[Table]\n)\n</code></pre> <p>List the types of entities that can be added to a dataset.</p> <p>Returns:</p> Type Description <code>Iterable[Table]</code> <p>An iterable of Table objects that can be included as an element of a dataset.</p> Source code in <code>src/deriva_ml/core/mixins/dataset.py</code> <pre><code>def list_dataset_element_types(self) -&gt; Iterable[Table]:\n    \"\"\"List the types of entities that can be added to a dataset.\n\n    Returns:\n        An iterable of Table objects that can be included as an element of a dataset.\n    \"\"\"\n\n    def is_domain_or_dataset_table(table: Table) -&gt; bool:\n        return self.model.is_domain_schema(table.schema.name) or table.name == self._dataset_table.name\n\n    return [t for a in self._dataset_table.find_associations() if is_domain_or_dataset_table(t := a.other_fkeys.pop().pk_table)]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_execution_dirs","title":"list_execution_dirs","text":"<pre><code>list_execution_dirs() -&gt; list[\n    dict[str, any]\n]\n</code></pre> <p>List execution working directories.</p> <p>Returns information about each execution directory in the working directory, useful for identifying orphaned or incomplete execution outputs.</p> <p>Returns:</p> Type Description <code>list[dict[str, any]]</code> <p>List of dicts, each containing: - 'execution_rid': The execution RID (directory name) - 'path': Full path to the directory - 'size_bytes': Total size in bytes - 'size_mb': Total size in megabytes - 'modified': Last modification time (datetime) - 'file_count': Number of files</p> Example <p>ml = DerivaML('deriva.example.org', 'my_catalog') dirs = ml.list_execution_dirs() for d in dirs: ...     print(f\"{d['execution_rid']}: {d['size_mb']:.1f} MB\")</p> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def list_execution_dirs(self) -&gt; list[dict[str, any]]:\n    \"\"\"List execution working directories.\n\n    Returns information about each execution directory in the working directory,\n    useful for identifying orphaned or incomplete execution outputs.\n\n    Returns:\n        List of dicts, each containing:\n            - 'execution_rid': The execution RID (directory name)\n            - 'path': Full path to the directory\n            - 'size_bytes': Total size in bytes\n            - 'size_mb': Total size in megabytes\n            - 'modified': Last modification time (datetime)\n            - 'file_count': Number of files\n\n    Example:\n        &gt;&gt;&gt; ml = DerivaML('deriva.example.org', 'my_catalog')\n        &gt;&gt;&gt; dirs = ml.list_execution_dirs()\n        &gt;&gt;&gt; for d in dirs:\n        ...     print(f\"{d['execution_rid']}: {d['size_mb']:.1f} MB\")\n    \"\"\"\n    from datetime import datetime\n\n    from deriva_ml.dataset.upload import upload_root\n\n    results = []\n    exec_root = upload_root(self.working_dir) / \"execution\"\n\n    if not exec_root.exists():\n        return results\n\n    for entry in exec_root.iterdir():\n        if entry.is_dir():\n            size_bytes = sum(f.stat().st_size for f in entry.rglob('*') if f.is_file())\n            file_count = sum(1 for f in entry.rglob('*') if f.is_file())\n            mtime = datetime.fromtimestamp(entry.stat().st_mtime)\n\n            results.append({\n                'execution_rid': entry.name,\n                'path': str(entry),\n                'size_bytes': size_bytes,\n                'size_mb': size_bytes / (1024 * 1024),\n                'modified': mtime,\n                'file_count': file_count,\n            })\n\n    return sorted(results, key=lambda x: x['modified'], reverse=True)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_feature_values","title":"list_feature_values","text":"<pre><code>list_feature_values(\n    table: Table | str,\n    feature_name: str,\n) -&gt; Iterable[FeatureRecord]\n</code></pre> <p>Retrieves all values for a feature as typed FeatureRecord instances.</p> <p>Returns an iterator of dynamically-generated FeatureRecord objects for each feature value. Each record is an instance of a Pydantic model specific to this feature, with typed attributes for all columns including the Execution that created the feature value.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>The table containing the feature, either as name or Table object.</p> required <code>feature_name</code> <code>str</code> <p>Name of the feature to retrieve values for.</p> required <p>Returns:</p> Type Description <code>Iterable[FeatureRecord]</code> <p>Iterable[FeatureRecord]: An iterator of FeatureRecord instances. Each instance has: - Execution: RID of the execution that created this feature value - Feature_Name: Name of the feature - All feature-specific columns as typed attributes - model_dump() method to convert back to a dictionary</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the feature doesn't exist or cannot be accessed.</p> Example Source code in <code>src/deriva_ml/core/mixins/feature.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef list_feature_values(\n    self, table: Table | str, feature_name: str\n) -&gt; Iterable[FeatureRecord]:\n    \"\"\"Retrieves all values for a feature as typed FeatureRecord instances.\n\n    Returns an iterator of dynamically-generated FeatureRecord objects for each\n    feature value. Each record is an instance of a Pydantic model specific to\n    this feature, with typed attributes for all columns including the Execution\n    that created the feature value.\n\n    Args:\n        table: The table containing the feature, either as name or Table object.\n        feature_name: Name of the feature to retrieve values for.\n\n    Returns:\n        Iterable[FeatureRecord]: An iterator of FeatureRecord instances.\n            Each instance has:\n            - Execution: RID of the execution that created this feature value\n            - Feature_Name: Name of the feature\n            - All feature-specific columns as typed attributes\n            - model_dump() method to convert back to a dictionary\n\n    Raises:\n        DerivaMLException: If the feature doesn't exist or cannot be accessed.\n\n    Example:\n        &gt;&gt;&gt; # Get typed feature records\n        &gt;&gt;&gt; for record in ml.list_feature_values(\"Image\", \"Quality\"):\n        ...     print(f\"Image {record.Image}: {record.ImageQuality}\")\n        ...     print(f\"Created by execution: {record.Execution}\")\n\n        &gt;&gt;&gt; # Convert records to dictionaries\n        &gt;&gt;&gt; records = list(ml.list_feature_values(\"Image\", \"Quality\"))\n        &gt;&gt;&gt; dicts = [r.model_dump() for r in records]\n    \"\"\"\n    # Get table and feature\n    table = self.model.name_to_table(table)\n    feature = self.lookup_feature(table, feature_name)\n\n    # Get the dynamically-generated FeatureRecord subclass for this feature\n    record_class = feature.feature_record_class()\n\n    # Build and execute query for feature values\n    pb = self.pathBuilder()\n    raw_values = pb.schemas[feature.feature_table.schema.name].tables[feature.feature_table.name].entities().fetch()\n\n    for raw_value in raw_values:\n        # Create a record instance from the raw dictionary\n        # Filter to only include fields that the record class expects\n        field_names = set(record_class.model_fields.keys())\n        filtered_data = {k: v for k, v in raw_value.items() if k in field_names}\n        yield record_class(**filtered_data)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_feature_values--get-typed-feature-records","title":"Get typed feature records","text":"<p>for record in ml.list_feature_values(\"Image\", \"Quality\"): ...     print(f\"Image {record.Image}: {record.ImageQuality}\") ...     print(f\"Created by execution: {record.Execution}\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_feature_values--convert-records-to-dictionaries","title":"Convert records to dictionaries","text":"<p>records = list(ml.list_feature_values(\"Image\", \"Quality\")) dicts = [r.model_dump() for r in records]</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_files","title":"list_files","text":"<pre><code>list_files(\n    file_types: list[str] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Lists files in the catalog with their metadata.</p> <p>Returns a list of files with their metadata including URL, MD5 hash, length, description, and associated file types. Files can be optionally filtered by type.</p> <p>Parameters:</p> Name Type Description Default <code>file_types</code> <code>list[str] | None</code> <p>Filter results to only include these file types.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>list[dict[str, Any]]: List of file records, each containing: - RID: Resource identifier - URL: File location - MD5: File hash - Length: File size - Description: File description - File_Types: List of associated file types</p> <p>Examples:</p> <p>List all files:     &gt;&gt;&gt; files = ml.list_files()     &gt;&gt;&gt; for f in files:     ...     print(f\"{f['RID']}: {f['URL']}\")</p> <p>Filter by file type:     &gt;&gt;&gt; image_files = ml.list_files([\"image\", \"png\"])</p> Source code in <code>src/deriva_ml/core/mixins/file.py</code> <pre><code>def list_files(self, file_types: list[str] | None = None) -&gt; list[dict[str, Any]]:\n    \"\"\"Lists files in the catalog with their metadata.\n\n    Returns a list of files with their metadata including URL, MD5 hash, length, description,\n    and associated file types. Files can be optionally filtered by type.\n\n    Args:\n        file_types: Filter results to only include these file types.\n\n    Returns:\n        list[dict[str, Any]]: List of file records, each containing:\n            - RID: Resource identifier\n            - URL: File location\n            - MD5: File hash\n            - Length: File size\n            - Description: File description\n            - File_Types: List of associated file types\n\n    Examples:\n        List all files:\n            &gt;&gt;&gt; files = ml.list_files()\n            &gt;&gt;&gt; for f in files:\n            ...     print(f\"{f['RID']}: {f['URL']}\")\n\n        Filter by file type:\n            &gt;&gt;&gt; image_files = ml.list_files([\"image\", \"png\"])\n    \"\"\"\n    asset_type_atable, file_fk, asset_type_fk = self.model.find_association(\"File\", \"Asset_Type\")\n    ml_path = self.pathBuilder().schemas[self.ml_schema]\n    file = ml_path.File\n    asset_type = ml_path.tables[asset_type_atable.name]\n\n    path = file.path\n    path = path.link(asset_type.alias(\"AT\"), on=file.RID == asset_type.columns[file_fk], join_type=\"left\")\n    if file_types:\n        path = path.filter(asset_type.columns[asset_type_fk] == datapath.Any(*file_types))\n    path = path.attributes(\n        path.File.RID,\n        path.File.URL,\n        path.File.MD5,\n        path.File.Length,\n        path.File.Description,\n        path.AT.columns[asset_type_fk],\n    )\n\n    file_map = {}\n    for f in path.fetch():\n        entry = file_map.setdefault(f[\"RID\"], {**f, \"File_Types\": []})\n        if ft := f.get(\"Asset_Type\"):  # assign-and-test in one go\n            entry[\"File_Types\"].append(ft)\n\n    # Now get rid of the File_Type key and return the result\n    return [(f, f.pop(\"Asset_Type\"))[0] for f in file_map.values()]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_foreign_keys","title":"list_foreign_keys","text":"<pre><code>list_foreign_keys(\n    table: str | Table,\n) -&gt; dict[str, Any]\n</code></pre> <p>List all foreign keys related to a table.</p> <p>Returns both outbound foreign keys (from this table to others) and inbound foreign keys (from other tables to this one). Useful for determining valid constraint names for visible-columns and visible-foreign-keys annotations.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with:</p> <code>dict[str, Any]</code> <ul> <li>table: Table name</li> </ul> <code>dict[str, Any]</code> <ul> <li>outbound: List of outbound foreign keys</li> </ul> <code>dict[str, Any]</code> <ul> <li>inbound: List of inbound foreign keys</li> </ul> <code>dict[str, Any]</code> <p>Each foreign key contains constraint_name, from_table, from_columns,</p> <code>dict[str, Any]</code> <p>to_table, to_columns.</p> Example <p>fkeys = ml.list_foreign_keys(\"Image\") for fk in fkeys[\"outbound\"]: ...     print(f\"{fk['constraint_name']} -&gt; {fk['to_table']}\")</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef list_foreign_keys(self, table: str | Table) -&gt; dict[str, Any]:\n    \"\"\"List all foreign keys related to a table.\n\n    Returns both outbound foreign keys (from this table to others) and\n    inbound foreign keys (from other tables to this one). Useful for\n    determining valid constraint names for visible-columns and\n    visible-foreign-keys annotations.\n\n    Args:\n        table: Table name or Table object.\n\n    Returns:\n        Dictionary with:\n        - table: Table name\n        - outbound: List of outbound foreign keys\n        - inbound: List of inbound foreign keys\n        Each foreign key contains constraint_name, from_table, from_columns,\n        to_table, to_columns.\n\n    Example:\n        &gt;&gt;&gt; fkeys = ml.list_foreign_keys(\"Image\")\n        &gt;&gt;&gt; for fk in fkeys[\"outbound\"]:\n        ...     print(f\"{fk['constraint_name']} -&gt; {fk['to_table']}\")\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    outbound = []\n    for fkey in table_obj.foreign_keys:\n        outbound.append({\n            \"constraint_name\": [fkey.constraint_schema.name, fkey.constraint_name],\n            \"from_table\": table_obj.name,\n            \"from_columns\": [col.name for col in fkey.columns],\n            \"to_table\": fkey.pk_table.name,\n            \"to_columns\": [col.name for col in fkey.referenced_columns],\n        })\n\n    inbound = []\n    for fkey in table_obj.referenced_by:\n        inbound.append({\n            \"constraint_name\": [fkey.constraint_schema.name, fkey.constraint_name],\n            \"from_table\": fkey.table.name,\n            \"from_columns\": [col.name for col in fkey.columns],\n            \"to_table\": table_obj.name,\n            \"to_columns\": [col.name for col in fkey.referenced_columns],\n        })\n\n    return {\n        \"table\": table_obj.name,\n        \"outbound\": outbound,\n        \"inbound\": inbound,\n    }\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.list_vocabulary_terms","title":"list_vocabulary_terms","text":"<pre><code>list_vocabulary_terms(\n    table: str | Table,\n) -&gt; list[VocabularyTerm]\n</code></pre> <p>Lists all terms in a vocabulary table.</p> <p>Retrieves all terms, their descriptions, and synonyms from a controlled vocabulary table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Vocabulary table to list terms from (name or Table object).</p> required <p>Returns:</p> Type Description <code>list[VocabularyTerm]</code> <p>list[VocabularyTerm]: List of vocabulary terms with their metadata.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If table doesn't exist or is not a vocabulary table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; terms = ml.list_vocabulary_terms(\"tissue_types\")\n&gt;&gt;&gt; for term in terms:\n...     print(f\"{term.name}: {term.description}\")\n...     if term.synonyms:\n...         print(f\"  Synonyms: {', '.join(term.synonyms)}\")\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/vocabulary.py</code> <pre><code>def list_vocabulary_terms(self, table: str | Table) -&gt; list[VocabularyTerm]:\n    \"\"\"Lists all terms in a vocabulary table.\n\n    Retrieves all terms, their descriptions, and synonyms from a controlled vocabulary table.\n\n    Args:\n        table: Vocabulary table to list terms from (name or Table object).\n\n    Returns:\n        list[VocabularyTerm]: List of vocabulary terms with their metadata.\n\n    Raises:\n        DerivaMLException: If table doesn't exist or is not a vocabulary table.\n\n    Examples:\n        &gt;&gt;&gt; terms = ml.list_vocabulary_terms(\"tissue_types\")\n        &gt;&gt;&gt; for term in terms:\n        ...     print(f\"{term.name}: {term.description}\")\n        ...     if term.synonyms:\n        ...         print(f\"  Synonyms: {', '.join(term.synonyms)}\")\n    \"\"\"\n    # Get path builder and table reference\n    pb = self.pathBuilder()\n    table = self.model.name_to_table(table.value if isinstance(table, MLVocab) else table)\n\n    # Validate table is a vocabulary table\n    if not (self.model.is_vocabulary(table)):\n        raise DerivaMLException(f\"The table {table} is not a controlled vocabulary\")\n\n    # Fetch and convert all terms to VocabularyTerm objects\n    return [VocabularyTerm(**v) for v in pb.schemas[table.schema.name].tables[table.name].entities().fetch()]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.lookup_asset","title":"lookup_asset","text":"<pre><code>lookup_asset(asset_rid: RID) -&gt; 'Asset'\n</code></pre> <p>Look up an asset by its RID.</p> <p>Returns an Asset object for the specified RID. The asset can be from any asset table in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>asset_rid</code> <code>RID</code> <p>The RID of the asset to look up.</p> required <p>Returns:</p> Type Description <code>'Asset'</code> <p>Asset object for the specified RID.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the RID is not found or is not an asset.</p> Example <p>asset = ml.lookup_asset(\"3JSE\") print(f\"File: {asset.filename}, Table: {asset.asset_table}\")</p> Source code in <code>src/deriva_ml/core/mixins/asset.py</code> <pre><code>def lookup_asset(self, asset_rid: RID) -&gt; \"Asset\":\n    \"\"\"Look up an asset by its RID.\n\n    Returns an Asset object for the specified RID. The asset can be from\n    any asset table in the catalog.\n\n    Args:\n        asset_rid: The RID of the asset to look up.\n\n    Returns:\n        Asset object for the specified RID.\n\n    Raises:\n        DerivaMLException: If the RID is not found or is not an asset.\n\n    Example:\n        &gt;&gt;&gt; asset = ml.lookup_asset(\"3JSE\")\n        &gt;&gt;&gt; print(f\"File: {asset.filename}, Table: {asset.asset_table}\")\n    \"\"\"\n    from deriva_ml.asset.asset import Asset\n\n    # Resolve the RID to find which table it belongs to\n    rid_info = self.resolve_rid(asset_rid)  # type: ignore[attr-defined]\n    asset_table = rid_info.table\n\n    if not self.model.is_asset(asset_table):\n        raise DerivaMLException(f\"RID {asset_rid} is not an asset (table: {asset_table.name})\")\n\n    # Query the asset table for this record\n    pb = self.pathBuilder()\n    asset_path = pb.schemas[asset_table.schema.name].tables[asset_table.name]\n\n    records = list(asset_path.filter(asset_path.RID == asset_rid).entities().fetch())\n    if not records:\n        raise DerivaMLException(f\"Asset {asset_rid} not found in table {asset_table.name}\")\n\n    record = records[0]\n\n    # Get asset types\n    asset_types = []\n    try:\n        type_assoc_table, asset_fk, _ = self.model.find_association(asset_table, \"Asset_Type\")\n        type_path = pb.schemas[type_assoc_table.schema.name].tables[type_assoc_table.name]\n        types = list(\n            type_path.filter(type_path.columns[asset_fk] == asset_rid)\n            .attributes(type_path.Asset_Type)\n            .fetch()\n        )\n        asset_types = [t[\"Asset_Type\"] for t in types]\n    except Exception:\n        pass  # No type association for this asset table\n\n    return Asset(\n        catalog=self,  # type: ignore[arg-type]\n        asset_rid=asset_rid,\n        asset_table=asset_table.name,\n        filename=record.get(\"Filename\", \"\"),\n        url=record.get(\"URL\", \"\"),\n        length=record.get(\"Length\", 0),\n        md5=record.get(\"MD5\", \"\"),\n        description=record.get(\"Description\", \"\"),\n        asset_types=asset_types,\n    )\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.lookup_dataset","title":"lookup_dataset","text":"<pre><code>lookup_dataset(\n    dataset: RID | DatasetSpec,\n    deleted: bool = False,\n) -&gt; \"Dataset\"\n</code></pre> <p>Look up a dataset by RID or DatasetSpec.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>RID | DatasetSpec</code> <p>Dataset RID or DatasetSpec to look up.</p> required <code>deleted</code> <code>bool</code> <p>If True, include datasets that have been marked as deleted.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>'Dataset'</code> <p>The dataset object for the specified RID.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the dataset is not found.</p> Example <p>dataset = ml.lookup_dataset(\"4HM\") print(f\"Version: {dataset.current_version}\")</p> Source code in <code>src/deriva_ml/core/mixins/dataset.py</code> <pre><code>def lookup_dataset(self, dataset: RID | DatasetSpec, deleted: bool = False) -&gt; \"Dataset\":\n    \"\"\"Look up a dataset by RID or DatasetSpec.\n\n    Args:\n        dataset: Dataset RID or DatasetSpec to look up.\n        deleted: If True, include datasets that have been marked as deleted.\n\n    Returns:\n        Dataset: The dataset object for the specified RID.\n\n    Raises:\n        DerivaMLException: If the dataset is not found.\n\n    Example:\n        &gt;&gt;&gt; dataset = ml.lookup_dataset(\"4HM\")\n        &gt;&gt;&gt; print(f\"Version: {dataset.current_version}\")\n    \"\"\"\n    if isinstance(dataset, DatasetSpec):\n        dataset_rid = dataset.rid\n    else:\n        dataset_rid = dataset\n\n    try:\n        return [ds for ds in self.find_datasets(deleted=deleted) if ds.dataset_rid == dataset_rid][0]\n    except IndexError:\n        raise DerivaMLException(f\"Dataset {dataset_rid} not found.\")\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.lookup_execution","title":"lookup_execution","text":"<pre><code>lookup_execution(\n    execution_rid: RID,\n) -&gt; \"ExecutionRecord\"\n</code></pre> <p>Look up an execution by RID and return an ExecutionRecord.</p> <p>Creates an ExecutionRecord object for querying and modifying execution metadata. The ExecutionRecord provides access to the catalog record state and allows updating mutable properties like status and description.</p> <p>For running computations with datasets and assets, use <code>restore_execution()</code> or <code>create_execution()</code> which return full Execution objects.</p> <p>Parameters:</p> Name Type Description Default <code>execution_rid</code> <code>RID</code> <p>Resource Identifier (RID) of the execution.</p> required <p>Returns:</p> Name Type Description <code>ExecutionRecord</code> <code>'ExecutionRecord'</code> <p>An execution record object bound to the catalog.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If execution_rid is not valid or doesn't refer to an Execution record.</p> Example <p>Look up an execution and query its state::</p> <pre><code>&gt;&gt;&gt; record = ml.lookup_execution(\"1-abc123\")\n&gt;&gt;&gt; print(f\"Status: {record.status}\")\n&gt;&gt;&gt; print(f\"Description: {record.description}\")\n</code></pre> <p>Update mutable properties::</p> <pre><code>&gt;&gt;&gt; record.status = Status.completed\n&gt;&gt;&gt; record.description = \"Analysis finished\"\n</code></pre> <p>Query relationships::</p> <pre><code>&gt;&gt;&gt; children = list(record.list_nested_executions())\n&gt;&gt;&gt; parents = list(record.list_parent_executions())\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/execution.py</code> <pre><code>def lookup_execution(self, execution_rid: RID) -&gt; \"ExecutionRecord\":\n    \"\"\"Look up an execution by RID and return an ExecutionRecord.\n\n    Creates an ExecutionRecord object for querying and modifying execution\n    metadata. The ExecutionRecord provides access to the catalog record\n    state and allows updating mutable properties like status and description.\n\n    For running computations with datasets and assets, use ``restore_execution()``\n    or ``create_execution()`` which return full Execution objects.\n\n    Args:\n        execution_rid: Resource Identifier (RID) of the execution.\n\n    Returns:\n        ExecutionRecord: An execution record object bound to the catalog.\n\n    Raises:\n        DerivaMLException: If execution_rid is not valid or doesn't refer\n            to an Execution record.\n\n    Example:\n        Look up an execution and query its state::\n\n            &gt;&gt;&gt; record = ml.lookup_execution(\"1-abc123\")\n            &gt;&gt;&gt; print(f\"Status: {record.status}\")\n            &gt;&gt;&gt; print(f\"Description: {record.description}\")\n\n        Update mutable properties::\n\n            &gt;&gt;&gt; record.status = Status.completed\n            &gt;&gt;&gt; record.description = \"Analysis finished\"\n\n        Query relationships::\n\n            &gt;&gt;&gt; children = list(record.list_nested_executions())\n            &gt;&gt;&gt; parents = list(record.list_parent_executions())\n    \"\"\"\n    # Import here to avoid circular dependency\n    from deriva_ml.execution.execution_record import ExecutionRecord\n\n    # Get execution record from catalog and verify it's an Execution\n    resolved = self.resolve_rid(execution_rid)\n    if resolved.table.name != \"Execution\":\n        raise DerivaMLException(\n            f\"RID '{execution_rid}' refers to a {resolved.table.name}, not an Execution\"\n        )\n\n    execution_data = self.retrieve_rid(execution_rid)\n\n    # Parse timestamps if present\n    start_time = None\n    stop_time = None\n    if execution_data.get(\"Start\"):\n        from datetime import datetime\n        try:\n            start_time = datetime.fromisoformat(execution_data[\"Start\"].replace(\"Z\", \"+00:00\"))\n        except (ValueError, AttributeError):\n            pass\n    if execution_data.get(\"Stop\"):\n        from datetime import datetime\n        try:\n            stop_time = datetime.fromisoformat(execution_data[\"Stop\"].replace(\"Z\", \"+00:00\"))\n        except (ValueError, AttributeError):\n            pass\n\n    # Look up the workflow if present\n    workflow_rid = execution_data.get(\"Workflow\")\n    workflow = self.lookup_workflow(workflow_rid) if workflow_rid else None\n\n    # Create ExecutionRecord bound to this catalog\n    record = ExecutionRecord(\n        execution_rid=execution_rid,\n        workflow=workflow,\n        status=Status(execution_data.get(\"Status\", \"Created\")),\n        description=execution_data.get(\"Description\"),\n        start_time=start_time,\n        stop_time=stop_time,\n        duration=execution_data.get(\"Duration\"),\n        _ml_instance=self,\n        _logger=getattr(self, \"_logger\", None),\n    )\n\n    return record\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.lookup_experiment","title":"lookup_experiment","text":"<pre><code>lookup_experiment(\n    execution_rid: RID,\n) -&gt; \"Experiment\"\n</code></pre> <p>Look up an experiment by execution RID.</p> <p>Creates an Experiment object for analyzing completed executions. Provides convenient access to execution metadata, configuration choices, model parameters, inputs, and outputs.</p> <p>Parameters:</p> Name Type Description Default <code>execution_rid</code> <code>RID</code> <p>Resource Identifier (RID) of the execution.</p> required <p>Returns:</p> Name Type Description <code>Experiment</code> <code>'Experiment'</code> <p>An experiment object for the given execution RID.</p> Example <p>exp = ml.lookup_experiment(\"47BE\") print(exp.name)  # e.g., \"cifar10_quick\" print(exp.config_choices)  # Hydra config names used print(exp.model_config)  # Model hyperparameters</p> Source code in <code>src/deriva_ml/core/mixins/execution.py</code> <pre><code>def lookup_experiment(self, execution_rid: RID) -&gt; \"Experiment\":\n    \"\"\"Look up an experiment by execution RID.\n\n    Creates an Experiment object for analyzing completed executions.\n    Provides convenient access to execution metadata, configuration choices,\n    model parameters, inputs, and outputs.\n\n    Args:\n        execution_rid: Resource Identifier (RID) of the execution.\n\n    Returns:\n        Experiment: An experiment object for the given execution RID.\n\n    Example:\n        &gt;&gt;&gt; exp = ml.lookup_experiment(\"47BE\")\n        &gt;&gt;&gt; print(exp.name)  # e.g., \"cifar10_quick\"\n        &gt;&gt;&gt; print(exp.config_choices)  # Hydra config names used\n        &gt;&gt;&gt; print(exp.model_config)  # Model hyperparameters\n    \"\"\"\n    from deriva_ml.experiment import Experiment\n\n    return Experiment(self, execution_rid)  # type: ignore[arg-type]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.lookup_feature","title":"lookup_feature","text":"<pre><code>lookup_feature(\n    table: str | Table,\n    feature_name: str,\n) -&gt; Feature\n</code></pre> <p>Retrieves a Feature object.</p> <p>Looks up and returns a Feature object that provides an interface to work with an existing feature definition in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>The table containing the feature, either as name or Table object.</p> required <code>feature_name</code> <code>str</code> <p>Name of the feature to look up.</p> required <p>Returns:</p> Name Type Description <code>Feature</code> <code>Feature</code> <p>An object representing the feature and its implementation.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the feature doesn't exist in the specified table.</p> Example <p>feature = ml.lookup_feature(\"samples\", \"expression_level\") print(feature.feature_name) 'expression_level'</p> Source code in <code>src/deriva_ml/core/mixins/feature.py</code> <pre><code>def lookup_feature(self, table: str | Table, feature_name: str) -&gt; Feature:\n    \"\"\"Retrieves a Feature object.\n\n    Looks up and returns a Feature object that provides an interface to work with an existing feature\n    definition in the catalog.\n\n    Args:\n        table: The table containing the feature, either as name or Table object.\n        feature_name: Name of the feature to look up.\n\n    Returns:\n        Feature: An object representing the feature and its implementation.\n\n    Raises:\n        DerivaMLException: If the feature doesn't exist in the specified table.\n\n    Example:\n        &gt;&gt;&gt; feature = ml.lookup_feature(\"samples\", \"expression_level\")\n        &gt;&gt;&gt; print(feature.feature_name)\n        'expression_level'\n    \"\"\"\n    return self.model.lookup_feature(table, feature_name)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.lookup_term","title":"lookup_term","text":"<pre><code>lookup_term(\n    table: str | Table, term_name: str\n) -&gt; VocabularyTermHandle\n</code></pre> <p>Finds a term in a vocabulary table.</p> <p>Searches for a term in the specified vocabulary table, matching either the primary name or any of its synonyms. Results are cached for performance - subsequent lookups in the same vocabulary table are served from cache.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Vocabulary table to search in (name or Table object).</p> required <code>term_name</code> <code>str</code> <p>Name or synonym of the term to find.</p> required <p>Returns:</p> Name Type Description <code>VocabularyTermHandle</code> <code>VocabularyTermHandle</code> <p>The matching vocabulary term, with methods to modify it.</p> <p>Raises:</p> Type Description <code>DerivaMLVocabularyException</code> <p>If the table is not a vocabulary table, or term is not found.</p> <p>Examples:</p> <p>Look up by primary name:     &gt;&gt;&gt; term = ml.lookup_term(\"tissue_types\", \"epithelial\")     &gt;&gt;&gt; print(term.description)</p> <p>Look up by synonym:     &gt;&gt;&gt; term = ml.lookup_term(\"tissue_types\", \"epithelium\")</p> <p>Modify the term:     &gt;&gt;&gt; term = ml.lookup_term(\"tissue_types\", \"epithelial\")     &gt;&gt;&gt; term.description = \"Updated description\"     &gt;&gt;&gt; term.synonyms = (\"epithelium\", \"epithelial_tissue\")</p> Source code in <code>src/deriva_ml/core/mixins/vocabulary.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef lookup_term(self, table: str | Table, term_name: str) -&gt; VocabularyTermHandle:\n    \"\"\"Finds a term in a vocabulary table.\n\n    Searches for a term in the specified vocabulary table, matching either the primary name\n    or any of its synonyms. Results are cached for performance - subsequent lookups in the\n    same vocabulary table are served from cache.\n\n    Args:\n        table: Vocabulary table to search in (name or Table object).\n        term_name: Name or synonym of the term to find.\n\n    Returns:\n        VocabularyTermHandle: The matching vocabulary term, with methods to modify it.\n\n    Raises:\n        DerivaMLVocabularyException: If the table is not a vocabulary table, or term is not found.\n\n    Examples:\n        Look up by primary name:\n            &gt;&gt;&gt; term = ml.lookup_term(\"tissue_types\", \"epithelial\")\n            &gt;&gt;&gt; print(term.description)\n\n        Look up by synonym:\n            &gt;&gt;&gt; term = ml.lookup_term(\"tissue_types\", \"epithelium\")\n\n        Modify the term:\n            &gt;&gt;&gt; term = ml.lookup_term(\"tissue_types\", \"epithelial\")\n            &gt;&gt;&gt; term.description = \"Updated description\"\n            &gt;&gt;&gt; term.synonyms = (\"epithelium\", \"epithelial_tissue\")\n    \"\"\"\n    # Get and validate vocabulary table reference\n    vocab_table = self.model.name_to_table(table)\n    if not self.model.is_vocabulary(vocab_table):\n        raise DerivaMLException(f\"The table {table} is not a controlled vocabulary\")\n\n    # Get schema and table names\n    schema_name, table_name = vocab_table.schema.name, vocab_table.name\n    cache_key = (schema_name, table_name)\n\n    # Check cache first\n    cache = self._get_vocab_cache()\n    if cache_key in cache:\n        term_lookup = cache[cache_key]\n        if term_name in term_lookup:\n            return term_lookup[term_name]\n        # Term not in cache - might be newly added, try server-side lookup\n    else:\n        # Vocabulary not cached yet - try server-side lookup first for single term\n        term = self._server_lookup_term(schema_name, table_name, term_name)\n        if term is not None:\n            # Found it - populate the full cache for future lookups\n            self._populate_vocab_cache(schema_name, table_name)\n            return self._get_vocab_cache()[cache_key][term_name]\n        # Not found by name - need to check synonyms, populate cache\n        term_lookup = self._populate_vocab_cache(schema_name, table_name)\n        if term_name in term_lookup:\n            return term_lookup[term_name]\n        raise DerivaMLInvalidTerm(table_name, term_name)\n\n    # Term not in cache - try server-side lookup (might be newly added)\n    term = self._server_lookup_term(schema_name, table_name, term_name)\n    if term is not None:\n        # Refresh cache to get the VocabularyTermHandle\n        self._populate_vocab_cache(schema_name, table_name)\n        return self._get_vocab_cache()[cache_key][term_name]\n\n    # Still not found - refresh cache and try one more time\n    term_lookup = self._populate_vocab_cache(schema_name, table_name)\n    if term_name in term_lookup:\n        return term_lookup[term_name]\n\n    # Term not found\n    raise DerivaMLInvalidTerm(table_name, term_name)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.lookup_workflow","title":"lookup_workflow","text":"<pre><code>lookup_workflow(rid: RID) -&gt; Workflow\n</code></pre> <p>Look up a workflow by its Resource Identifier (RID).</p> <p>Retrieves a workflow from the catalog by its RID and returns a Workflow object bound to the catalog. The returned Workflow can be modified (e.g., updating its description) and changes will be reflected in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>rid</code> <code>RID</code> <p>Resource Identifier of the workflow to look up.</p> required <p>Returns:</p> Name Type Description <code>Workflow</code> <code>Workflow</code> <p>The workflow object bound to this catalog, allowing properties like <code>description</code> to be updated.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the RID does not correspond to a workflow in the catalog.</p> <p>Examples:</p> <p>Look up a workflow and read its properties::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; print(f\"Name: {workflow.name}\")\n&gt;&gt;&gt; print(f\"Description: {workflow.description}\")\n&gt;&gt;&gt; print(f\"Type: {workflow.workflow_type}\")\n</code></pre> <p>Update a workflow's description (persisted to catalog)::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.description = \"Updated analysis pipeline for RNA sequences\"\n&gt;&gt;&gt; # The change is immediately written to the catalog\n</code></pre> <p>Attempting to update on a read-only catalog raises an error::</p> <pre><code>&gt;&gt;&gt; snapshot = ml.catalog_snapshot(\"2023-01-15T10:30:00\")\n&gt;&gt;&gt; workflow = snapshot.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.description = \"New description\"\nDerivaMLException: Cannot update workflow description on a read-only\n    catalog snapshot. Use a writable catalog connection instead.\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/workflow.py</code> <pre><code>def lookup_workflow(self, rid: RID) -&gt; Workflow:\n    \"\"\"Look up a workflow by its Resource Identifier (RID).\n\n    Retrieves a workflow from the catalog by its RID and returns a Workflow\n    object bound to the catalog. The returned Workflow can be modified (e.g.,\n    updating its description) and changes will be reflected in the catalog.\n\n    Args:\n        rid: Resource Identifier of the workflow to look up.\n\n    Returns:\n        Workflow: The workflow object bound to this catalog, allowing\n            properties like ``description`` to be updated.\n\n    Raises:\n        DerivaMLException: If the RID does not correspond to a workflow\n            in the catalog.\n\n    Examples:\n        Look up a workflow and read its properties::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; print(f\"Name: {workflow.name}\")\n            &gt;&gt;&gt; print(f\"Description: {workflow.description}\")\n            &gt;&gt;&gt; print(f\"Type: {workflow.workflow_type}\")\n\n        Update a workflow's description (persisted to catalog)::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.description = \"Updated analysis pipeline for RNA sequences\"\n            &gt;&gt;&gt; # The change is immediately written to the catalog\n\n        Attempting to update on a read-only catalog raises an error::\n\n            &gt;&gt;&gt; snapshot = ml.catalog_snapshot(\"2023-01-15T10:30:00\")\n            &gt;&gt;&gt; workflow = snapshot.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.description = \"New description\"\n            DerivaMLException: Cannot update workflow description on a read-only\n                catalog snapshot. Use a writable catalog connection instead.\n    \"\"\"\n    # Get the workflow table path\n    workflow_path = self.pathBuilder().schemas[self.ml_schema].Workflow\n\n    # Filter by RID\n    records = list(workflow_path.filter(workflow_path.RID == rid).entities().fetch())\n\n    if not records:\n        raise DerivaMLException(f\"Workflow with RID '{rid}' not found in the catalog\")\n\n    w = records[0]\n    workflow = Workflow(\n        name=w[\"Name\"],\n        url=w[\"URL\"],\n        workflow_type=w[\"Workflow_Type\"],\n        version=w[\"Version\"],\n        description=w[\"Description\"],\n        rid=w[\"RID\"],\n        checksum=w[\"Checksum\"],\n    )\n    # Bind the workflow to this catalog instance for write-back support\n    workflow._ml_instance = self  # type: ignore[assignment]\n    return workflow\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.lookup_workflow_by_url","title":"lookup_workflow_by_url","text":"<pre><code>lookup_workflow_by_url(\n    url_or_checksum: str,\n) -&gt; Workflow\n</code></pre> <p>Look up a workflow by URL or checksum and return the full Workflow object.</p> <p>Searches for a workflow in the catalog that matches the given URL or checksum and returns a Workflow object bound to the catalog. This allows you to both identify a workflow by its source code location and modify its properties (e.g., description).</p> <p>The URL should be a GitHub URL pointing to the specific version of the workflow source code. The format typically includes the commit hash::</p> <pre><code>https://github.com/org/repo/blob/&lt;commit_hash&gt;/path/to/workflow.py\n</code></pre> <p>Alternatively, you can search by the Git object hash (checksum) of the workflow file.</p> <p>Parameters:</p> Name Type Description Default <code>url_or_checksum</code> <code>str</code> <p>GitHub URL with commit hash, or Git object hash (checksum) of the workflow file.</p> required <p>Returns:</p> Name Type Description <code>Workflow</code> <code>Workflow</code> <p>The workflow object bound to this catalog, allowing properties like <code>description</code> to be updated.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If no workflow with the given URL or checksum is found in the catalog.</p> <p>Examples:</p> <p>Look up a workflow by its GitHub URL::</p> <pre><code>&gt;&gt;&gt; url = \"https://github.com/org/repo/blob/abc123/analysis.py\"\n&gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(url)\n&gt;&gt;&gt; print(f\"Found: {workflow.name}\")\n&gt;&gt;&gt; print(f\"Version: {workflow.version}\")\n</code></pre> <p>Look up by Git object hash (checksum)::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(\"abc123def456789...\")\n&gt;&gt;&gt; print(f\"Name: {workflow.name}\")\n&gt;&gt;&gt; print(f\"URL: {workflow.url}\")\n</code></pre> <p>Update the workflow's description after lookup::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(url)\n&gt;&gt;&gt; workflow.description = \"Updated analysis pipeline\"\n&gt;&gt;&gt; # The change is persisted to the catalog\n</code></pre> <p>Typical GitHub URL formats supported::</p> <pre><code># Full blob URL with commit hash\nhttps://github.com/org/repo/blob/abc123def/src/workflow.py\n\n# The URL is matched exactly, so ensure it matches what was\n# recorded when the workflow was registered\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/workflow.py</code> <pre><code>def lookup_workflow_by_url(self, url_or_checksum: str) -&gt; Workflow:\n    \"\"\"Look up a workflow by URL or checksum and return the full Workflow object.\n\n    Searches for a workflow in the catalog that matches the given URL or\n    checksum and returns a Workflow object bound to the catalog. This allows\n    you to both identify a workflow by its source code location and modify\n    its properties (e.g., description).\n\n    The URL should be a GitHub URL pointing to the specific version of the\n    workflow source code. The format typically includes the commit hash::\n\n        https://github.com/org/repo/blob/&lt;commit_hash&gt;/path/to/workflow.py\n\n    Alternatively, you can search by the Git object hash (checksum) of the\n    workflow file.\n\n    Args:\n        url_or_checksum: GitHub URL with commit hash, or Git object hash\n            (checksum) of the workflow file.\n\n    Returns:\n        Workflow: The workflow object bound to this catalog, allowing\n            properties like ``description`` to be updated.\n\n    Raises:\n        DerivaMLException: If no workflow with the given URL or checksum\n            is found in the catalog.\n\n    Examples:\n        Look up a workflow by its GitHub URL::\n\n            &gt;&gt;&gt; url = \"https://github.com/org/repo/blob/abc123/analysis.py\"\n            &gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(url)\n            &gt;&gt;&gt; print(f\"Found: {workflow.name}\")\n            &gt;&gt;&gt; print(f\"Version: {workflow.version}\")\n\n        Look up by Git object hash (checksum)::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(\"abc123def456789...\")\n            &gt;&gt;&gt; print(f\"Name: {workflow.name}\")\n            &gt;&gt;&gt; print(f\"URL: {workflow.url}\")\n\n        Update the workflow's description after lookup::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(url)\n            &gt;&gt;&gt; workflow.description = \"Updated analysis pipeline\"\n            &gt;&gt;&gt; # The change is persisted to the catalog\n\n        Typical GitHub URL formats supported::\n\n            # Full blob URL with commit hash\n            https://github.com/org/repo/blob/abc123def/src/workflow.py\n\n            # The URL is matched exactly, so ensure it matches what was\n            # recorded when the workflow was registered\n    \"\"\"\n    # Find the RID first\n    rid = self._find_workflow_rid_by_url(url_or_checksum)\n    if rid is None:\n        raise DerivaMLException(\n            f\"Workflow with URL or checksum '{url_or_checksum}' not found in the catalog\"\n        )\n\n    # Use lookup_workflow to get the full object with catalog binding\n    return self.lookup_workflow(rid)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.pathBuilder","title":"pathBuilder","text":"<pre><code>pathBuilder() -&gt; SchemaWrapper\n</code></pre> <p>Returns catalog path builder for queries.</p> <p>The path builder provides a fluent interface for constructing complex queries against the catalog. This is a core component used by many other methods to interact with the catalog.</p> <p>Returns:</p> Type Description <code>SchemaWrapper</code> <p>datapath._CatalogWrapper: A new instance of the catalog path builder.</p> Example <p>path = ml.pathBuilder.schemas['my_schema'].tables['my_table'] results = path.entities().fetch()</p> Source code in <code>src/deriva_ml/core/mixins/path_builder.py</code> <pre><code>def pathBuilder(self) -&gt; SchemaWrapper:\n    \"\"\"Returns catalog path builder for queries.\n\n    The path builder provides a fluent interface for constructing complex queries against the catalog.\n    This is a core component used by many other methods to interact with the catalog.\n\n    Returns:\n        datapath._CatalogWrapper: A new instance of the catalog path builder.\n\n    Example:\n        &gt;&gt;&gt; path = ml.pathBuilder.schemas['my_schema'].tables['my_table']\n        &gt;&gt;&gt; results = path.entities().fetch()\n    \"\"\"\n    return self.catalog.getPathBuilder()\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.remove_visible_column","title":"remove_visible_column","text":"<pre><code>remove_visible_column(\n    table: str | Table,\n    context: str,\n    column: str | list[str] | int,\n) -&gt; list[Any]\n</code></pre> <p>Remove a column from the visible-columns list for a specific context.</p> <p>Convenience method for removing columns without replacing the entire visible-columns annotation. Changes are staged until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>context</code> <code>str</code> <p>The context to modify (e.g., \"compact\", \"detailed\").</p> required <code>column</code> <code>str | list[str] | int</code> <p>Column to remove. Can be: - String: column name to find and remove - List: foreign key reference [schema, constraint] to find and remove - Integer: index position to remove (0-indexed)</p> required <p>Returns:</p> Type Description <code>list[Any]</code> <p>The updated column list for the context.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If annotation or context doesn't exist, or column not found.</p> Example <p>ml.remove_visible_column(\"Image\", \"compact\", \"Description\") ml.remove_visible_column(\"Image\", \"compact\", 0)  # Remove first column ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef remove_visible_column(\n    self,\n    table: str | Table,\n    context: str,\n    column: str | list[str] | int,\n) -&gt; list[Any]:\n    \"\"\"Remove a column from the visible-columns list for a specific context.\n\n    Convenience method for removing columns without replacing the entire\n    visible-columns annotation. Changes are staged until apply_annotations()\n    is called.\n\n    Args:\n        table: Table name or Table object.\n        context: The context to modify (e.g., \"compact\", \"detailed\").\n        column: Column to remove. Can be:\n            - String: column name to find and remove\n            - List: foreign key reference [schema, constraint] to find and remove\n            - Integer: index position to remove (0-indexed)\n\n    Returns:\n        The updated column list for the context.\n\n    Raises:\n        DerivaMLException: If annotation or context doesn't exist, or column not found.\n\n    Example:\n        &gt;&gt;&gt; ml.remove_visible_column(\"Image\", \"compact\", \"Description\")\n        &gt;&gt;&gt; ml.remove_visible_column(\"Image\", \"compact\", 0)  # Remove first column\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    # Get visible_columns annotation\n    visible_cols = table_obj.annotations.get(VISIBLE_COLUMNS_TAG, {})\n    if not visible_cols:\n        raise DerivaMLException(f\"Table '{table_obj.name}' has no visible-columns annotation.\")\n\n    # Get the context list\n    context_list = visible_cols.get(context)\n    if context_list is None:\n        raise DerivaMLException(f\"Context '{context}' not found in visible-columns annotation.\")\n    if isinstance(context_list, str):\n        raise DerivaMLException(\n            f\"Context '{context}' references another context '{context_list}'. \"\n            \"Set it explicitly first with set_visible_columns().\"\n        )\n\n    # Make a copy\n    context_list = list(context_list)\n    removed = None\n\n    # Remove by index or by value\n    if isinstance(column, int):\n        if 0 &lt;= column &lt; len(context_list):\n            removed = context_list.pop(column)\n        else:\n            raise DerivaMLException(\n                f\"Index {column} out of range (list has {len(context_list)} items).\"\n            )\n    else:\n        # Find and remove the column\n        for i, item in enumerate(context_list):\n            if item == column:\n                removed = context_list.pop(i)\n                break\n            # Also check if it's a pseudo-column with matching source\n            if isinstance(item, dict) and isinstance(column, str):\n                if item.get(\"source\") == column:\n                    removed = context_list.pop(i)\n                    break\n\n        if removed is None:\n            raise DerivaMLException(f\"Column {column!r} not found in context '{context}'.\")\n\n    # Update the annotation\n    visible_cols[context] = context_list\n    table_obj.annotations[VISIBLE_COLUMNS_TAG] = visible_cols\n\n    return context_list\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.remove_visible_foreign_key","title":"remove_visible_foreign_key","text":"<pre><code>remove_visible_foreign_key(\n    table: str | Table,\n    context: str,\n    foreign_key: list[str] | int,\n) -&gt; list[Any]\n</code></pre> <p>Remove a foreign key from the visible-foreign-keys list for a specific context.</p> <p>Convenience method for removing related tables without replacing the entire visible-foreign-keys annotation. Changes are staged until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>context</code> <code>str</code> <p>The context to modify (e.g., \"detailed\", \"*\").</p> required <code>foreign_key</code> <code>list[str] | int</code> <p>Foreign key to remove. Can be: - List: foreign key reference [schema, constraint] to find and remove - Integer: index position to remove (0-indexed)</p> required <p>Returns:</p> Type Description <code>list[Any]</code> <p>The updated foreign key list for the context.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If annotation or context doesn't exist, or foreign key not found.</p> Example <p>ml.remove_visible_foreign_key(\"Subject\", \"detailed\", [\"domain\", \"Image_Subject_fkey\"]) ml.remove_visible_foreign_key(\"Subject\", \"detailed\", 0)  # Remove first ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef remove_visible_foreign_key(\n    self,\n    table: str | Table,\n    context: str,\n    foreign_key: list[str] | int,\n) -&gt; list[Any]:\n    \"\"\"Remove a foreign key from the visible-foreign-keys list for a specific context.\n\n    Convenience method for removing related tables without replacing the entire\n    visible-foreign-keys annotation. Changes are staged until apply_annotations()\n    is called.\n\n    Args:\n        table: Table name or Table object.\n        context: The context to modify (e.g., \"detailed\", \"*\").\n        foreign_key: Foreign key to remove. Can be:\n            - List: foreign key reference [schema, constraint] to find and remove\n            - Integer: index position to remove (0-indexed)\n\n    Returns:\n        The updated foreign key list for the context.\n\n    Raises:\n        DerivaMLException: If annotation or context doesn't exist, or foreign key not found.\n\n    Example:\n        &gt;&gt;&gt; ml.remove_visible_foreign_key(\"Subject\", \"detailed\", [\"domain\", \"Image_Subject_fkey\"])\n        &gt;&gt;&gt; ml.remove_visible_foreign_key(\"Subject\", \"detailed\", 0)  # Remove first\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    # Get visible_foreign_keys annotation\n    visible_fkeys = table_obj.annotations.get(VISIBLE_FOREIGN_KEYS_TAG, {})\n    if not visible_fkeys:\n        raise DerivaMLException(\n            f\"Table '{table_obj.name}' has no visible-foreign-keys annotation.\"\n        )\n\n    # Get the context list\n    context_list = visible_fkeys.get(context)\n    if context_list is None:\n        raise DerivaMLException(\n            f\"Context '{context}' not found in visible-foreign-keys annotation.\"\n        )\n    if isinstance(context_list, str):\n        raise DerivaMLException(\n            f\"Context '{context}' references another context '{context_list}'. \"\n            \"Set it explicitly first with set_visible_foreign_keys().\"\n        )\n\n    # Make a copy\n    context_list = list(context_list)\n    removed = None\n\n    # Remove by index or by value\n    if isinstance(foreign_key, int):\n        if 0 &lt;= foreign_key &lt; len(context_list):\n            removed = context_list.pop(foreign_key)\n        else:\n            raise DerivaMLException(\n                f\"Index {foreign_key} out of range (list has {len(context_list)} items).\"\n            )\n    else:\n        # Find and remove the foreign key\n        for i, item in enumerate(context_list):\n            if item == foreign_key:\n                removed = context_list.pop(i)\n                break\n\n        if removed is None:\n            raise DerivaMLException(\n                f\"Foreign key {foreign_key!r} not found in context '{context}'.\"\n            )\n\n    # Update the annotation\n    visible_fkeys[context] = context_list\n    table_obj.annotations[VISIBLE_FOREIGN_KEYS_TAG] = visible_fkeys\n\n    return context_list\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.reorder_visible_columns","title":"reorder_visible_columns","text":"<pre><code>reorder_visible_columns(\n    table: str | Table,\n    context: str,\n    new_order: list[int]\n    | list[\n        str | list[str] | dict[str, Any]\n    ],\n) -&gt; list[Any]\n</code></pre> <p>Reorder columns in the visible-columns list for a specific context.</p> <p>Convenience method for reordering columns without manually reconstructing the list. Changes are staged until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>context</code> <code>str</code> <p>The context to modify (e.g., \"compact\", \"detailed\").</p> required <code>new_order</code> <code>list[int] | list[str | list[str] | dict[str, Any]]</code> <p>The new order specification. Can be: - List of indices: [2, 0, 1, 3] reorders by current positions - List of column specs: [\"Name\", \"RID\", ...] specifies exact order</p> required <p>Returns:</p> Type Description <code>list[Any]</code> <p>The reordered column list.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If annotation or context doesn't exist, or invalid order.</p> Example <p>ml.reorder_visible_columns(\"Image\", \"compact\", [2, 0, 1, 3, 4]) ml.reorder_visible_columns(\"Image\", \"compact\", [\"Filename\", \"Subject\", \"RID\"]) ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef reorder_visible_columns(\n    self,\n    table: str | Table,\n    context: str,\n    new_order: list[int] | list[str | list[str] | dict[str, Any]],\n) -&gt; list[Any]:\n    \"\"\"Reorder columns in the visible-columns list for a specific context.\n\n    Convenience method for reordering columns without manually reconstructing\n    the list. Changes are staged until apply_annotations() is called.\n\n    Args:\n        table: Table name or Table object.\n        context: The context to modify (e.g., \"compact\", \"detailed\").\n        new_order: The new order specification. Can be:\n            - List of indices: [2, 0, 1, 3] reorders by current positions\n            - List of column specs: [\"Name\", \"RID\", ...] specifies exact order\n\n    Returns:\n        The reordered column list.\n\n    Raises:\n        DerivaMLException: If annotation or context doesn't exist, or invalid order.\n\n    Example:\n        &gt;&gt;&gt; ml.reorder_visible_columns(\"Image\", \"compact\", [2, 0, 1, 3, 4])\n        &gt;&gt;&gt; ml.reorder_visible_columns(\"Image\", \"compact\", [\"Filename\", \"Subject\", \"RID\"])\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    # Get visible_columns annotation\n    visible_cols = table_obj.annotations.get(VISIBLE_COLUMNS_TAG, {})\n    if not visible_cols:\n        raise DerivaMLException(f\"Table '{table_obj.name}' has no visible-columns annotation.\")\n\n    # Get the context list\n    context_list = visible_cols.get(context)\n    if context_list is None:\n        raise DerivaMLException(f\"Context '{context}' not found in visible-columns annotation.\")\n    if isinstance(context_list, str):\n        raise DerivaMLException(\n            f\"Context '{context}' references another context '{context_list}'. \"\n            \"Set it explicitly first with set_visible_columns().\"\n        )\n\n    original_list = list(context_list)\n\n    # Determine if new_order is indices or column specs\n    if new_order and isinstance(new_order[0], int):\n        # Reorder by indices\n        if len(new_order) != len(original_list):\n            raise DerivaMLException(\n                f\"Index list length ({len(new_order)}) must match \"\n                f\"current list length ({len(original_list)}).\"\n            )\n        if set(new_order) != set(range(len(original_list))):\n            raise DerivaMLException(\"Index list must contain each index exactly once.\")\n        new_list = [original_list[i] for i in new_order]\n    else:\n        # new_order is the exact new column list\n        new_list = list(new_order)\n\n    # Update the annotation\n    visible_cols[context] = new_list\n    table_obj.annotations[VISIBLE_COLUMNS_TAG] = visible_cols\n\n    return new_list\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.reorder_visible_foreign_keys","title":"reorder_visible_foreign_keys","text":"<pre><code>reorder_visible_foreign_keys(\n    table: str | Table,\n    context: str,\n    new_order: list[int]\n    | list[list[str] | dict[str, Any]],\n) -&gt; list[Any]\n</code></pre> <p>Reorder foreign keys in the visible-foreign-keys list for a specific context.</p> <p>Convenience method for reordering related tables without manually reconstructing the list. Changes are staged until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>context</code> <code>str</code> <p>The context to modify (e.g., \"detailed\", \"*\").</p> required <code>new_order</code> <code>list[int] | list[list[str] | dict[str, Any]]</code> <p>The new order specification. Can be: - List of indices: [2, 0, 1] reorders by current positions - List of foreign key refs: [[\"schema\", \"fkey1\"], ...] specifies exact order</p> required <p>Returns:</p> Type Description <code>list[Any]</code> <p>The reordered foreign key list.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If annotation or context doesn't exist, or invalid order.</p> Example <p>ml.reorder_visible_foreign_keys(\"Subject\", \"detailed\", [2, 0, 1]) ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef reorder_visible_foreign_keys(\n    self,\n    table: str | Table,\n    context: str,\n    new_order: list[int] | list[list[str] | dict[str, Any]],\n) -&gt; list[Any]:\n    \"\"\"Reorder foreign keys in the visible-foreign-keys list for a specific context.\n\n    Convenience method for reordering related tables without manually\n    reconstructing the list. Changes are staged until apply_annotations()\n    is called.\n\n    Args:\n        table: Table name or Table object.\n        context: The context to modify (e.g., \"detailed\", \"*\").\n        new_order: The new order specification. Can be:\n            - List of indices: [2, 0, 1] reorders by current positions\n            - List of foreign key refs: [[\"schema\", \"fkey1\"], ...] specifies exact order\n\n    Returns:\n        The reordered foreign key list.\n\n    Raises:\n        DerivaMLException: If annotation or context doesn't exist, or invalid order.\n\n    Example:\n        &gt;&gt;&gt; ml.reorder_visible_foreign_keys(\"Subject\", \"detailed\", [2, 0, 1])\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    # Get visible_foreign_keys annotation\n    visible_fkeys = table_obj.annotations.get(VISIBLE_FOREIGN_KEYS_TAG, {})\n    if not visible_fkeys:\n        raise DerivaMLException(\n            f\"Table '{table_obj.name}' has no visible-foreign-keys annotation.\"\n        )\n\n    # Get the context list\n    context_list = visible_fkeys.get(context)\n    if context_list is None:\n        raise DerivaMLException(\n            f\"Context '{context}' not found in visible-foreign-keys annotation.\"\n        )\n    if isinstance(context_list, str):\n        raise DerivaMLException(\n            f\"Context '{context}' references another context '{context_list}'. \"\n            \"Set it explicitly first with set_visible_foreign_keys().\"\n        )\n\n    original_list = list(context_list)\n\n    # Determine if new_order is indices or foreign key specs\n    if new_order and isinstance(new_order[0], int):\n        # Reorder by indices\n        if len(new_order) != len(original_list):\n            raise DerivaMLException(\n                f\"Index list length ({len(new_order)}) must match \"\n                f\"current list length ({len(original_list)}).\"\n            )\n        if set(new_order) != set(range(len(original_list))):\n            raise DerivaMLException(\"Index list must contain each index exactly once.\")\n        new_list = [original_list[i] for i in new_order]\n    else:\n        # new_order is the exact new foreign key list\n        new_list = list(new_order)\n\n    # Update the annotation\n    visible_fkeys[context] = new_list\n    table_obj.annotations[VISIBLE_FOREIGN_KEYS_TAG] = visible_fkeys\n\n    return new_list\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.resolve_rid","title":"resolve_rid","text":"<pre><code>resolve_rid(\n    rid: RID,\n) -&gt; ResolveRidResult\n</code></pre> <p>Resolves RID to catalog location.</p> <p>Looks up a RID and returns information about where it exists in the catalog, including schema, table, and column metadata.</p> <p>Parameters:</p> Name Type Description Default <code>rid</code> <code>RID</code> <p>Resource Identifier to resolve.</p> required <p>Returns:</p> Name Type Description <code>ResolveRidResult</code> <code>ResolveRidResult</code> <p>Named tuple containing: - schema: Schema name - table: Table name - columns: Column definitions - datapath: Path builder for accessing the entity</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If RID doesn't exist in catalog.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; result = ml.resolve_rid(\"1-abc123\")\n&gt;&gt;&gt; print(f\"Found in {result.schema}.{result.table}\")\n&gt;&gt;&gt; data = result.datapath.entities().fetch()\n</code></pre> Source code in <code>src/deriva_ml/core/mixins/rid_resolution.py</code> <pre><code>def resolve_rid(self, rid: RID) -&gt; ResolveRidResult:\n    \"\"\"Resolves RID to catalog location.\n\n    Looks up a RID and returns information about where it exists in the catalog, including schema,\n    table, and column metadata.\n\n    Args:\n        rid: Resource Identifier to resolve.\n\n    Returns:\n        ResolveRidResult: Named tuple containing:\n            - schema: Schema name\n            - table: Table name\n            - columns: Column definitions\n            - datapath: Path builder for accessing the entity\n\n    Raises:\n        DerivaMLException: If RID doesn't exist in catalog.\n\n    Examples:\n        &gt;&gt;&gt; result = ml.resolve_rid(\"1-abc123\")\n        &gt;&gt;&gt; print(f\"Found in {result.schema}.{result.table}\")\n        &gt;&gt;&gt; data = result.datapath.entities().fetch()\n    \"\"\"\n    try:\n        # Attempt to resolve RID using catalog model\n        return self.catalog.resolve_rid(rid, self.model.model)\n    except KeyError as _e:\n        raise DerivaMLException(f\"Invalid RID {rid}\")\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.resolve_rids","title":"resolve_rids","text":"<pre><code>resolve_rids(\n    rids: set[RID] | list[RID],\n    candidate_tables: list[Table]\n    | None = None,\n) -&gt; dict[RID, BatchRidResult]\n</code></pre> <p>Batch resolve multiple RIDs efficiently.</p> <p>Resolves multiple RIDs in batched queries, significantly faster than calling resolve_rid() for each RID individually. Instead of N network calls for N RIDs, this makes one query per candidate table.</p> <p>Parameters:</p> Name Type Description Default <code>rids</code> <code>set[RID] | list[RID]</code> <p>Set or list of RIDs to resolve.</p> required <code>candidate_tables</code> <code>list[Table] | None</code> <p>Optional list of Table objects to search in. If not provided, searches all tables in domain and ML schemas.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[RID, BatchRidResult]</code> <p>dict[RID, BatchRidResult]: Mapping from each resolved RID to its BatchRidResult containing table information.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If any RID cannot be resolved.</p> Example <p>results = ml.resolve_rids([\"1-ABC\", \"2-DEF\", \"3-GHI\"]) for rid, info in results.items(): ...     print(f\"{rid} is in table {info.table_name}\")</p> Source code in <code>src/deriva_ml/core/mixins/rid_resolution.py</code> <pre><code>def resolve_rids(\n    self,\n    rids: set[RID] | list[RID],\n    candidate_tables: list[Table] | None = None,\n) -&gt; dict[RID, BatchRidResult]:\n    \"\"\"Batch resolve multiple RIDs efficiently.\n\n    Resolves multiple RIDs in batched queries, significantly faster than\n    calling resolve_rid() for each RID individually. Instead of N network\n    calls for N RIDs, this makes one query per candidate table.\n\n    Args:\n        rids: Set or list of RIDs to resolve.\n        candidate_tables: Optional list of Table objects to search in.\n            If not provided, searches all tables in domain and ML schemas.\n\n    Returns:\n        dict[RID, BatchRidResult]: Mapping from each resolved RID to its\n            BatchRidResult containing table information.\n\n    Raises:\n        DerivaMLException: If any RID cannot be resolved.\n\n    Example:\n        &gt;&gt;&gt; results = ml.resolve_rids([\"1-ABC\", \"2-DEF\", \"3-GHI\"])\n        &gt;&gt;&gt; for rid, info in results.items():\n        ...     print(f\"{rid} is in table {info.table_name}\")\n    \"\"\"\n    rids = set(rids)\n    if not rids:\n        return {}\n\n    results: dict[RID, BatchRidResult] = {}\n    remaining_rids = set(rids)\n\n    # Determine which tables to search\n    if candidate_tables is None:\n        # Search all tables in domain and ML schemas\n        candidate_tables = []\n        for schema_name in [*self.model.domain_schemas, self.model.ml_schema]:\n            schema = self.model.model.schemas.get(schema_name)\n            if schema:\n                candidate_tables.extend(schema.tables.values())\n\n    pb = self.pathBuilder()\n\n    # Query each candidate table for matching RIDs\n    for table in candidate_tables:\n        if not remaining_rids:\n            break\n\n        schema_name = table.schema.name\n        table_name = table.name\n\n        # Build a query with RID filter for all remaining RIDs\n        table_path = pb.schemas[schema_name].tables[table_name]\n\n        # Use ERMrest's Any quantifier for IN-style query\n        # Query only for RID column to minimize data transfer\n        try:\n            # Filter: RID = any(rid1, rid2, ...) - ERMrest's way of doing IN clause\n            found_entities = list(\n                table_path.filter(table_path.RID == AnyQuantifier(*remaining_rids))\n                .attributes(table_path.RID)\n                .fetch()\n            )\n        except Exception:\n            # Table might not support this query, skip it\n            continue\n\n        # Process found RIDs\n        for entity in found_entities:\n            rid = entity[\"RID\"]\n            if rid in remaining_rids:\n                results[rid] = BatchRidResult(\n                    rid=rid,\n                    table=table,\n                    table_name=table_name,\n                    schema_name=schema_name,\n                )\n                remaining_rids.remove(rid)\n\n    # Check if any RIDs were not found\n    if remaining_rids:\n        raise DerivaMLException(f\"Invalid RIDs: {remaining_rids}\")\n\n    return results\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.restore_execution","title":"restore_execution","text":"<pre><code>restore_execution(\n    execution_rid: RID | None = None,\n) -&gt; \"Execution\"\n</code></pre> <p>Restores a previous execution.</p> <p>Given an execution RID, retrieves the execution configuration and restores the local compute environment. This routine has a number of side effects.</p> <ol> <li> <p>The datasets specified in the configuration are downloaded and placed in the cache-dir. If a version is not specified in the configuration, then a new minor version number is created for the dataset and downloaded.</p> </li> <li> <p>If any execution assets are provided in the configuration, they are downloaded and placed in the working directory.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>execution_rid</code> <code>RID | None</code> <p>Resource Identifier (RID) of the execution to restore.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Execution</code> <code>'Execution'</code> <p>An execution object representing the restored execution environment.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If execution_rid is not valid or execution cannot be restored.</p> Example <p>execution = ml.restore_execution(\"1-abc123\")</p> Source code in <code>src/deriva_ml/core/mixins/execution.py</code> <pre><code>def restore_execution(self, execution_rid: RID | None = None) -&gt; \"Execution\":\n    \"\"\"Restores a previous execution.\n\n    Given an execution RID, retrieves the execution configuration and restores the local compute environment.\n    This routine has a number of side effects.\n\n    1. The datasets specified in the configuration are downloaded and placed in the cache-dir. If a version is\n    not specified in the configuration, then a new minor version number is created for the dataset and downloaded.\n\n    2. If any execution assets are provided in the configuration, they are downloaded and placed\n    in the working directory.\n\n    Args:\n        execution_rid: Resource Identifier (RID) of the execution to restore.\n\n    Returns:\n        Execution: An execution object representing the restored execution environment.\n\n    Raises:\n        DerivaMLException: If execution_rid is not valid or execution cannot be restored.\n\n    Example:\n        &gt;&gt;&gt; execution = ml.restore_execution(\"1-abc123\")\n    \"\"\"\n    # Import here to avoid circular dependency\n    from deriva_ml.execution.execution import Execution\n\n    # If no RID provided, try to find single execution in working directory\n    if not execution_rid:\n        e_rids = execution_rids(self.working_dir)\n        if len(e_rids) != 1:\n            raise DerivaMLException(f\"Multiple execution RIDs were found {e_rids}.\")\n        execution_rid = e_rids[0]\n\n    # Try to load configuration from a file\n    cfile = asset_file_path(\n        prefix=self.working_dir,\n        exec_rid=execution_rid,\n        file_name=\"configuration.json\",\n        asset_table=self.model.name_to_table(\"Execution_Metadata\"),\n        metadata={},\n    )\n\n    # Load configuration from a file or create from an execution record\n    if cfile.exists():\n        configuration = ExecutionConfiguration.load_configuration(cfile)\n    else:\n        execution = self.retrieve_rid(execution_rid)\n        # Look up the workflow object from the RID\n        workflow_rid = execution.get(\"Workflow\")\n        workflow = self.lookup_workflow(workflow_rid) if workflow_rid else None\n        configuration = ExecutionConfiguration(\n            workflow=workflow,\n            description=execution[\"Description\"],\n        )\n\n    # Create and return an execution instance\n    return Execution(configuration, self, reload=execution_rid)  # type: ignore[arg-type]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.retrieve_rid","title":"retrieve_rid","text":"<pre><code>retrieve_rid(\n    rid: RID,\n) -&gt; dict[str, Any]\n</code></pre> <p>Retrieves complete record for RID.</p> <p>Fetches all column values for the entity identified by the RID.</p> <p>Parameters:</p> Name Type Description Default <code>rid</code> <code>RID</code> <p>Resource Identifier of the record to retrieve.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing all column values for the entity.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the RID doesn't exist in the catalog.</p> Example <p>record = ml.retrieve_rid(\"1-abc123\") print(f\"Name: {record['name']}, Created: {record['creation_date']}\")</p> Source code in <code>src/deriva_ml/core/mixins/rid_resolution.py</code> <pre><code>def retrieve_rid(self, rid: RID) -&gt; dict[str, Any]:\n    \"\"\"Retrieves complete record for RID.\n\n    Fetches all column values for the entity identified by the RID.\n\n    Args:\n        rid: Resource Identifier of the record to retrieve.\n\n    Returns:\n        dict[str, Any]: Dictionary containing all column values for the entity.\n\n    Raises:\n        DerivaMLException: If the RID doesn't exist in the catalog.\n\n    Example:\n        &gt;&gt;&gt; record = ml.retrieve_rid(\"1-abc123\")\n        &gt;&gt;&gt; print(f\"Name: {record['name']}, Created: {record['creation_date']}\")\n    \"\"\"\n    # Resolve RID and fetch the first (only) matching record\n    return self.resolve_rid(rid).datapath.entities().fetch()[0]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.set_column_display","title":"set_column_display","text":"<pre><code>set_column_display(\n    table: str | Table,\n    column_name: str,\n    annotation: dict[str, Any] | None,\n) -&gt; str\n</code></pre> <p>Set the column-display annotation on a column.</p> <p>Controls how a column's values are rendered, including custom formatting and markdown patterns. Changes are staged locally until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object containing the column.</p> required <code>column_name</code> <code>str</code> <p>Name of the column.</p> required <code>annotation</code> <code>dict[str, Any] | None</code> <p>The column-display annotation value. Set to None to remove.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Column identifier (table.column).</p> Example <p>ml.set_column_display(\"Measurement\", \"Value\", { ...     \"*\": {\"pre_format\": {\"format\": \"%.2f\"}} ... }) ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef set_column_display(\n    self,\n    table: str | Table,\n    column_name: str,\n    annotation: dict[str, Any] | None,\n) -&gt; str:\n    \"\"\"Set the column-display annotation on a column.\n\n    Controls how a column's values are rendered, including custom\n    formatting and markdown patterns.\n    Changes are staged locally until apply_annotations() is called.\n\n    Args:\n        table: Table name or Table object containing the column.\n        column_name: Name of the column.\n        annotation: The column-display annotation value. Set to None to remove.\n\n    Returns:\n        Column identifier (table.column).\n\n    Example:\n        &gt;&gt;&gt; ml.set_column_display(\"Measurement\", \"Value\", {\n        ...     \"*\": {\"pre_format\": {\"format\": \"%.2f\"}}\n        ... })\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n    column = table_obj.columns[column_name]\n\n    if annotation is None:\n        column.annotations.pop(COLUMN_DISPLAY_TAG, None)\n    else:\n        column.annotations[COLUMN_DISPLAY_TAG] = annotation\n\n    return f\"{table_obj.name}.{column_name}\"\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.set_display_annotation","title":"set_display_annotation","text":"<pre><code>set_display_annotation(\n    table: str | Table,\n    annotation: dict[str, Any] | None,\n    column_name: str | None = None,\n) -&gt; str\n</code></pre> <p>Set the display annotation on a table or column.</p> <p>The display annotation controls basic naming and display options. Changes are staged locally until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>annotation</code> <code>dict[str, Any] | None</code> <p>The display annotation value. Set to None to remove.</p> required <code>column_name</code> <code>str | None</code> <p>If provided, sets annotation on the column; otherwise on the table.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Target identifier (table name or table.column).</p> Example <p>ml.set_display_annotation(\"Image\", {\"name\": \"Images\"}) ml.set_display_annotation(\"Image\", {\"name\": \"File Name\"}, column_name=\"Filename\") ml.apply_annotations()  # Commit changes</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef set_display_annotation(\n    self,\n    table: str | Table,\n    annotation: dict[str, Any] | None,\n    column_name: str | None = None,\n) -&gt; str:\n    \"\"\"Set the display annotation on a table or column.\n\n    The display annotation controls basic naming and display options.\n    Changes are staged locally until apply_annotations() is called.\n\n    Args:\n        table: Table name or Table object.\n        annotation: The display annotation value. Set to None to remove.\n        column_name: If provided, sets annotation on the column; otherwise on the table.\n\n    Returns:\n        Target identifier (table name or table.column).\n\n    Example:\n        &gt;&gt;&gt; ml.set_display_annotation(\"Image\", {\"name\": \"Images\"})\n        &gt;&gt;&gt; ml.set_display_annotation(\"Image\", {\"name\": \"File Name\"}, column_name=\"Filename\")\n        &gt;&gt;&gt; ml.apply_annotations()  # Commit changes\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    if column_name:\n        column = table_obj.columns[column_name]\n        if annotation is None:\n            column.annotations.pop(DISPLAY_TAG, None)\n        else:\n            column.annotations[DISPLAY_TAG] = annotation\n        return f\"{table_obj.name}.{column_name}\"\n    else:\n        if annotation is None:\n            table_obj.annotations.pop(DISPLAY_TAG, None)\n        else:\n            table_obj.annotations[DISPLAY_TAG] = annotation\n        return table_obj.name\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.set_table_display","title":"set_table_display","text":"<pre><code>set_table_display(\n    table: str | Table,\n    annotation: dict[str, Any] | None,\n) -&gt; str\n</code></pre> <p>Set the table-display annotation on a table.</p> <p>Controls table-level display options like row naming patterns, page size, and row ordering. Changes are staged locally until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>annotation</code> <code>dict[str, Any] | None</code> <p>The table-display annotation value. Set to None to remove.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Table name.</p> Example <p>ml.set_table_display(\"Subject\", { ...     \"row_name\": { ...         \"row_markdown_pattern\": \"{{{Name}}} ({{{Species}}})\" ...     } ... }) ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef set_table_display(\n    self,\n    table: str | Table,\n    annotation: dict[str, Any] | None,\n) -&gt; str:\n    \"\"\"Set the table-display annotation on a table.\n\n    Controls table-level display options like row naming patterns,\n    page size, and row ordering.\n    Changes are staged locally until apply_annotations() is called.\n\n    Args:\n        table: Table name or Table object.\n        annotation: The table-display annotation value. Set to None to remove.\n\n    Returns:\n        Table name.\n\n    Example:\n        &gt;&gt;&gt; ml.set_table_display(\"Subject\", {\n        ...     \"row_name\": {\n        ...         \"row_markdown_pattern\": \"{{{Name}}} ({{{Species}}})\"\n        ...     }\n        ... })\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    if annotation is None:\n        table_obj.annotations.pop(TABLE_DISPLAY_TAG, None)\n    else:\n        table_obj.annotations[TABLE_DISPLAY_TAG] = annotation\n\n    return table_obj.name\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.set_visible_columns","title":"set_visible_columns","text":"<pre><code>set_visible_columns(\n    table: str | Table,\n    annotation: dict[str, Any] | None,\n) -&gt; str\n</code></pre> <p>Set the visible-columns annotation on a table.</p> <p>Controls which columns appear in different UI contexts and their order. Changes are staged locally until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>annotation</code> <code>dict[str, Any] | None</code> <p>The visible-columns annotation value. Set to None to remove.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Table name.</p> Example <p>ml.set_visible_columns(\"Image\", { ...     \"compact\": [\"RID\", \"Filename\", \"Subject\"], ...     \"detailed\": [\"RID\", \"Filename\", \"Subject\", \"Description\"] ... }) ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef set_visible_columns(\n    self,\n    table: str | Table,\n    annotation: dict[str, Any] | None,\n) -&gt; str:\n    \"\"\"Set the visible-columns annotation on a table.\n\n    Controls which columns appear in different UI contexts and their order.\n    Changes are staged locally until apply_annotations() is called.\n\n    Args:\n        table: Table name or Table object.\n        annotation: The visible-columns annotation value. Set to None to remove.\n\n    Returns:\n        Table name.\n\n    Example:\n        &gt;&gt;&gt; ml.set_visible_columns(\"Image\", {\n        ...     \"compact\": [\"RID\", \"Filename\", \"Subject\"],\n        ...     \"detailed\": [\"RID\", \"Filename\", \"Subject\", \"Description\"]\n        ... })\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    if annotation is None:\n        table_obj.annotations.pop(VISIBLE_COLUMNS_TAG, None)\n    else:\n        table_obj.annotations[VISIBLE_COLUMNS_TAG] = annotation\n\n    return table_obj.name\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.set_visible_foreign_keys","title":"set_visible_foreign_keys","text":"<pre><code>set_visible_foreign_keys(\n    table: str | Table,\n    annotation: dict[str, Any] | None,\n) -&gt; str\n</code></pre> <p>Set the visible-foreign-keys annotation on a table.</p> <p>Controls which related tables (via inbound foreign keys) appear in different UI contexts and their order. Changes are staged locally until apply_annotations() is called.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or Table object.</p> required <code>annotation</code> <code>dict[str, Any] | None</code> <p>The visible-foreign-keys annotation value. Set to None to remove.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Table name.</p> Example <p>ml.set_visible_foreign_keys(\"Subject\", { ...     \"detailed\": [ ...         [\"domain\", \"Image_Subject_fkey\"], ...         [\"domain\", \"Diagnosis_Subject_fkey\"] ...     ] ... }) ml.apply_annotations()</p> Source code in <code>src/deriva_ml/core/mixins/annotation.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef set_visible_foreign_keys(\n    self,\n    table: str | Table,\n    annotation: dict[str, Any] | None,\n) -&gt; str:\n    \"\"\"Set the visible-foreign-keys annotation on a table.\n\n    Controls which related tables (via inbound foreign keys) appear in\n    different UI contexts and their order.\n    Changes are staged locally until apply_annotations() is called.\n\n    Args:\n        table: Table name or Table object.\n        annotation: The visible-foreign-keys annotation value. Set to None to remove.\n\n    Returns:\n        Table name.\n\n    Example:\n        &gt;&gt;&gt; ml.set_visible_foreign_keys(\"Subject\", {\n        ...     \"detailed\": [\n        ...         [\"domain\", \"Image_Subject_fkey\"],\n        ...         [\"domain\", \"Diagnosis_Subject_fkey\"]\n        ...     ]\n        ... })\n        &gt;&gt;&gt; ml.apply_annotations()\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n\n    if annotation is None:\n        table_obj.annotations.pop(VISIBLE_FOREIGN_KEYS_TAG, None)\n    else:\n        table_obj.annotations[VISIBLE_FOREIGN_KEYS_TAG] = annotation\n\n    return table_obj.name\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.table_path","title":"table_path","text":"<pre><code>table_path(\n    table: str | Table,\n    schema: str | None = None,\n) -&gt; Path\n</code></pre> <p>Returns a local filesystem path for table CSV files.</p> <p>Generates a standardized path where CSV files should be placed when preparing to upload data to a table. The path follows the project's directory structure conventions.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Name of the table or Table object to get the path for.</p> required <code>schema</code> <code>str | None</code> <p>Schema name for the path. If None, uses the table's schema or default_schema.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Filesystem path where the CSV file should be placed.</p> Example <p>path = ml.table_path(\"experiment_results\") df.to_csv(path) # Save data for upload</p> Source code in <code>src/deriva_ml/core/mixins/path_builder.py</code> <pre><code>def table_path(self, table: str | Table, schema: str | None = None) -&gt; Path:\n    \"\"\"Returns a local filesystem path for table CSV files.\n\n    Generates a standardized path where CSV files should be placed when preparing to upload data to a table.\n    The path follows the project's directory structure conventions.\n\n    Args:\n        table: Name of the table or Table object to get the path for.\n        schema: Schema name for the path. If None, uses the table's schema or default_schema.\n\n    Returns:\n        Path: Filesystem path where the CSV file should be placed.\n\n    Example:\n        &gt;&gt;&gt; path = ml.table_path(\"experiment_results\")\n        &gt;&gt;&gt; df.to_csv(path) # Save data for upload\n    \"\"\"\n    table_obj = self.model.name_to_table(table)\n    # Use table's schema if available, otherwise use provided schema or default\n    schema = schema or table_obj.schema.name\n    return _table_path(\n        self.working_dir,\n        schema=schema,\n        table=table_obj.name,\n    )\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.user_list","title":"user_list","text":"<pre><code>user_list() -&gt; List[Dict[str, str]]\n</code></pre> <p>Returns catalog user list.</p> <p>Retrieves basic information about all users who have access to the catalog, including their identifiers and full names.</p> <p>Returns:</p> Type Description <code>List[Dict[str, str]]</code> <p>List[Dict[str, str]]: List of user information dictionaries, each containing: - 'ID': User identifier - 'Full_Name': User's full name</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; users = ml.user_list()\n&gt;&gt;&gt; for user in users:\n...     print(f\"{user['Full_Name']} ({user['ID']})\")\n</code></pre> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def user_list(self) -&gt; List[Dict[str, str]]:\n    \"\"\"Returns catalog user list.\n\n    Retrieves basic information about all users who have access to the catalog, including their\n    identifiers and full names.\n\n    Returns:\n        List[Dict[str, str]]: List of user information dictionaries, each containing:\n            - 'ID': User identifier\n            - 'Full_Name': User's full name\n\n    Examples:\n\n        &gt;&gt;&gt; users = ml.user_list()\n        &gt;&gt;&gt; for user in users:\n        ...     print(f\"{user['Full_Name']} ({user['ID']})\")\n    \"\"\"\n    # Get the user table path and fetch basic user info\n    user_path = self.pathBuilder().public.ERMrest_Client.path\n    return [{\"ID\": u[\"ID\"], \"Full_Name\": u[\"Full_Name\"]} for u in user_path.entities().fetch()]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.validate_schema","title":"validate_schema","text":"<pre><code>validate_schema(\n    strict: bool = False,\n) -&gt; \"SchemaValidationReport\"\n</code></pre> <p>Validate that the catalog's ML schema matches the expected structure.</p> <p>This method inspects the catalog schema and verifies that it contains all the required tables, columns, vocabulary terms, and relationships that are created by the ML schema initialization routines in create_schema.py.</p> <p>The validation checks: - All required ML tables exist (Dataset, Execution, Workflow, etc.) - All required columns exist with correct types - All required vocabulary tables exist (Asset_Type, Dataset_Type, etc.) - All required vocabulary terms are initialized - All association tables exist for relationships</p> <p>In strict mode, the validator also reports errors for: - Extra tables not in the expected schema - Extra columns not in the expected table definitions</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool</code> <p>If True, extra tables and columns are reported as errors.    If False (default), they are reported as informational items.    Use strict=True to verify a clean ML catalog matches exactly.    Use strict=False to validate a catalog that may have domain extensions.</p> <code>False</code> <p>Returns:</p> Type Description <code>'SchemaValidationReport'</code> <p>SchemaValidationReport with validation results. Key attributes: - is_valid: True if no errors were found - errors: List of error-level issues - warnings: List of warning-level issues - info: List of informational items - to_text(): Human-readable report - to_dict(): JSON-serializable dictionary</p> Example <p>ml = DerivaML('localhost', 'my_catalog') report = ml.validate_schema(strict=False) if report.is_valid: ...     print(\"Schema is valid!\") ... else: ...     print(report.to_text())</p> Note <p>This method validates the ML schema (typically 'deriva-ml'), not the domain schema. Domain-specific tables and columns are not checked unless they are part of the ML schema itself.</p> See Also <ul> <li>deriva_ml.schema.validation.SchemaValidationReport</li> <li>deriva_ml.schema.validation.validate_ml_schema</li> </ul> Source code in <code>src/deriva_ml/core/base.py</code> <pre><code>def validate_schema(self, strict: bool = False) -&gt; \"SchemaValidationReport\":\n    \"\"\"Validate that the catalog's ML schema matches the expected structure.\n\n    This method inspects the catalog schema and verifies that it contains all\n    the required tables, columns, vocabulary terms, and relationships that are\n    created by the ML schema initialization routines in create_schema.py.\n\n    The validation checks:\n    - All required ML tables exist (Dataset, Execution, Workflow, etc.)\n    - All required columns exist with correct types\n    - All required vocabulary tables exist (Asset_Type, Dataset_Type, etc.)\n    - All required vocabulary terms are initialized\n    - All association tables exist for relationships\n\n    In strict mode, the validator also reports errors for:\n    - Extra tables not in the expected schema\n    - Extra columns not in the expected table definitions\n\n    Args:\n        strict: If True, extra tables and columns are reported as errors.\n               If False (default), they are reported as informational items.\n               Use strict=True to verify a clean ML catalog matches exactly.\n               Use strict=False to validate a catalog that may have domain extensions.\n\n    Returns:\n        SchemaValidationReport with validation results. Key attributes:\n            - is_valid: True if no errors were found\n            - errors: List of error-level issues\n            - warnings: List of warning-level issues\n            - info: List of informational items\n            - to_text(): Human-readable report\n            - to_dict(): JSON-serializable dictionary\n\n    Example:\n        &gt;&gt;&gt; ml = DerivaML('localhost', 'my_catalog')\n        &gt;&gt;&gt; report = ml.validate_schema(strict=False)\n        &gt;&gt;&gt; if report.is_valid:\n        ...     print(\"Schema is valid!\")\n        ... else:\n        ...     print(report.to_text())\n\n        &gt;&gt;&gt; # Strict validation for a fresh ML catalog\n        &gt;&gt;&gt; report = ml.validate_schema(strict=True)\n        &gt;&gt;&gt; print(f\"Found {len(report.errors)} errors, {len(report.warnings)} warnings\")\n\n        &gt;&gt;&gt; # Get report as dictionary for JSON/logging\n        &gt;&gt;&gt; import json\n        &gt;&gt;&gt; print(json.dumps(report.to_dict(), indent=2))\n\n    Note:\n        This method validates the ML schema (typically 'deriva-ml'), not the\n        domain schema. Domain-specific tables and columns are not checked\n        unless they are part of the ML schema itself.\n\n    See Also:\n        - deriva_ml.schema.validation.SchemaValidationReport\n        - deriva_ml.schema.validation.validate_ml_schema\n    \"\"\"\n    from deriva_ml.schema.validation import validate_ml_schema\n    return validate_ml_schema(self, strict=strict)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.validate_schema--strict-validation-for-a-fresh-ml-catalog","title":"Strict validation for a fresh ML catalog","text":"<p>report = ml.validate_schema(strict=True) print(f\"Found {len(report.errors)} errors, {len(report.warnings)} warnings\")</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaML.validate_schema--get-report-as-dictionary-for-jsonlogging","title":"Get report as dictionary for JSON/logging","text":"<p>import json print(json.dumps(report.to_dict(), indent=2))</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaMLConfig","title":"DerivaMLConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration model for DerivaML instances.</p> <p>This Pydantic model defines all configurable parameters for a DerivaML instance. It can be used directly or via Hydra configuration files.</p> <p>Attributes:</p> Name Type Description <code>hostname</code> <code>str</code> <p>Hostname of the Deriva server (e.g., 'deriva.example.org').</p> <code>catalog_id</code> <code>str | int</code> <p>Catalog identifier, either numeric ID or catalog name.</p> <code>domain_schemas</code> <code>str | set[str] | None</code> <p>Optional set of domain schema names. If None, auto-detects all non-system schemas. Use this when working with catalogs that have multiple user-defined schemas.</p> <code>default_schema</code> <code>str | None</code> <p>The default schema for table creation operations. If None and there is exactly one domain schema, that schema is used. If there are multiple domain schemas, this must be specified for table creation to work without explicit schema parameters.</p> <code>project_name</code> <code>str | None</code> <p>Project name for organizing outputs. Defaults to default_schema.</p> <code>cache_dir</code> <code>str | Path | None</code> <p>Directory for caching downloaded datasets. Defaults to working_dir/cache.</p> <code>working_dir</code> <code>str | Path | None</code> <p>Base directory for computation data. Defaults to ~/deriva-ml.</p> <code>hydra_runtime_output_dir</code> <code>str | Path | None</code> <p>Hydra's runtime output directory (set automatically).</p> <code>ml_schema</code> <code>str</code> <p>Schema name for ML tables. Defaults to 'deriva-ml'.</p> <code>logging_level</code> <code>Any</code> <p>Logging level for DerivaML. Defaults to WARNING.</p> <code>deriva_logging_level</code> <code>Any</code> <p>Logging level for Deriva libraries. Defaults to WARNING.</p> <code>credential</code> <code>Any</code> <p>Authentication credentials. If None, retrieved automatically.</p> <code>s3_bucket</code> <code>str | None</code> <p>S3 bucket URL for dataset bag storage (e.g., 's3://my-bucket'). If provided, enables MINID creation and S3 upload for dataset exports. If None, MINID functionality is disabled regardless of use_minid setting.</p> <code>use_minid</code> <code>bool | None</code> <p>Whether to use MINID service for dataset bags. Only effective when s3_bucket is configured. Defaults to True when s3_bucket is set, False otherwise.</p> <code>check_auth</code> <code>bool</code> <p>Whether to verify authentication on connection. Defaults to True.</p> <code>clean_execution_dir</code> <code>bool</code> <p>Whether to automatically clean execution working directories after successful upload. Defaults to True. Set to False to retain local copies of execution outputs for debugging or manual inspection.</p> Example <p>config = DerivaMLConfig( ...     hostname='deriva.example.org', ...     catalog_id=1, ...     default_schema='my_domain', ...     logging_level=logging.INFO ... )</p> Source code in <code>src/deriva_ml/core/config.py</code> <pre><code>class DerivaMLConfig(BaseModel):\n    \"\"\"Configuration model for DerivaML instances.\n\n    This Pydantic model defines all configurable parameters for a DerivaML instance.\n    It can be used directly or via Hydra configuration files.\n\n    Attributes:\n        hostname: Hostname of the Deriva server (e.g., 'deriva.example.org').\n        catalog_id: Catalog identifier, either numeric ID or catalog name.\n        domain_schemas: Optional set of domain schema names. If None, auto-detects all\n            non-system schemas. Use this when working with catalogs that have multiple\n            user-defined schemas.\n        default_schema: The default schema for table creation operations. If None and\n            there is exactly one domain schema, that schema is used. If there are multiple\n            domain schemas, this must be specified for table creation to work without\n            explicit schema parameters.\n        project_name: Project name for organizing outputs. Defaults to default_schema.\n        cache_dir: Directory for caching downloaded datasets. Defaults to working_dir/cache.\n        working_dir: Base directory for computation data. Defaults to ~/deriva-ml.\n        hydra_runtime_output_dir: Hydra's runtime output directory (set automatically).\n        ml_schema: Schema name for ML tables. Defaults to 'deriva-ml'.\n        logging_level: Logging level for DerivaML. Defaults to WARNING.\n        deriva_logging_level: Logging level for Deriva libraries. Defaults to WARNING.\n        credential: Authentication credentials. If None, retrieved automatically.\n        s3_bucket: S3 bucket URL for dataset bag storage (e.g., 's3://my-bucket').\n            If provided, enables MINID creation and S3 upload for dataset exports.\n            If None, MINID functionality is disabled regardless of use_minid setting.\n        use_minid: Whether to use MINID service for dataset bags. Only effective when\n            s3_bucket is configured. Defaults to True when s3_bucket is set, False otherwise.\n        check_auth: Whether to verify authentication on connection. Defaults to True.\n        clean_execution_dir: Whether to automatically clean execution working directories\n            after successful upload. Defaults to True. Set to False to retain local copies\n            of execution outputs for debugging or manual inspection.\n\n    Example:\n        &gt;&gt;&gt; config = DerivaMLConfig(\n        ...     hostname='deriva.example.org',\n        ...     catalog_id=1,\n        ...     default_schema='my_domain',\n        ...     logging_level=logging.INFO\n        ... )\n    \"\"\"\n\n    hostname: str\n    catalog_id: str | int = 1\n    domain_schemas: str | set[str] | None = None\n    default_schema: str | None = None\n    project_name: str | None = None\n    cache_dir: str | Path | None = None\n    working_dir: str | Path | None = None\n    hydra_runtime_output_dir: str | Path | None = None\n    ml_schema: str = ML_SCHEMA\n    logging_level: Any = logging.WARNING\n    deriva_logging_level: Any = logging.WARNING\n    credential: Any = None\n    s3_bucket: str | None = None\n    use_minid: bool | None = None  # None means \"auto\" - True if s3_bucket is set\n    check_auth: bool = True\n    clean_execution_dir: bool = True\n\n    @model_validator(mode=\"after\")\n    def init_working_dir(self) -&gt; \"DerivaMLConfig\":\n        \"\"\"Initialize working directory and resolve use_minid after model validation.\n\n        Sets up the working directory path, computing a default if not specified.\n        Also captures Hydra's runtime output directory for logging and outputs.\n\n        Resolves the use_minid flag based on s3_bucket configuration:\n        - If use_minid is explicitly set, use that value (but it only takes effect if s3_bucket is set)\n        - If use_minid is None (auto), set it to True if s3_bucket is configured, False otherwise\n\n        This validator runs after all field validation and ensures the working\n        directory is available for Hydra configuration resolution.\n\n        Returns:\n            Self: The configuration instance with initialized paths.\n        \"\"\"\n        self.working_dir = DerivaMLConfig.compute_workdir(self.working_dir, self.catalog_id, self.hostname)\n        self.hydra_runtime_output_dir = Path(HydraConfig.get().runtime.output_dir)\n\n        # Resolve use_minid based on s3_bucket configuration\n        if self.use_minid is None:\n            # Auto mode: enable MINID if s3_bucket is configured\n            self.use_minid = self.s3_bucket is not None\n        elif self.use_minid and self.s3_bucket is None:\n            # User requested MINID but no S3 bucket configured - disable MINID\n            self.use_minid = False\n\n        return self\n\n    @staticmethod\n    def compute_workdir(\n        working_dir: str | Path | None,\n        catalog_id: str | int | None = None,\n        hostname: str | None = None,\n    ) -&gt; Path:\n        \"\"\"Compute the effective working directory path.\n\n        Creates a standardized working directory path. If a base directory is provided,\n        appends the current username to prevent conflicts between users. If no directory\n        is provided, uses ~/.deriva-ml. The hostname and catalog_id are appended to\n        separate data from different servers and catalogs.\n\n        Args:\n            working_dir: Base working directory path, or None for default.\n            catalog_id: Catalog identifier to include in the path. If None, no\n                       catalog subdirectory is created.\n            hostname: Server hostname to include in the path. If None, no\n                     hostname subdirectory is created.\n\n        Returns:\n            Path: Absolute path to the working directory.\n\n        Example:\n            &gt;&gt;&gt; DerivaMLConfig.compute_workdir('/shared/data', '52', 'ml.example.org')\n            PosixPath('/shared/data/username/deriva-ml/ml.example.org/52')\n            &gt;&gt;&gt; DerivaMLConfig.compute_workdir(None, 1, 'localhost')\n            PosixPath('/home/username/.deriva-ml/localhost/1')\n        \"\"\"\n        # Append username and deriva-ml to provided path, or use ~/.deriva-ml as base\n        if working_dir:\n            base_dir = Path(working_dir) / getpass.getuser() / \"deriva-ml\"\n        else:\n            base_dir = Path.home() / \".deriva-ml\"\n        # Append hostname if provided to separate data from different servers\n        if hostname is not None:\n            base_dir = base_dir / hostname\n        # Append catalog_id if provided\n        if catalog_id is not None:\n            base_dir = base_dir / str(catalog_id)\n        return base_dir.absolute()\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaMLConfig.compute_workdir","title":"compute_workdir  <code>staticmethod</code>","text":"<pre><code>compute_workdir(\n    working_dir: str | Path | None,\n    catalog_id: str | int | None = None,\n    hostname: str | None = None,\n) -&gt; Path\n</code></pre> <p>Compute the effective working directory path.</p> <p>Creates a standardized working directory path. If a base directory is provided, appends the current username to prevent conflicts between users. If no directory is provided, uses ~/.deriva-ml. The hostname and catalog_id are appended to separate data from different servers and catalogs.</p> <p>Parameters:</p> Name Type Description Default <code>working_dir</code> <code>str | Path | None</code> <p>Base working directory path, or None for default.</p> required <code>catalog_id</code> <code>str | int | None</code> <p>Catalog identifier to include in the path. If None, no        catalog subdirectory is created.</p> <code>None</code> <code>hostname</code> <code>str | None</code> <p>Server hostname to include in the path. If None, no      hostname subdirectory is created.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Absolute path to the working directory.</p> Example <p>DerivaMLConfig.compute_workdir('/shared/data', '52', 'ml.example.org') PosixPath('/shared/data/username/deriva-ml/ml.example.org/52') DerivaMLConfig.compute_workdir(None, 1, 'localhost') PosixPath('/home/username/.deriva-ml/localhost/1')</p> Source code in <code>src/deriva_ml/core/config.py</code> <pre><code>@staticmethod\ndef compute_workdir(\n    working_dir: str | Path | None,\n    catalog_id: str | int | None = None,\n    hostname: str | None = None,\n) -&gt; Path:\n    \"\"\"Compute the effective working directory path.\n\n    Creates a standardized working directory path. If a base directory is provided,\n    appends the current username to prevent conflicts between users. If no directory\n    is provided, uses ~/.deriva-ml. The hostname and catalog_id are appended to\n    separate data from different servers and catalogs.\n\n    Args:\n        working_dir: Base working directory path, or None for default.\n        catalog_id: Catalog identifier to include in the path. If None, no\n                   catalog subdirectory is created.\n        hostname: Server hostname to include in the path. If None, no\n                 hostname subdirectory is created.\n\n    Returns:\n        Path: Absolute path to the working directory.\n\n    Example:\n        &gt;&gt;&gt; DerivaMLConfig.compute_workdir('/shared/data', '52', 'ml.example.org')\n        PosixPath('/shared/data/username/deriva-ml/ml.example.org/52')\n        &gt;&gt;&gt; DerivaMLConfig.compute_workdir(None, 1, 'localhost')\n        PosixPath('/home/username/.deriva-ml/localhost/1')\n    \"\"\"\n    # Append username and deriva-ml to provided path, or use ~/.deriva-ml as base\n    if working_dir:\n        base_dir = Path(working_dir) / getpass.getuser() / \"deriva-ml\"\n    else:\n        base_dir = Path.home() / \".deriva-ml\"\n    # Append hostname if provided to separate data from different servers\n    if hostname is not None:\n        base_dir = base_dir / hostname\n    # Append catalog_id if provided\n    if catalog_id is not None:\n        base_dir = base_dir / str(catalog_id)\n    return base_dir.absolute()\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaMLConfig.init_working_dir","title":"init_working_dir","text":"<pre><code>init_working_dir() -&gt; DerivaMLConfig\n</code></pre> <p>Initialize working directory and resolve use_minid after model validation.</p> <p>Sets up the working directory path, computing a default if not specified. Also captures Hydra's runtime output directory for logging and outputs.</p> <p>Resolves the use_minid flag based on s3_bucket configuration: - If use_minid is explicitly set, use that value (but it only takes effect if s3_bucket is set) - If use_minid is None (auto), set it to True if s3_bucket is configured, False otherwise</p> <p>This validator runs after all field validation and ensures the working directory is available for Hydra configuration resolution.</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>DerivaMLConfig</code> <p>The configuration instance with initialized paths.</p> Source code in <code>src/deriva_ml/core/config.py</code> <pre><code>@model_validator(mode=\"after\")\ndef init_working_dir(self) -&gt; \"DerivaMLConfig\":\n    \"\"\"Initialize working directory and resolve use_minid after model validation.\n\n    Sets up the working directory path, computing a default if not specified.\n    Also captures Hydra's runtime output directory for logging and outputs.\n\n    Resolves the use_minid flag based on s3_bucket configuration:\n    - If use_minid is explicitly set, use that value (but it only takes effect if s3_bucket is set)\n    - If use_minid is None (auto), set it to True if s3_bucket is configured, False otherwise\n\n    This validator runs after all field validation and ensures the working\n    directory is available for Hydra configuration resolution.\n\n    Returns:\n        Self: The configuration instance with initialized paths.\n    \"\"\"\n    self.working_dir = DerivaMLConfig.compute_workdir(self.working_dir, self.catalog_id, self.hostname)\n    self.hydra_runtime_output_dir = Path(HydraConfig.get().runtime.output_dir)\n\n    # Resolve use_minid based on s3_bucket configuration\n    if self.use_minid is None:\n        # Auto mode: enable MINID if s3_bucket is configured\n        self.use_minid = self.s3_bucket is not None\n    elif self.use_minid and self.s3_bucket is None:\n        # User requested MINID but no S3 bucket configured - disable MINID\n        self.use_minid = False\n\n    return self\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaMLException","title":"DerivaMLException","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for all DerivaML errors.</p> <p>This is the root exception for all DerivaML-specific errors. Catching this exception will catch any error raised by the DerivaML library.</p> <p>Attributes:</p> Name Type Description <code>_msg</code> <p>The error message stored for later access.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>Descriptive error message. Defaults to empty string.</p> <code>''</code> Example <p>raise DerivaMLException(\"Failed to connect to catalog\") DerivaMLException: Failed to connect to catalog</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLException(Exception):\n    \"\"\"Base exception class for all DerivaML errors.\n\n    This is the root exception for all DerivaML-specific errors. Catching this\n    exception will catch any error raised by the DerivaML library.\n\n    Attributes:\n        _msg: The error message stored for later access.\n\n    Args:\n        msg: Descriptive error message. Defaults to empty string.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLException(\"Failed to connect to catalog\")\n        DerivaMLException: Failed to connect to catalog\n    \"\"\"\n\n    def __init__(self, msg: str = \"\") -&gt; None:\n        super().__init__(msg)\n        self._msg = msg\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaMLInvalidTerm","title":"DerivaMLInvalidTerm","text":"<p>               Bases: <code>DerivaMLNotFoundError</code></p> <p>Exception raised when a vocabulary term is not found or invalid.</p> <p>Raised when attempting to look up or use a term that doesn't exist in a controlled vocabulary table, or when a term name/synonym cannot be resolved.</p> <p>Parameters:</p> Name Type Description Default <code>vocabulary</code> <code>str</code> <p>Name of the vocabulary table being searched.</p> required <code>term</code> <code>str</code> <p>The term name that was not found.</p> required <code>msg</code> <code>str</code> <p>Additional context about the error. Defaults to \"Term doesn't exist\".</p> <code>\"Term doesn't exist\"</code> Example <p>raise DerivaMLInvalidTerm(\"Diagnosis\", \"unknown_condition\") DerivaMLInvalidTerm: Invalid term unknown_condition in vocabulary Diagnosis: Term doesn't exist.</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLInvalidTerm(DerivaMLNotFoundError):\n    \"\"\"Exception raised when a vocabulary term is not found or invalid.\n\n    Raised when attempting to look up or use a term that doesn't exist in\n    a controlled vocabulary table, or when a term name/synonym cannot be resolved.\n\n    Args:\n        vocabulary: Name of the vocabulary table being searched.\n        term: The term name that was not found.\n        msg: Additional context about the error. Defaults to \"Term doesn't exist\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLInvalidTerm(\"Diagnosis\", \"unknown_condition\")\n        DerivaMLInvalidTerm: Invalid term unknown_condition in vocabulary Diagnosis: Term doesn't exist.\n    \"\"\"\n\n    def __init__(self, vocabulary: str, term: str, msg: str = \"Term doesn't exist\") -&gt; None:\n        super().__init__(f\"Invalid term {term} in vocabulary {vocabulary}: {msg}.\")\n        self.vocabulary = vocabulary\n        self.term = term\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.DerivaMLTableTypeError","title":"DerivaMLTableTypeError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when a RID or table is not of the expected type.</p> <p>Raised when an operation requires a specific table type (e.g., Dataset, Execution) but receives a RID or table reference of a different type.</p> <p>Parameters:</p> Name Type Description Default <code>table_type</code> <code>str</code> <p>The expected table type (e.g., \"Dataset\", \"Execution\").</p> required <code>table</code> <code>str</code> <p>The actual table name or RID that was provided.</p> required Example <p>raise DerivaMLTableTypeError(\"Dataset\", \"1-ABC123\") DerivaMLTableTypeError: Table 1-ABC123 is not of type Dataset.</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLTableTypeError(DerivaMLDataError):\n    \"\"\"Exception raised when a RID or table is not of the expected type.\n\n    Raised when an operation requires a specific table type (e.g., Dataset,\n    Execution) but receives a RID or table reference of a different type.\n\n    Args:\n        table_type: The expected table type (e.g., \"Dataset\", \"Execution\").\n        table: The actual table name or RID that was provided.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLTableTypeError(\"Dataset\", \"1-ABC123\")\n        DerivaMLTableTypeError: Table 1-ABC123 is not of type Dataset.\n    \"\"\"\n\n    def __init__(self, table_type: str, table: str) -&gt; None:\n        super().__init__(f\"Table {table} is not of type {table_type}.\")\n        self.table_type = table_type\n        self.table = table\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.ExecAssetType","title":"ExecAssetType","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Execution asset type identifiers.</p> <p>Defines the types of assets that can be produced or consumed during an execution. These types are used to categorize files associated with workflow runs.</p> <p>Attributes:</p> Name Type Description <code>input_file</code> <code>str</code> <p>Input file consumed by the execution.</p> <code>output_file</code> <code>str</code> <p>Output file produced by the execution.</p> <code>notebook_output</code> <code>str</code> <p>Jupyter notebook output from the execution.</p> <code>model_file</code> <code>str</code> <p>Machine learning model file (e.g., .pkl, .h5, .pt).</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class ExecAssetType(BaseStrEnum):\n    \"\"\"Execution asset type identifiers.\n\n    Defines the types of assets that can be produced or consumed during an execution.\n    These types are used to categorize files associated with workflow runs.\n\n    Attributes:\n        input_file (str): Input file consumed by the execution.\n        output_file (str): Output file produced by the execution.\n        notebook_output (str): Jupyter notebook output from the execution.\n        model_file (str): Machine learning model file (e.g., .pkl, .h5, .pt).\n    \"\"\"\n\n    input_file = \"Input_File\"\n    output_file = \"Output_File\"\n    notebook_output = \"Notebook_Output\"\n    model_file = \"Model_File\"\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.ExecMetadataType","title":"ExecMetadataType","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Execution metadata type identifiers.</p> <p>Defines the types of metadata that can be associated with an execution.</p> <p>Attributes:</p> Name Type Description <code>execution_config</code> <code>str</code> <p>General execution configuration data.</p> <code>runtime_env</code> <code>str</code> <p>Runtime environment information.</p> <code>hydra_config</code> <code>str</code> <p>Hydra YAML configuration files (config.yaml, overrides.yaml).</p> <code>deriva_config</code> <code>str</code> <p>DerivaML execution configuration (configuration.json).</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class ExecMetadataType(BaseStrEnum):\n    \"\"\"Execution metadata type identifiers.\n\n    Defines the types of metadata that can be associated with an execution.\n\n    Attributes:\n        execution_config (str): General execution configuration data.\n        runtime_env (str): Runtime environment information.\n        hydra_config (str): Hydra YAML configuration files (config.yaml, overrides.yaml).\n        deriva_config (str): DerivaML execution configuration (configuration.json).\n    \"\"\"\n\n    execution_config = \"Execution_Config\"\n    runtime_env = \"Runtime_Env\"\n    hydra_config = \"Hydra_Config\"\n    deriva_config = \"Deriva_Config\"\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.FileSpec","title":"FileSpec","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specification for a file to be added to the Deriva catalog.</p> <p>Represents file metadata required for creating entries in the File table. Handles URL normalization, ensuring local file paths are converted to tag URIs that uniquely identify the file's origin.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>File location as URL or local path. Local paths are converted to tag URIs.</p> <code>md5</code> <code>str</code> <p>MD5 checksum for integrity verification.</p> <code>length</code> <code>int</code> <p>File size in bytes.</p> <code>description</code> <code>str | None</code> <p>Optional description of the file's contents or purpose.</p> <code>file_types</code> <code>list[str] | None</code> <p>List of file type classifications from the Asset_Type vocabulary.</p> Note <p>The 'File' type is automatically added to file_types if not present when using create_filespecs().</p> Example <p>spec = FileSpec( ...     url=\"/data/results.csv\", ...     md5=\"d41d8cd98f00b204e9800998ecf8427e\", ...     length=1024, ...     description=\"Analysis results\", ...     file_types=[\"CSV\", \"Data\"] ... )</p> Source code in <code>src/deriva_ml/core/filespec.py</code> <pre><code>class FileSpec(BaseModel):\n    \"\"\"Specification for a file to be added to the Deriva catalog.\n\n    Represents file metadata required for creating entries in the File table.\n    Handles URL normalization, ensuring local file paths are converted to\n    tag URIs that uniquely identify the file's origin.\n\n    Attributes:\n        url: File location as URL or local path. Local paths are converted to tag URIs.\n        md5: MD5 checksum for integrity verification.\n        length: File size in bytes.\n        description: Optional description of the file's contents or purpose.\n        file_types: List of file type classifications from the Asset_Type vocabulary.\n\n    Note:\n        The 'File' type is automatically added to file_types if not present when\n        using create_filespecs().\n\n    Example:\n        &gt;&gt;&gt; spec = FileSpec(\n        ...     url=\"/data/results.csv\",\n        ...     md5=\"d41d8cd98f00b204e9800998ecf8427e\",\n        ...     length=1024,\n        ...     description=\"Analysis results\",\n        ...     file_types=[\"CSV\", \"Data\"]\n        ... )\n    \"\"\"\n\n    model_config = {\"populate_by_name\": True}\n\n    url: str = Field(alias=\"URL\")\n    md5: str = Field(alias=\"MD5\")\n    length: int = Field(alias=\"Length\")\n    description: str | None = Field(default=\"\", alias=\"Description\")\n    file_types: list[str] | None = Field(default_factory=list)\n\n    @field_validator(\"url\")\n    @classmethod\n    def validate_file_url(cls, url: str) -&gt; str:\n        \"\"\"Examine the provided URL. If it's a local path, convert it into a tag URL.\n\n        Args:\n            url: The URL to validate and potentially convert\n\n        Returns:\n            The validated/converted URL\n\n        Raises:\n            ValidationError: If the URL is not a file URL\n        \"\"\"\n        url_parts = urlparse(url)\n        if url_parts.scheme == \"tag\":\n            # Already a tag URL, so just return it.\n            return url\n        elif (not url_parts.scheme) or url_parts.scheme == \"file\":\n            # There is no scheme part of the URL, or it is a file URL, so it is a local file path.\n            # Convert to a tag URL.\n            return f\"tag://{gethostname()},{date.today()}:file://{url_parts.path}\"\n        else:\n            raise ValueError(\"url is not a file URL\")\n\n    @classmethod\n    def create_filespecs(\n        cls, path: Path | str, description: str, file_types: list[str] | Callable[[Path], list[str]] | None = None\n    ) -&gt; Generator[FileSpec, None, None]:\n        \"\"\"Generate FileSpec objects for a file or directory.\n\n        Creates FileSpec objects with computed MD5 checksums for each file found.\n        For directories, recursively processes all files. The 'File' type is\n        automatically prepended to file_types if not already present.\n\n        Args:\n            path: Path to a file or directory. If directory, all files are processed recursively.\n            description: Description to apply to all generated FileSpecs.\n            file_types: Either a static list of file types, or a callable that takes a Path\n                and returns a list of types for that specific file. Allows dynamic type\n                assignment based on file extension, content, etc.\n\n        Yields:\n            FileSpec: A specification for each file with computed checksums and metadata.\n\n        Example:\n            Static file types:\n                &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data/images\", \"Images\", [\"Image\"])\n\n            Dynamic file types based on extension:\n                &gt;&gt;&gt; def get_types(path):\n                ...     ext = path.suffix.lower()\n                ...     return {\"png\": [\"PNG\", \"Image\"], \".jpg\": [\"JPEG\", \"Image\"]}.get(ext, [])\n                &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data\", \"Mixed files\", get_types)\n        \"\"\"\n        path = Path(path)\n        file_types = file_types or []\n        # Convert static list to callable for uniform handling\n        file_types_fn = file_types if callable(file_types) else lambda _x: file_types\n\n        def create_spec(file_path: Path) -&gt; FileSpec:\n            \"\"\"Create a FileSpec for a single file with computed hashes.\"\"\"\n            hashes = hash_utils.compute_file_hashes(file_path, hashes=frozenset([\"md5\", \"sha256\"]))\n            md5 = hashes[\"md5\"][0]\n            type_list = file_types_fn(file_path)\n            return FileSpec(\n                length=path.stat().st_size,\n                md5=md5,\n                description=description,\n                url=file_path.as_posix(),\n                # Ensure 'File' type is always included\n                file_types=type_list if \"File\" in type_list else [\"File\"] + type_list,\n            )\n\n        # Handle both single files and directories (recursive)\n        files = [path] if path.is_file() else [f for f in Path(path).rglob(\"*\") if f.is_file()]\n        return (create_spec(file) for file in files)\n\n    @staticmethod\n    def read_filespec(path: Path | str) -&gt; Generator[FileSpec, None, None]:\n        \"\"\"Read FileSpec objects from a JSON Lines file.\n\n        Parses a JSONL file where each line is a JSON object representing a FileSpec.\n        Empty lines are skipped. This is useful for batch processing pre-computed\n        file specifications.\n\n        Args:\n            path: Path to the .jsonl file containing FileSpec data.\n\n        Yields:\n            FileSpec: Parsed FileSpec object for each valid line.\n\n        Example:\n            &gt;&gt;&gt; for spec in FileSpec.read_filespec(\"files.jsonl\"):\n            ...     print(f\"{spec.url}: {spec.md5}\")\n        \"\"\"\n        path = Path(path)\n        with path.open(\"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                line = line.strip()\n                if not line:\n                    continue\n                yield FileSpec(**json.loads(line))\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.FileSpec.create_filespecs","title":"create_filespecs  <code>classmethod</code>","text":"<pre><code>create_filespecs(\n    path: Path | str,\n    description: str,\n    file_types: list[str]\n    | Callable[[Path], list[str]]\n    | None = None,\n) -&gt; Generator[FileSpec, None, None]\n</code></pre> <p>Generate FileSpec objects for a file or directory.</p> <p>Creates FileSpec objects with computed MD5 checksums for each file found. For directories, recursively processes all files. The 'File' type is automatically prepended to file_types if not already present.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to a file or directory. If directory, all files are processed recursively.</p> required <code>description</code> <code>str</code> <p>Description to apply to all generated FileSpecs.</p> required <code>file_types</code> <code>list[str] | Callable[[Path], list[str]] | None</code> <p>Either a static list of file types, or a callable that takes a Path and returns a list of types for that specific file. Allows dynamic type assignment based on file extension, content, etc.</p> <code>None</code> <p>Yields:</p> Name Type Description <code>FileSpec</code> <code>FileSpec</code> <p>A specification for each file with computed checksums and metadata.</p> Example <p>Static file types:     &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data/images\", \"Images\", [\"Image\"])</p> <p>Dynamic file types based on extension:     &gt;&gt;&gt; def get_types(path):     ...     ext = path.suffix.lower()     ...     return {\"png\": [\"PNG\", \"Image\"], \".jpg\": [\"JPEG\", \"Image\"]}.get(ext, [])     &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data\", \"Mixed files\", get_types)</p> Source code in <code>src/deriva_ml/core/filespec.py</code> <pre><code>@classmethod\ndef create_filespecs(\n    cls, path: Path | str, description: str, file_types: list[str] | Callable[[Path], list[str]] | None = None\n) -&gt; Generator[FileSpec, None, None]:\n    \"\"\"Generate FileSpec objects for a file or directory.\n\n    Creates FileSpec objects with computed MD5 checksums for each file found.\n    For directories, recursively processes all files. The 'File' type is\n    automatically prepended to file_types if not already present.\n\n    Args:\n        path: Path to a file or directory. If directory, all files are processed recursively.\n        description: Description to apply to all generated FileSpecs.\n        file_types: Either a static list of file types, or a callable that takes a Path\n            and returns a list of types for that specific file. Allows dynamic type\n            assignment based on file extension, content, etc.\n\n    Yields:\n        FileSpec: A specification for each file with computed checksums and metadata.\n\n    Example:\n        Static file types:\n            &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data/images\", \"Images\", [\"Image\"])\n\n        Dynamic file types based on extension:\n            &gt;&gt;&gt; def get_types(path):\n            ...     ext = path.suffix.lower()\n            ...     return {\"png\": [\"PNG\", \"Image\"], \".jpg\": [\"JPEG\", \"Image\"]}.get(ext, [])\n            &gt;&gt;&gt; specs = FileSpec.create_filespecs(\"/data\", \"Mixed files\", get_types)\n    \"\"\"\n    path = Path(path)\n    file_types = file_types or []\n    # Convert static list to callable for uniform handling\n    file_types_fn = file_types if callable(file_types) else lambda _x: file_types\n\n    def create_spec(file_path: Path) -&gt; FileSpec:\n        \"\"\"Create a FileSpec for a single file with computed hashes.\"\"\"\n        hashes = hash_utils.compute_file_hashes(file_path, hashes=frozenset([\"md5\", \"sha256\"]))\n        md5 = hashes[\"md5\"][0]\n        type_list = file_types_fn(file_path)\n        return FileSpec(\n            length=path.stat().st_size,\n            md5=md5,\n            description=description,\n            url=file_path.as_posix(),\n            # Ensure 'File' type is always included\n            file_types=type_list if \"File\" in type_list else [\"File\"] + type_list,\n        )\n\n    # Handle both single files and directories (recursive)\n    files = [path] if path.is_file() else [f for f in Path(path).rglob(\"*\") if f.is_file()]\n    return (create_spec(file) for file in files)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.FileSpec.read_filespec","title":"read_filespec  <code>staticmethod</code>","text":"<pre><code>read_filespec(\n    path: Path | str,\n) -&gt; Generator[FileSpec, None, None]\n</code></pre> <p>Read FileSpec objects from a JSON Lines file.</p> <p>Parses a JSONL file where each line is a JSON object representing a FileSpec. Empty lines are skipped. This is useful for batch processing pre-computed file specifications.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to the .jsonl file containing FileSpec data.</p> required <p>Yields:</p> Name Type Description <code>FileSpec</code> <code>FileSpec</code> <p>Parsed FileSpec object for each valid line.</p> Example <p>for spec in FileSpec.read_filespec(\"files.jsonl\"): ...     print(f\"{spec.url}: {spec.md5}\")</p> Source code in <code>src/deriva_ml/core/filespec.py</code> <pre><code>@staticmethod\ndef read_filespec(path: Path | str) -&gt; Generator[FileSpec, None, None]:\n    \"\"\"Read FileSpec objects from a JSON Lines file.\n\n    Parses a JSONL file where each line is a JSON object representing a FileSpec.\n    Empty lines are skipped. This is useful for batch processing pre-computed\n    file specifications.\n\n    Args:\n        path: Path to the .jsonl file containing FileSpec data.\n\n    Yields:\n        FileSpec: Parsed FileSpec object for each valid line.\n\n    Example:\n        &gt;&gt;&gt; for spec in FileSpec.read_filespec(\"files.jsonl\"):\n        ...     print(f\"{spec.url}: {spec.md5}\")\n    \"\"\"\n    path = Path(path)\n    with path.open(\"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n            yield FileSpec(**json.loads(line))\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.FileSpec.validate_file_url","title":"validate_file_url  <code>classmethod</code>","text":"<pre><code>validate_file_url(url: str) -&gt; str\n</code></pre> <p>Examine the provided URL. If it's a local path, convert it into a tag URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to validate and potentially convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>The validated/converted URL</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the URL is not a file URL</p> Source code in <code>src/deriva_ml/core/filespec.py</code> <pre><code>@field_validator(\"url\")\n@classmethod\ndef validate_file_url(cls, url: str) -&gt; str:\n    \"\"\"Examine the provided URL. If it's a local path, convert it into a tag URL.\n\n    Args:\n        url: The URL to validate and potentially convert\n\n    Returns:\n        The validated/converted URL\n\n    Raises:\n        ValidationError: If the URL is not a file URL\n    \"\"\"\n    url_parts = urlparse(url)\n    if url_parts.scheme == \"tag\":\n        # Already a tag URL, so just return it.\n        return url\n    elif (not url_parts.scheme) or url_parts.scheme == \"file\":\n        # There is no scheme part of the URL, or it is a file URL, so it is a local file path.\n        # Convert to a tag URL.\n        return f\"tag://{gethostname()},{date.today()}:file://{url_parts.path}\"\n    else:\n        raise ValueError(\"url is not a file URL\")\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.FileUploadState","title":"FileUploadState","text":"<p>               Bases: <code>BaseModel</code></p> <p>Tracks the state and result of a file upload operation.</p> <p>Attributes:</p> Name Type Description <code>state</code> <code>UploadState</code> <p>Current state of the upload (success, failed, etc.).</p> <code>status</code> <code>str</code> <p>Detailed status message.</p> <code>result</code> <code>Any</code> <p>Upload result data, if any.</p> Source code in <code>src/deriva_ml/core/ermrest.py</code> <pre><code>class FileUploadState(BaseModel):\n    \"\"\"Tracks the state and result of a file upload operation.\n\n    Attributes:\n        state (UploadState): Current state of the upload (success, failed, etc.).\n        status (str): Detailed status message.\n        result (Any): Upload result data, if any.\n    \"\"\"\n    state: UploadState\n    status: str\n    result: Any\n\n    @computed_field\n    @property\n    def rid(self) -&gt; RID | None:\n        return self.result and self.result[\"RID\"]\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.LoggerMixin","title":"LoggerMixin","text":"<p>Mixin class that provides a _logger attribute.</p> <p>Classes that inherit from this mixin get a _logger property that returns a child logger under the deriva_ml namespace, named after the class.</p> Example <p>class MyProcessor(LoggerMixin): ...     def process(self): ...         self._logger.info(\"Processing started\") ...</p> Source code in <code>src/deriva_ml/core/logging_config.py</code> <pre><code>class LoggerMixin:\n    \"\"\"Mixin class that provides a _logger attribute.\n\n    Classes that inherit from this mixin get a _logger property that\n    returns a child logger under the deriva_ml namespace, named after\n    the class.\n\n    Example:\n        &gt;&gt;&gt; class MyProcessor(LoggerMixin):\n        ...     def process(self):\n        ...         self._logger.info(\"Processing started\")\n        ...\n        &gt;&gt;&gt; # Logs to 'deriva_ml.MyProcessor'\n    \"\"\"\n\n    @property\n    def _logger(self) -&gt; logging.Logger:\n        \"\"\"Get the logger for this class.\"\"\"\n        return get_logger(self.__class__.__name__)\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.LoggerMixin--logs-to-deriva_mlmyprocessor","title":"Logs to 'deriva_ml.MyProcessor'","text":""},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.MLAsset","title":"MLAsset","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Asset type identifiers.</p> <p>Defines the types of assets that can be associated with executions.</p> <p>Attributes:</p> Name Type Description <code>execution_metadata</code> <code>str</code> <p>Metadata about an execution.</p> <code>execution_asset</code> <code>str</code> <p>Asset produced by an execution.</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class MLAsset(BaseStrEnum):\n    \"\"\"Asset type identifiers.\n\n    Defines the types of assets that can be associated with executions.\n\n    Attributes:\n        execution_metadata (str): Metadata about an execution.\n        execution_asset (str): Asset produced by an execution.\n    \"\"\"\n\n    execution_metadata = \"Execution_Metadata\"\n    execution_asset = \"Execution_Asset\"\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.MLVocab","title":"MLVocab","text":"<p>               Bases: <code>BaseStrEnum</code></p> <p>Controlled vocabulary table identifiers.</p> <p>Defines the names of controlled vocabulary tables used in DerivaML. These tables store standardized terms with descriptions and synonyms for consistent data classification across the catalog.</p> <p>Attributes:</p> Name Type Description <code>dataset_type</code> <code>str</code> <p>Dataset classification vocabulary (e.g., \"Training\", \"Test\").</p> <code>workflow_type</code> <code>str</code> <p>Workflow classification vocabulary (e.g., \"Python\", \"Notebook\").</p> <code>asset_type</code> <code>str</code> <p>Asset/file type classification vocabulary (e.g., \"Image\", \"CSV\").</p> <code>asset_role</code> <code>str</code> <p>Asset role vocabulary for execution relationships (e.g., \"Input\", \"Output\").</p> <code>feature_name</code> <code>str</code> <p>Feature name vocabulary for ML feature definitions.</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class MLVocab(BaseStrEnum):\n    \"\"\"Controlled vocabulary table identifiers.\n\n    Defines the names of controlled vocabulary tables used in DerivaML. These tables\n    store standardized terms with descriptions and synonyms for consistent data\n    classification across the catalog.\n\n    Attributes:\n        dataset_type (str): Dataset classification vocabulary (e.g., \"Training\", \"Test\").\n        workflow_type (str): Workflow classification vocabulary (e.g., \"Python\", \"Notebook\").\n        asset_type (str): Asset/file type classification vocabulary (e.g., \"Image\", \"CSV\").\n        asset_role (str): Asset role vocabulary for execution relationships (e.g., \"Input\", \"Output\").\n        feature_name (str): Feature name vocabulary for ML feature definitions.\n    \"\"\"\n\n    dataset_type = \"Dataset_Type\"\n    workflow_type = \"Workflow_Type\"\n    asset_type = \"Asset_Type\"\n    asset_role = \"Asset_Role\"\n    feature_name = \"Feature_Name\"\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.UploadState","title":"UploadState","text":"<p>               Bases: <code>Enum</code></p> <p>File upload operation states.</p> <p>Represents the various states a file upload operation can be in, from initiation to completion.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>int</code> <p>Upload completed successfully.</p> <code>failed</code> <code>int</code> <p>Upload failed.</p> <code>pending</code> <code>int</code> <p>Upload is queued.</p> <code>running</code> <code>int</code> <p>Upload is in progress.</p> <code>paused</code> <code>int</code> <p>Upload is temporarily paused.</p> <code>aborted</code> <code>int</code> <p>Upload was aborted.</p> <code>cancelled</code> <code>int</code> <p>Upload was cancelled.</p> <code>timeout</code> <code>int</code> <p>Upload timed out.</p> Source code in <code>src/deriva_ml/core/enums.py</code> <pre><code>class UploadState(Enum):\n    \"\"\"File upload operation states.\n\n    Represents the various states a file upload operation can be in, from initiation to completion.\n\n    Attributes:\n        success (int): Upload completed successfully.\n        failed (int): Upload failed.\n        pending (int): Upload is queued.\n        running (int): Upload is in progress.\n        paused (int): Upload is temporarily paused.\n        aborted (int): Upload was aborted.\n        cancelled (int): Upload was cancelled.\n        timeout (int): Upload timed out.\n    \"\"\"\n\n    success = 0\n    failed = 1\n    pending = 2\n    running = 3\n    paused = 4\n    aborted = 5\n    cancelled = 6\n    timeout = 7\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.configure_logging","title":"configure_logging","text":"<pre><code>configure_logging(\n    level: int = logging.WARNING,\n    deriva_level: int | None = None,\n    format_string: str = DEFAULT_FORMAT,\n    handler: Handler | None = None,\n) -&gt; logging.Logger\n</code></pre> <p>Configure logging for DerivaML and related libraries.</p> <p>This function sets up logging levels for DerivaML, related libraries (deriva-py, bdbag, bagit), and Hydra loggers. It is designed to:</p> <ol> <li>Configure only specific logger namespaces, not the root logger</li> <li>Respect Hydra's logging configuration when running under Hydra</li> <li>Allow deriva-py libraries to have a separate logging level</li> </ol> The logging level hierarchy <ul> <li>deriva_ml logger: uses <code>level</code></li> <li>Hydra loggers: follow <code>level</code> (deriva_ml level)</li> <li>Deriva/bdbag/bagit loggers: use <code>deriva_level</code> (defaults to <code>level</code>)</li> </ul> When running under Hydra <ul> <li>Only sets log levels on specific loggers</li> <li>Does NOT add handlers (Hydra has already configured them)</li> <li>Does NOT call basicConfig()</li> </ul> <p>When running standalone (no Hydra):     - Sets log levels on specific loggers     - Adds a StreamHandler to deriva_ml logger if none exists     - Still does NOT touch the root logger or call basicConfig()</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>Log level for deriva_ml and Hydra loggers. Defaults to WARNING.</p> <code>WARNING</code> <code>deriva_level</code> <code>int | None</code> <p>Log level for deriva-py libraries (deriva, bagit, bdbag).          If None, uses the same level as <code>level</code>.</p> <code>None</code> <code>format_string</code> <code>str</code> <p>Format string for log messages (used only when adding           handlers outside Hydra context).</p> <code>DEFAULT_FORMAT</code> <code>handler</code> <code>Handler | None</code> <p>Optional handler to add to the deriva_ml logger. If None and     not running under Hydra, uses StreamHandler with format_string.</p> <code>None</code> <p>Returns:</p> Type Description <code>Logger</code> <p>The configured deriva_ml logger.</p> Example <p>import logging</p> Source code in <code>src/deriva_ml/core/logging_config.py</code> <pre><code>def configure_logging(\n    level: int = logging.WARNING,\n    deriva_level: int | None = None,\n    format_string: str = DEFAULT_FORMAT,\n    handler: logging.Handler | None = None,\n) -&gt; logging.Logger:\n    \"\"\"Configure logging for DerivaML and related libraries.\n\n    This function sets up logging levels for DerivaML, related libraries\n    (deriva-py, bdbag, bagit), and Hydra loggers. It is designed to:\n\n    1. Configure only specific logger namespaces, not the root logger\n    2. Respect Hydra's logging configuration when running under Hydra\n    3. Allow deriva-py libraries to have a separate logging level\n\n    The logging level hierarchy:\n        - deriva_ml logger: uses `level`\n        - Hydra loggers: follow `level` (deriva_ml level)\n        - Deriva/bdbag/bagit loggers: use `deriva_level` (defaults to `level`)\n\n    When running under Hydra:\n        - Only sets log levels on specific loggers\n        - Does NOT add handlers (Hydra has already configured them)\n        - Does NOT call basicConfig()\n\n    When running standalone (no Hydra):\n        - Sets log levels on specific loggers\n        - Adds a StreamHandler to deriva_ml logger if none exists\n        - Still does NOT touch the root logger or call basicConfig()\n\n    Args:\n        level: Log level for deriva_ml and Hydra loggers. Defaults to WARNING.\n        deriva_level: Log level for deriva-py libraries (deriva, bagit, bdbag).\n                     If None, uses the same level as `level`.\n        format_string: Format string for log messages (used only when adding\n                      handlers outside Hydra context).\n        handler: Optional handler to add to the deriva_ml logger. If None and\n                not running under Hydra, uses StreamHandler with format_string.\n\n    Returns:\n        The configured deriva_ml logger.\n\n    Example:\n        &gt;&gt;&gt; import logging\n        &gt;&gt;&gt; # Same level for everything\n        &gt;&gt;&gt; configure_logging(level=logging.DEBUG)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Verbose DerivaML, quieter deriva-py libraries\n        &gt;&gt;&gt; configure_logging(\n        ...     level=logging.INFO,\n        ...     deriva_level=logging.WARNING,\n        ... )\n    \"\"\"\n    if deriva_level is None:\n        deriva_level = level\n\n    # Configure main DerivaML logger\n    logger = get_logger()\n    logger.setLevel(level)\n\n    # Configure Hydra loggers to follow deriva_ml level\n    for logger_name in HYDRA_LOGGERS:\n        logging.getLogger(logger_name).setLevel(level)\n\n    # Configure deriva-py and related library loggers\n    for logger_name in DERIVA_LOGGERS:\n        logging.getLogger(logger_name).setLevel(deriva_level)\n\n    # Only add handlers if not running under Hydra\n    # Hydra configures handlers via dictConfig, we don't want to duplicate\n    if not is_hydra_initialized():\n        if not logger.handlers:\n            if handler is None:\n                handler = logging.StreamHandler()\n                handler.setFormatter(logging.Formatter(format_string))\n            logger.addHandler(handler)\n\n    return logger\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.configure_logging--same-level-for-everything","title":"Same level for everything","text":"<p>configure_logging(level=logging.DEBUG)</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.configure_logging--verbose-derivaml-quieter-deriva-py-libraries","title":"Verbose DerivaML, quieter deriva-py libraries","text":"<p>configure_logging( ...     level=logging.INFO, ...     deriva_level=logging.WARNING, ... )</p>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.get_logger","title":"get_logger","text":"<pre><code>get_logger(\n    name: str | None = None,\n) -&gt; logging.Logger\n</code></pre> <p>Get a DerivaML logger.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional sub-logger name. If provided, returns a child logger   under the deriva_ml namespace (e.g., 'deriva_ml.dataset').   If None, returns the main deriva_ml logger.</p> <code>None</code> <p>Returns:</p> Type Description <code>Logger</code> <p>The configured logger instance.</p> Example <p>logger = get_logger()  # Main deriva_ml logger dataset_logger = get_logger(\"dataset\")  # deriva_ml.dataset</p> Source code in <code>src/deriva_ml/core/logging_config.py</code> <pre><code>def get_logger(name: str | None = None) -&gt; logging.Logger:\n    \"\"\"Get a DerivaML logger.\n\n    Args:\n        name: Optional sub-logger name. If provided, returns a child logger\n              under the deriva_ml namespace (e.g., 'deriva_ml.dataset').\n              If None, returns the main deriva_ml logger.\n\n    Returns:\n        The configured logger instance.\n\n    Example:\n        &gt;&gt;&gt; logger = get_logger()  # Main deriva_ml logger\n        &gt;&gt;&gt; dataset_logger = get_logger(\"dataset\")  # deriva_ml.dataset\n    \"\"\"\n    if name is None:\n        return logging.getLogger(LOGGER_NAME)\n    return logging.getLogger(f\"{LOGGER_NAME}.{name}\")\n</code></pre>"},{"location":"code-docs/deriva_ml_base/#deriva_ml.core.is_hydra_initialized","title":"is_hydra_initialized","text":"<pre><code>is_hydra_initialized() -&gt; bool\n</code></pre> <p>Check if running within an initialized Hydra context.</p> <p>This is used to determine whether Hydra is managing logging configuration. When Hydra is initialized, we avoid adding handlers or calling basicConfig since Hydra has already configured logging via dictConfig.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if Hydra's GlobalHydra is initialized, False otherwise.</p> Example <p>if is_hydra_initialized(): ...     # Hydra is managing logging ...     pass</p> Source code in <code>src/deriva_ml/core/logging_config.py</code> <pre><code>def is_hydra_initialized() -&gt; bool:\n    \"\"\"Check if running within an initialized Hydra context.\n\n    This is used to determine whether Hydra is managing logging configuration.\n    When Hydra is initialized, we avoid adding handlers or calling basicConfig\n    since Hydra has already configured logging via dictConfig.\n\n    Returns:\n        True if Hydra's GlobalHydra is initialized, False otherwise.\n\n    Example:\n        &gt;&gt;&gt; if is_hydra_initialized():\n        ...     # Hydra is managing logging\n        ...     pass\n    \"\"\"\n    try:\n        from hydra.core.global_hydra import GlobalHydra\n\n        return GlobalHydra.instance().is_initialized()\n    except (ImportError, Exception):\n        return False\n</code></pre>"},{"location":"code-docs/deriva_model/","title":"DerivaModel","text":"<p>The DerivaModel class provides schema introspection and manipulation capabilities for Deriva catalogs. It handles table relationships, associations, and catalog structure management.</p> <p>Model module for DerivaML.</p> <p>This module provides catalog and database model classes, as well as handle wrappers for ERMrest model objects and annotation builders.</p> <p>Key components: - DerivaModel: Schema analysis utilities - DatabaseModel: SQLite database from BDBag - SchemaBuilder/SchemaORM: Create ORM from Deriva Model (Phase 1) - DataLoader: Fill database from data source (Phase 2) - DataSource: Protocol for data sources (BagDataSource, CatalogDataSource) - ForeignKeyOrderer: Compute FK-safe insertion order</p> <p>Lazy imports are used for DatabaseModel and DerivaMLDatabase to avoid circular imports with the dataset module.</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.Aggregate","title":"Aggregate","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Aggregation functions for pseudo-columns.</p> <p>Used when a pseudo-column follows an inbound foreign key and returns multiple values that need to be aggregated.</p> <p>Attributes:</p> Name Type Description <code>MIN</code> <p>Minimum value</p> <code>MAX</code> <p>Maximum value</p> <code>CNT</code> <p>Count of values</p> <code>CNT_D</code> <p>Count of distinct values</p> <code>ARRAY</code> <p>Array of all values</p> <code>ARRAY_D</code> <p>Array of distinct values</p> Example Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>class Aggregate(str, Enum):\n    \"\"\"Aggregation functions for pseudo-columns.\n\n    Used when a pseudo-column follows an inbound foreign key and returns\n    multiple values that need to be aggregated.\n\n    Attributes:\n        MIN: Minimum value\n        MAX: Maximum value\n        CNT: Count of values\n        CNT_D: Count of distinct values\n        ARRAY: Array of all values\n        ARRAY_D: Array of distinct values\n\n    Example:\n        &gt;&gt;&gt; # Count related records\n        &gt;&gt;&gt; pc = PseudoColumn(\n        ...     source=[InboundFK(\"domain\", \"Sample_Subject_fkey\"), \"RID\"],\n        ...     aggregate=Aggregate.CNT,\n        ...     markdown_name=\"Sample Count\"\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Get distinct values as array\n        &gt;&gt;&gt; pc = PseudoColumn(\n        ...     source=[InboundFK(\"domain\", \"Tag_Item_fkey\"), \"Name\"],\n        ...     aggregate=Aggregate.ARRAY_D,\n        ...     markdown_name=\"Tags\"\n        ... )\n    \"\"\"\n    MIN = \"min\"\n    MAX = \"max\"\n    CNT = \"cnt\"\n    CNT_D = \"cnt_d\"\n    ARRAY = \"array\"\n    ARRAY_D = \"array_d\"\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.Aggregate--count-related-records","title":"Count related records","text":"<p>pc = PseudoColumn( ...     source=[InboundFK(\"domain\", \"Sample_Subject_fkey\"), \"RID\"], ...     aggregate=Aggregate.CNT, ...     markdown_name=\"Sample Count\" ... )</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.Aggregate--get-distinct-values-as-array","title":"Get distinct values as array","text":"<p>pc = PseudoColumn( ...     source=[InboundFK(\"domain\", \"Tag_Item_fkey\"), \"Name\"], ...     aggregate=Aggregate.ARRAY_D, ...     markdown_name=\"Tags\" ... )</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ArrayUxMode","title":"ArrayUxMode","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Display modes for array values in pseudo-columns.</p> <p>Controls how arrays of values are rendered in the UI.</p> <p>Attributes:</p> Name Type Description <code>RAW</code> <p>Raw array display</p> <code>CSV</code> <p>Comma-separated values</p> <code>OLIST</code> <p>Ordered (numbered) list</p> <code>ULIST</code> <p>Unordered (bulleted) list</p> Example <p>pc = PseudoColumn( ...     source=[InboundFK(\"domain\", \"Tag_Item_fkey\"), \"Name\"], ...     aggregate=Aggregate.ARRAY, ...     display=PseudoColumnDisplay(array_ux_mode=ArrayUxMode.CSV) ... )</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>class ArrayUxMode(str, Enum):\n    \"\"\"Display modes for array values in pseudo-columns.\n\n    Controls how arrays of values are rendered in the UI.\n\n    Attributes:\n        RAW: Raw array display\n        CSV: Comma-separated values\n        OLIST: Ordered (numbered) list\n        ULIST: Unordered (bulleted) list\n\n    Example:\n        &gt;&gt;&gt; pc = PseudoColumn(\n        ...     source=[InboundFK(\"domain\", \"Tag_Item_fkey\"), \"Name\"],\n        ...     aggregate=Aggregate.ARRAY,\n        ...     display=PseudoColumnDisplay(array_ux_mode=ArrayUxMode.CSV)\n        ... )\n    \"\"\"\n    RAW = \"raw\"\n    CSV = \"csv\"\n    OLIST = \"olist\"\n    ULIST = \"ulist\"\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.BagDataSource","title":"BagDataSource","text":"<p>DataSource implementation for BDBag directories.</p> <p>Reads data from CSV files in a bag's data/ directory. Handles asset URL localization via fetch.txt.</p> Example <p>source = BagDataSource(Path(\"/path/to/bag\"))</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>class BagDataSource:\n    \"\"\"DataSource implementation for BDBag directories.\n\n    Reads data from CSV files in a bag's data/ directory.\n    Handles asset URL localization via fetch.txt.\n\n    Example:\n        source = BagDataSource(Path(\"/path/to/bag\"))\n\n        # List available tables\n        print(source.list_available_tables())\n\n        # Get data for a table\n        for row in source.get_table_data(\"Image\"):\n            print(row[\"Filename\"])\n    \"\"\"\n\n    def __init__(\n        self,\n        bag_path: Path,\n        model: Model | None = None,\n        asset_localization: bool = True,\n    ):\n        \"\"\"Initialize from a bag path.\n\n        Args:\n            bag_path: Path to BDBag directory.\n            model: Optional ERMrest Model for schema info. If not provided,\n                will try to load from bag's schema.json.\n            asset_localization: Whether to localize asset URLs to local paths\n                using fetch.txt mapping.\n        \"\"\"\n        self.bag_path = Path(bag_path)\n        self.data_path = self.bag_path / \"data\"\n\n        # Load model if not provided\n        if model is None:\n            schema_file = self.data_path / \"schema.json\"\n            if schema_file.exists():\n                self.model = Model.fromfile(\"file-system\", schema_file)\n            else:\n                self.model = None\n                logger.warning(f\"No schema.json found in {self.bag_path}\")\n        else:\n            self.model = model\n\n        # Build asset map for URL localization\n        self._asset_map = self._build_asset_map() if asset_localization else {}\n\n        # Cache of table name -&gt; list of csv file paths (multiple paths for nested datasets)\n        self._csv_cache: dict[str, list[Path]] = {}\n        self._build_csv_cache()\n\n    def _build_csv_cache(self) -&gt; None:\n        \"\"\"Build cache mapping table names to CSV file paths.\n\n        Nested datasets can produce multiple CSV files for the same table\n        at different directory depths. All paths are collected so that\n        get_table_data() yields the union of all rows.\n        \"\"\"\n        for csv_file in self.data_path.rglob(\"*.csv\"):\n            table_name = csv_file.stem\n            self._csv_cache.setdefault(table_name, []).append(csv_file)\n\n    def _build_asset_map(self) -&gt; dict[str, str]:\n        \"\"\"Build a map from remote URLs to local file paths using fetch.txt.\n\n        Returns:\n            Dictionary mapping URL paths to local file paths.\n        \"\"\"\n        fetch_map = {}\n        fetch_file = self.bag_path / \"fetch.txt\"\n\n        if not fetch_file.exists():\n            logger.debug(f\"No fetch.txt in bag {self.bag_path.name}\")\n            return fetch_map\n\n        try:\n            with fetch_file.open(newline=\"\\n\") as f:\n                for row in f:\n                    # Rows in fetch.txt are tab-separated: URL, size, local_path\n                    fields = row.split(\"\\t\")\n                    if len(fields) &gt;= 3:\n                        local_file = fields[2].replace(\"\\n\", \"\")\n                        local_path = f\"{self.bag_path}/{local_file}\"\n                        fetch_map[urlparse(fields[0]).path] = local_path\n        except Exception as e:\n            logger.warning(f\"Error reading fetch.txt: {e}\")\n\n        return fetch_map\n\n    def _get_table_name(self, table: DerivaTable | str) -&gt; str:\n        \"\"\"Extract table name from table object or string.\"\"\"\n        if isinstance(table, DerivaTable):\n            return table.name\n        # Handle schema.table format\n        if \".\" in table:\n            return table.split(\".\")[-1]\n        return table\n\n    def _is_asset_table(self, table_name: str) -&gt; bool:\n        \"\"\"Check if a table is an asset table (has Filename, URL, etc. columns).\"\"\"\n        if self.model is None:\n            return False\n\n        for schema in self.model.schemas.values():\n            if table_name in schema.tables:\n                table = schema.tables[table_name]\n                return ASSET_COLUMNS.issubset({c.name for c in table.columns})\n        return False\n\n    def _localize_asset_row(self, row: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"Replace URL with local path in asset table row.\n\n        Args:\n            row: Dictionary of column values.\n\n        Returns:\n            Updated dictionary with localized file path.\n        \"\"\"\n        if \"URL\" in row and \"Filename\" in row:\n            url = row.get(\"URL\")\n            if url and url in self._asset_map:\n                row = dict(row)  # Copy to avoid mutating original\n                row[\"Filename\"] = self._asset_map[url]\n        return row\n\n    def get_table_data(\n        self,\n        table: DerivaTable | str,\n    ) -&gt; Iterator[dict[str, Any]]:\n        \"\"\"Read table data from CSV files.\n\n        Nested datasets may produce multiple CSV files for the same table\n        at different directory depths. This method yields rows from all of\n        them so that the full dataset (including parent and child records)\n        is loaded.\n\n        Args:\n            table: Table object or name.\n\n        Yields:\n            Dictionary per row with column names as keys.\n        \"\"\"\n        table_name = self._get_table_name(table)\n        csv_files = self._csv_cache.get(table_name)\n\n        if not csv_files:\n            logger.debug(f\"No CSV file found for table {table_name}\")\n            return\n\n        is_asset = self._is_asset_table(table_name)\n\n        for csv_file in csv_files:\n            if not csv_file.exists():\n                continue\n            with csv_file.open(newline=\"\") as f:\n                reader = csv.DictReader(f)\n                for row in reader:\n                    if is_asset and self._asset_map:\n                        row = self._localize_asset_row(row)\n                    yield row\n\n    def has_table(self, table: DerivaTable | str) -&gt; bool:\n        \"\"\"Check if CSV exists for table.\n\n        Args:\n            table: Table object or name.\n\n        Returns:\n            True if CSV file exists for this table.\n        \"\"\"\n        table_name = self._get_table_name(table)\n        return table_name in self._csv_cache\n\n    def list_available_tables(self) -&gt; list[str]:\n        \"\"\"List all CSV files in data directory.\n\n        Returns:\n            List of table names (without .csv extension).\n        \"\"\"\n        return sorted(self._csv_cache.keys())\n\n    def get_row_count(self, table: DerivaTable | str) -&gt; int:\n        \"\"\"Get the number of rows across all CSV files for a table.\n\n        Args:\n            table: Table object or name.\n\n        Returns:\n            Number of data rows (excluding headers).\n        \"\"\"\n        table_name = self._get_table_name(table)\n        csv_files = self._csv_cache.get(table_name)\n\n        if not csv_files:\n            return 0\n\n        total = 0\n        for csv_file in csv_files:\n            if csv_file.exists():\n                with csv_file.open(newline=\"\") as f:\n                    # Count lines minus header\n                    total += sum(1 for _ in f) - 1\n        return total\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.BagDataSource--list-available-tables","title":"List available tables","text":"<p>print(source.list_available_tables())</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.BagDataSource--get-data-for-a-table","title":"Get data for a table","text":"<p>for row in source.get_table_data(\"Image\"):     print(row[\"Filename\"])</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.BagDataSource.__init__","title":"__init__","text":"<pre><code>__init__(\n    bag_path: Path,\n    model: Model | None = None,\n    asset_localization: bool = True,\n)\n</code></pre> <p>Initialize from a bag path.</p> <p>Parameters:</p> Name Type Description Default <code>bag_path</code> <code>Path</code> <p>Path to BDBag directory.</p> required <code>model</code> <code>Model | None</code> <p>Optional ERMrest Model for schema info. If not provided, will try to load from bag's schema.json.</p> <code>None</code> <code>asset_localization</code> <code>bool</code> <p>Whether to localize asset URLs to local paths using fetch.txt mapping.</p> <code>True</code> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def __init__(\n    self,\n    bag_path: Path,\n    model: Model | None = None,\n    asset_localization: bool = True,\n):\n    \"\"\"Initialize from a bag path.\n\n    Args:\n        bag_path: Path to BDBag directory.\n        model: Optional ERMrest Model for schema info. If not provided,\n            will try to load from bag's schema.json.\n        asset_localization: Whether to localize asset URLs to local paths\n            using fetch.txt mapping.\n    \"\"\"\n    self.bag_path = Path(bag_path)\n    self.data_path = self.bag_path / \"data\"\n\n    # Load model if not provided\n    if model is None:\n        schema_file = self.data_path / \"schema.json\"\n        if schema_file.exists():\n            self.model = Model.fromfile(\"file-system\", schema_file)\n        else:\n            self.model = None\n            logger.warning(f\"No schema.json found in {self.bag_path}\")\n    else:\n        self.model = model\n\n    # Build asset map for URL localization\n    self._asset_map = self._build_asset_map() if asset_localization else {}\n\n    # Cache of table name -&gt; list of csv file paths (multiple paths for nested datasets)\n    self._csv_cache: dict[str, list[Path]] = {}\n    self._build_csv_cache()\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.BagDataSource.get_row_count","title":"get_row_count","text":"<pre><code>get_row_count(\n    table: Table | str,\n) -&gt; int\n</code></pre> <p>Get the number of rows across all CSV files for a table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>Table object or name.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of data rows (excluding headers).</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def get_row_count(self, table: DerivaTable | str) -&gt; int:\n    \"\"\"Get the number of rows across all CSV files for a table.\n\n    Args:\n        table: Table object or name.\n\n    Returns:\n        Number of data rows (excluding headers).\n    \"\"\"\n    table_name = self._get_table_name(table)\n    csv_files = self._csv_cache.get(table_name)\n\n    if not csv_files:\n        return 0\n\n    total = 0\n    for csv_file in csv_files:\n        if csv_file.exists():\n            with csv_file.open(newline=\"\") as f:\n                # Count lines minus header\n                total += sum(1 for _ in f) - 1\n    return total\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.BagDataSource.get_table_data","title":"get_table_data","text":"<pre><code>get_table_data(\n    table: Table | str,\n) -&gt; Iterator[dict[str, Any]]\n</code></pre> <p>Read table data from CSV files.</p> <p>Nested datasets may produce multiple CSV files for the same table at different directory depths. This method yields rows from all of them so that the full dataset (including parent and child records) is loaded.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>Table object or name.</p> required <p>Yields:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary per row with column names as keys.</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def get_table_data(\n    self,\n    table: DerivaTable | str,\n) -&gt; Iterator[dict[str, Any]]:\n    \"\"\"Read table data from CSV files.\n\n    Nested datasets may produce multiple CSV files for the same table\n    at different directory depths. This method yields rows from all of\n    them so that the full dataset (including parent and child records)\n    is loaded.\n\n    Args:\n        table: Table object or name.\n\n    Yields:\n        Dictionary per row with column names as keys.\n    \"\"\"\n    table_name = self._get_table_name(table)\n    csv_files = self._csv_cache.get(table_name)\n\n    if not csv_files:\n        logger.debug(f\"No CSV file found for table {table_name}\")\n        return\n\n    is_asset = self._is_asset_table(table_name)\n\n    for csv_file in csv_files:\n        if not csv_file.exists():\n            continue\n        with csv_file.open(newline=\"\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                if is_asset and self._asset_map:\n                    row = self._localize_asset_row(row)\n                yield row\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.BagDataSource.has_table","title":"has_table","text":"<pre><code>has_table(table: Table | str) -&gt; bool\n</code></pre> <p>Check if CSV exists for table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>Table object or name.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if CSV file exists for this table.</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def has_table(self, table: DerivaTable | str) -&gt; bool:\n    \"\"\"Check if CSV exists for table.\n\n    Args:\n        table: Table object or name.\n\n    Returns:\n        True if CSV file exists for this table.\n    \"\"\"\n    table_name = self._get_table_name(table)\n    return table_name in self._csv_cache\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.BagDataSource.list_available_tables","title":"list_available_tables","text":"<pre><code>list_available_tables() -&gt; list[str]\n</code></pre> <p>List all CSV files in data directory.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of table names (without .csv extension).</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def list_available_tables(self) -&gt; list[str]:\n    \"\"\"List all CSV files in data directory.\n\n    Returns:\n        List of table names (without .csv extension).\n    \"\"\"\n    return sorted(self._csv_cache.keys())\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.CatalogDataSource","title":"CatalogDataSource","text":"<p>DataSource implementation for remote Deriva catalog.</p> <p>Fetches data via ERMrest API / datapath with pagination support.</p> Example <p>catalog = server.connect_ermrest(catalog_id) source = CatalogDataSource(catalog, schemas=['domain', 'deriva-ml'])</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>class CatalogDataSource:\n    \"\"\"DataSource implementation for remote Deriva catalog.\n\n    Fetches data via ERMrest API / datapath with pagination support.\n\n    Example:\n        catalog = server.connect_ermrest(catalog_id)\n        source = CatalogDataSource(catalog, schemas=['domain', 'deriva-ml'])\n\n        # List available tables\n        print(source.list_available_tables())\n\n        # Get data for a table\n        for row in source.get_table_data(\"Image\"):\n            print(row[\"Filename\"])\n    \"\"\"\n\n    def __init__(\n        self,\n        catalog: ErmrestCatalog,\n        schemas: list[str],\n        batch_size: int = 1000,\n    ):\n        \"\"\"Initialize from catalog connection.\n\n        Args:\n            catalog: ERMrest catalog connection.\n            schemas: Schemas to fetch data from.\n            batch_size: Number of rows per API request.\n        \"\"\"\n        self.catalog = catalog\n        self.schemas = schemas\n        self.batch_size = batch_size\n        self._pb = catalog.getPathBuilder()\n        self._model = catalog.getCatalogModel()\n\n    def _get_table_info(self, table: DerivaTable | str) -&gt; tuple[str, str] | None:\n        \"\"\"Get schema and table name for a table.\n\n        Args:\n            table: Table object or name.\n\n        Returns:\n            Tuple of (schema_name, table_name) or None if not found.\n        \"\"\"\n        if isinstance(table, DerivaTable):\n            return table.schema.name, table.name\n\n        # Handle schema.table format\n        if \".\" in table:\n            parts = table.split(\".\")\n            schema_name, table_name = parts[0], parts[1]\n            if schema_name in self.schemas:\n                return schema_name, table_name\n            return None\n\n        # Search schemas for table\n        for schema_name in self.schemas:\n            if schema_name in self._model.schemas:\n                schema = self._model.schemas[schema_name]\n                if table in schema.tables:\n                    return schema_name, table\n\n        return None\n\n    def get_table_data(\n        self,\n        table: DerivaTable | str,\n    ) -&gt; Iterator[dict[str, Any]]:\n        \"\"\"Fetch table data via ERMrest API.\n\n        Uses pagination to handle large tables efficiently.\n\n        Args:\n            table: Table object or name.\n\n        Yields:\n            Dictionary per row with column names as keys.\n        \"\"\"\n        table_info = self._get_table_info(table)\n        if table_info is None:\n            logger.warning(f\"Table {table} not found in schemas {self.schemas}\")\n            return\n\n        schema_name, table_name = table_info\n\n        # Build path\n        path = self._pb.schemas[schema_name].tables[table_name]\n\n        # Paginated fetch using RID ordering\n        last_rid = None\n        while True:\n            # Build query with optional RID filter\n            query = path.entities()\n            if last_rid is not None:\n                query = query.filter(path.RID &gt; last_rid)\n\n            # Fetch batch ordered by RID\n            try:\n                entities = list(query.sort(path.RID).fetch(limit=self.batch_size))\n            except Exception as e:\n                logger.error(f\"Error fetching from {schema_name}.{table_name}: {e}\")\n                break\n\n            if not entities:\n                break\n\n            for entity in entities:\n                yield dict(entity)\n\n            # Track last RID for pagination\n            last_rid = entities[-1][\"RID\"]\n\n            if len(entities) &lt; self.batch_size:\n                break\n\n    def has_table(self, table: DerivaTable | str) -&gt; bool:\n        \"\"\"Check if table exists in catalog.\n\n        Args:\n            table: Table object or name.\n\n        Returns:\n            True if table exists in configured schemas.\n        \"\"\"\n        return self._get_table_info(table) is not None\n\n    def list_available_tables(self) -&gt; list[str]:\n        \"\"\"List all tables in configured schemas.\n\n        Returns:\n            List of fully-qualified table names (schema.table).\n        \"\"\"\n        tables = []\n        for schema_name in self.schemas:\n            if schema_name in self._model.schemas:\n                schema = self._model.schemas[schema_name]\n                for table_name in schema.tables.keys():\n                    tables.append(f\"{schema_name}.{table_name}\")\n        return sorted(tables)\n\n    def get_row_count(self, table: DerivaTable | str) -&gt; int:\n        \"\"\"Get the number of rows in a table.\n\n        Args:\n            table: Table object or name.\n\n        Returns:\n            Number of rows in the table.\n        \"\"\"\n        table_info = self._get_table_info(table)\n        if table_info is None:\n            return 0\n\n        schema_name, table_name = table_info\n        path = self._pb.schemas[schema_name].tables[table_name]\n\n        try:\n            # Use count aggregate\n            result = path.aggregates(path.RID.cnt.alias(\"count\")).fetch()\n            return result[0][\"count\"] if result else 0\n        except Exception as e:\n            logger.error(f\"Error counting {schema_name}.{table_name}: {e}\")\n            return 0\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.CatalogDataSource--list-available-tables","title":"List available tables","text":"<p>print(source.list_available_tables())</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.CatalogDataSource--get-data-for-a-table","title":"Get data for a table","text":"<p>for row in source.get_table_data(\"Image\"):     print(row[\"Filename\"])</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.CatalogDataSource.__init__","title":"__init__","text":"<pre><code>__init__(\n    catalog: ErmrestCatalog,\n    schemas: list[str],\n    batch_size: int = 1000,\n)\n</code></pre> <p>Initialize from catalog connection.</p> <p>Parameters:</p> Name Type Description Default <code>catalog</code> <code>ErmrestCatalog</code> <p>ERMrest catalog connection.</p> required <code>schemas</code> <code>list[str]</code> <p>Schemas to fetch data from.</p> required <code>batch_size</code> <code>int</code> <p>Number of rows per API request.</p> <code>1000</code> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def __init__(\n    self,\n    catalog: ErmrestCatalog,\n    schemas: list[str],\n    batch_size: int = 1000,\n):\n    \"\"\"Initialize from catalog connection.\n\n    Args:\n        catalog: ERMrest catalog connection.\n        schemas: Schemas to fetch data from.\n        batch_size: Number of rows per API request.\n    \"\"\"\n    self.catalog = catalog\n    self.schemas = schemas\n    self.batch_size = batch_size\n    self._pb = catalog.getPathBuilder()\n    self._model = catalog.getCatalogModel()\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.CatalogDataSource.get_row_count","title":"get_row_count","text":"<pre><code>get_row_count(\n    table: Table | str,\n) -&gt; int\n</code></pre> <p>Get the number of rows in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>Table object or name.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of rows in the table.</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def get_row_count(self, table: DerivaTable | str) -&gt; int:\n    \"\"\"Get the number of rows in a table.\n\n    Args:\n        table: Table object or name.\n\n    Returns:\n        Number of rows in the table.\n    \"\"\"\n    table_info = self._get_table_info(table)\n    if table_info is None:\n        return 0\n\n    schema_name, table_name = table_info\n    path = self._pb.schemas[schema_name].tables[table_name]\n\n    try:\n        # Use count aggregate\n        result = path.aggregates(path.RID.cnt.alias(\"count\")).fetch()\n        return result[0][\"count\"] if result else 0\n    except Exception as e:\n        logger.error(f\"Error counting {schema_name}.{table_name}: {e}\")\n        return 0\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.CatalogDataSource.get_table_data","title":"get_table_data","text":"<pre><code>get_table_data(\n    table: Table | str,\n) -&gt; Iterator[dict[str, Any]]\n</code></pre> <p>Fetch table data via ERMrest API.</p> <p>Uses pagination to handle large tables efficiently.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>Table object or name.</p> required <p>Yields:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary per row with column names as keys.</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def get_table_data(\n    self,\n    table: DerivaTable | str,\n) -&gt; Iterator[dict[str, Any]]:\n    \"\"\"Fetch table data via ERMrest API.\n\n    Uses pagination to handle large tables efficiently.\n\n    Args:\n        table: Table object or name.\n\n    Yields:\n        Dictionary per row with column names as keys.\n    \"\"\"\n    table_info = self._get_table_info(table)\n    if table_info is None:\n        logger.warning(f\"Table {table} not found in schemas {self.schemas}\")\n        return\n\n    schema_name, table_name = table_info\n\n    # Build path\n    path = self._pb.schemas[schema_name].tables[table_name]\n\n    # Paginated fetch using RID ordering\n    last_rid = None\n    while True:\n        # Build query with optional RID filter\n        query = path.entities()\n        if last_rid is not None:\n            query = query.filter(path.RID &gt; last_rid)\n\n        # Fetch batch ordered by RID\n        try:\n            entities = list(query.sort(path.RID).fetch(limit=self.batch_size))\n        except Exception as e:\n            logger.error(f\"Error fetching from {schema_name}.{table_name}: {e}\")\n            break\n\n        if not entities:\n            break\n\n        for entity in entities:\n            yield dict(entity)\n\n        # Track last RID for pagination\n        last_rid = entities[-1][\"RID\"]\n\n        if len(entities) &lt; self.batch_size:\n            break\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.CatalogDataSource.has_table","title":"has_table","text":"<pre><code>has_table(table: Table | str) -&gt; bool\n</code></pre> <p>Check if table exists in catalog.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>Table object or name.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if table exists in configured schemas.</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def has_table(self, table: DerivaTable | str) -&gt; bool:\n    \"\"\"Check if table exists in catalog.\n\n    Args:\n        table: Table object or name.\n\n    Returns:\n        True if table exists in configured schemas.\n    \"\"\"\n    return self._get_table_info(table) is not None\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.CatalogDataSource.list_available_tables","title":"list_available_tables","text":"<pre><code>list_available_tables() -&gt; list[str]\n</code></pre> <p>List all tables in configured schemas.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of fully-qualified table names (schema.table).</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def list_available_tables(self) -&gt; list[str]:\n    \"\"\"List all tables in configured schemas.\n\n    Returns:\n        List of fully-qualified table names (schema.table).\n    \"\"\"\n    tables = []\n    for schema_name in self.schemas:\n        if schema_name in self._model.schemas:\n            schema = self._model.schemas[schema_name]\n            for table_name in schema.tables.keys():\n                tables.append(f\"{schema_name}.{table_name}\")\n    return sorted(tables)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ColumnDisplay","title":"ColumnDisplay  <code>dataclass</code>","text":"<p>               Bases: <code>AnnotationBuilder</code></p> <p>Column-display annotation builder.</p> <p>Controls how column values are rendered.</p> Example <p>cd = ColumnDisplay() cd.default(ColumnDisplayOptions( ...     pre_format=PreFormat(format=\"%.2f\") ... ))</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass ColumnDisplay(AnnotationBuilder):\n    \"\"\"Column-display annotation builder.\n\n    Controls how column values are rendered.\n\n    Example:\n        &gt;&gt;&gt; cd = ColumnDisplay()\n        &gt;&gt;&gt; cd.default(ColumnDisplayOptions(\n        ...     pre_format=PreFormat(format=\"%.2f\")\n        ... ))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Markdown link\n        &gt;&gt;&gt; cd = ColumnDisplay()\n        &gt;&gt;&gt; cd.default(ColumnDisplayOptions(\n        ...     markdown_pattern=\"[Link]({{{_value}}})\"\n        ... ))\n    \"\"\"\n    tag = TAG_COLUMN_DISPLAY\n\n    _contexts: dict[str, ColumnDisplayOptions | str] = field(default_factory=dict)\n\n    def set_context(\n        self,\n        context: str,\n        options: ColumnDisplayOptions | str\n    ) -&gt; \"ColumnDisplay\":\n        \"\"\"Set options for a context.\"\"\"\n        self._contexts[context] = options\n        return self\n\n    def default(self, options: ColumnDisplayOptions) -&gt; \"ColumnDisplay\":\n        \"\"\"Set default options.\"\"\"\n        return self.set_context(CONTEXT_DEFAULT, options)\n\n    def compact(self, options: ColumnDisplayOptions) -&gt; \"ColumnDisplay\":\n        \"\"\"Set options for compact view.\"\"\"\n        return self.set_context(CONTEXT_COMPACT, options)\n\n    def detailed(self, options: ColumnDisplayOptions) -&gt; \"ColumnDisplay\":\n        \"\"\"Set options for detailed view.\"\"\"\n        return self.set_context(CONTEXT_DETAILED, options)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        for context, options in self._contexts.items():\n            if isinstance(options, str):\n                result[context] = options\n            else:\n                result[context] = options.to_dict()\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ColumnDisplay--markdown-link","title":"Markdown link","text":"<p>cd = ColumnDisplay() cd.default(ColumnDisplayOptions( ...     markdown_pattern=\"Link\" ... ))</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ColumnDisplay.compact","title":"compact","text":"<pre><code>compact(\n    options: ColumnDisplayOptions,\n) -&gt; \"ColumnDisplay\"\n</code></pre> <p>Set options for compact view.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def compact(self, options: ColumnDisplayOptions) -&gt; \"ColumnDisplay\":\n    \"\"\"Set options for compact view.\"\"\"\n    return self.set_context(CONTEXT_COMPACT, options)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ColumnDisplay.default","title":"default","text":"<pre><code>default(\n    options: ColumnDisplayOptions,\n) -&gt; \"ColumnDisplay\"\n</code></pre> <p>Set default options.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def default(self, options: ColumnDisplayOptions) -&gt; \"ColumnDisplay\":\n    \"\"\"Set default options.\"\"\"\n    return self.set_context(CONTEXT_DEFAULT, options)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ColumnDisplay.detailed","title":"detailed","text":"<pre><code>detailed(\n    options: ColumnDisplayOptions,\n) -&gt; \"ColumnDisplay\"\n</code></pre> <p>Set options for detailed view.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def detailed(self, options: ColumnDisplayOptions) -&gt; \"ColumnDisplay\":\n    \"\"\"Set options for detailed view.\"\"\"\n    return self.set_context(CONTEXT_DETAILED, options)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ColumnDisplay.set_context","title":"set_context","text":"<pre><code>set_context(\n    context: str,\n    options: ColumnDisplayOptions | str,\n) -&gt; \"ColumnDisplay\"\n</code></pre> <p>Set options for a context.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def set_context(\n    self,\n    context: str,\n    options: ColumnDisplayOptions | str\n) -&gt; \"ColumnDisplay\":\n    \"\"\"Set options for a context.\"\"\"\n    self._contexts[context] = options\n    return self\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ColumnDisplayOptions","title":"ColumnDisplayOptions  <code>dataclass</code>","text":"<p>Options for displaying a column in a specific context.</p> <p>Parameters:</p> Name Type Description Default <code>pre_format</code> <code>PreFormat | None</code> <p>Pre-formatting options</p> <code>None</code> <code>markdown_pattern</code> <code>str | None</code> <p>Template for rendering</p> <code>None</code> <code>template_engine</code> <code>TemplateEngine | None</code> <p>Template engine to use</p> <code>None</code> <code>column_order</code> <code>list[SortKey] | Literal[False] | None</code> <p>Sort order, or False to disable</p> <code>None</code> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass ColumnDisplayOptions:\n    \"\"\"Options for displaying a column in a specific context.\n\n    Args:\n        pre_format: Pre-formatting options\n        markdown_pattern: Template for rendering\n        template_engine: Template engine to use\n        column_order: Sort order, or False to disable\n    \"\"\"\n    pre_format: PreFormat | None = None\n    markdown_pattern: str | None = None\n    template_engine: TemplateEngine | None = None\n    column_order: list[SortKey] | Literal[False] | None = None\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        if self.pre_format is not None:\n            result[\"pre_format\"] = self.pre_format.to_dict()\n        if self.markdown_pattern is not None:\n            result[\"markdown_pattern\"] = self.markdown_pattern\n        if self.template_engine is not None:\n            result[\"template_engine\"] = self.template_engine.value\n        if self.column_order is not None:\n            if self.column_order is False:\n                result[\"column_order\"] = False\n            else:\n                result[\"column_order\"] = [\n                    k.to_dict() if isinstance(k, SortKey) else k\n                    for k in self.column_order\n                ]\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader","title":"DataLoader","text":"<p>Loads data into a database with FK ordering.</p> <p>Phase 2 of the two-phase database creation pattern. Takes a SchemaORM (from Phase 1) and populates it from a DataSource.</p> <p>Automatically orders tables by FK dependencies to ensure referential integrity during loading.</p> Example Source code in <code>src/deriva_ml/model/data_loader.py</code> <pre><code>class DataLoader:\n    \"\"\"Loads data into a database with FK ordering.\n\n    Phase 2 of the two-phase database creation pattern. Takes a\n    SchemaORM (from Phase 1) and populates it from a DataSource.\n\n    Automatically orders tables by FK dependencies to ensure\n    referential integrity during loading.\n\n    Example:\n        # Phase 1: Create ORM\n        orm = SchemaBuilder(model, schemas).build()\n\n        # Phase 2: Fill with data from bag\n        source = BagDataSource(bag_path)\n        loader = DataLoader(orm, source)\n        counts = loader.load_tables()  # All tables\n        print(f\"Loaded {sum(counts.values())} total rows\")\n\n        # Or load specific tables\n        counts = loader.load_tables(['Subject', 'Image'])\n\n        # With progress callback\n        def on_progress(table, count, total):\n            print(f\"Loaded {table}: {count} rows\")\n        loader.load_tables(progress_callback=on_progress)\n    \"\"\"\n\n    def __init__(\n        self,\n        schema_orm: SchemaORM,\n        data_source: DataSource,\n    ):\n        \"\"\"Initialize the loader.\n\n        Args:\n            schema_orm: ORM structure from SchemaBuilder.\n            data_source: Source of data to load (BagDataSource, CatalogDataSource, etc.).\n        \"\"\"\n        self.orm = schema_orm\n        self.source = data_source\n        self.orderer = ForeignKeyOrderer(\n            schema_orm.model,\n            schema_orm.schemas,\n        )\n\n    def load_tables(\n        self,\n        tables: list[str | DerivaTable] | None = None,\n        on_conflict: str = \"ignore\",\n        batch_size: int = 1000,\n        progress_callback: Callable[[str, int, int], None] | None = None,\n    ) -&gt; dict[str, int]:\n        \"\"\"Load data into specified tables with FK ordering.\n\n        Tables are automatically ordered by FK dependencies to ensure\n        referenced tables are populated first.\n\n        Args:\n            tables: Tables to load. If None, loads all tables that have\n                data in the source.\n            on_conflict: How to handle duplicate keys:\n                - \"ignore\": Skip rows with duplicate keys (default)\n                - \"replace\": Replace existing rows\n                - \"error\": Raise error on duplicates\n            batch_size: Number of rows per insert batch.\n            progress_callback: Optional callback(table_name, rows_loaded, total_tables)\n                called after each table is loaded.\n\n        Returns:\n            Dict mapping table names to row counts loaded.\n        \"\"\"\n        # Determine tables to load\n        if tables is None:\n            # Get all tables that have data in source\n            available = set(self.source.list_available_tables())\n            # Filter to tables that exist in ORM\n            orm_tables = set(self.orm.list_tables())\n\n            # Match available tables to ORM tables\n            tables_to_load = []\n            for orm_table in orm_tables:\n                # Check both qualified and unqualified names\n                table_name = orm_table.split(\".\")[-1]\n                if orm_table in available or table_name in available:\n                    tables_to_load.append(orm_table)\n        else:\n            tables_to_load = [\n                t if isinstance(t, str) else f\"{t.schema.name}.{t.name}\"\n                for t in tables\n            ]\n\n        # Compute insertion order\n        try:\n            ordered_tables = self.orderer.get_insertion_order(tables_to_load)\n        except ValueError as e:\n            # Some tables might not be in the model, just use original order\n            logger.warning(f\"Could not compute FK ordering: {e}\")\n            ordered_tables = [\n                self.orderer._to_table(t) if isinstance(t, str) else t\n                for t in tables_to_load\n                if self._table_exists(t)\n            ]\n\n        # Load in order\n        counts = {}\n        total_tables = len(ordered_tables)\n\n        for i, table in enumerate(ordered_tables):\n            table_key = f\"{table.schema.name}.{table.name}\"\n\n            count = self._load_table(table, on_conflict, batch_size)\n            counts[table_key] = count\n\n            if progress_callback:\n                progress_callback(table_key, count, total_tables)\n\n            if count &gt; 0:\n                logger.info(f\"Loaded {count} rows into {table_key}\")\n\n        return counts\n\n    def _table_exists(self, table: str | DerivaTable) -&gt; bool:\n        \"\"\"Check if table exists in ORM.\"\"\"\n        try:\n            if isinstance(table, str):\n                self.orm.find_table(table)\n            else:\n                self.orm.find_table(f\"{table.schema.name}.{table.name}\")\n            return True\n        except KeyError:\n            return False\n\n    def _load_table(\n        self,\n        table: DerivaTable,\n        on_conflict: str,\n        batch_size: int,\n    ) -&gt; int:\n        \"\"\"Load a single table.\n\n        Args:\n            table: Table to load.\n            on_conflict: Conflict handling strategy.\n            batch_size: Rows per batch.\n\n        Returns:\n            Number of rows loaded.\n        \"\"\"\n        table_key = f\"{table.schema.name}.{table.name}\"\n\n        # Find SQL table\n        try:\n            sql_table = self.orm.find_table(table_key)\n        except KeyError:\n            logger.warning(f\"Table {table_key} not found in ORM\")\n            return 0\n\n        # Check if source has data\n        if not self.source.has_table(table):\n            logger.debug(f\"No data for {table_key} in source\")\n            return 0\n\n        # Get data from source\n        rows_loaded = 0\n        batch = []\n\n        with self.orm.engine.begin() as conn:\n            for row in self.source.get_table_data(table):\n                batch.append(row)\n\n                if len(batch) &gt;= batch_size:\n                    rows_loaded += self._insert_batch(\n                        conn, sql_table, batch, on_conflict\n                    )\n                    batch = []\n\n            # Insert remaining rows\n            if batch:\n                rows_loaded += self._insert_batch(\n                    conn, sql_table, batch, on_conflict\n                )\n\n        return rows_loaded\n\n    def _insert_batch(\n        self,\n        conn: Any,\n        sql_table: Any,\n        rows: list[dict[str, Any]],\n        on_conflict: str,\n    ) -&gt; int:\n        \"\"\"Insert a batch of rows.\n\n        Args:\n            conn: Database connection.\n            sql_table: SQLAlchemy table.\n            rows: List of row dictionaries.\n            on_conflict: Conflict handling strategy.\n\n        Returns:\n            Number of rows inserted.\n        \"\"\"\n        if not rows:\n            return 0\n\n        try:\n            if on_conflict == \"ignore\":\n                stmt = sqlite_insert(sql_table).on_conflict_do_nothing()\n            elif on_conflict == \"replace\":\n                # For SQLite, we need to specify all columns for upsert\n                stmt = sqlite_insert(sql_table)\n                update_cols = {\n                    c.name: c for c in stmt.excluded\n                    if c.name not in (\"RID\",)  # Don't update primary key\n                }\n                stmt = stmt.on_conflict_do_update(\n                    index_elements=[\"RID\"],\n                    set_=update_cols,\n                )\n            else:\n                stmt = sql_table.insert()\n\n            conn.execute(stmt, rows)\n            return len(rows)\n\n        except Exception as e:\n            logger.error(f\"Error inserting into {sql_table.name}: {e}\")\n            if on_conflict == \"error\":\n                raise\n            return 0\n\n    def load_table(\n        self,\n        table: str | DerivaTable,\n        on_conflict: str = \"ignore\",\n        batch_size: int = 1000,\n    ) -&gt; int:\n        \"\"\"Load a single table (without FK ordering).\n\n        Use this when you know the dependencies are already satisfied\n        or for loading a single table.\n\n        Args:\n            table: Table to load.\n            on_conflict: Conflict handling strategy.\n            batch_size: Rows per batch.\n\n        Returns:\n            Number of rows loaded.\n        \"\"\"\n        if isinstance(table, str):\n            table = self.orderer._to_table(table)\n\n        return self._load_table(table, on_conflict, batch_size)\n\n    def get_load_order(\n        self,\n        tables: list[str | DerivaTable] | None = None,\n    ) -&gt; list[str]:\n        \"\"\"Get the FK-safe load order for tables without loading.\n\n        Useful for previewing or manually controlling load order.\n\n        Args:\n            tables: Tables to order. If None, orders all available.\n\n        Returns:\n            List of table names in safe insertion order.\n        \"\"\"\n        if tables is None:\n            available = self.source.list_available_tables()\n            tables = [t for t in available if self._table_exists(t)]\n\n        ordered = self.orderer.get_insertion_order(tables)\n        return [f\"{t.schema.name}.{t.name}\" for t in ordered]\n\n    def validate_load_order(\n        self,\n        tables: list[str | DerivaTable],\n    ) -&gt; list[tuple[str, str, str]]:\n        \"\"\"Validate that tables can be loaded in the given order.\n\n        Args:\n            tables: Ordered list of tables.\n\n        Returns:\n            List of FK violations as (table, missing_dep, fk_name) tuples.\n            Empty if order is valid.\n        \"\"\"\n        return self.orderer.validate_insertion_order(tables)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader--phase-1-create-orm","title":"Phase 1: Create ORM","text":"<p>orm = SchemaBuilder(model, schemas).build()</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader--phase-2-fill-with-data-from-bag","title":"Phase 2: Fill with data from bag","text":"<p>source = BagDataSource(bag_path) loader = DataLoader(orm, source) counts = loader.load_tables()  # All tables print(f\"Loaded {sum(counts.values())} total rows\")</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader--or-load-specific-tables","title":"Or load specific tables","text":"<p>counts = loader.load_tables(['Subject', 'Image'])</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader--with-progress-callback","title":"With progress callback","text":"<p>def on_progress(table, count, total):     print(f\"Loaded {table}: {count} rows\") loader.load_tables(progress_callback=on_progress)</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader.__init__","title":"__init__","text":"<pre><code>__init__(\n    schema_orm: SchemaORM,\n    data_source: DataSource,\n)\n</code></pre> <p>Initialize the loader.</p> <p>Parameters:</p> Name Type Description Default <code>schema_orm</code> <code>SchemaORM</code> <p>ORM structure from SchemaBuilder.</p> required <code>data_source</code> <code>DataSource</code> <p>Source of data to load (BagDataSource, CatalogDataSource, etc.).</p> required Source code in <code>src/deriva_ml/model/data_loader.py</code> <pre><code>def __init__(\n    self,\n    schema_orm: SchemaORM,\n    data_source: DataSource,\n):\n    \"\"\"Initialize the loader.\n\n    Args:\n        schema_orm: ORM structure from SchemaBuilder.\n        data_source: Source of data to load (BagDataSource, CatalogDataSource, etc.).\n    \"\"\"\n    self.orm = schema_orm\n    self.source = data_source\n    self.orderer = ForeignKeyOrderer(\n        schema_orm.model,\n        schema_orm.schemas,\n    )\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader.get_load_order","title":"get_load_order","text":"<pre><code>get_load_order(\n    tables: list[str | Table]\n    | None = None,\n) -&gt; list[str]\n</code></pre> <p>Get the FK-safe load order for tables without loading.</p> <p>Useful for previewing or manually controlling load order.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list[str | Table] | None</code> <p>Tables to order. If None, orders all available.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of table names in safe insertion order.</p> Source code in <code>src/deriva_ml/model/data_loader.py</code> <pre><code>def get_load_order(\n    self,\n    tables: list[str | DerivaTable] | None = None,\n) -&gt; list[str]:\n    \"\"\"Get the FK-safe load order for tables without loading.\n\n    Useful for previewing or manually controlling load order.\n\n    Args:\n        tables: Tables to order. If None, orders all available.\n\n    Returns:\n        List of table names in safe insertion order.\n    \"\"\"\n    if tables is None:\n        available = self.source.list_available_tables()\n        tables = [t for t in available if self._table_exists(t)]\n\n    ordered = self.orderer.get_insertion_order(tables)\n    return [f\"{t.schema.name}.{t.name}\" for t in ordered]\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader.load_table","title":"load_table","text":"<pre><code>load_table(\n    table: str | Table,\n    on_conflict: str = \"ignore\",\n    batch_size: int = 1000,\n) -&gt; int\n</code></pre> <p>Load a single table (without FK ordering).</p> <p>Use this when you know the dependencies are already satisfied or for loading a single table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table to load.</p> required <code>on_conflict</code> <code>str</code> <p>Conflict handling strategy.</p> <code>'ignore'</code> <code>batch_size</code> <code>int</code> <p>Rows per batch.</p> <code>1000</code> <p>Returns:</p> Type Description <code>int</code> <p>Number of rows loaded.</p> Source code in <code>src/deriva_ml/model/data_loader.py</code> <pre><code>def load_table(\n    self,\n    table: str | DerivaTable,\n    on_conflict: str = \"ignore\",\n    batch_size: int = 1000,\n) -&gt; int:\n    \"\"\"Load a single table (without FK ordering).\n\n    Use this when you know the dependencies are already satisfied\n    or for loading a single table.\n\n    Args:\n        table: Table to load.\n        on_conflict: Conflict handling strategy.\n        batch_size: Rows per batch.\n\n    Returns:\n        Number of rows loaded.\n    \"\"\"\n    if isinstance(table, str):\n        table = self.orderer._to_table(table)\n\n    return self._load_table(table, on_conflict, batch_size)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader.load_tables","title":"load_tables","text":"<pre><code>load_tables(\n    tables: list[str | Table]\n    | None = None,\n    on_conflict: str = \"ignore\",\n    batch_size: int = 1000,\n    progress_callback: Callable[\n        [str, int, int], None\n    ]\n    | None = None,\n) -&gt; dict[str, int]\n</code></pre> <p>Load data into specified tables with FK ordering.</p> <p>Tables are automatically ordered by FK dependencies to ensure referenced tables are populated first.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list[str | Table] | None</code> <p>Tables to load. If None, loads all tables that have data in the source.</p> <code>None</code> <code>on_conflict</code> <code>str</code> <p>How to handle duplicate keys: - \"ignore\": Skip rows with duplicate keys (default) - \"replace\": Replace existing rows - \"error\": Raise error on duplicates</p> <code>'ignore'</code> <code>batch_size</code> <code>int</code> <p>Number of rows per insert batch.</p> <code>1000</code> <code>progress_callback</code> <code>Callable[[str, int, int], None] | None</code> <p>Optional callback(table_name, rows_loaded, total_tables) called after each table is loaded.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict mapping table names to row counts loaded.</p> Source code in <code>src/deriva_ml/model/data_loader.py</code> <pre><code>def load_tables(\n    self,\n    tables: list[str | DerivaTable] | None = None,\n    on_conflict: str = \"ignore\",\n    batch_size: int = 1000,\n    progress_callback: Callable[[str, int, int], None] | None = None,\n) -&gt; dict[str, int]:\n    \"\"\"Load data into specified tables with FK ordering.\n\n    Tables are automatically ordered by FK dependencies to ensure\n    referenced tables are populated first.\n\n    Args:\n        tables: Tables to load. If None, loads all tables that have\n            data in the source.\n        on_conflict: How to handle duplicate keys:\n            - \"ignore\": Skip rows with duplicate keys (default)\n            - \"replace\": Replace existing rows\n            - \"error\": Raise error on duplicates\n        batch_size: Number of rows per insert batch.\n        progress_callback: Optional callback(table_name, rows_loaded, total_tables)\n            called after each table is loaded.\n\n    Returns:\n        Dict mapping table names to row counts loaded.\n    \"\"\"\n    # Determine tables to load\n    if tables is None:\n        # Get all tables that have data in source\n        available = set(self.source.list_available_tables())\n        # Filter to tables that exist in ORM\n        orm_tables = set(self.orm.list_tables())\n\n        # Match available tables to ORM tables\n        tables_to_load = []\n        for orm_table in orm_tables:\n            # Check both qualified and unqualified names\n            table_name = orm_table.split(\".\")[-1]\n            if orm_table in available or table_name in available:\n                tables_to_load.append(orm_table)\n    else:\n        tables_to_load = [\n            t if isinstance(t, str) else f\"{t.schema.name}.{t.name}\"\n            for t in tables\n        ]\n\n    # Compute insertion order\n    try:\n        ordered_tables = self.orderer.get_insertion_order(tables_to_load)\n    except ValueError as e:\n        # Some tables might not be in the model, just use original order\n        logger.warning(f\"Could not compute FK ordering: {e}\")\n        ordered_tables = [\n            self.orderer._to_table(t) if isinstance(t, str) else t\n            for t in tables_to_load\n            if self._table_exists(t)\n        ]\n\n    # Load in order\n    counts = {}\n    total_tables = len(ordered_tables)\n\n    for i, table in enumerate(ordered_tables):\n        table_key = f\"{table.schema.name}.{table.name}\"\n\n        count = self._load_table(table, on_conflict, batch_size)\n        counts[table_key] = count\n\n        if progress_callback:\n            progress_callback(table_key, count, total_tables)\n\n        if count &gt; 0:\n            logger.info(f\"Loaded {count} rows into {table_key}\")\n\n    return counts\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataLoader.validate_load_order","title":"validate_load_order","text":"<pre><code>validate_load_order(\n    tables: list[str | Table],\n) -&gt; list[tuple[str, str, str]]\n</code></pre> <p>Validate that tables can be loaded in the given order.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list[str | Table]</code> <p>Ordered list of tables.</p> required <p>Returns:</p> Type Description <code>list[tuple[str, str, str]]</code> <p>List of FK violations as (table, missing_dep, fk_name) tuples.</p> <code>list[tuple[str, str, str]]</code> <p>Empty if order is valid.</p> Source code in <code>src/deriva_ml/model/data_loader.py</code> <pre><code>def validate_load_order(\n    self,\n    tables: list[str | DerivaTable],\n) -&gt; list[tuple[str, str, str]]:\n    \"\"\"Validate that tables can be loaded in the given order.\n\n    Args:\n        tables: Ordered list of tables.\n\n    Returns:\n        List of FK violations as (table, missing_dep, fk_name) tuples.\n        Empty if order is valid.\n    \"\"\"\n    return self.orderer.validate_insertion_order(tables)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataSource","title":"DataSource","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for data sources that can fill a database.</p> <p>Implementations provide data for populating SQLite tables from different sources (bags, remote catalogs, etc.).</p> <p>This is used with DataLoader in Phase 2 of the two-phase pattern.</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>@runtime_checkable\nclass DataSource(Protocol):\n    \"\"\"Protocol for data sources that can fill a database.\n\n    Implementations provide data for populating SQLite tables from\n    different sources (bags, remote catalogs, etc.).\n\n    This is used with DataLoader in Phase 2 of the two-phase pattern.\n    \"\"\"\n\n    def get_table_data(\n        self,\n        table: DerivaTable | str,\n    ) -&gt; Iterator[dict[str, Any]]:\n        \"\"\"Yield rows for a table as dictionaries.\n\n        Args:\n            table: Table object or name to get data for.\n\n        Yields:\n            Dictionary per row with column names as keys.\n        \"\"\"\n        ...\n\n    def has_table(self, table: DerivaTable | str) -&gt; bool:\n        \"\"\"Check if this source has data for the table.\n\n        Args:\n            table: Table object or name to check.\n\n        Returns:\n            True if data is available for this table.\n        \"\"\"\n        ...\n\n    def list_available_tables(self) -&gt; list[str]:\n        \"\"\"List tables with available data.\n\n        Returns:\n            List of table names (may include schema prefix).\n        \"\"\"\n        ...\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataSource.get_table_data","title":"get_table_data","text":"<pre><code>get_table_data(\n    table: Table | str,\n) -&gt; Iterator[dict[str, Any]]\n</code></pre> <p>Yield rows for a table as dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>Table object or name to get data for.</p> required <p>Yields:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary per row with column names as keys.</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def get_table_data(\n    self,\n    table: DerivaTable | str,\n) -&gt; Iterator[dict[str, Any]]:\n    \"\"\"Yield rows for a table as dictionaries.\n\n    Args:\n        table: Table object or name to get data for.\n\n    Yields:\n        Dictionary per row with column names as keys.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataSource.has_table","title":"has_table","text":"<pre><code>has_table(table: Table | str) -&gt; bool\n</code></pre> <p>Check if this source has data for the table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | str</code> <p>Table object or name to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if data is available for this table.</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def has_table(self, table: DerivaTable | str) -&gt; bool:\n    \"\"\"Check if this source has data for the table.\n\n    Args:\n        table: Table object or name to check.\n\n    Returns:\n        True if data is available for this table.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DataSource.list_available_tables","title":"list_available_tables","text":"<pre><code>list_available_tables() -&gt; list[str]\n</code></pre> <p>List tables with available data.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of table names (may include schema prefix).</p> Source code in <code>src/deriva_ml/model/data_sources.py</code> <pre><code>def list_available_tables(self) -&gt; list[str]:\n    \"\"\"List tables with available data.\n\n    Returns:\n        List of table names (may include schema prefix).\n    \"\"\"\n    ...\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel","title":"DerivaModel","text":"<p>Augmented interface to deriva model class.</p> <p>This class provides a number of DerivaML specific methods that augment the interface in the deriva model class.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>ERMRest model for the catalog.</p> <code>catalog</code> <code>ErmrestCatalog</code> <p>ERMRest catalog for the model.</p> <code>hostname</code> <p>Hostname of the ERMRest server.</p> <code>ml_schema</code> <p>The ML schema name for the catalog.</p> <code>domain_schemas</code> <p>Frozenset of all domain schema names in the catalog.</p> <code>default_schema</code> <p>The default schema for table creation operations.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>class DerivaModel:\n    \"\"\"Augmented interface to deriva model class.\n\n    This class provides a number of DerivaML specific methods that augment the interface in the deriva model class.\n\n    Attributes:\n        model: ERMRest model for the catalog.\n        catalog: ERMRest catalog for the model.\n        hostname: Hostname of the ERMRest server.\n        ml_schema: The ML schema name for the catalog.\n        domain_schemas: Frozenset of all domain schema names in the catalog.\n        default_schema: The default schema for table creation operations.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Model,\n        ml_schema: str = ML_SCHEMA,\n        domain_schemas: str | set[str] | None = None,\n        default_schema: str | None = None,\n    ):\n        \"\"\"Create and initialize a DerivaModel instance.\n\n        This method will connect to a catalog and initialize schema configuration.\n        This class is intended to be used as a base class on which domain-specific interfaces are built.\n\n        Args:\n            model: The ERMRest model for the catalog.\n            ml_schema: The ML schema name.\n            domain_schemas: Optional explicit set of domain schema names. If None,\n                auto-detects all non-system schemas.\n            default_schema: The default schema for table creation operations. If None\n                and there is exactly one domain schema, that schema is used as default.\n                If there are multiple domain schemas, default_schema must be specified.\n        \"\"\"\n        self.model = model\n        self.configuration = None\n        self.catalog: ErmrestCatalog = self.model.catalog\n        self.hostname = self.catalog.deriva_server.server if isinstance(self.catalog, ErmrestCatalog) else \"localhost\"\n\n        self.ml_schema = ml_schema\n        self._system_schemas = frozenset(SYSTEM_SCHEMAS | {ml_schema})\n\n        # Determine domain schemas\n        if domain_schemas is not None:\n            if isinstance(domain_schemas, str):\n                domain_schemas = {domain_schemas}\n            self.domain_schemas = frozenset(domain_schemas)\n        else:\n            # Auto-detect all domain schemas\n            self.domain_schemas = get_domain_schemas(self.model.schemas.keys(), ml_schema)\n\n        # Determine default schema for table creation\n        if default_schema is not None:\n            if default_schema not in self.domain_schemas:\n                raise DerivaMLException(\n                    f\"default_schema '{default_schema}' is not in domain_schemas: {self.domain_schemas}\"\n                )\n            self.default_schema = default_schema\n        elif len(self.domain_schemas) == 1:\n            # Single domain schema - use it as default\n            self.default_schema = next(iter(self.domain_schemas))\n        elif len(self.domain_schemas) == 0:\n            # No domain schemas - default_schema will be None\n            self.default_schema = None\n        else:\n            # Multiple domain schemas, no explicit default\n            self.default_schema = None\n\n    def is_system_schema(self, schema_name: str) -&gt; bool:\n        \"\"\"Check if a schema is a system or ML schema.\n\n        Args:\n            schema_name: Name of the schema to check.\n\n        Returns:\n            True if the schema is a system or ML schema.\n        \"\"\"\n        return is_system_schema(schema_name, self.ml_schema)\n\n    def is_domain_schema(self, schema_name: str) -&gt; bool:\n        \"\"\"Check if a schema is a domain schema.\n\n        Args:\n            schema_name: Name of the schema to check.\n\n        Returns:\n            True if the schema is a domain schema.\n        \"\"\"\n        return schema_name in self.domain_schemas\n\n    def _require_default_schema(self) -&gt; str:\n        \"\"\"Get default schema, raising an error if not set.\n\n        Returns:\n            The default schema name.\n\n        Raises:\n            DerivaMLException: If default_schema is not set.\n        \"\"\"\n        if self.default_schema is None:\n            raise DerivaMLException(\n                f\"No default_schema set. With multiple domain schemas {self.domain_schemas}, \"\n                \"you must either specify a default_schema when creating DerivaML or \"\n                \"pass an explicit schema parameter to this method.\"\n            )\n        return self.default_schema\n\n    def refresh_model(self) -&gt; None:\n        self.model = self.catalog.getCatalogModel()\n\n    @property\n    def chaise_config(self) -&gt; dict[str, Any]:\n        \"\"\"Return the chaise configuration.\"\"\"\n        return self.model.chaise_config\n\n    def get_schema_description(self, include_system_columns: bool = False) -&gt; dict[str, Any]:\n        \"\"\"Return a JSON description of the catalog schema structure.\n\n        Provides a structured representation of the domain and ML schemas including\n        tables, columns, foreign keys, and relationships. Useful for understanding\n        the data model structure programmatically.\n\n        Args:\n            include_system_columns: If True, include RID, RCT, RMT, RCB, RMB columns.\n                Default False to reduce output size.\n\n        Returns:\n            Dictionary with schema structure:\n            {\n                \"domain_schemas\": [\"schema_name1\", \"schema_name2\"],\n                \"default_schema\": \"schema_name1\",\n                \"ml_schema\": \"deriva-ml\",\n                \"schemas\": {\n                    \"schema_name\": {\n                        \"tables\": {\n                            \"TableName\": {\n                                \"comment\": \"description\",\n                                \"is_vocabulary\": bool,\n                                \"is_asset\": bool,\n                                \"is_association\": bool,\n                                \"columns\": [...],\n                                \"foreign_keys\": [...],\n                                \"features\": [...]\n                            }\n                        }\n                    }\n                }\n            }\n        \"\"\"\n        system_columns = {\"RID\", \"RCT\", \"RMT\", \"RCB\", \"RMB\"}\n        result = {\n            \"domain_schemas\": sorted(self.domain_schemas),\n            \"default_schema\": self.default_schema,\n            \"ml_schema\": self.ml_schema,\n            \"schemas\": {},\n        }\n\n        # Include all domain schemas and the ML schema\n        for schema_name in [*self.domain_schemas, self.ml_schema]:\n            schema = self.model.schemas.get(schema_name)\n            if not schema:\n                continue\n\n            schema_info = {\"tables\": {}}\n\n            for table_name, table in schema.tables.items():\n                # Get columns\n                columns = []\n                for col in table.columns:\n                    if not include_system_columns and col.name in system_columns:\n                        continue\n                    columns.append({\n                        \"name\": col.name,\n                        \"type\": str(col.type.typename),\n                        \"nullok\": col.nullok,\n                        \"comment\": col.comment or \"\",\n                    })\n\n                # Get foreign keys\n                foreign_keys = []\n                for fk in table.foreign_keys:\n                    fk_cols = [c.name for c in fk.foreign_key_columns]\n                    ref_cols = [c.name for c in fk.referenced_columns]\n                    foreign_keys.append({\n                        \"columns\": fk_cols,\n                        \"referenced_table\": f\"{fk.pk_table.schema.name}.{fk.pk_table.name}\",\n                        \"referenced_columns\": ref_cols,\n                    })\n\n                # Get features if this is a domain table\n                features = []\n                if self.is_domain_schema(schema_name):\n                    try:\n                        for f in self.find_features(table):\n                            features.append({\n                                \"name\": f.feature_name,\n                                \"feature_table\": f.feature_table.name,\n                            })\n                    except Exception:\n                        pass  # Table may not support features\n\n                table_info = {\n                    \"comment\": table.comment or \"\",\n                    \"is_vocabulary\": self.is_vocabulary(table),\n                    \"is_asset\": self.is_asset(table),\n                    \"is_association\": bool(self.is_association(table)),\n                    \"columns\": columns,\n                    \"foreign_keys\": foreign_keys,\n                }\n                if features:\n                    table_info[\"features\"] = features\n\n                schema_info[\"tables\"][table_name] = table_info\n\n            result[\"schemas\"][schema_name] = schema_info\n\n        return result\n\n    def __getattr__(self, name: str) -&gt; Any:\n        # Called only if `name` is not found in Manager.  Delegate attributes to model class.\n        return getattr(self.model, name)\n\n    def name_to_table(self, table: TableInput) -&gt; Table:\n        \"\"\"Return the table object corresponding to the given table name.\n\n        Searches domain schemas first (in sorted order), then ML schema, then WWW.\n        If the table name appears in more than one schema, returns the first match.\n\n        Args:\n          table: A ERMRest table object or a string that is the name of the table.\n\n        Returns:\n          Table object.\n\n        Raises:\n          DerivaMLException: If the table doesn't exist in any searchable schema.\n        \"\"\"\n        if isinstance(table, Table):\n            return table\n\n        # Search domain schemas (sorted for deterministic order), then ML schema, then WWW\n        search_order = [*sorted(self.domain_schemas), self.ml_schema, \"WWW\"]\n        for sname in search_order:\n            if sname not in self.model.schemas:\n                continue\n            s = self.model.schemas[sname]\n            if table in s.tables:\n                return s.tables[table]\n        raise DerivaMLException(f\"The table {table} doesn't exist.\")\n\n    def is_vocabulary(self, table_name: TableInput) -&gt; bool:\n        \"\"\"Check if a given table is a controlled vocabulary table.\n\n        Args:\n          table_name: A ERMRest table object or the name of the table.\n\n        Returns:\n          Table object if the table is a controlled vocabulary, False otherwise.\n\n        Raises:\n          DerivaMLException: if the table doesn't exist.\n\n        \"\"\"\n        vocab_columns = {\"NAME\", \"URI\", \"SYNONYMS\", \"DESCRIPTION\", \"ID\"}\n        table = self.name_to_table(table_name)\n        return vocab_columns.issubset({c.name.upper() for c in table.columns})\n\n    def vocab_columns(self, table_name: TableInput) -&gt; dict[str, str]:\n        \"\"\"Return mapping from canonical vocab column name to actual column name.\n\n        Canonical names are TitleCase (Name, ID, URI, Description, Synonyms).\n        Actual names reflect the table's schema \u2014 could be lowercase for\n        FaceBase-style catalogs or TitleCase for DerivaML-native tables.\n\n        Args:\n            table_name: A table object or the name of the table.\n\n        Returns:\n            Dict mapping canonical name to actual column name in the table.\n            E.g. ``{\"Name\": \"name\", \"ID\": \"id\", ...}`` for FaceBase tables\n            or ``{\"Name\": \"Name\", \"ID\": \"ID\", ...}`` for DerivaML tables.\n        \"\"\"\n        table = self.name_to_table(table_name)\n        col_map = {c.name.upper(): c.name for c in table.columns}\n        return {canon: col_map[canon.upper()] for canon in (\"Name\", \"ID\", \"URI\", \"Description\", \"Synonyms\")}\n\n    def is_association(\n        self,\n        table_name: str | Table,\n        unqualified: bool = True,\n        pure: bool = True,\n        min_arity: int = 2,\n        max_arity: int = 2,\n    ) -&gt; bool | set[str] | int:\n        \"\"\"Check the specified table to see if it is an association table.\n\n        Args:\n            table_name: param unqualified:\n            pure: return: (Default value = True)\n            table_name: str | Table:\n            unqualified:  (Default value = True)\n\n        Returns:\n\n\n        \"\"\"\n        table = self.name_to_table(table_name)\n        return table.is_association(unqualified=unqualified, pure=pure, min_arity=min_arity, max_arity=max_arity)\n\n    def find_association(self, table1: Table | str, table2: Table | str) -&gt; tuple[Table, Column, Column]:\n        \"\"\"Given two tables, return an association table that connects the two and the two columns used to link them..\n\n        Raises:\n            DerivaML exception if there is either not an association table or more than one association table.\n        \"\"\"\n        table1 = self.name_to_table(table1)\n        table2 = self.name_to_table(table2)\n\n        tables = [\n            (a.table, a.self_fkey.columns[0].name, other_key.columns[0].name)\n            for a in table1.find_associations(pure=False)\n            if len(a.other_fkeys) == 1 and (other_key := a.other_fkeys.pop()).pk_table == table2\n        ]\n\n        if len(tables) == 1:\n            return tables[0]\n        elif len(tables) == 0:\n            raise DerivaMLException(f\"No association tables found between {table1.name} and {table2.name}.\")\n        else:\n            raise DerivaMLException(\n                f\"There are {len(tables)} association tables between {table1.name} and {table2.name}.\"\n            )\n\n    def is_asset(self, table_name: TableInput) -&gt; bool:\n        \"\"\"True if the specified table is an asset table.\n\n        Args:\n            table_name: str | Table:\n\n        Returns:\n            True if the specified table is an asset table, False otherwise.\n\n        \"\"\"\n        asset_columns = {\"Filename\", \"URL\", \"Length\", \"MD5\", \"Description\"}\n        table = self.name_to_table(table_name)\n        return asset_columns.issubset({c.name for c in table.columns})\n\n    def find_assets(self, with_metadata: bool = False) -&gt; list[Table]:\n        \"\"\"Return the list of asset tables in the current model\"\"\"\n        return [t for s in self.model.schemas.values() for t in s.tables.values() if self.is_asset(t)]\n\n    def find_vocabularies(self) -&gt; list[Table]:\n        \"\"\"Return a list of all controlled vocabulary tables in domain and ML schemas.\"\"\"\n        tables = []\n        for schema_name in [*self.domain_schemas, self.ml_schema]:\n            schema = self.model.schemas.get(schema_name)\n            if schema:\n                tables.extend(t for t in schema.tables.values() if self.is_vocabulary(t))\n        return tables\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def find_features(self, table: TableInput | None = None) -&gt; Iterable[Feature]:\n        \"\"\"List features in the catalog.\n\n        If a table is specified, returns only features for that table.\n        If no table is specified, returns all features across all tables in the catalog.\n\n        Args:\n            table: Optional table to find features for. If None, returns all features\n                in the catalog.\n\n        Returns:\n            An iterable of Feature instances describing the features.\n        \"\"\"\n\n        def is_feature(a: FindAssociationResult) -&gt; bool:\n            \"\"\"Check if association represents a feature.\n\n            Args:\n                a: Association result to check\n            Returns:\n                bool: True if association represents a feature\n            \"\"\"\n            return {\n                \"Feature_Name\",\n                \"Execution\",\n                a.self_fkey.foreign_key_columns[0].name,\n            }.issubset({c.name for c in a.table.columns})\n\n        def find_table_features(t: Table) -&gt; list[Feature]:\n            \"\"\"Find all features for a single table.\"\"\"\n            return [\n                Feature(a, self) for a in t.find_associations(min_arity=3, max_arity=3, pure=False) if is_feature(a)\n            ]\n\n        if table is not None:\n            # Find features for a specific table\n            return find_table_features(self.name_to_table(table))\n        else:\n            # Find all features across all domain and ML schema tables\n            features: list[Feature] = []\n            for schema_name in [*self.domain_schemas, self.ml_schema]:\n                schema = self.model.schemas.get(schema_name)\n                if schema:\n                    for t in schema.tables.values():\n                        features.extend(find_table_features(t))\n            return features\n\n    def lookup_feature(self, table: TableInput, feature_name: str) -&gt; Feature:\n        \"\"\"Lookup the named feature associated with the provided table.\n\n        Args:\n            table: param feature_name:\n            table: str | Table:\n            feature_name: str:\n\n        Returns:\n            A Feature class that represents the requested feature.\n\n        Raises:\n          DerivaMLException: If the feature cannot be found.\n        \"\"\"\n        table = self.name_to_table(table)\n        try:\n            return [f for f in self.find_features(table) if f.feature_name == feature_name][0]\n        except IndexError:\n            raise DerivaMLException(f\"Feature {table.name}:{feature_name} doesn't exist.\")\n\n    def asset_metadata(self, table: str | Table) -&gt; set[str]:\n        \"\"\"Return the metadata columns for an asset table.\"\"\"\n\n        table = self.name_to_table(table)\n\n        if not self.is_asset(table):\n            raise DerivaMLTableTypeError(\"asset table\", table.name)\n        return {c.name for c in table.columns} - DerivaAssetColumns\n\n    def apply(self) -&gt; None:\n        \"\"\"Call ERMRestModel.apply\"\"\"\n        if self.catalog == \"file-system\":\n            raise DerivaMLException(\"Cannot apply() to non-catalog model.\")\n        else:\n            self.model.apply()\n\n    def is_dataset_rid(self, rid: RID, deleted: bool = False) -&gt; bool:\n        \"\"\"Check if a given RID is a dataset RID.\"\"\"\n        try:\n            rid_info = self.model.catalog.resolve_rid(rid, self.model)\n        except KeyError as _e:\n            raise DerivaMLException(f\"Invalid RID {rid}\")\n        if rid_info.table.name != \"Dataset\":\n            return False\n        elif deleted:\n            # Got a dataset rid. Now check to see if its deleted or not.\n            return True\n        else:\n            return not list(rid_info.datapath.entities().fetch())[0][\"Deleted\"]\n\n    def list_dataset_element_types(self) -&gt; list[Table]:\n        \"\"\"\n        Lists the data types of elements contained within a dataset.\n\n        This method analyzes the dataset and identifies the data types for all\n        elements within it. It is useful for understanding the structure and\n        content of the dataset and allows for better manipulation and usage of its\n        data.\n\n        Returns:\n            list[str]: A list of strings where each string represents a data type\n            of an element found in the dataset.\n\n        \"\"\"\n\n        dataset_table = self.name_to_table(\"Dataset\")\n\n        def is_domain_or_dataset_table(table: Table) -&gt; bool:\n            return self.is_domain_schema(table.schema.name) or table.name == dataset_table.name\n\n        return [t for a in dataset_table.find_associations() if is_domain_or_dataset_table(t := a.other_fkeys.pop().pk_table)]\n\n    def _prepare_wide_table(\n        self, dataset, dataset_rid: RID, include_tables: list[str]\n    ) -&gt; tuple[dict[str, Any], list[tuple]]:\n        \"\"\"\n        Generates details of a wide table from the model\n\n        Args:\n            include_tables (list[str] | None): List of table names to include in the denormalized dataset. If None,\n                all tables from the dataset will be included.\n\n        Returns:\n            str: SQL query string that represents the process of denormalization.\n        \"\"\"\n\n        # Skip over tables that we don't want to include in the denormalized dataset.\n        # Also, strip off the Dataset/Dataset_X part of the path so we don't include dataset columns in the denormalized\n        # table.\n        include_tables = set(include_tables)\n        for t in include_tables:\n            # Check to make sure the table is in the catalog.\n            _ = self.name_to_table(t)\n\n        table_paths = [\n            path\n            for path in self._schema_to_paths()\n            if path[-1].name in include_tables and include_tables.intersection({p.name for p in path})\n        ]\n        paths_by_element = defaultdict(list)\n        for p in table_paths:\n            paths_by_element[p[2].name].append(p)\n\n        skip_columns = {\"RCT\", \"RMT\", \"RCB\", \"RMB\"}\n        element_tables = {}\n        for element_table, paths in paths_by_element.items():\n            graph = {}\n            for path in paths:\n                for left, right in zip(path[0:], path[1:]):\n                    graph.setdefault(left.name, set()).add(right.name)\n\n            # New lets remove any cycles that we may have in the graph.\n            # We will use a topological sort to find the order in which we need to join the tables.\n            # If we find a cycle, we will remove the table from the graph and splice in an additional ON clause.\n            # We will then repeat the process until there are no cycles.\n            graph_has_cycles = True\n            element_join_tables = []\n            element_join_conditions = {}\n            while graph_has_cycles:\n                try:\n                    ts = TopologicalSorter(graph)\n                    element_join_tables = list(reversed(list(ts.static_order())))\n                    graph_has_cycles = False\n                except CycleError as e:\n                    cycle_nodes = e.args[1]\n                    if len(cycle_nodes) &gt; 3:\n                        raise DerivaMLException(f\"Unexpected cycle found when normalizing dataset {cycle_nodes}\")\n                    # Remove cycle from graph and splice in additional ON constraint.\n                    graph[cycle_nodes[1]].remove(cycle_nodes[0])\n\n            # The Dataset_Version table is a special case as it points to dataset and dataset to version.\n            if \"Dataset_Version\" in element_join_tables:\n                element_join_tables.remove(\"Dataset_Version\")\n\n            for path in paths:\n                for left, right in zip(path[0:], path[1:]):\n                    if right.name == \"Dataset_Version\":\n                        # The Dataset_Version table is a special case as it points to dataset and dataset to version.\n                        continue\n                    if element_join_tables.index(right.name) &lt; element_join_tables.index(left.name):\n                        continue\n                    table_relationship = self._table_relationship(left, right)\n                    element_join_conditions.setdefault(right.name, set()).add(\n                        (table_relationship[0], table_relationship[1])\n                    )\n            element_tables[element_table] = (element_join_tables, element_join_conditions)\n        # Get the list of columns that will appear in the final denormalized dataset.\n        denormalized_columns = [\n            (table_name, c.name)\n            for table_name in include_tables\n            if not self.is_association(table_name)  # Don't include association columns in the denormalized view.'\n            for c in self.name_to_table(table_name).columns\n            if (not include_tables or table_name in include_tables) and (c.name not in skip_columns)\n        ]\n        return element_tables, denormalized_columns\n\n    def _table_relationship(\n        self,\n        table1: TableInput,\n        table2: TableInput,\n    ) -&gt; tuple[Column, Column]:\n        \"\"\"Return columns used to relate two tables.\"\"\"\n        table1 = self.name_to_table(table1)\n        table2 = self.name_to_table(table2)\n        relationships = [\n            (fk.foreign_key_columns[0], fk.referenced_columns[0]) for fk in table1.foreign_keys if fk.pk_table == table2\n        ]\n        relationships.extend(\n            [(fk.referenced_columns[0], fk.foreign_key_columns[0]) for fk in table1.referenced_by if fk.table == table2]\n        )\n        if len(relationships) != 1:\n            raise DerivaMLException(\n                f\"Ambiguous linkage between {table1.name} and {table2.name}: {[(r[0].name, r[1].name) for r in relationships]}\"\n            )\n        return relationships[0]\n\n    def _schema_to_paths(\n        self,\n        root: Table | None = None,\n        path: list[Table] | None = None,\n        exclude_tables: set[str] | None = None,\n    ) -&gt; list[list[Table]]:\n        \"\"\"Return a list of paths through the schema graph.\n\n        Args:\n            root: The root table to start from.\n            path: The current path being built.\n            exclude_tables: Optional set of table names to skip during traversal.\n                Tables in this set will not be visited, effectively pruning branches\n                of the FK graph that pass through them.\n\n        Returns:\n            A list of paths through the schema graph.\n        \"\"\"\n        path = path or []\n        exclude_tables = exclude_tables or set()\n\n        root = root or self.model.schemas[self.ml_schema].tables[\"Dataset\"]\n        path = path.copy() if path else []\n        parent = path[-1] if path else None  # Table that we are coming from.\n        path.append(root)\n        paths = [path]\n\n        def find_arcs(table: Table) -&gt; set[Table]:\n            \"\"\"Given a path through the model, return the FKs that link the tables\"\"\"\n            # Valid schemas for traversal: all domain schemas + ML schema\n            valid_schemas = self.domain_schemas | {self.ml_schema}\n            arc_list = [fk.pk_table for fk in table.foreign_keys] + [fk.table for fk in table.referenced_by]\n            arc_list = [t for t in arc_list if t.schema.name in valid_schemas]\n            domain_tables = [t for t in arc_list if self.is_domain_schema(t.schema.name)]\n            if multiple_columns := [c for c, cnt in Counter(domain_tables).items() if cnt &gt; 1]:\n                raise DerivaMLException(f\"Ambiguous relationship in {table.name} {multiple_columns}\")\n            return set(arc_list)\n\n        def is_nested_dataset_loopback(n1: Table, n2: Table) -&gt; bool:\n            \"\"\"Test to see if node is an association table used to link elements to datasets.\"\"\"\n            # If we have node_name &lt;- node_name_dataset-&gt; Dataset then we are looping\n            # back around to a new dataset element\n            dataset_table = self.model.schemas[self.ml_schema].tables[\"Dataset\"]\n            assoc_table = [a for a in dataset_table.find_associations() if a.table == n2]\n            return len(assoc_table) == 1 and n1 != dataset_table\n\n        # Don't follow vocabulary terms back to their use.\n        if self.is_vocabulary(root):\n            return paths\n\n        for child in find_arcs(root):\n            #        if child.name in {\"Dataset_Execution\", \"Dataset_Dataset\", \"Execution\"}:\n            if child.name in {\"Dataset_Dataset\", \"Execution\"}:\n                continue\n            if child.name in exclude_tables:\n                continue\n            if child == parent:\n                # Don't loop back via referred_by\n                continue\n            if is_nested_dataset_loopback(root, child):\n                continue\n            if child in path:\n                raise DerivaMLException(f\"Cycle in schema path: {child.name} path:{[p.name for p in path]}\")\n\n            paths.extend(self._schema_to_paths(child, path, exclude_tables))\n        return paths\n\n    def create_table(self, table_def: TableDefinition, schema: str | None = None) -&gt; Table:\n        \"\"\"Create a new table from TableDefinition.\n\n        Args:\n            table_def: Table definition (dataclass or dict).\n            schema: Schema to create the table in. If None, uses default_schema.\n\n        Returns:\n            The newly created Table.\n\n        Raises:\n            DerivaMLException: If no schema specified and default_schema is not set.\n\n        Note: @validate_call removed because TableDefinition is now a dataclass from\n        deriva.core.typed and Pydantic validation doesn't work well with dataclass fields.\n        \"\"\"\n        schema = schema or self._require_default_schema()\n        # Handle both TableDefinition (dataclass with to_dict) and plain dicts\n        table_dict = table_def.to_dict() if hasattr(table_def, 'to_dict') else table_def\n        return self.model.schemas[schema].create_table(table_dict)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.chaise_config","title":"chaise_config  <code>property</code>","text":"<pre><code>chaise_config: dict[str, Any]\n</code></pre> <p>Return the chaise configuration.</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.__init__","title":"__init__","text":"<pre><code>__init__(\n    model: Model,\n    ml_schema: str = ML_SCHEMA,\n    domain_schemas: str\n    | set[str]\n    | None = None,\n    default_schema: str | None = None,\n)\n</code></pre> <p>Create and initialize a DerivaModel instance.</p> <p>This method will connect to a catalog and initialize schema configuration. This class is intended to be used as a base class on which domain-specific interfaces are built.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>The ERMRest model for the catalog.</p> required <code>ml_schema</code> <code>str</code> <p>The ML schema name.</p> <code>ML_SCHEMA</code> <code>domain_schemas</code> <code>str | set[str] | None</code> <p>Optional explicit set of domain schema names. If None, auto-detects all non-system schemas.</p> <code>None</code> <code>default_schema</code> <code>str | None</code> <p>The default schema for table creation operations. If None and there is exactly one domain schema, that schema is used as default. If there are multiple domain schemas, default_schema must be specified.</p> <code>None</code> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def __init__(\n    self,\n    model: Model,\n    ml_schema: str = ML_SCHEMA,\n    domain_schemas: str | set[str] | None = None,\n    default_schema: str | None = None,\n):\n    \"\"\"Create and initialize a DerivaModel instance.\n\n    This method will connect to a catalog and initialize schema configuration.\n    This class is intended to be used as a base class on which domain-specific interfaces are built.\n\n    Args:\n        model: The ERMRest model for the catalog.\n        ml_schema: The ML schema name.\n        domain_schemas: Optional explicit set of domain schema names. If None,\n            auto-detects all non-system schemas.\n        default_schema: The default schema for table creation operations. If None\n            and there is exactly one domain schema, that schema is used as default.\n            If there are multiple domain schemas, default_schema must be specified.\n    \"\"\"\n    self.model = model\n    self.configuration = None\n    self.catalog: ErmrestCatalog = self.model.catalog\n    self.hostname = self.catalog.deriva_server.server if isinstance(self.catalog, ErmrestCatalog) else \"localhost\"\n\n    self.ml_schema = ml_schema\n    self._system_schemas = frozenset(SYSTEM_SCHEMAS | {ml_schema})\n\n    # Determine domain schemas\n    if domain_schemas is not None:\n        if isinstance(domain_schemas, str):\n            domain_schemas = {domain_schemas}\n        self.domain_schemas = frozenset(domain_schemas)\n    else:\n        # Auto-detect all domain schemas\n        self.domain_schemas = get_domain_schemas(self.model.schemas.keys(), ml_schema)\n\n    # Determine default schema for table creation\n    if default_schema is not None:\n        if default_schema not in self.domain_schemas:\n            raise DerivaMLException(\n                f\"default_schema '{default_schema}' is not in domain_schemas: {self.domain_schemas}\"\n            )\n        self.default_schema = default_schema\n    elif len(self.domain_schemas) == 1:\n        # Single domain schema - use it as default\n        self.default_schema = next(iter(self.domain_schemas))\n    elif len(self.domain_schemas) == 0:\n        # No domain schemas - default_schema will be None\n        self.default_schema = None\n    else:\n        # Multiple domain schemas, no explicit default\n        self.default_schema = None\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.apply","title":"apply","text":"<pre><code>apply() -&gt; None\n</code></pre> <p>Call ERMRestModel.apply</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def apply(self) -&gt; None:\n    \"\"\"Call ERMRestModel.apply\"\"\"\n    if self.catalog == \"file-system\":\n        raise DerivaMLException(\"Cannot apply() to non-catalog model.\")\n    else:\n        self.model.apply()\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.asset_metadata","title":"asset_metadata","text":"<pre><code>asset_metadata(\n    table: str | Table,\n) -&gt; set[str]\n</code></pre> <p>Return the metadata columns for an asset table.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def asset_metadata(self, table: str | Table) -&gt; set[str]:\n    \"\"\"Return the metadata columns for an asset table.\"\"\"\n\n    table = self.name_to_table(table)\n\n    if not self.is_asset(table):\n        raise DerivaMLTableTypeError(\"asset table\", table.name)\n    return {c.name for c in table.columns} - DerivaAssetColumns\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.create_table","title":"create_table","text":"<pre><code>create_table(\n    table_def: TableDefinition,\n    schema: str | None = None,\n) -&gt; Table\n</code></pre> <p>Create a new table from TableDefinition.</p> <p>Parameters:</p> Name Type Description Default <code>table_def</code> <code>TableDefinition</code> <p>Table definition (dataclass or dict).</p> required <code>schema</code> <code>str | None</code> <p>Schema to create the table in. If None, uses default_schema.</p> <code>None</code> <p>Returns:</p> Type Description <code>Table</code> <p>The newly created Table.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If no schema specified and default_schema is not set.</p> <p>Note: @validate_call removed because TableDefinition is now a dataclass from deriva.core.typed and Pydantic validation doesn't work well with dataclass fields.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def create_table(self, table_def: TableDefinition, schema: str | None = None) -&gt; Table:\n    \"\"\"Create a new table from TableDefinition.\n\n    Args:\n        table_def: Table definition (dataclass or dict).\n        schema: Schema to create the table in. If None, uses default_schema.\n\n    Returns:\n        The newly created Table.\n\n    Raises:\n        DerivaMLException: If no schema specified and default_schema is not set.\n\n    Note: @validate_call removed because TableDefinition is now a dataclass from\n    deriva.core.typed and Pydantic validation doesn't work well with dataclass fields.\n    \"\"\"\n    schema = schema or self._require_default_schema()\n    # Handle both TableDefinition (dataclass with to_dict) and plain dicts\n    table_dict = table_def.to_dict() if hasattr(table_def, 'to_dict') else table_def\n    return self.model.schemas[schema].create_table(table_dict)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.find_assets","title":"find_assets","text":"<pre><code>find_assets(\n    with_metadata: bool = False,\n) -&gt; list[Table]\n</code></pre> <p>Return the list of asset tables in the current model</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def find_assets(self, with_metadata: bool = False) -&gt; list[Table]:\n    \"\"\"Return the list of asset tables in the current model\"\"\"\n    return [t for s in self.model.schemas.values() for t in s.tables.values() if self.is_asset(t)]\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.find_association","title":"find_association","text":"<pre><code>find_association(\n    table1: Table | str,\n    table2: Table | str,\n) -&gt; tuple[Table, Column, Column]\n</code></pre> <p>Given two tables, return an association table that connects the two and the two columns used to link them..</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def find_association(self, table1: Table | str, table2: Table | str) -&gt; tuple[Table, Column, Column]:\n    \"\"\"Given two tables, return an association table that connects the two and the two columns used to link them..\n\n    Raises:\n        DerivaML exception if there is either not an association table or more than one association table.\n    \"\"\"\n    table1 = self.name_to_table(table1)\n    table2 = self.name_to_table(table2)\n\n    tables = [\n        (a.table, a.self_fkey.columns[0].name, other_key.columns[0].name)\n        for a in table1.find_associations(pure=False)\n        if len(a.other_fkeys) == 1 and (other_key := a.other_fkeys.pop()).pk_table == table2\n    ]\n\n    if len(tables) == 1:\n        return tables[0]\n    elif len(tables) == 0:\n        raise DerivaMLException(f\"No association tables found between {table1.name} and {table2.name}.\")\n    else:\n        raise DerivaMLException(\n            f\"There are {len(tables)} association tables between {table1.name} and {table2.name}.\"\n        )\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.find_features","title":"find_features","text":"<pre><code>find_features(\n    table: TableInput | None = None,\n) -&gt; Iterable[Feature]\n</code></pre> <p>List features in the catalog.</p> <p>If a table is specified, returns only features for that table. If no table is specified, returns all features across all tables in the catalog.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>TableInput | None</code> <p>Optional table to find features for. If None, returns all features in the catalog.</p> <code>None</code> <p>Returns:</p> Type Description <code>Iterable[Feature]</code> <p>An iterable of Feature instances describing the features.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef find_features(self, table: TableInput | None = None) -&gt; Iterable[Feature]:\n    \"\"\"List features in the catalog.\n\n    If a table is specified, returns only features for that table.\n    If no table is specified, returns all features across all tables in the catalog.\n\n    Args:\n        table: Optional table to find features for. If None, returns all features\n            in the catalog.\n\n    Returns:\n        An iterable of Feature instances describing the features.\n    \"\"\"\n\n    def is_feature(a: FindAssociationResult) -&gt; bool:\n        \"\"\"Check if association represents a feature.\n\n        Args:\n            a: Association result to check\n        Returns:\n            bool: True if association represents a feature\n        \"\"\"\n        return {\n            \"Feature_Name\",\n            \"Execution\",\n            a.self_fkey.foreign_key_columns[0].name,\n        }.issubset({c.name for c in a.table.columns})\n\n    def find_table_features(t: Table) -&gt; list[Feature]:\n        \"\"\"Find all features for a single table.\"\"\"\n        return [\n            Feature(a, self) for a in t.find_associations(min_arity=3, max_arity=3, pure=False) if is_feature(a)\n        ]\n\n    if table is not None:\n        # Find features for a specific table\n        return find_table_features(self.name_to_table(table))\n    else:\n        # Find all features across all domain and ML schema tables\n        features: list[Feature] = []\n        for schema_name in [*self.domain_schemas, self.ml_schema]:\n            schema = self.model.schemas.get(schema_name)\n            if schema:\n                for t in schema.tables.values():\n                    features.extend(find_table_features(t))\n        return features\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.find_vocabularies","title":"find_vocabularies","text":"<pre><code>find_vocabularies() -&gt; list[Table]\n</code></pre> <p>Return a list of all controlled vocabulary tables in domain and ML schemas.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def find_vocabularies(self) -&gt; list[Table]:\n    \"\"\"Return a list of all controlled vocabulary tables in domain and ML schemas.\"\"\"\n    tables = []\n    for schema_name in [*self.domain_schemas, self.ml_schema]:\n        schema = self.model.schemas.get(schema_name)\n        if schema:\n            tables.extend(t for t in schema.tables.values() if self.is_vocabulary(t))\n    return tables\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.get_schema_description","title":"get_schema_description","text":"<pre><code>get_schema_description(\n    include_system_columns: bool = False,\n) -&gt; dict[str, Any]\n</code></pre> <p>Return a JSON description of the catalog schema structure.</p> <p>Provides a structured representation of the domain and ML schemas including tables, columns, foreign keys, and relationships. Useful for understanding the data model structure programmatically.</p> <p>Parameters:</p> Name Type Description Default <code>include_system_columns</code> <code>bool</code> <p>If True, include RID, RCT, RMT, RCB, RMB columns. Default False to reduce output size.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with schema structure:</p> <code>dict[str, Any]</code> <p>{ \"domain_schemas\": [\"schema_name1\", \"schema_name2\"], \"default_schema\": \"schema_name1\", \"ml_schema\": \"deriva-ml\", \"schemas\": {     \"schema_name\": {         \"tables\": {             \"TableName\": {                 \"comment\": \"description\",                 \"is_vocabulary\": bool,                 \"is_asset\": bool,                 \"is_association\": bool,                 \"columns\": [...],                 \"foreign_keys\": [...],                 \"features\": [...]             }         }     } }</p> <code>dict[str, Any]</code> <p>}</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def get_schema_description(self, include_system_columns: bool = False) -&gt; dict[str, Any]:\n    \"\"\"Return a JSON description of the catalog schema structure.\n\n    Provides a structured representation of the domain and ML schemas including\n    tables, columns, foreign keys, and relationships. Useful for understanding\n    the data model structure programmatically.\n\n    Args:\n        include_system_columns: If True, include RID, RCT, RMT, RCB, RMB columns.\n            Default False to reduce output size.\n\n    Returns:\n        Dictionary with schema structure:\n        {\n            \"domain_schemas\": [\"schema_name1\", \"schema_name2\"],\n            \"default_schema\": \"schema_name1\",\n            \"ml_schema\": \"deriva-ml\",\n            \"schemas\": {\n                \"schema_name\": {\n                    \"tables\": {\n                        \"TableName\": {\n                            \"comment\": \"description\",\n                            \"is_vocabulary\": bool,\n                            \"is_asset\": bool,\n                            \"is_association\": bool,\n                            \"columns\": [...],\n                            \"foreign_keys\": [...],\n                            \"features\": [...]\n                        }\n                    }\n                }\n            }\n        }\n    \"\"\"\n    system_columns = {\"RID\", \"RCT\", \"RMT\", \"RCB\", \"RMB\"}\n    result = {\n        \"domain_schemas\": sorted(self.domain_schemas),\n        \"default_schema\": self.default_schema,\n        \"ml_schema\": self.ml_schema,\n        \"schemas\": {},\n    }\n\n    # Include all domain schemas and the ML schema\n    for schema_name in [*self.domain_schemas, self.ml_schema]:\n        schema = self.model.schemas.get(schema_name)\n        if not schema:\n            continue\n\n        schema_info = {\"tables\": {}}\n\n        for table_name, table in schema.tables.items():\n            # Get columns\n            columns = []\n            for col in table.columns:\n                if not include_system_columns and col.name in system_columns:\n                    continue\n                columns.append({\n                    \"name\": col.name,\n                    \"type\": str(col.type.typename),\n                    \"nullok\": col.nullok,\n                    \"comment\": col.comment or \"\",\n                })\n\n            # Get foreign keys\n            foreign_keys = []\n            for fk in table.foreign_keys:\n                fk_cols = [c.name for c in fk.foreign_key_columns]\n                ref_cols = [c.name for c in fk.referenced_columns]\n                foreign_keys.append({\n                    \"columns\": fk_cols,\n                    \"referenced_table\": f\"{fk.pk_table.schema.name}.{fk.pk_table.name}\",\n                    \"referenced_columns\": ref_cols,\n                })\n\n            # Get features if this is a domain table\n            features = []\n            if self.is_domain_schema(schema_name):\n                try:\n                    for f in self.find_features(table):\n                        features.append({\n                            \"name\": f.feature_name,\n                            \"feature_table\": f.feature_table.name,\n                        })\n                except Exception:\n                    pass  # Table may not support features\n\n            table_info = {\n                \"comment\": table.comment or \"\",\n                \"is_vocabulary\": self.is_vocabulary(table),\n                \"is_asset\": self.is_asset(table),\n                \"is_association\": bool(self.is_association(table)),\n                \"columns\": columns,\n                \"foreign_keys\": foreign_keys,\n            }\n            if features:\n                table_info[\"features\"] = features\n\n            schema_info[\"tables\"][table_name] = table_info\n\n        result[\"schemas\"][schema_name] = schema_info\n\n    return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.is_asset","title":"is_asset","text":"<pre><code>is_asset(\n    table_name: TableInput,\n) -&gt; bool\n</code></pre> <p>True if the specified table is an asset table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>TableInput</code> <p>str | Table:</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the specified table is an asset table, False otherwise.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def is_asset(self, table_name: TableInput) -&gt; bool:\n    \"\"\"True if the specified table is an asset table.\n\n    Args:\n        table_name: str | Table:\n\n    Returns:\n        True if the specified table is an asset table, False otherwise.\n\n    \"\"\"\n    asset_columns = {\"Filename\", \"URL\", \"Length\", \"MD5\", \"Description\"}\n    table = self.name_to_table(table_name)\n    return asset_columns.issubset({c.name for c in table.columns})\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.is_association","title":"is_association","text":"<pre><code>is_association(\n    table_name: str | Table,\n    unqualified: bool = True,\n    pure: bool = True,\n    min_arity: int = 2,\n    max_arity: int = 2,\n) -&gt; bool | set[str] | int\n</code></pre> <p>Check the specified table to see if it is an association table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str | Table</code> <p>param unqualified:</p> required <code>pure</code> <code>bool</code> <p>return: (Default value = True)</p> <code>True</code> <code>table_name</code> <code>str | Table</code> <p>str | Table:</p> required <code>unqualified</code> <code>bool</code> <p>(Default value = True)</p> <code>True</code> <p>Returns:</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def is_association(\n    self,\n    table_name: str | Table,\n    unqualified: bool = True,\n    pure: bool = True,\n    min_arity: int = 2,\n    max_arity: int = 2,\n) -&gt; bool | set[str] | int:\n    \"\"\"Check the specified table to see if it is an association table.\n\n    Args:\n        table_name: param unqualified:\n        pure: return: (Default value = True)\n        table_name: str | Table:\n        unqualified:  (Default value = True)\n\n    Returns:\n\n\n    \"\"\"\n    table = self.name_to_table(table_name)\n    return table.is_association(unqualified=unqualified, pure=pure, min_arity=min_arity, max_arity=max_arity)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.is_dataset_rid","title":"is_dataset_rid","text":"<pre><code>is_dataset_rid(\n    rid: RID, deleted: bool = False\n) -&gt; bool\n</code></pre> <p>Check if a given RID is a dataset RID.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def is_dataset_rid(self, rid: RID, deleted: bool = False) -&gt; bool:\n    \"\"\"Check if a given RID is a dataset RID.\"\"\"\n    try:\n        rid_info = self.model.catalog.resolve_rid(rid, self.model)\n    except KeyError as _e:\n        raise DerivaMLException(f\"Invalid RID {rid}\")\n    if rid_info.table.name != \"Dataset\":\n        return False\n    elif deleted:\n        # Got a dataset rid. Now check to see if its deleted or not.\n        return True\n    else:\n        return not list(rid_info.datapath.entities().fetch())[0][\"Deleted\"]\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.is_domain_schema","title":"is_domain_schema","text":"<pre><code>is_domain_schema(\n    schema_name: str,\n) -&gt; bool\n</code></pre> <p>Check if a schema is a domain schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Name of the schema to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the schema is a domain schema.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def is_domain_schema(self, schema_name: str) -&gt; bool:\n    \"\"\"Check if a schema is a domain schema.\n\n    Args:\n        schema_name: Name of the schema to check.\n\n    Returns:\n        True if the schema is a domain schema.\n    \"\"\"\n    return schema_name in self.domain_schemas\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.is_system_schema","title":"is_system_schema","text":"<pre><code>is_system_schema(\n    schema_name: str,\n) -&gt; bool\n</code></pre> <p>Check if a schema is a system or ML schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Name of the schema to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the schema is a system or ML schema.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def is_system_schema(self, schema_name: str) -&gt; bool:\n    \"\"\"Check if a schema is a system or ML schema.\n\n    Args:\n        schema_name: Name of the schema to check.\n\n    Returns:\n        True if the schema is a system or ML schema.\n    \"\"\"\n    return is_system_schema(schema_name, self.ml_schema)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.is_vocabulary","title":"is_vocabulary","text":"<pre><code>is_vocabulary(\n    table_name: TableInput,\n) -&gt; bool\n</code></pre> <p>Check if a given table is a controlled vocabulary table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>TableInput</code> <p>A ERMRest table object or the name of the table.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Table object if the table is a controlled vocabulary, False otherwise.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>if the table doesn't exist.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def is_vocabulary(self, table_name: TableInput) -&gt; bool:\n    \"\"\"Check if a given table is a controlled vocabulary table.\n\n    Args:\n      table_name: A ERMRest table object or the name of the table.\n\n    Returns:\n      Table object if the table is a controlled vocabulary, False otherwise.\n\n    Raises:\n      DerivaMLException: if the table doesn't exist.\n\n    \"\"\"\n    vocab_columns = {\"NAME\", \"URI\", \"SYNONYMS\", \"DESCRIPTION\", \"ID\"}\n    table = self.name_to_table(table_name)\n    return vocab_columns.issubset({c.name.upper() for c in table.columns})\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.list_dataset_element_types","title":"list_dataset_element_types","text":"<pre><code>list_dataset_element_types() -&gt; (\n    list[Table]\n)\n</code></pre> <p>Lists the data types of elements contained within a dataset.</p> <p>This method analyzes the dataset and identifies the data types for all elements within it. It is useful for understanding the structure and content of the dataset and allows for better manipulation and usage of its data.</p> <p>Returns:</p> Type Description <code>list[Table]</code> <p>list[str]: A list of strings where each string represents a data type</p> <code>list[Table]</code> <p>of an element found in the dataset.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def list_dataset_element_types(self) -&gt; list[Table]:\n    \"\"\"\n    Lists the data types of elements contained within a dataset.\n\n    This method analyzes the dataset and identifies the data types for all\n    elements within it. It is useful for understanding the structure and\n    content of the dataset and allows for better manipulation and usage of its\n    data.\n\n    Returns:\n        list[str]: A list of strings where each string represents a data type\n        of an element found in the dataset.\n\n    \"\"\"\n\n    dataset_table = self.name_to_table(\"Dataset\")\n\n    def is_domain_or_dataset_table(table: Table) -&gt; bool:\n        return self.is_domain_schema(table.schema.name) or table.name == dataset_table.name\n\n    return [t for a in dataset_table.find_associations() if is_domain_or_dataset_table(t := a.other_fkeys.pop().pk_table)]\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.lookup_feature","title":"lookup_feature","text":"<pre><code>lookup_feature(\n    table: TableInput, feature_name: str\n) -&gt; Feature\n</code></pre> <p>Lookup the named feature associated with the provided table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>TableInput</code> <p>param feature_name:</p> required <code>table</code> <code>TableInput</code> <p>str | Table:</p> required <code>feature_name</code> <code>str</code> <p>str:</p> required <p>Returns:</p> Type Description <code>Feature</code> <p>A Feature class that represents the requested feature.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the feature cannot be found.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def lookup_feature(self, table: TableInput, feature_name: str) -&gt; Feature:\n    \"\"\"Lookup the named feature associated with the provided table.\n\n    Args:\n        table: param feature_name:\n        table: str | Table:\n        feature_name: str:\n\n    Returns:\n        A Feature class that represents the requested feature.\n\n    Raises:\n      DerivaMLException: If the feature cannot be found.\n    \"\"\"\n    table = self.name_to_table(table)\n    try:\n        return [f for f in self.find_features(table) if f.feature_name == feature_name][0]\n    except IndexError:\n        raise DerivaMLException(f\"Feature {table.name}:{feature_name} doesn't exist.\")\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.name_to_table","title":"name_to_table","text":"<pre><code>name_to_table(\n    table: TableInput,\n) -&gt; Table\n</code></pre> <p>Return the table object corresponding to the given table name.</p> <p>Searches domain schemas first (in sorted order), then ML schema, then WWW. If the table name appears in more than one schema, returns the first match.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>TableInput</code> <p>A ERMRest table object or a string that is the name of the table.</p> required <p>Returns:</p> Type Description <code>Table</code> <p>Table object.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the table doesn't exist in any searchable schema.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def name_to_table(self, table: TableInput) -&gt; Table:\n    \"\"\"Return the table object corresponding to the given table name.\n\n    Searches domain schemas first (in sorted order), then ML schema, then WWW.\n    If the table name appears in more than one schema, returns the first match.\n\n    Args:\n      table: A ERMRest table object or a string that is the name of the table.\n\n    Returns:\n      Table object.\n\n    Raises:\n      DerivaMLException: If the table doesn't exist in any searchable schema.\n    \"\"\"\n    if isinstance(table, Table):\n        return table\n\n    # Search domain schemas (sorted for deterministic order), then ML schema, then WWW\n    search_order = [*sorted(self.domain_schemas), self.ml_schema, \"WWW\"]\n    for sname in search_order:\n        if sname not in self.model.schemas:\n            continue\n        s = self.model.schemas[sname]\n        if table in s.tables:\n            return s.tables[table]\n    raise DerivaMLException(f\"The table {table} doesn't exist.\")\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.DerivaModel.vocab_columns","title":"vocab_columns","text":"<pre><code>vocab_columns(\n    table_name: TableInput,\n) -&gt; dict[str, str]\n</code></pre> <p>Return mapping from canonical vocab column name to actual column name.</p> <p>Canonical names are TitleCase (Name, ID, URI, Description, Synonyms). Actual names reflect the table's schema \u2014 could be lowercase for FaceBase-style catalogs or TitleCase for DerivaML-native tables.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>TableInput</code> <p>A table object or the name of the table.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dict mapping canonical name to actual column name in the table.</p> <code>dict[str, str]</code> <p>E.g. <code>{\"Name\": \"name\", \"ID\": \"id\", ...}</code> for FaceBase tables</p> <code>dict[str, str]</code> <p>or <code>{\"Name\": \"Name\", \"ID\": \"ID\", ...}</code> for DerivaML tables.</p> Source code in <code>src/deriva_ml/model/catalog.py</code> <pre><code>def vocab_columns(self, table_name: TableInput) -&gt; dict[str, str]:\n    \"\"\"Return mapping from canonical vocab column name to actual column name.\n\n    Canonical names are TitleCase (Name, ID, URI, Description, Synonyms).\n    Actual names reflect the table's schema \u2014 could be lowercase for\n    FaceBase-style catalogs or TitleCase for DerivaML-native tables.\n\n    Args:\n        table_name: A table object or the name of the table.\n\n    Returns:\n        Dict mapping canonical name to actual column name in the table.\n        E.g. ``{\"Name\": \"name\", \"ID\": \"id\", ...}`` for FaceBase tables\n        or ``{\"Name\": \"Name\", \"ID\": \"ID\", ...}`` for DerivaML tables.\n    \"\"\"\n    table = self.name_to_table(table_name)\n    col_map = {c.name.upper(): c.name for c in table.columns}\n    return {canon: col_map[canon.upper()] for canon in (\"Name\", \"ID\", \"URI\", \"Description\", \"Synonyms\")}\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.Display","title":"Display  <code>dataclass</code>","text":"<p>               Bases: <code>AnnotationBuilder</code></p> <p>Display annotation for tables and columns.</p> <p>Controls the display name, description/tooltip, and how null values and foreign key links are rendered. Can be applied to both tables and columns.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Display name shown in the UI (mutually exclusive with markdown_name)</p> <code>None</code> <code>markdown_name</code> <code>str | None</code> <p>Markdown-formatted display name (mutually exclusive with name)</p> <code>None</code> <code>name_style</code> <code>NameStyle | None</code> <p>Styling options for automatic name formatting</p> <code>None</code> <code>comment</code> <code>str | None</code> <p>Description text shown as tooltip/help text</p> <code>None</code> <code>show_null</code> <code>dict[str, bool | str] | None</code> <p>How to display null values, per context</p> <code>None</code> <code>show_foreign_key_link</code> <code>dict[str, bool] | None</code> <p>Whether to show FK values as links, per context</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both name and markdown_name are provided</p> Example <p>Basic display name::</p> <pre><code>&gt;&gt;&gt; display = Display(name=\"Research Subjects\")\n&gt;&gt;&gt; handle.set_annotation(display)\n</code></pre> <p>With description/tooltip::</p> <pre><code>&gt;&gt;&gt; display = Display(\n...     name=\"Subjects\",\n...     comment=\"Individuals enrolled in research studies\"\n... )\n</code></pre> <p>Markdown-formatted name::</p> <pre><code>&gt;&gt;&gt; display = Display(markdown_name=\"**Bold** _Italic_ Name\")\n</code></pre> <p>Context-specific null display::</p> <pre><code>&gt;&gt;&gt; from deriva_ml.model import CONTEXT_COMPACT, CONTEXT_DETAILED\n&gt;&gt;&gt; display = Display(\n...     name=\"Value\",\n...     show_null={\n...         CONTEXT_COMPACT: False,      # Hide nulls in lists\n...         CONTEXT_DETAILED: '\"N/A\"'    # Show \"N/A\" string\n...     }\n... )\n</code></pre> <p>Control foreign key link display::</p> <pre><code>&gt;&gt;&gt; display = Display(\n...     name=\"Subject\",\n...     show_foreign_key_link={CONTEXT_COMPACT: False}\n... )\n</code></pre> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass Display(AnnotationBuilder):\n    \"\"\"Display annotation for tables and columns.\n\n    Controls the display name, description/tooltip, and how null values\n    and foreign key links are rendered. Can be applied to both tables\n    and columns.\n\n    Args:\n        name: Display name shown in the UI (mutually exclusive with markdown_name)\n        markdown_name: Markdown-formatted display name (mutually exclusive with name)\n        name_style: Styling options for automatic name formatting\n        comment: Description text shown as tooltip/help text\n        show_null: How to display null values, per context\n        show_foreign_key_link: Whether to show FK values as links, per context\n\n    Raises:\n        ValueError: If both name and markdown_name are provided\n\n    Example:\n        Basic display name::\n\n            &gt;&gt;&gt; display = Display(name=\"Research Subjects\")\n            &gt;&gt;&gt; handle.set_annotation(display)\n\n        With description/tooltip::\n\n            &gt;&gt;&gt; display = Display(\n            ...     name=\"Subjects\",\n            ...     comment=\"Individuals enrolled in research studies\"\n            ... )\n\n        Markdown-formatted name::\n\n            &gt;&gt;&gt; display = Display(markdown_name=\"**Bold** _Italic_ Name\")\n\n        Context-specific null display::\n\n            &gt;&gt;&gt; from deriva_ml.model import CONTEXT_COMPACT, CONTEXT_DETAILED\n            &gt;&gt;&gt; display = Display(\n            ...     name=\"Value\",\n            ...     show_null={\n            ...         CONTEXT_COMPACT: False,      # Hide nulls in lists\n            ...         CONTEXT_DETAILED: '\"N/A\"'    # Show \"N/A\" string\n            ...     }\n            ... )\n\n        Control foreign key link display::\n\n            &gt;&gt;&gt; display = Display(\n            ...     name=\"Subject\",\n            ...     show_foreign_key_link={CONTEXT_COMPACT: False}\n            ... )\n    \"\"\"\n    tag = TAG_DISPLAY\n\n    name: str | None = None\n    markdown_name: str | None = None\n    name_style: NameStyle | None = None\n    comment: str | None = None\n    show_null: dict[str, bool | str] | None = None\n    show_foreign_key_link: dict[str, bool] | None = None\n\n    def __post_init__(self):\n        if self.name and self.markdown_name:\n            raise ValueError(\"name and markdown_name are mutually exclusive\")\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        if self.name is not None:\n            result[\"name\"] = self.name\n        if self.markdown_name is not None:\n            result[\"markdown_name\"] = self.markdown_name\n        if self.name_style is not None:\n            style_dict = self.name_style.to_dict()\n            if style_dict:\n                result[\"name_style\"] = style_dict\n        if self.comment is not None:\n            result[\"comment\"] = self.comment\n        if self.show_null is not None:\n            result[\"show_null\"] = self.show_null\n        if self.show_foreign_key_link is not None:\n            result[\"show_foreign_key_link\"] = self.show_foreign_key_link\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.Facet","title":"Facet  <code>dataclass</code>","text":"<p>A facet definition for filtering.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | list[str | InboundFK | OutboundFK] | None</code> <p>Path to source data</p> <code>None</code> <code>sourcekey</code> <code>str | None</code> <p>Reference to named source</p> <code>None</code> <code>markdown_name</code> <code>str | None</code> <p>Display name</p> <code>None</code> <code>comment</code> <code>str | None</code> <p>Description</p> <code>None</code> <code>entity</code> <code>bool | None</code> <p>Whether this is an entity facet</p> <code>None</code> <code>open</code> <code>bool | None</code> <p>Start expanded</p> <code>None</code> <code>ux_mode</code> <code>FacetUxMode | None</code> <p>UI mode (choices, ranges, check_presence)</p> <code>None</code> <code>bar_plot</code> <code>bool | None</code> <p>Show bar plot</p> <code>None</code> <code>choices</code> <code>list[Any] | None</code> <p>Preset choice values</p> <code>None</code> <code>ranges</code> <code>list[FacetRange] | None</code> <p>Preset range values</p> <code>None</code> <code>not_null</code> <code>bool | None</code> <p>Filter to non-null values</p> <code>None</code> <code>hide_null_choice</code> <code>bool | None</code> <p>Hide \"null\" option</p> <code>None</code> <code>hide_not_null_choice</code> <code>bool | None</code> <p>Hide \"not null\" option</p> <code>None</code> <code>n_bins</code> <code>int | None</code> <p>Number of bins for histogram</p> <code>None</code> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass Facet:\n    \"\"\"A facet definition for filtering.\n\n    Args:\n        source: Path to source data\n        sourcekey: Reference to named source\n        markdown_name: Display name\n        comment: Description\n        entity: Whether this is an entity facet\n        open: Start expanded\n        ux_mode: UI mode (choices, ranges, check_presence)\n        bar_plot: Show bar plot\n        choices: Preset choice values\n        ranges: Preset range values\n        not_null: Filter to non-null values\n        hide_null_choice: Hide \"null\" option\n        hide_not_null_choice: Hide \"not null\" option\n        n_bins: Number of bins for histogram\n    \"\"\"\n    source: str | list[str | InboundFK | OutboundFK] | None = None\n    sourcekey: str | None = None\n    markdown_name: str | None = None\n    comment: str | None = None\n    entity: bool | None = None\n    open: bool | None = None\n    ux_mode: FacetUxMode | None = None\n    bar_plot: bool | None = None\n    choices: list[Any] | None = None\n    ranges: list[FacetRange] | None = None\n    not_null: bool | None = None\n    hide_null_choice: bool | None = None\n    hide_not_null_choice: bool | None = None\n    n_bins: int | None = None\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n\n        if self.source is not None:\n            if isinstance(self.source, str):\n                result[\"source\"] = self.source\n            else:\n                result[\"source\"] = [\n                    item.to_dict() if hasattr(item, \"to_dict\") else item\n                    for item in self.source\n                ]\n\n        if self.sourcekey is not None:\n            result[\"sourcekey\"] = self.sourcekey\n        if self.markdown_name is not None:\n            result[\"markdown_name\"] = self.markdown_name\n        if self.comment is not None:\n            result[\"comment\"] = self.comment\n        if self.entity is not None:\n            result[\"entity\"] = self.entity\n        if self.open is not None:\n            result[\"open\"] = self.open\n        if self.ux_mode is not None:\n            result[\"ux_mode\"] = self.ux_mode.value\n        if self.bar_plot is not None:\n            result[\"bar_plot\"] = self.bar_plot\n        if self.choices is not None:\n            result[\"choices\"] = self.choices\n        if self.ranges is not None:\n            result[\"ranges\"] = [r.to_dict() for r in self.ranges]\n        if self.not_null is not None:\n            result[\"not_null\"] = self.not_null\n        if self.hide_null_choice is not None:\n            result[\"hide_null_choice\"] = self.hide_null_choice\n        if self.hide_not_null_choice is not None:\n            result[\"hide_not_null_choice\"] = self.hide_not_null_choice\n        if self.n_bins is not None:\n            result[\"n_bins\"] = self.n_bins\n\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.FacetList","title":"FacetList  <code>dataclass</code>","text":"<p>A list of facets for filtering (visible_columns.filter).</p> Example <p>facets = FacetList([ ...     Facet(source=\"Species\", open=True), ...     Facet(source=\"Age\", ux_mode=FacetUxMode.RANGES) ... ])</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass FacetList:\n    \"\"\"A list of facets for filtering (visible_columns.filter).\n\n    Example:\n        &gt;&gt;&gt; facets = FacetList([\n        ...     Facet(source=\"Species\", open=True),\n        ...     Facet(source=\"Age\", ux_mode=FacetUxMode.RANGES)\n        ... ])\n    \"\"\"\n    facets: list[Facet] = field(default_factory=list)\n\n    def add(self, facet: Facet) -&gt; \"FacetList\":\n        \"\"\"Add a facet to the list.\"\"\"\n        self.facets.append(facet)\n        return self\n\n    def to_dict(self) -&gt; dict[str, list[dict]]:\n        return {\"and\": [f.to_dict() for f in self.facets]}\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.FacetList.add","title":"add","text":"<pre><code>add(facet: Facet) -&gt; 'FacetList'\n</code></pre> <p>Add a facet to the list.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def add(self, facet: Facet) -&gt; \"FacetList\":\n    \"\"\"Add a facet to the list.\"\"\"\n    self.facets.append(facet)\n    return self\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.FacetRange","title":"FacetRange  <code>dataclass</code>","text":"<p>A range for facet filtering.</p> <p>Parameters:</p> Name Type Description Default <code>min</code> <code>float | None</code> <p>Minimum value</p> <code>None</code> <code>max</code> <code>float | None</code> <p>Maximum value</p> <code>None</code> <code>min_exclusive</code> <code>bool | None</code> <p>Exclude min value</p> <code>None</code> <code>max_exclusive</code> <code>bool | None</code> <p>Exclude max value</p> <code>None</code> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass FacetRange:\n    \"\"\"A range for facet filtering.\n\n    Args:\n        min: Minimum value\n        max: Maximum value\n        min_exclusive: Exclude min value\n        max_exclusive: Exclude max value\n    \"\"\"\n    min: float | None = None\n    max: float | None = None\n    min_exclusive: bool | None = None\n    max_exclusive: bool | None = None\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        if self.min is not None:\n            result[\"min\"] = self.min\n        if self.max is not None:\n            result[\"max\"] = self.max\n        if self.min_exclusive is not None:\n            result[\"min_exclusive\"] = self.min_exclusive\n        if self.max_exclusive is not None:\n            result[\"max_exclusive\"] = self.max_exclusive\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.FacetUxMode","title":"FacetUxMode","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>UX modes for facet filters in the search panel.</p> <p>Controls how users interact with a facet filter.</p> <p>Attributes:</p> Name Type Description <code>CHOICES</code> <p>Checkbox list for selecting values</p> <code>RANGES</code> <p>Range slider/inputs for numeric or date ranges</p> <code>CHECK_PRESENCE</code> <p>Check if value exists or is null</p> Example Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>class FacetUxMode(str, Enum):\n    \"\"\"UX modes for facet filters in the search panel.\n\n    Controls how users interact with a facet filter.\n\n    Attributes:\n        CHOICES: Checkbox list for selecting values\n        RANGES: Range slider/inputs for numeric or date ranges\n        CHECK_PRESENCE: Check if value exists or is null\n\n    Example:\n        &gt;&gt;&gt; # Choice-based facet\n        &gt;&gt;&gt; Facet(source=\"Status\", ux_mode=FacetUxMode.CHOICES)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Range-based facet for numeric values\n        &gt;&gt;&gt; Facet(source=\"Age\", ux_mode=FacetUxMode.RANGES)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Check presence (has value / no value)\n        &gt;&gt;&gt; Facet(source=\"Notes\", ux_mode=FacetUxMode.CHECK_PRESENCE)\n    \"\"\"\n    CHOICES = \"choices\"\n    RANGES = \"ranges\"\n    CHECK_PRESENCE = \"check_presence\"\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.FacetUxMode--choice-based-facet","title":"Choice-based facet","text":"<p>Facet(source=\"Status\", ux_mode=FacetUxMode.CHOICES)</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.FacetUxMode--range-based-facet-for-numeric-values","title":"Range-based facet for numeric values","text":"<p>Facet(source=\"Age\", ux_mode=FacetUxMode.RANGES)</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.FacetUxMode--check-presence-has-value-no-value","title":"Check presence (has value / no value)","text":"<p>Facet(source=\"Notes\", ux_mode=FacetUxMode.CHECK_PRESENCE)</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer","title":"ForeignKeyOrderer","text":"<p>Computes insertion order for tables based on FK dependencies.</p> <p>Uses topological sort to ensure referenced tables are populated before tables that reference them. Handles cycles by either raising an error or breaking them.</p> Example <p>orderer = ForeignKeyOrderer(model, schemas=['domain', 'deriva-ml'])</p> Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>class ForeignKeyOrderer:\n    \"\"\"Computes insertion order for tables based on FK dependencies.\n\n    Uses topological sort to ensure referenced tables are populated\n    before tables that reference them. Handles cycles by either\n    raising an error or breaking them.\n\n    Example:\n        orderer = ForeignKeyOrderer(model, schemas=['domain', 'deriva-ml'])\n\n        # Get insertion order\n        tables_to_fill = ['Image', 'Subject', 'Diagnosis']\n        ordered = orderer.get_insertion_order(tables_to_fill)\n        # Returns: ['Subject', 'Image', 'Diagnosis']\n\n        # Get all tables in safe order\n        all_ordered = orderer.get_insertion_order()\n\n        # Get FK dependencies for a table\n        deps = orderer.get_dependencies('Image')\n        # Returns: {'Subject', 'Dataset', ...}\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Model,\n        schemas: list[str],\n    ):\n        \"\"\"Initialize the orderer.\n\n        Args:\n            model: ERMrest Model object.\n            schemas: Schemas to consider for FK relationships.\n        \"\"\"\n        self.model = model\n        self.schemas = set(schemas)\n        self._table_cache: dict[str, DerivaTable] = {}\n        self._build_table_cache()\n\n    def _build_table_cache(self) -&gt; None:\n        \"\"\"Build cache mapping table names to Table objects.\"\"\"\n        for schema_name in self.schemas:\n            if schema_name not in self.model.schemas:\n                continue\n            schema = self.model.schemas[schema_name]\n            for table_name, table in schema.tables.items():\n                # Store both qualified and unqualified names\n                self._table_cache[f\"{schema_name}.{table_name}\"] = table\n                # Only store unqualified if not already present (avoids conflicts)\n                if table_name not in self._table_cache:\n                    self._table_cache[table_name] = table\n\n    def _to_table(self, t: str | DerivaTable) -&gt; DerivaTable:\n        \"\"\"Convert table name to Table object.\n\n        Args:\n            t: Table name or Table object.\n\n        Returns:\n            DerivaTable object.\n\n        Raises:\n            ValueError: If table not found.\n        \"\"\"\n        if isinstance(t, DerivaTable):\n            return t\n\n        if t in self._table_cache:\n            return self._table_cache[t]\n\n        raise ValueError(f\"Table {t} not found in schemas {self.schemas}\")\n\n    def _table_key(self, t: DerivaTable) -&gt; str:\n        \"\"\"Get unique key for a table.\"\"\"\n        return f\"{t.schema.name}.{t.name}\"\n\n    def get_dependencies(self, table: str | DerivaTable) -&gt; set[DerivaTable]:\n        \"\"\"Get tables that this table depends on (FK targets).\n\n        Args:\n            table: Table name or object.\n\n        Returns:\n            Set of tables that must be populated before this table.\n        \"\"\"\n        t = self._to_table(table)\n        dependencies = set()\n\n        for fk in t.foreign_keys:\n            pk_table = fk.pk_table\n            # Only include dependencies within our schemas\n            if pk_table.schema.name in self.schemas:\n                # Don't include self-references as dependencies\n                if self._table_key(pk_table) != self._table_key(t):\n                    dependencies.add(pk_table)\n\n        return dependencies\n\n    def get_dependents(self, table: str | DerivaTable) -&gt; set[DerivaTable]:\n        \"\"\"Get tables that depend on this table (FK sources).\n\n        Args:\n            table: Table name or object.\n\n        Returns:\n            Set of tables that reference this table.\n        \"\"\"\n        t = self._to_table(table)\n        dependents = set()\n\n        for schema_name in self.schemas:\n            if schema_name not in self.model.schemas:\n                continue\n\n            for other_table in self.model.schemas[schema_name].tables.values():\n                if self._table_key(other_table) == self._table_key(t):\n                    continue\n\n                for fk in other_table.foreign_keys:\n                    if self._table_key(fk.pk_table) == self._table_key(t):\n                        dependents.add(other_table)\n                        break\n\n        return dependents\n\n    def _build_dependency_graph(\n        self,\n        tables: list[str | DerivaTable] | None = None,\n    ) -&gt; dict[str, set[str]]:\n        \"\"\"Build FK dependency graph.\n\n        Args:\n            tables: Tables to include. If None, includes all tables.\n\n        Returns:\n            Dict mapping table key -&gt; set of table keys it depends on.\n        \"\"\"\n        if tables is None:\n            # Include all tables in schemas\n            table_objs = []\n            for schema_name in self.schemas:\n                if schema_name in self.model.schemas:\n                    table_objs.extend(self.model.schemas[schema_name].tables.values())\n        else:\n            table_objs = [self._to_table(t) for t in tables]\n\n        table_keys = {self._table_key(t) for t in table_objs}\n        graph: dict[str, set[str]] = {}\n\n        for t in table_objs:\n            key = self._table_key(t)\n            deps = set()\n\n            for fk in t.foreign_keys:\n                pk_key = self._table_key(fk.pk_table)\n                # Only include deps within our table set\n                if pk_key in table_keys and pk_key != key:\n                    deps.add(pk_key)\n\n            graph[key] = deps\n\n        return graph\n\n    def get_insertion_order(\n        self,\n        tables: list[str | DerivaTable] | None = None,\n        handle_cycles: bool = True,\n    ) -&gt; list[DerivaTable]:\n        \"\"\"Compute FK-safe insertion order for the given tables.\n\n        Returns tables ordered so that all FK dependencies are satisfied\n        when inserting in order.\n\n        Args:\n            tables: Tables to order. If None, orders all tables in schemas.\n            handle_cycles: If True, break cycles by removing edges.\n                If False, raise CycleError on cycles.\n\n        Returns:\n            Ordered list of Table objects (insert from first to last).\n\n        Raises:\n            CycleError: If handle_cycles=False and cycles exist.\n        \"\"\"\n        graph = self._build_dependency_graph(tables)\n\n        try:\n            ts = TopologicalSorter(graph)\n            ordered_keys = list(ts.static_order())\n        except CycleError as e:\n            if handle_cycles:\n                ordered_keys = self._break_cycles_and_sort(graph, e)\n            else:\n                raise\n\n        # Convert keys back to Table objects\n        return [self._table_cache[key] for key in ordered_keys]\n\n    def get_deletion_order(\n        self,\n        tables: list[str | DerivaTable] | None = None,\n        handle_cycles: bool = True,\n    ) -&gt; list[DerivaTable]:\n        \"\"\"Compute FK-safe deletion order for the given tables.\n\n        Returns tables in reverse dependency order - tables that are\n        referenced should be deleted last.\n\n        Args:\n            tables: Tables to order. If None, orders all tables in schemas.\n            handle_cycles: If True, break cycles. If False, raise on cycles.\n\n        Returns:\n            Ordered list of Table objects (delete from first to last).\n        \"\"\"\n        insertion_order = self.get_insertion_order(tables, handle_cycles)\n        return list(reversed(insertion_order))\n\n    def _break_cycles_and_sort(\n        self,\n        graph: dict[str, set[str]],\n        error: CycleError,\n        _depth: int = 0,\n    ) -&gt; list[str]:\n        \"\"\"Handle cycles by breaking them and re-sorting.\n\n        Uses a simple strategy of removing edges from cycle members\n        until no cycles remain.\n\n        Args:\n            graph: Dependency graph.\n            error: CycleError with cycle info.\n\n        Returns:\n            Ordered list of table keys.\n        \"\"\"\n        max_depth = len(graph)  # Can't have more cycles than edges\n        if _depth &gt; max_depth:\n            logger.error(\"Too many cycles to break, returning arbitrary order\")\n            return list(graph.keys())\n\n        # Get cycle from error message.\n        # CycleError.args[1] is like ['A', 'B', 'C', 'A'] where first == last.\n        cycle = list(error.args[1]) if len(error.args) &gt; 1 else []\n\n        if cycle:\n            logger.warning(f\"Breaking cycle in FK dependencies: {' -&gt; '.join(cycle)}\")\n\n            # Remove one edge from the cycle to break it.\n            # cycle[-1] == cycle[0], so the unique nodes are cycle[:-1].\n            # Each consecutive pair cycle[i] -&gt; cycle[i+1] corresponds to\n            # graph[cycle[i+1]] containing cycle[i] (i.e., cycle[i+1] depends on cycle[i]).\n            # Remove the last real edge: cycle[-2] from graph[cycle[-1]].\n            edge_removed = False\n            if len(cycle) &gt;= 3:\n                dep_node = cycle[-2]  # the dependency\n                node = cycle[-1]      # the node that depends on dep_node\n                if node in graph and dep_node in graph[node]:\n                    graph[node].remove(dep_node)\n                    logger.debug(f\"Removed dependency {node} -&gt; {dep_node}\")\n                    edge_removed = True\n\n            if not edge_removed:\n                # Try removing any edge in the cycle\n                for i in range(len(cycle) - 1):\n                    dep_node, node = cycle[i], cycle[i + 1]\n                    if node in graph and dep_node in graph[node]:\n                        graph[node].remove(dep_node)\n                        logger.debug(f\"Removed dependency {node} -&gt; {dep_node}\")\n                        edge_removed = True\n                        break\n\n        # Try again\n        try:\n            ts = TopologicalSorter(graph)\n            return list(ts.static_order())\n        except CycleError as e:\n            # Recursively break more cycles\n            return self._break_cycles_and_sort(graph, e, _depth + 1)\n\n    def validate_insertion_order(\n        self,\n        tables: list[str | DerivaTable],\n    ) -&gt; list[tuple[str, str, str]]:\n        \"\"\"Validate that a list of tables can be inserted in order.\n\n        Checks each table to ensure all its FK dependencies are\n        satisfied by tables earlier in the list.\n\n        Args:\n            tables: Ordered list of tables to validate.\n\n        Returns:\n            List of (table, missing_dependency, fk_name) tuples for\n            any unsatisfied dependencies. Empty list if valid.\n        \"\"\"\n        table_objs = [self._to_table(t) for t in tables]\n        seen_keys = set()\n        violations = []\n\n        for t in table_objs:\n            key = self._table_key(t)\n\n            for fk in t.foreign_keys:\n                pk_key = self._table_key(fk.pk_table)\n                # Skip self-references and tables not in our set\n                if pk_key == key:\n                    continue\n                if pk_key not in {self._table_key(x) for x in table_objs}:\n                    continue\n\n                if pk_key not in seen_keys:\n                    violations.append((key, pk_key, fk.name[1]))\n\n            seen_keys.add(key)\n\n        return violations\n\n    def get_all_tables(self) -&gt; list[DerivaTable]:\n        \"\"\"Get all tables in configured schemas.\n\n        Returns:\n            List of all Table objects.\n        \"\"\"\n        tables = []\n        for schema_name in self.schemas:\n            if schema_name in self.model.schemas:\n                tables.extend(self.model.schemas[schema_name].tables.values())\n        return tables\n\n    def find_cycles(self) -&gt; list[list[str]]:\n        \"\"\"Find all FK dependency cycles in the schema.\n\n        Returns:\n            List of cycles, each cycle is a list of table keys.\n        \"\"\"\n        graph = self._build_dependency_graph()\n        cycles = []\n\n        # Use DFS to find cycles\n        visited = set()\n        rec_stack = set()\n        path = []\n\n        def dfs(node: str) -&gt; bool:\n            visited.add(node)\n            rec_stack.add(node)\n            path.append(node)\n\n            for neighbor in graph.get(node, set()):\n                if neighbor not in visited:\n                    if dfs(neighbor):\n                        return True\n                elif neighbor in rec_stack:\n                    # Found cycle\n                    idx = path.index(neighbor)\n                    cycle = path[idx:] + [neighbor]\n                    cycles.append(cycle)\n\n            path.pop()\n            rec_stack.remove(node)\n            return False\n\n        for node in graph:\n            if node not in visited:\n                dfs(node)\n\n        return cycles\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer--get-insertion-order","title":"Get insertion order","text":"<p>tables_to_fill = ['Image', 'Subject', 'Diagnosis'] ordered = orderer.get_insertion_order(tables_to_fill)</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer--returns-subject-image-diagnosis","title":"Returns: ['Subject', 'Image', 'Diagnosis']","text":""},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer--get-all-tables-in-safe-order","title":"Get all tables in safe order","text":"<p>all_ordered = orderer.get_insertion_order()</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer--get-fk-dependencies-for-a-table","title":"Get FK dependencies for a table","text":"<p>deps = orderer.get_dependencies('Image')</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer--returns-subject-dataset","title":"Returns: {'Subject', 'Dataset', ...}","text":""},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer.__init__","title":"__init__","text":"<pre><code>__init__(\n    model: Model, schemas: list[str]\n)\n</code></pre> <p>Initialize the orderer.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>ERMrest Model object.</p> required <code>schemas</code> <code>list[str]</code> <p>Schemas to consider for FK relationships.</p> required Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>def __init__(\n    self,\n    model: Model,\n    schemas: list[str],\n):\n    \"\"\"Initialize the orderer.\n\n    Args:\n        model: ERMrest Model object.\n        schemas: Schemas to consider for FK relationships.\n    \"\"\"\n    self.model = model\n    self.schemas = set(schemas)\n    self._table_cache: dict[str, DerivaTable] = {}\n    self._build_table_cache()\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer.find_cycles","title":"find_cycles","text":"<pre><code>find_cycles() -&gt; list[list[str]]\n</code></pre> <p>Find all FK dependency cycles in the schema.</p> <p>Returns:</p> Type Description <code>list[list[str]]</code> <p>List of cycles, each cycle is a list of table keys.</p> Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>def find_cycles(self) -&gt; list[list[str]]:\n    \"\"\"Find all FK dependency cycles in the schema.\n\n    Returns:\n        List of cycles, each cycle is a list of table keys.\n    \"\"\"\n    graph = self._build_dependency_graph()\n    cycles = []\n\n    # Use DFS to find cycles\n    visited = set()\n    rec_stack = set()\n    path = []\n\n    def dfs(node: str) -&gt; bool:\n        visited.add(node)\n        rec_stack.add(node)\n        path.append(node)\n\n        for neighbor in graph.get(node, set()):\n            if neighbor not in visited:\n                if dfs(neighbor):\n                    return True\n            elif neighbor in rec_stack:\n                # Found cycle\n                idx = path.index(neighbor)\n                cycle = path[idx:] + [neighbor]\n                cycles.append(cycle)\n\n        path.pop()\n        rec_stack.remove(node)\n        return False\n\n    for node in graph:\n        if node not in visited:\n            dfs(node)\n\n    return cycles\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer.get_all_tables","title":"get_all_tables","text":"<pre><code>get_all_tables() -&gt; list[DerivaTable]\n</code></pre> <p>Get all tables in configured schemas.</p> <p>Returns:</p> Type Description <code>list[Table]</code> <p>List of all Table objects.</p> Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>def get_all_tables(self) -&gt; list[DerivaTable]:\n    \"\"\"Get all tables in configured schemas.\n\n    Returns:\n        List of all Table objects.\n    \"\"\"\n    tables = []\n    for schema_name in self.schemas:\n        if schema_name in self.model.schemas:\n            tables.extend(self.model.schemas[schema_name].tables.values())\n    return tables\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer.get_deletion_order","title":"get_deletion_order","text":"<pre><code>get_deletion_order(\n    tables: list[str | Table]\n    | None = None,\n    handle_cycles: bool = True,\n) -&gt; list[DerivaTable]\n</code></pre> <p>Compute FK-safe deletion order for the given tables.</p> <p>Returns tables in reverse dependency order - tables that are referenced should be deleted last.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list[str | Table] | None</code> <p>Tables to order. If None, orders all tables in schemas.</p> <code>None</code> <code>handle_cycles</code> <code>bool</code> <p>If True, break cycles. If False, raise on cycles.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[Table]</code> <p>Ordered list of Table objects (delete from first to last).</p> Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>def get_deletion_order(\n    self,\n    tables: list[str | DerivaTable] | None = None,\n    handle_cycles: bool = True,\n) -&gt; list[DerivaTable]:\n    \"\"\"Compute FK-safe deletion order for the given tables.\n\n    Returns tables in reverse dependency order - tables that are\n    referenced should be deleted last.\n\n    Args:\n        tables: Tables to order. If None, orders all tables in schemas.\n        handle_cycles: If True, break cycles. If False, raise on cycles.\n\n    Returns:\n        Ordered list of Table objects (delete from first to last).\n    \"\"\"\n    insertion_order = self.get_insertion_order(tables, handle_cycles)\n    return list(reversed(insertion_order))\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer.get_dependencies","title":"get_dependencies","text":"<pre><code>get_dependencies(\n    table: str | Table,\n) -&gt; set[DerivaTable]\n</code></pre> <p>Get tables that this table depends on (FK targets).</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or object.</p> required <p>Returns:</p> Type Description <code>set[Table]</code> <p>Set of tables that must be populated before this table.</p> Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>def get_dependencies(self, table: str | DerivaTable) -&gt; set[DerivaTable]:\n    \"\"\"Get tables that this table depends on (FK targets).\n\n    Args:\n        table: Table name or object.\n\n    Returns:\n        Set of tables that must be populated before this table.\n    \"\"\"\n    t = self._to_table(table)\n    dependencies = set()\n\n    for fk in t.foreign_keys:\n        pk_table = fk.pk_table\n        # Only include dependencies within our schemas\n        if pk_table.schema.name in self.schemas:\n            # Don't include self-references as dependencies\n            if self._table_key(pk_table) != self._table_key(t):\n                dependencies.add(pk_table)\n\n    return dependencies\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer.get_dependents","title":"get_dependents","text":"<pre><code>get_dependents(\n    table: str | Table,\n) -&gt; set[DerivaTable]\n</code></pre> <p>Get tables that depend on this table (FK sources).</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | Table</code> <p>Table name or object.</p> required <p>Returns:</p> Type Description <code>set[Table]</code> <p>Set of tables that reference this table.</p> Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>def get_dependents(self, table: str | DerivaTable) -&gt; set[DerivaTable]:\n    \"\"\"Get tables that depend on this table (FK sources).\n\n    Args:\n        table: Table name or object.\n\n    Returns:\n        Set of tables that reference this table.\n    \"\"\"\n    t = self._to_table(table)\n    dependents = set()\n\n    for schema_name in self.schemas:\n        if schema_name not in self.model.schemas:\n            continue\n\n        for other_table in self.model.schemas[schema_name].tables.values():\n            if self._table_key(other_table) == self._table_key(t):\n                continue\n\n            for fk in other_table.foreign_keys:\n                if self._table_key(fk.pk_table) == self._table_key(t):\n                    dependents.add(other_table)\n                    break\n\n    return dependents\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer.get_insertion_order","title":"get_insertion_order","text":"<pre><code>get_insertion_order(\n    tables: list[str | Table]\n    | None = None,\n    handle_cycles: bool = True,\n) -&gt; list[DerivaTable]\n</code></pre> <p>Compute FK-safe insertion order for the given tables.</p> <p>Returns tables ordered so that all FK dependencies are satisfied when inserting in order.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list[str | Table] | None</code> <p>Tables to order. If None, orders all tables in schemas.</p> <code>None</code> <code>handle_cycles</code> <code>bool</code> <p>If True, break cycles by removing edges. If False, raise CycleError on cycles.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[Table]</code> <p>Ordered list of Table objects (insert from first to last).</p> <p>Raises:</p> Type Description <code>CycleError</code> <p>If handle_cycles=False and cycles exist.</p> Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>def get_insertion_order(\n    self,\n    tables: list[str | DerivaTable] | None = None,\n    handle_cycles: bool = True,\n) -&gt; list[DerivaTable]:\n    \"\"\"Compute FK-safe insertion order for the given tables.\n\n    Returns tables ordered so that all FK dependencies are satisfied\n    when inserting in order.\n\n    Args:\n        tables: Tables to order. If None, orders all tables in schemas.\n        handle_cycles: If True, break cycles by removing edges.\n            If False, raise CycleError on cycles.\n\n    Returns:\n        Ordered list of Table objects (insert from first to last).\n\n    Raises:\n        CycleError: If handle_cycles=False and cycles exist.\n    \"\"\"\n    graph = self._build_dependency_graph(tables)\n\n    try:\n        ts = TopologicalSorter(graph)\n        ordered_keys = list(ts.static_order())\n    except CycleError as e:\n        if handle_cycles:\n            ordered_keys = self._break_cycles_and_sort(graph, e)\n        else:\n            raise\n\n    # Convert keys back to Table objects\n    return [self._table_cache[key] for key in ordered_keys]\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.ForeignKeyOrderer.validate_insertion_order","title":"validate_insertion_order","text":"<pre><code>validate_insertion_order(\n    tables: list[str | Table],\n) -&gt; list[tuple[str, str, str]]\n</code></pre> <p>Validate that a list of tables can be inserted in order.</p> <p>Checks each table to ensure all its FK dependencies are satisfied by tables earlier in the list.</p> <p>Parameters:</p> Name Type Description Default <code>tables</code> <code>list[str | Table]</code> <p>Ordered list of tables to validate.</p> required <p>Returns:</p> Type Description <code>list[tuple[str, str, str]]</code> <p>List of (table, missing_dependency, fk_name) tuples for</p> <code>list[tuple[str, str, str]]</code> <p>any unsatisfied dependencies. Empty list if valid.</p> Source code in <code>src/deriva_ml/model/fk_orderer.py</code> <pre><code>def validate_insertion_order(\n    self,\n    tables: list[str | DerivaTable],\n) -&gt; list[tuple[str, str, str]]:\n    \"\"\"Validate that a list of tables can be inserted in order.\n\n    Checks each table to ensure all its FK dependencies are\n    satisfied by tables earlier in the list.\n\n    Args:\n        tables: Ordered list of tables to validate.\n\n    Returns:\n        List of (table, missing_dependency, fk_name) tuples for\n        any unsatisfied dependencies. Empty list if valid.\n    \"\"\"\n    table_objs = [self._to_table(t) for t in tables]\n    seen_keys = set()\n    violations = []\n\n    for t in table_objs:\n        key = self._table_key(t)\n\n        for fk in t.foreign_keys:\n            pk_key = self._table_key(fk.pk_table)\n            # Skip self-references and tables not in our set\n            if pk_key == key:\n                continue\n            if pk_key not in {self._table_key(x) for x in table_objs}:\n                continue\n\n            if pk_key not in seen_keys:\n                violations.append((key, pk_key, fk.name[1]))\n\n        seen_keys.add(key)\n\n    return violations\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.InboundFK","title":"InboundFK  <code>dataclass</code>","text":"<p>An inbound foreign key path step for pseudo-column source paths.</p> <p>Use this when following a foreign key FROM another table TO the current table. This is common when counting or aggregating related records.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>str</code> <p>Schema name containing the FK constraint</p> required <code>constraint</code> <code>str</code> <p>Foreign key constraint name</p> required Example <p>Count images related to a subject (Image has FK to Subject)::</p> <pre><code>&gt;&gt;&gt; # In Subject table, count related images\n&gt;&gt;&gt; pc = PseudoColumn(\n...     source=[InboundFK(\"domain\", \"Image_Subject_fkey\"), \"RID\"],\n...     aggregate=Aggregate.CNT,\n...     markdown_name=\"Image Count\"\n... )\n</code></pre> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass InboundFK:\n    \"\"\"An inbound foreign key path step for pseudo-column source paths.\n\n    Use this when following a foreign key FROM another table TO the current table.\n    This is common when counting or aggregating related records.\n\n    Args:\n        schema: Schema name containing the FK constraint\n        constraint: Foreign key constraint name\n\n    Example:\n        Count images related to a subject (Image has FK to Subject)::\n\n            &gt;&gt;&gt; # In Subject table, count related images\n            &gt;&gt;&gt; pc = PseudoColumn(\n            ...     source=[InboundFK(\"domain\", \"Image_Subject_fkey\"), \"RID\"],\n            ...     aggregate=Aggregate.CNT,\n            ...     markdown_name=\"Image Count\"\n            ... )\n    \"\"\"\n    schema: str\n    constraint: str\n\n    def to_dict(self) -&gt; dict[str, list[str]]:\n        return {\"inbound\": [self.schema, self.constraint]}\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.NameStyle","title":"NameStyle  <code>dataclass</code>","text":"<p>Styling options for automatic display name formatting.</p> <p>Applied to table or column names when no explicit display name is set.</p> <p>Parameters:</p> Name Type Description Default <code>underline_space</code> <code>bool | None</code> <p>Replace underscores with spaces (e.g., \"First_Name\" -&gt; \"First Name\")</p> <code>None</code> <code>title_case</code> <code>bool | None</code> <p>Apply title case formatting (e.g., \"firstname\" -&gt; \"Firstname\")</p> <code>None</code> <code>markdown</code> <code>bool | None</code> <p>Render the name as markdown</p> <code>None</code> Example Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass NameStyle:\n    \"\"\"Styling options for automatic display name formatting.\n\n    Applied to table or column names when no explicit display name is set.\n\n    Args:\n        underline_space: Replace underscores with spaces (e.g., \"First_Name\" -&gt; \"First Name\")\n        title_case: Apply title case formatting (e.g., \"firstname\" -&gt; \"Firstname\")\n        markdown: Render the name as markdown\n\n    Example:\n        &gt;&gt;&gt; # Transform \"Subject_ID\" to \"Subject Id\" with title case\n        &gt;&gt;&gt; display = Display(\n        ...     name_style=NameStyle(underline_space=True, title_case=True)\n        ... )\n    \"\"\"\n    underline_space: bool | None = None\n    title_case: bool | None = None\n    markdown: bool | None = None\n\n    def to_dict(self) -&gt; dict[str, bool]:\n        \"\"\"Convert to dictionary, excluding None values.\"\"\"\n        result = {}\n        if self.underline_space is not None:\n            result[\"underline_space\"] = self.underline_space\n        if self.title_case is not None:\n            result[\"title_case\"] = self.title_case\n        if self.markdown is not None:\n            result[\"markdown\"] = self.markdown\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.NameStyle--transform-subject_id-to-subject-id-with-title-case","title":"Transform \"Subject_ID\" to \"Subject Id\" with title case","text":"<p>display = Display( ...     name_style=NameStyle(underline_space=True, title_case=True) ... )</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.NameStyle.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, bool]\n</code></pre> <p>Convert to dictionary, excluding None values.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def to_dict(self) -&gt; dict[str, bool]:\n    \"\"\"Convert to dictionary, excluding None values.\"\"\"\n    result = {}\n    if self.underline_space is not None:\n        result[\"underline_space\"] = self.underline_space\n    if self.title_case is not None:\n        result[\"title_case\"] = self.title_case\n    if self.markdown is not None:\n        result[\"markdown\"] = self.markdown\n    return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.OutboundFK","title":"OutboundFK  <code>dataclass</code>","text":"<p>An outbound foreign key path step for pseudo-column source paths.</p> <p>Use this when following a foreign key FROM the current table TO another table. This is common when displaying values from referenced tables.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>str</code> <p>Schema name containing the FK constraint</p> required <code>constraint</code> <code>str</code> <p>Foreign key constraint name</p> required Example <p>Show species name from a related Species table::</p> <pre><code>&gt;&gt;&gt; # Subject has FK to Species, display Species.Name\n&gt;&gt;&gt; pc = PseudoColumn(\n...     source=[OutboundFK(\"domain\", \"Subject_Species_fkey\"), \"Name\"],\n...     markdown_name=\"Species\"\n... )\n</code></pre> <p>Chain multiple outbound FKs::</p> <pre><code>&gt;&gt;&gt; # Image -&gt; Subject -&gt; Species\n&gt;&gt;&gt; pc = PseudoColumn(\n...     source=[\n...         OutboundFK(\"domain\", \"Image_Subject_fkey\"),\n...         OutboundFK(\"domain\", \"Subject_Species_fkey\"),\n...         \"Name\"\n...     ],\n...     markdown_name=\"Species\"\n... )\n</code></pre> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass OutboundFK:\n    \"\"\"An outbound foreign key path step for pseudo-column source paths.\n\n    Use this when following a foreign key FROM the current table TO another table.\n    This is common when displaying values from referenced tables.\n\n    Args:\n        schema: Schema name containing the FK constraint\n        constraint: Foreign key constraint name\n\n    Example:\n        Show species name from a related Species table::\n\n            &gt;&gt;&gt; # Subject has FK to Species, display Species.Name\n            &gt;&gt;&gt; pc = PseudoColumn(\n            ...     source=[OutboundFK(\"domain\", \"Subject_Species_fkey\"), \"Name\"],\n            ...     markdown_name=\"Species\"\n            ... )\n\n        Chain multiple outbound FKs::\n\n            &gt;&gt;&gt; # Image -&gt; Subject -&gt; Species\n            &gt;&gt;&gt; pc = PseudoColumn(\n            ...     source=[\n            ...         OutboundFK(\"domain\", \"Image_Subject_fkey\"),\n            ...         OutboundFK(\"domain\", \"Subject_Species_fkey\"),\n            ...         \"Name\"\n            ...     ],\n            ...     markdown_name=\"Species\"\n            ... )\n    \"\"\"\n    schema: str\n    constraint: str\n\n    def to_dict(self) -&gt; dict[str, list[str]]:\n        return {\"outbound\": [self.schema, self.constraint]}\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.PreFormat","title":"PreFormat  <code>dataclass</code>","text":"<p>Pre-formatting options for column values.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str | None</code> <p>Printf-style format string (e.g., \"%.2f\")</p> <code>None</code> <code>bool_true_value</code> <code>str | None</code> <p>Display value for True</p> <code>None</code> <code>bool_false_value</code> <code>str | None</code> <p>Display value for False</p> <code>None</code> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass PreFormat:\n    \"\"\"Pre-formatting options for column values.\n\n    Args:\n        format: Printf-style format string (e.g., \"%.2f\")\n        bool_true_value: Display value for True\n        bool_false_value: Display value for False\n    \"\"\"\n    format: str | None = None\n    bool_true_value: str | None = None\n    bool_false_value: str | None = None\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        if self.format is not None:\n            result[\"format\"] = self.format\n        if self.bool_true_value is not None:\n            result[\"bool_true_value\"] = self.bool_true_value\n        if self.bool_false_value is not None:\n            result[\"bool_false_value\"] = self.bool_false_value\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.PseudoColumn","title":"PseudoColumn  <code>dataclass</code>","text":"<p>A pseudo-column definition for visible columns and foreign keys.</p> <p>Pseudo-columns display computed values, values from related tables, or custom markdown patterns. They appear as columns in table views but are not actual database columns.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | list[str | InboundFK | OutboundFK] | None</code> <p>Path to source data. Can be: - A column name (string) - A list of FK path steps ending with a column name</p> <code>None</code> <code>sourcekey</code> <code>str | None</code> <p>Reference to a named source in source-definitions annotation</p> <code>None</code> <code>markdown_name</code> <code>str | None</code> <p>Display name for the column (supports markdown)</p> <code>None</code> <code>comment</code> <code>str | Literal[False] | None</code> <p>Description/tooltip text (or False to hide)</p> <code>None</code> <code>entity</code> <code>bool | None</code> <p>Whether this represents an entity (affects rendering)</p> <code>None</code> <code>aggregate</code> <code>Aggregate | None</code> <p>Aggregation function when source returns multiple values</p> <code>None</code> <code>self_link</code> <code>bool | None</code> <p>Make the value a link to the current row</p> <code>None</code> <code>display</code> <code>PseudoColumnDisplay | None</code> <p>Display formatting options</p> <code>None</code> <code>array_options</code> <code>dict[str, Any] | None</code> <p>Options for array aggregates (max_length, order)</p> <code>None</code> Note <p>source and sourcekey are mutually exclusive. Use source for inline definitions, sourcekey to reference pre-defined sources.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both source and sourcekey are provided</p> Example <p>Simple column with custom display name::</p> <pre><code>&gt;&gt;&gt; PseudoColumn(source=\"Internal_ID\", markdown_name=\"ID\")\n</code></pre> <p>Outbound FK traversal (display value from referenced table)::</p> <pre><code>&gt;&gt;&gt; # Subject has FK to Species - show Species.Name\n&gt;&gt;&gt; PseudoColumn(\n...     source=[OutboundFK(\"domain\", \"Subject_Species_fkey\"), \"Name\"],\n...     markdown_name=\"Species\"\n... )\n</code></pre> <p>Inbound FK with aggregation (count related records)::</p> <pre><code>&gt;&gt;&gt; # Count images pointing to this subject\n&gt;&gt;&gt; PseudoColumn(\n...     source=[InboundFK(\"domain\", \"Image_Subject_fkey\"), \"RID\"],\n...     aggregate=Aggregate.CNT,\n...     markdown_name=\"Images\"\n... )\n</code></pre> <p>Multi-hop FK path::</p> <pre><code>&gt;&gt;&gt; # Image -&gt; Subject -&gt; Species\n&gt;&gt;&gt; PseudoColumn(\n...     source=[\n...         OutboundFK(\"domain\", \"Image_Subject_fkey\"),\n...         OutboundFK(\"domain\", \"Subject_Species_fkey\"),\n...         \"Name\"\n...     ],\n...     markdown_name=\"Species\"\n... )\n</code></pre> <p>With custom display formatting::</p> <pre><code>&gt;&gt;&gt; PseudoColumn(\n...     source=\"URL\",\n...     display=PseudoColumnDisplay(\n...         markdown_pattern=\"[Download]({{{_value}}})\",\n...         show_foreign_key_link=False\n...     )\n... )\n</code></pre> <p>Array aggregate with display options::</p> <pre><code>&gt;&gt;&gt; PseudoColumn(\n...     source=[InboundFK(\"domain\", \"Tag_Item_fkey\"), \"Name\"],\n...     aggregate=Aggregate.ARRAY_D,\n...     display=PseudoColumnDisplay(array_ux_mode=ArrayUxMode.CSV),\n...     markdown_name=\"Tags\"\n... )\n</code></pre> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass PseudoColumn:\n    \"\"\"A pseudo-column definition for visible columns and foreign keys.\n\n    Pseudo-columns display computed values, values from related tables,\n    or custom markdown patterns. They appear as columns in table views\n    but are not actual database columns.\n\n    Args:\n        source: Path to source data. Can be:\n            - A column name (string)\n            - A list of FK path steps ending with a column name\n        sourcekey: Reference to a named source in source-definitions annotation\n        markdown_name: Display name for the column (supports markdown)\n        comment: Description/tooltip text (or False to hide)\n        entity: Whether this represents an entity (affects rendering)\n        aggregate: Aggregation function when source returns multiple values\n        self_link: Make the value a link to the current row\n        display: Display formatting options\n        array_options: Options for array aggregates (max_length, order)\n\n    Note:\n        source and sourcekey are mutually exclusive. Use source for inline\n        definitions, sourcekey to reference pre-defined sources.\n\n    Raises:\n        ValueError: If both source and sourcekey are provided\n\n    Example:\n        Simple column with custom display name::\n\n            &gt;&gt;&gt; PseudoColumn(source=\"Internal_ID\", markdown_name=\"ID\")\n\n        Outbound FK traversal (display value from referenced table)::\n\n            &gt;&gt;&gt; # Subject has FK to Species - show Species.Name\n            &gt;&gt;&gt; PseudoColumn(\n            ...     source=[OutboundFK(\"domain\", \"Subject_Species_fkey\"), \"Name\"],\n            ...     markdown_name=\"Species\"\n            ... )\n\n        Inbound FK with aggregation (count related records)::\n\n            &gt;&gt;&gt; # Count images pointing to this subject\n            &gt;&gt;&gt; PseudoColumn(\n            ...     source=[InboundFK(\"domain\", \"Image_Subject_fkey\"), \"RID\"],\n            ...     aggregate=Aggregate.CNT,\n            ...     markdown_name=\"Images\"\n            ... )\n\n        Multi-hop FK path::\n\n            &gt;&gt;&gt; # Image -&gt; Subject -&gt; Species\n            &gt;&gt;&gt; PseudoColumn(\n            ...     source=[\n            ...         OutboundFK(\"domain\", \"Image_Subject_fkey\"),\n            ...         OutboundFK(\"domain\", \"Subject_Species_fkey\"),\n            ...         \"Name\"\n            ...     ],\n            ...     markdown_name=\"Species\"\n            ... )\n\n        With custom display formatting::\n\n            &gt;&gt;&gt; PseudoColumn(\n            ...     source=\"URL\",\n            ...     display=PseudoColumnDisplay(\n            ...         markdown_pattern=\"[Download]({{{_value}}})\",\n            ...         show_foreign_key_link=False\n            ...     )\n            ... )\n\n        Array aggregate with display options::\n\n            &gt;&gt;&gt; PseudoColumn(\n            ...     source=[InboundFK(\"domain\", \"Tag_Item_fkey\"), \"Name\"],\n            ...     aggregate=Aggregate.ARRAY_D,\n            ...     display=PseudoColumnDisplay(array_ux_mode=ArrayUxMode.CSV),\n            ...     markdown_name=\"Tags\"\n            ... )\n    \"\"\"\n    source: str | list[str | InboundFK | OutboundFK] | None = None\n    sourcekey: str | None = None\n    markdown_name: str | None = None\n    comment: str | Literal[False] | None = None\n    entity: bool | None = None\n    aggregate: Aggregate | None = None\n    self_link: bool | None = None\n    display: PseudoColumnDisplay | None = None\n    array_options: dict[str, Any] | None = None  # Can be complex\n\n    def __post_init__(self):\n        if self.source is not None and self.sourcekey is not None:\n            raise ValueError(\"source and sourcekey are mutually exclusive\")\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n\n        if self.source is not None:\n            if isinstance(self.source, str):\n                result[\"source\"] = self.source\n            else:\n                # Convert path elements\n                result[\"source\"] = [\n                    item.to_dict() if hasattr(item, \"to_dict\") else item\n                    for item in self.source\n                ]\n\n        if self.sourcekey is not None:\n            result[\"sourcekey\"] = self.sourcekey\n        if self.markdown_name is not None:\n            result[\"markdown_name\"] = self.markdown_name\n        if self.comment is not None:\n            result[\"comment\"] = self.comment\n        if self.entity is not None:\n            result[\"entity\"] = self.entity\n        if self.aggregate is not None:\n            result[\"aggregate\"] = self.aggregate.value\n        if self.self_link is not None:\n            result[\"self_link\"] = self.self_link\n        if self.display is not None:\n            result[\"display\"] = self.display.to_dict()\n        if self.array_options is not None:\n            result[\"array_options\"] = self.array_options\n\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.PseudoColumnDisplay","title":"PseudoColumnDisplay  <code>dataclass</code>","text":"<p>Display options for a pseudo-column.</p> <p>Parameters:</p> Name Type Description Default <code>markdown_pattern</code> <code>str | None</code> <p>Handlebars/mustache template</p> <code>None</code> <code>template_engine</code> <code>TemplateEngine | None</code> <p>Template engine to use</p> <code>None</code> <code>show_foreign_key_link</code> <code>bool | None</code> <p>Show as clickable link</p> <code>None</code> <code>array_ux_mode</code> <code>ArrayUxMode | None</code> <p>How to render array values</p> <code>None</code> <code>column_order</code> <code>list[SortKey] | Literal[False] | None</code> <p>Sort order for the column, or False to disable</p> <code>None</code> <code>wait_for</code> <code>list[str] | None</code> <p>Template variables to wait for before rendering</p> <code>None</code> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass PseudoColumnDisplay:\n    \"\"\"Display options for a pseudo-column.\n\n    Args:\n        markdown_pattern: Handlebars/mustache template\n        template_engine: Template engine to use\n        show_foreign_key_link: Show as clickable link\n        array_ux_mode: How to render array values\n        column_order: Sort order for the column, or False to disable\n        wait_for: Template variables to wait for before rendering\n    \"\"\"\n    markdown_pattern: str | None = None\n    template_engine: TemplateEngine | None = None\n    show_foreign_key_link: bool | None = None\n    array_ux_mode: ArrayUxMode | None = None\n    column_order: list[SortKey] | Literal[False] | None = None\n    wait_for: list[str] | None = None\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        if self.markdown_pattern is not None:\n            result[\"markdown_pattern\"] = self.markdown_pattern\n        if self.template_engine is not None:\n            result[\"template_engine\"] = self.template_engine.value\n        if self.show_foreign_key_link is not None:\n            result[\"show_foreign_key_link\"] = self.show_foreign_key_link\n        if self.array_ux_mode is not None:\n            result[\"array_ux_mode\"] = self.array_ux_mode.value\n        if self.column_order is not None:\n            if self.column_order is False:\n                result[\"column_order\"] = False\n            else:\n                result[\"column_order\"] = [\n                    k.to_dict() if isinstance(k, SortKey) else k\n                    for k in self.column_order\n                ]\n        if self.wait_for is not None:\n            result[\"wait_for\"] = self.wait_for\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaBuilder","title":"SchemaBuilder","text":"<p>Creates SQLAlchemy ORM from a Deriva catalog model.</p> <p>Phase 1 of the two-phase database creation pattern. This class handles only schema/ORM creation - no data loading.</p> <p>The Model can come from either a live catalog or a schema.json file: - From catalog: model = catalog.getCatalogModel() - From file: model = Model.fromfile(\"file-system\", \"path/to/schema.json\")</p> Example Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>class SchemaBuilder:\n    \"\"\"Creates SQLAlchemy ORM from a Deriva catalog model.\n\n    Phase 1 of the two-phase database creation pattern. This class handles\n    only schema/ORM creation - no data loading.\n\n    The Model can come from either a live catalog or a schema.json file:\n    - From catalog: model = catalog.getCatalogModel()\n    - From file: model = Model.fromfile(\"file-system\", \"path/to/schema.json\")\n\n    Example:\n        # Create ORM from catalog model\n        model = catalog.getCatalogModel()\n        builder = SchemaBuilder(model, schemas=['domain', 'deriva-ml'])\n        orm = builder.build()\n\n        # Create ORM from schema file\n        model = Model.fromfile(\"file-system\", \"schema.json\")\n        builder = SchemaBuilder(model, schemas=['domain'], database_path=\"local.db\")\n        orm = builder.build()\n\n        # Use the ORM\n        ImageClass = orm.get_orm_class(\"Image\")\n        with Session(orm.engine) as session:\n            images = session.query(ImageClass).all()\n\n        # Clean up\n        orm.dispose()\n    \"\"\"\n\n    # Type mapping from ERMrest to SQLAlchemy\n    _TYPE_MAP = {\n        \"boolean\": ERMRestBoolean,\n        \"date\": StringToDate,\n        \"float4\": StringToFloat,\n        \"float8\": StringToFloat,\n        \"int2\": StringToInteger,\n        \"int4\": StringToInteger,\n        \"int8\": StringToInteger,\n        \"json\": JSON,\n        \"jsonb\": JSON,\n        \"timestamptz\": StringToDateTime,\n        \"timestamp\": StringToDateTime,\n    }\n\n    def __init__(\n        self,\n        model: Model,\n        schemas: list[str],\n        database_path: Path | str = \":memory:\",\n    ):\n        \"\"\"Initialize the schema builder.\n\n        Args:\n            model: ERMrest Model object (from catalog or schema.json file).\n            schemas: List of schema names to include in the ORM.\n            database_path: Path to SQLite database file. Use \":memory:\" for\n                in-memory database (default). If a Path or string is provided,\n                separate .db files will be created for each schema.\n        \"\"\"\n        self.model = model\n        self.schemas = schemas\n        self.database_path = Path(database_path) if database_path != \":memory:\" else database_path\n\n        # Will be set during build()\n        self.engine: Engine | None = None\n        self.metadata: MetaData | None = None\n        self.Base: AutomapBase | None = None\n        self._class_prefix: str = \"\"\n\n    @staticmethod\n    def _sql_type(deriva_type: DerivaType) -&gt; TypeEngine:\n        \"\"\"Map ERMrest type to SQLAlchemy type with CSV string conversion.\n\n        Args:\n            deriva_type: ERMrest type object.\n\n        Returns:\n            SQLAlchemy type class.\n        \"\"\"\n        return SchemaBuilder._TYPE_MAP.get(deriva_type.typename, String)\n\n    def _is_key_column(self, column: DerivaColumn, table: DerivaTable) -&gt; bool:\n        \"\"\"Check if column is the primary key (RID).\"\"\"\n        return column in [key.unique_columns[0] for key in table.keys] and column.name == \"RID\"\n\n    def build(self) -&gt; SchemaORM:\n        \"\"\"Build the SQLAlchemy ORM structure.\n\n        Creates SQLite tables from the ERMrest schema and generates\n        ORM classes via SQLAlchemy automap.\n\n        Returns:\n            SchemaORM object containing engine, metadata, Base, and utilities.\n\n        Note:\n            In-memory databases (database_path=\":memory:\") do not support\n            SQLite schema attachments, so all tables will be created in a\n            single database without schema prefixes in table names.\n        \"\"\"\n        # Create unique prefix for ORM class names\n        self._class_prefix = f\"_{id(self)}_\"\n\n        # Determine if we're using in-memory or file-based database\n        self._use_schemas = self.database_path != \":memory:\"\n\n        # Create engine\n        if self.database_path == \":memory:\":\n            self.engine = create_engine(\"sqlite:///:memory:\", future=True)\n        else:\n            # Ensure the database path exists\n            if isinstance(self.database_path, Path):\n                if self.database_path.suffix == \".db\":\n                    # Single file path\n                    self.database_path.parent.mkdir(parents=True, exist_ok=True)\n                    main_db = self.database_path\n                else:\n                    # Directory path\n                    self.database_path.mkdir(parents=True, exist_ok=True)\n                    main_db = self.database_path / \"main.db\"\n            else:\n                main_db = Path(self.database_path)\n                main_db.parent.mkdir(parents=True, exist_ok=True)\n\n            self.engine = create_engine(f\"sqlite:///{main_db.resolve()}\", future=True)\n\n            # Attach schema-specific databases\n            event.listen(self.engine, \"connect\", self._attach_schemas)\n\n        self.metadata = MetaData()\n        self.Base = automap_base(metadata=self.metadata)\n\n        # Build the schema\n        self._create_tables()\n\n        logger.info(\n            \"Built ORM for schemas %s with %d tables\",\n            self.schemas,\n            len(self.metadata.tables),\n        )\n\n        return SchemaORM(\n            engine=self.engine,\n            metadata=self.metadata,\n            Base=self.Base,\n            model=self.model,\n            schemas=self.schemas,\n            class_prefix=self._class_prefix,\n            use_schemas=self._use_schemas,\n        )\n\n    def _attach_schemas(self, dbapi_conn, _conn_record):\n        \"\"\"Attach schema-specific SQLite databases.\"\"\"\n        cur = dbapi_conn.cursor()\n        db_dir = self.database_path if self.database_path.is_dir() else self.database_path.parent\n        for schema in self.schemas:\n            schema_file = (db_dir / f\"{schema}.db\").resolve()\n            cur.execute(f\"ATTACH DATABASE '{schema_file}' AS '{schema}'\")\n        cur.close()\n\n    def _create_tables(self) -&gt; None:\n        \"\"\"Create SQLite tables from the ERMrest schema.\"\"\"\n\n        def col(model, name: str):\n            \"\"\"Get column from ORM class, handling both attribute and table column access.\"\"\"\n            try:\n                return getattr(model, name).property.columns[0]\n            except AttributeError:\n                return model.__table__.c[name]\n\n        def guess_attr_name(col_name: str) -&gt; str:\n            \"\"\"Generate relationship attribute name from column name.\"\"\"\n            return col_name[:-3] if col_name.lower().endswith(\"_id\") else col_name\n\n        def make_table_name(schema_name: str, table_name: str) -&gt; str:\n            \"\"\"Generate table name, including schema prefix if using schemas.\"\"\"\n            if self._use_schemas:\n                return f\"{schema_name}.{table_name}\"\n            else:\n                # For in-memory, use underscore separator to avoid conflicts\n                return f\"{schema_name}_{table_name}\"\n\n        database_tables: list[SQLTable] = []\n\n        for schema_name in self.schemas:\n            if schema_name not in self.model.schemas:\n                logger.warning(f\"Schema {schema_name} not found in model\")\n                continue\n\n            for table in self.model.schemas[schema_name].tables.values():\n                database_columns: list[SQLColumn] = []\n\n                for c in table.columns:\n                    database_column = SQLColumn(\n                        name=c.name,\n                        type_=self._sql_type(c.type),\n                        comment=c.comment,\n                        default=c.default,\n                        primary_key=self._is_key_column(c, table),\n                        nullable=c.nullok,\n                    )\n                    database_columns.append(database_column)\n\n                # Use schema prefix only for file-based databases\n                if self._use_schemas:\n                    database_table = SQLTable(\n                        table.name, self.metadata, *database_columns, schema=schema_name\n                    )\n                else:\n                    # For in-memory, embed schema in table name\n                    full_name = f\"{schema_name}_{table.name}\".replace(\"-\", \"_\")\n                    database_table = SQLTable(\n                        full_name, self.metadata, *database_columns\n                    )\n\n                # Add unique constraints\n                for key in table.keys:\n                    key_columns = [c.name for c in key.unique_columns]\n                    database_table.append_constraint(\n                        SQLUniqueConstraint(*key_columns, name=key.name[1])\n                    )\n\n                # Add foreign key constraints (within same schema only for now)\n                for fk in table.foreign_keys:\n                    if fk.pk_table.schema.name not in self.schemas:\n                        continue\n                    if fk.pk_table.schema.name != schema_name:\n                        continue\n\n                    # Build reference column names\n                    if self._use_schemas:\n                        refcols = [\n                            f\"{schema_name}.{c.table.name}.{c.name}\"\n                            for c in fk.referenced_columns\n                        ]\n                    else:\n                        # For in-memory, use the embedded schema name\n                        ref_table_name = f\"{schema_name}_{fk.pk_table.name}\".replace(\"-\", \"_\")\n                        refcols = [\n                            f\"{ref_table_name}.{c.name}\"\n                            for c in fk.referenced_columns\n                        ]\n\n                    database_table.append_constraint(\n                        SQLForeignKeyConstraint(\n                            columns=[f\"{c.name}\" for c in fk.foreign_key_columns],\n                            refcolumns=refcols,\n                            name=fk.name[1],\n                            comment=fk.comment,\n                        )\n                    )\n\n                database_tables.append(database_table)\n\n        # Create all tables\n        with self.engine.begin() as conn:\n            self.metadata.create_all(conn, tables=database_tables, checkfirst=True)\n\n        # Configure ORM class naming\n        def name_for_scalar_relationship(_base, local_cls, referred_cls, constraint):\n            cols = list(constraint.columns) if constraint is not None else []\n            if len(cols) == 1:\n                name = cols[0].key\n                if name in {c.key for c in local_cls.__table__.columns}:\n                    name += \"_rel\"\n                return name\n            return constraint.name or referred_cls.__name__.lower()\n\n        def name_for_collection_relationship(_base, local_cls, referred_cls, constraint):\n            backref_name = constraint.name.replace(\"_fkey\", \"_collection\")\n            return backref_name or (referred_cls.__name__.lower() + \"_collection\")\n\n        def classname_for_table(_base, tablename, table):\n            return self._class_prefix + tablename.replace(\".\", \"_\").replace(\"-\", \"_\")\n\n        # Build ORM mappings\n        self.Base.prepare(\n            self.engine,\n            name_for_scalar_relationship=name_for_scalar_relationship,\n            name_for_collection_relationship=name_for_collection_relationship,\n            classname_for_table=classname_for_table,\n            reflect=True,\n        )\n\n        # Add cross-schema relationships\n        for schema_name in self.schemas:\n            if schema_name not in self.model.schemas:\n                continue\n\n            for table in self.model.schemas[schema_name].tables.values():\n                for fk in table.foreign_keys:\n                    if fk.pk_table.schema.name not in self.schemas:\n                        continue\n                    if fk.pk_table.schema.name == schema_name:\n                        continue\n\n                    table_name = make_table_name(schema_name, table.name)\n                    table_class = self._get_orm_class_by_name(table_name)\n                    foreign_key_column_name = fk.foreign_key_columns[0].name\n                    foreign_key_column = col(table_class, foreign_key_column_name)\n\n                    referenced_table_name = make_table_name(fk.pk_table.schema.name, fk.pk_table.name)\n                    referenced_class = self._get_orm_class_by_name(referenced_table_name)\n                    referenced_column = col(referenced_class, fk.referenced_columns[0].name)\n\n                    relationship_attr = guess_attr_name(foreign_key_column_name)\n                    backref_attr = fk.name[1].replace(\"_fkey\", \"_collection\")\n\n                    # Check if relationship already exists\n                    existing_attr = getattr(table_class, relationship_attr, None)\n                    from sqlalchemy.orm import RelationshipProperty\n                    from sqlalchemy.orm.attributes import InstrumentedAttribute\n\n                    is_relationship = isinstance(existing_attr, InstrumentedAttribute) and isinstance(\n                        existing_attr.property, RelationshipProperty\n                    )\n                    if not is_relationship:\n                        setattr(\n                            table_class,\n                            relationship_attr,\n                            relationship(\n                                referenced_class,\n                                foreign_keys=[foreign_key_column],\n                                primaryjoin=foreign(foreign_key_column) == referenced_column,\n                                backref=backref(backref_attr, viewonly=True),\n                                viewonly=True,\n                            ),\n                        )\n\n        # Configure mappers\n        self.Base.registry.configure()\n\n    def _get_orm_class_by_name(self, table_name: str) -&gt; Any | None:\n        \"\"\"Get ORM class by table name (internal use during build).\n\n        Handles both schema.table format (file-based) and schema_table format (in-memory).\n        \"\"\"\n        # Try exact match first\n        if table_name in self.metadata.tables:\n            sql_table = self.metadata.tables[table_name]\n        else:\n            # For in-memory databases, table names use underscore separator\n            # Try converting schema.table to schema_table format\n            if \".\" in table_name and not self._use_schemas:\n                converted_name = table_name.replace(\".\", \"_\").replace(\"-\", \"_\")\n                if converted_name in self.metadata.tables:\n                    sql_table = self.metadata.tables[converted_name]\n                else:\n                    sql_table = None\n            else:\n                # Try matching just the table name part\n                sql_table = None\n                for full_name, table in self.metadata.tables.items():\n                    # Handle both . and _ separators\n                    table_part = full_name.split(\".\")[-1] if \".\" in full_name else full_name.split(\"_\", 1)[-1] if \"_\" in full_name else full_name\n                    if table_part == table_name or full_name.endswith(f\"_{table_name}\"):\n                        sql_table = table\n                        break\n\n        if sql_table is None:\n            raise KeyError(f\"Table {table_name} not found\")\n\n        for mapper in self.Base.registry.mappers:\n            if mapper.persist_selectable is sql_table or sql_table in mapper.tables:\n                return mapper.class_\n        return None\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaBuilder--create-orm-from-catalog-model","title":"Create ORM from catalog model","text":"<p>model = catalog.getCatalogModel() builder = SchemaBuilder(model, schemas=['domain', 'deriva-ml']) orm = builder.build()</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaBuilder--create-orm-from-schema-file","title":"Create ORM from schema file","text":"<p>model = Model.fromfile(\"file-system\", \"schema.json\") builder = SchemaBuilder(model, schemas=['domain'], database_path=\"local.db\") orm = builder.build()</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaBuilder--use-the-orm","title":"Use the ORM","text":"<p>ImageClass = orm.get_orm_class(\"Image\") with Session(orm.engine) as session:     images = session.query(ImageClass).all()</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaBuilder--clean-up","title":"Clean up","text":"<p>orm.dispose()</p>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaBuilder.__init__","title":"__init__","text":"<pre><code>__init__(\n    model: Model,\n    schemas: list[str],\n    database_path: Path\n    | str = \":memory:\",\n)\n</code></pre> <p>Initialize the schema builder.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>ERMrest Model object (from catalog or schema.json file).</p> required <code>schemas</code> <code>list[str]</code> <p>List of schema names to include in the ORM.</p> required <code>database_path</code> <code>Path | str</code> <p>Path to SQLite database file. Use \":memory:\" for in-memory database (default). If a Path or string is provided, separate .db files will be created for each schema.</p> <code>':memory:'</code> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def __init__(\n    self,\n    model: Model,\n    schemas: list[str],\n    database_path: Path | str = \":memory:\",\n):\n    \"\"\"Initialize the schema builder.\n\n    Args:\n        model: ERMrest Model object (from catalog or schema.json file).\n        schemas: List of schema names to include in the ORM.\n        database_path: Path to SQLite database file. Use \":memory:\" for\n            in-memory database (default). If a Path or string is provided,\n            separate .db files will be created for each schema.\n    \"\"\"\n    self.model = model\n    self.schemas = schemas\n    self.database_path = Path(database_path) if database_path != \":memory:\" else database_path\n\n    # Will be set during build()\n    self.engine: Engine | None = None\n    self.metadata: MetaData | None = None\n    self.Base: AutomapBase | None = None\n    self._class_prefix: str = \"\"\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaBuilder.build","title":"build","text":"<pre><code>build() -&gt; SchemaORM\n</code></pre> <p>Build the SQLAlchemy ORM structure.</p> <p>Creates SQLite tables from the ERMrest schema and generates ORM classes via SQLAlchemy automap.</p> <p>Returns:</p> Type Description <code>SchemaORM</code> <p>SchemaORM object containing engine, metadata, Base, and utilities.</p> Note <p>In-memory databases (database_path=\":memory:\") do not support SQLite schema attachments, so all tables will be created in a single database without schema prefixes in table names.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def build(self) -&gt; SchemaORM:\n    \"\"\"Build the SQLAlchemy ORM structure.\n\n    Creates SQLite tables from the ERMrest schema and generates\n    ORM classes via SQLAlchemy automap.\n\n    Returns:\n        SchemaORM object containing engine, metadata, Base, and utilities.\n\n    Note:\n        In-memory databases (database_path=\":memory:\") do not support\n        SQLite schema attachments, so all tables will be created in a\n        single database without schema prefixes in table names.\n    \"\"\"\n    # Create unique prefix for ORM class names\n    self._class_prefix = f\"_{id(self)}_\"\n\n    # Determine if we're using in-memory or file-based database\n    self._use_schemas = self.database_path != \":memory:\"\n\n    # Create engine\n    if self.database_path == \":memory:\":\n        self.engine = create_engine(\"sqlite:///:memory:\", future=True)\n    else:\n        # Ensure the database path exists\n        if isinstance(self.database_path, Path):\n            if self.database_path.suffix == \".db\":\n                # Single file path\n                self.database_path.parent.mkdir(parents=True, exist_ok=True)\n                main_db = self.database_path\n            else:\n                # Directory path\n                self.database_path.mkdir(parents=True, exist_ok=True)\n                main_db = self.database_path / \"main.db\"\n        else:\n            main_db = Path(self.database_path)\n            main_db.parent.mkdir(parents=True, exist_ok=True)\n\n        self.engine = create_engine(f\"sqlite:///{main_db.resolve()}\", future=True)\n\n        # Attach schema-specific databases\n        event.listen(self.engine, \"connect\", self._attach_schemas)\n\n    self.metadata = MetaData()\n    self.Base = automap_base(metadata=self.metadata)\n\n    # Build the schema\n    self._create_tables()\n\n    logger.info(\n        \"Built ORM for schemas %s with %d tables\",\n        self.schemas,\n        len(self.metadata.tables),\n    )\n\n    return SchemaORM(\n        engine=self.engine,\n        metadata=self.metadata,\n        Base=self.Base,\n        model=self.model,\n        schemas=self.schemas,\n        class_prefix=self._class_prefix,\n        use_schemas=self._use_schemas,\n    )\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM","title":"SchemaORM","text":"<p>Container for SQLAlchemy ORM components.</p> <p>Provides access to the ORM structure and utility methods for table/class lookup. This is the result of Phase 1 (SchemaBuilder).</p> <p>Attributes:</p> Name Type Description <code>engine</code> <p>SQLAlchemy Engine for database connections.</p> <code>metadata</code> <p>SQLAlchemy MetaData with table definitions.</p> <code>Base</code> <p>SQLAlchemy automap base for ORM classes.</p> <code>model</code> <p>ERMrest Model the ORM was built from.</p> <code>schemas</code> <p>List of schema names included.</p> <code>use_schemas</code> <p>Whether schema prefixes are used (False for in-memory).</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>class SchemaORM:\n    \"\"\"Container for SQLAlchemy ORM components.\n\n    Provides access to the ORM structure and utility methods for\n    table/class lookup. This is the result of Phase 1 (SchemaBuilder).\n\n    Attributes:\n        engine: SQLAlchemy Engine for database connections.\n        metadata: SQLAlchemy MetaData with table definitions.\n        Base: SQLAlchemy automap base for ORM classes.\n        model: ERMrest Model the ORM was built from.\n        schemas: List of schema names included.\n        use_schemas: Whether schema prefixes are used (False for in-memory).\n    \"\"\"\n\n    def __init__(\n        self,\n        engine: Engine,\n        metadata: MetaData,\n        Base: AutomapBase,\n        model: Model,\n        schemas: list[str],\n        class_prefix: str,\n        use_schemas: bool = True,\n    ):\n        \"\"\"Initialize SchemaORM container.\n\n        Args:\n            engine: SQLAlchemy Engine.\n            metadata: SQLAlchemy MetaData with tables.\n            Base: Automap base with ORM classes.\n            model: Source ERMrest Model.\n            schemas: Schemas that were included.\n            class_prefix: Prefix used for ORM class names.\n            use_schemas: Whether schema prefixes are used (False for in-memory).\n        \"\"\"\n        self.engine = engine\n        self.metadata = metadata\n        self.Base = Base\n        self.model = model\n        self.schemas = schemas\n        self._class_prefix = class_prefix\n        self._use_schemas = use_schemas\n        self._disposed = False\n\n    def list_tables(self) -&gt; list[str]:\n        \"\"\"List all tables in the database.\n\n        Returns:\n            List of fully-qualified table names (schema.table), sorted.\n        \"\"\"\n        tables = list(self.metadata.tables.keys())\n        tables.sort()\n        return tables\n\n    def find_table(self, table_name: str) -&gt; SQLTable:\n        \"\"\"Find a table by name.\n\n        Handles both schema.table format and schema_table format (for in-memory databases).\n\n        Args:\n            table_name: Table name, with or without schema prefix.\n                Can be \"schema.table\", \"schema_table\", or just \"table\".\n\n        Returns:\n            SQLAlchemy Table object.\n\n        Raises:\n            KeyError: If table not found.\n        \"\"\"\n        # Try exact match first\n        if table_name in self.metadata.tables:\n            return self.metadata.tables[table_name]\n\n        # Try converting schema.table to schema_table format (for in-memory)\n        if \".\" in table_name and not self._use_schemas:\n            converted_name = table_name.replace(\".\", \"_\").replace(\"-\", \"_\")\n            if converted_name in self.metadata.tables:\n                return self.metadata.tables[converted_name]\n\n        # Try matching just the table name part\n        for full_name, table in self.metadata.tables.items():\n            # Handle . separator (file-based)\n            if \".\" in full_name and full_name.split(\".\")[-1] == table_name:\n                return table\n            # Handle _ separator (in-memory) - match suffix after first _\n            if \"_\" in full_name and \".\" not in full_name:\n                # Check if table_name matches the part after schema prefix\n                parts = full_name.split(\"_\", 1)\n                if len(parts) &gt; 1 and parts[1] == table_name:\n                    return table\n                # Also check if it ends with the table name\n                if full_name.endswith(f\"_{table_name}\"):\n                    return table\n\n        raise KeyError(f\"Table {table_name} not found\")\n\n    def get_orm_class(self, table_name: str) -&gt; Any | None:\n        \"\"\"Get the ORM class for a table by name.\n\n        Args:\n            table_name: Table name, with or without schema prefix.\n\n        Returns:\n            SQLAlchemy ORM class for the table.\n\n        Raises:\n            KeyError: If table not found.\n        \"\"\"\n        sql_table = self.find_table(table_name)\n        return self.get_orm_class_for_table(sql_table)\n\n    def get_orm_class_for_table(self, table: SQLTable | DerivaTable | str) -&gt; Any | None:\n        \"\"\"Get the ORM class for a table.\n\n        Args:\n            table: SQLAlchemy Table, Deriva Table, or table name.\n\n        Returns:\n            SQLAlchemy ORM class, or None if not found.\n        \"\"\"\n        if isinstance(table, DerivaTable):\n            # Try schema.table format first (file-based), then schema_table (in-memory)\n            table_key = f\"{table.schema.name}.{table.name}\"\n            table = self.metadata.tables.get(table_key)\n            if table is None and not self._use_schemas:\n                # Try underscore format for in-memory databases\n                table_key = f\"{table.schema.name}_{table.name}\".replace(\"-\", \"_\")\n                table = self.metadata.tables.get(table_key)\n        if isinstance(table, str):\n            table = self.find_table(table)\n        if table is None:\n            return None\n\n        for mapper in self.Base.registry.mappers:\n            if mapper.persist_selectable is table or table in mapper.tables:\n                return mapper.class_\n        return None\n\n    def get_table_contents(self, table: str) -&gt; Generator[dict[str, Any], None, None]:\n        \"\"\"Retrieve all rows from a table as dictionaries.\n\n        Args:\n            table: Table name (with or without schema prefix).\n\n        Yields:\n            Dictionary for each row with column names as keys.\n        \"\"\"\n        sql_table = self.find_table(table)\n        with self.engine.connect() as conn:\n            result = conn.execute(select(sql_table))\n            for row in result.mappings():\n                yield dict(row)\n\n    @staticmethod\n    def is_association_table(\n        table_class,\n        min_arity: int = 2,\n        max_arity: int = 2,\n        unqualified: bool = True,\n        pure: bool = True,\n        no_overlap: bool = True,\n        return_fkeys: bool = False,\n    ):\n        \"\"\"Check if an ORM class represents an association table.\n\n        An association table links two or more tables through foreign keys,\n        with a composite unique key covering those foreign keys.\n\n        Args:\n            table_class: SQLAlchemy ORM class to check.\n            min_arity: Minimum number of foreign keys (default 2).\n            max_arity: Maximum number of foreign keys (default 2).\n            unqualified: If True, reject associations with extra key columns.\n            pure: If True, reject associations with extra non-key columns.\n            no_overlap: If True, reject associations with shared FK columns.\n            return_fkeys: If True, return the foreign keys instead of arity.\n\n        Returns:\n            If return_fkeys=False: Integer arity if association, False otherwise.\n            If return_fkeys=True: Set of foreign keys if association, False otherwise.\n        \"\"\"\n        if min_arity &lt; 2:\n            raise ValueError(\"An association cannot have arity &lt; 2\")\n        if max_arity is not None and max_arity &lt; min_arity:\n            raise ValueError(\"max_arity cannot be less than min_arity\")\n\n        mapper = inspect(table_class).mapper\n        system_cols = {\"RID\", \"RCT\", \"RMT\", \"RCB\", \"RMB\"}\n\n        non_sys_cols = {\n            col.name for col in mapper.columns if col.name not in system_cols\n        }\n\n        unique_columns = [\n            {c.name for c in constraint.columns}\n            for constraint in inspect(table_class).local_table.constraints\n            if isinstance(constraint, SQLUniqueConstraint)\n        ]\n\n        non_sys_key_colsets = {\n            frozenset(uc)\n            for uc in unique_columns\n            if uc.issubset(non_sys_cols) and len(uc) &gt; 1\n        }\n\n        if not non_sys_key_colsets:\n            return False\n\n        # Choose longest compound key\n        row_key = sorted(non_sys_key_colsets, key=lambda s: len(s), reverse=True)[0]\n        foreign_keys = list(inspect(table_class).relationships.values())\n\n        covered_fkeys = {\n            fkey for fkey in foreign_keys\n            if {c.name for c in fkey.local_columns}.issubset(row_key)\n        }\n        covered_fkey_cols = set()\n\n        if len(covered_fkeys) &lt; min_arity:\n            return False\n        if max_arity is not None and len(covered_fkeys) &gt; max_arity:\n            return False\n\n        for fkey in covered_fkeys:\n            fkcols = {c.name for c in fkey.local_columns}\n            if no_overlap and fkcols.intersection(covered_fkey_cols):\n                return False\n            covered_fkey_cols.update(fkcols)\n\n        if unqualified and row_key.difference(covered_fkey_cols):\n            return False\n\n        if pure and non_sys_cols.difference(row_key):\n            return False\n\n        return covered_fkeys if return_fkeys else len(covered_fkeys)\n\n    def get_association_class(\n        self,\n        left_cls: Type[Any],\n        right_cls: Type[Any],\n    ) -&gt; tuple[Any, Any, Any] | None:\n        \"\"\"Find an association class connecting two ORM classes.\n\n        Args:\n            left_cls: First ORM class.\n            right_cls: Second ORM class.\n\n        Returns:\n            Tuple of (association_class, left_relationship, right_relationship),\n            or None if no association found.\n        \"\"\"\n        for _, left_rel in inspect(left_cls).relationships.items():\n            mid_cls = left_rel.mapper.class_\n            is_assoc = self.is_association_table(mid_cls, return_fkeys=True)\n\n            if not is_assoc:\n                continue\n\n            assoc_local_columns_left = list(is_assoc)[0].local_columns\n            assoc_local_columns_right = list(is_assoc)[1].local_columns\n\n            found_left = found_right = False\n\n            for r in inspect(left_cls).relationships.values():\n                remote_side = list(r.remote_side)[0]\n                if remote_side in assoc_local_columns_left:\n                    found_left = r\n                if remote_side in assoc_local_columns_right:\n                    found_left = r\n                    # Swap if backwards\n                    assoc_local_columns_left, assoc_local_columns_right = (\n                        assoc_local_columns_right,\n                        assoc_local_columns_left,\n                    )\n\n            for r in inspect(right_cls).relationships.values():\n                remote_side = list(r.remote_side)[0]\n                if remote_side in assoc_local_columns_right:\n                    found_right = r\n\n            if found_left and found_right:\n                return mid_cls, found_left.class_attribute, found_right.class_attribute\n\n        return None\n\n    def dispose(self) -&gt; None:\n        \"\"\"Dispose of SQLAlchemy resources.\n\n        Call this when done with the database to properly clean up connections.\n        After calling dispose(), the instance should not be used further.\n        \"\"\"\n        if self._disposed:\n            return\n\n        if hasattr(self, \"Base\") and self.Base is not None:\n            self.Base.registry.dispose()\n        if hasattr(self, \"engine\") and self.engine is not None:\n            self.engine.dispose()\n\n        self._disposed = True\n\n    def __del__(self) -&gt; None:\n        \"\"\"Cleanup resources when garbage collected.\"\"\"\n        self.dispose()\n\n    def __enter__(self) -&gt; \"SchemaORM\":\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb) -&gt; bool:\n        \"\"\"Context manager exit - dispose resources.\"\"\"\n        self.dispose()\n        return False\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.__del__","title":"__del__","text":"<pre><code>__del__() -&gt; None\n</code></pre> <p>Cleanup resources when garbage collected.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def __del__(self) -&gt; None:\n    \"\"\"Cleanup resources when garbage collected.\"\"\"\n    self.dispose()\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.__enter__","title":"__enter__","text":"<pre><code>__enter__() -&gt; 'SchemaORM'\n</code></pre> <p>Context manager entry.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def __enter__(self) -&gt; \"SchemaORM\":\n    \"\"\"Context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.__exit__","title":"__exit__","text":"<pre><code>__exit__(\n    exc_type, exc_val, exc_tb\n) -&gt; bool\n</code></pre> <p>Context manager exit - dispose resources.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb) -&gt; bool:\n    \"\"\"Context manager exit - dispose resources.\"\"\"\n    self.dispose()\n    return False\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.__init__","title":"__init__","text":"<pre><code>__init__(\n    engine: Engine,\n    metadata: MetaData,\n    Base: AutomapBase,\n    model: Model,\n    schemas: list[str],\n    class_prefix: str,\n    use_schemas: bool = True,\n)\n</code></pre> <p>Initialize SchemaORM container.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>Engine</code> <p>SQLAlchemy Engine.</p> required <code>metadata</code> <code>MetaData</code> <p>SQLAlchemy MetaData with tables.</p> required <code>Base</code> <code>AutomapBase</code> <p>Automap base with ORM classes.</p> required <code>model</code> <code>Model</code> <p>Source ERMrest Model.</p> required <code>schemas</code> <code>list[str]</code> <p>Schemas that were included.</p> required <code>class_prefix</code> <code>str</code> <p>Prefix used for ORM class names.</p> required <code>use_schemas</code> <code>bool</code> <p>Whether schema prefixes are used (False for in-memory).</p> <code>True</code> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def __init__(\n    self,\n    engine: Engine,\n    metadata: MetaData,\n    Base: AutomapBase,\n    model: Model,\n    schemas: list[str],\n    class_prefix: str,\n    use_schemas: bool = True,\n):\n    \"\"\"Initialize SchemaORM container.\n\n    Args:\n        engine: SQLAlchemy Engine.\n        metadata: SQLAlchemy MetaData with tables.\n        Base: Automap base with ORM classes.\n        model: Source ERMrest Model.\n        schemas: Schemas that were included.\n        class_prefix: Prefix used for ORM class names.\n        use_schemas: Whether schema prefixes are used (False for in-memory).\n    \"\"\"\n    self.engine = engine\n    self.metadata = metadata\n    self.Base = Base\n    self.model = model\n    self.schemas = schemas\n    self._class_prefix = class_prefix\n    self._use_schemas = use_schemas\n    self._disposed = False\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.dispose","title":"dispose","text":"<pre><code>dispose() -&gt; None\n</code></pre> <p>Dispose of SQLAlchemy resources.</p> <p>Call this when done with the database to properly clean up connections. After calling dispose(), the instance should not be used further.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def dispose(self) -&gt; None:\n    \"\"\"Dispose of SQLAlchemy resources.\n\n    Call this when done with the database to properly clean up connections.\n    After calling dispose(), the instance should not be used further.\n    \"\"\"\n    if self._disposed:\n        return\n\n    if hasattr(self, \"Base\") and self.Base is not None:\n        self.Base.registry.dispose()\n    if hasattr(self, \"engine\") and self.engine is not None:\n        self.engine.dispose()\n\n    self._disposed = True\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.find_table","title":"find_table","text":"<pre><code>find_table(table_name: str) -&gt; SQLTable\n</code></pre> <p>Find a table by name.</p> <p>Handles both schema.table format and schema_table format (for in-memory databases).</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name, with or without schema prefix. Can be \"schema.table\", \"schema_table\", or just \"table\".</p> required <p>Returns:</p> Type Description <code>Table</code> <p>SQLAlchemy Table object.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If table not found.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def find_table(self, table_name: str) -&gt; SQLTable:\n    \"\"\"Find a table by name.\n\n    Handles both schema.table format and schema_table format (for in-memory databases).\n\n    Args:\n        table_name: Table name, with or without schema prefix.\n            Can be \"schema.table\", \"schema_table\", or just \"table\".\n\n    Returns:\n        SQLAlchemy Table object.\n\n    Raises:\n        KeyError: If table not found.\n    \"\"\"\n    # Try exact match first\n    if table_name in self.metadata.tables:\n        return self.metadata.tables[table_name]\n\n    # Try converting schema.table to schema_table format (for in-memory)\n    if \".\" in table_name and not self._use_schemas:\n        converted_name = table_name.replace(\".\", \"_\").replace(\"-\", \"_\")\n        if converted_name in self.metadata.tables:\n            return self.metadata.tables[converted_name]\n\n    # Try matching just the table name part\n    for full_name, table in self.metadata.tables.items():\n        # Handle . separator (file-based)\n        if \".\" in full_name and full_name.split(\".\")[-1] == table_name:\n            return table\n        # Handle _ separator (in-memory) - match suffix after first _\n        if \"_\" in full_name and \".\" not in full_name:\n            # Check if table_name matches the part after schema prefix\n            parts = full_name.split(\"_\", 1)\n            if len(parts) &gt; 1 and parts[1] == table_name:\n                return table\n            # Also check if it ends with the table name\n            if full_name.endswith(f\"_{table_name}\"):\n                return table\n\n    raise KeyError(f\"Table {table_name} not found\")\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.get_association_class","title":"get_association_class","text":"<pre><code>get_association_class(\n    left_cls: Type[Any],\n    right_cls: Type[Any],\n) -&gt; tuple[Any, Any, Any] | None\n</code></pre> <p>Find an association class connecting two ORM classes.</p> <p>Parameters:</p> Name Type Description Default <code>left_cls</code> <code>Type[Any]</code> <p>First ORM class.</p> required <code>right_cls</code> <code>Type[Any]</code> <p>Second ORM class.</p> required <p>Returns:</p> Type Description <code>tuple[Any, Any, Any] | None</code> <p>Tuple of (association_class, left_relationship, right_relationship),</p> <code>tuple[Any, Any, Any] | None</code> <p>or None if no association found.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def get_association_class(\n    self,\n    left_cls: Type[Any],\n    right_cls: Type[Any],\n) -&gt; tuple[Any, Any, Any] | None:\n    \"\"\"Find an association class connecting two ORM classes.\n\n    Args:\n        left_cls: First ORM class.\n        right_cls: Second ORM class.\n\n    Returns:\n        Tuple of (association_class, left_relationship, right_relationship),\n        or None if no association found.\n    \"\"\"\n    for _, left_rel in inspect(left_cls).relationships.items():\n        mid_cls = left_rel.mapper.class_\n        is_assoc = self.is_association_table(mid_cls, return_fkeys=True)\n\n        if not is_assoc:\n            continue\n\n        assoc_local_columns_left = list(is_assoc)[0].local_columns\n        assoc_local_columns_right = list(is_assoc)[1].local_columns\n\n        found_left = found_right = False\n\n        for r in inspect(left_cls).relationships.values():\n            remote_side = list(r.remote_side)[0]\n            if remote_side in assoc_local_columns_left:\n                found_left = r\n            if remote_side in assoc_local_columns_right:\n                found_left = r\n                # Swap if backwards\n                assoc_local_columns_left, assoc_local_columns_right = (\n                    assoc_local_columns_right,\n                    assoc_local_columns_left,\n                )\n\n        for r in inspect(right_cls).relationships.values():\n            remote_side = list(r.remote_side)[0]\n            if remote_side in assoc_local_columns_right:\n                found_right = r\n\n        if found_left and found_right:\n            return mid_cls, found_left.class_attribute, found_right.class_attribute\n\n    return None\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.get_orm_class","title":"get_orm_class","text":"<pre><code>get_orm_class(\n    table_name: str,\n) -&gt; Any | None\n</code></pre> <p>Get the ORM class for a table by name.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name, with or without schema prefix.</p> required <p>Returns:</p> Type Description <code>Any | None</code> <p>SQLAlchemy ORM class for the table.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If table not found.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def get_orm_class(self, table_name: str) -&gt; Any | None:\n    \"\"\"Get the ORM class for a table by name.\n\n    Args:\n        table_name: Table name, with or without schema prefix.\n\n    Returns:\n        SQLAlchemy ORM class for the table.\n\n    Raises:\n        KeyError: If table not found.\n    \"\"\"\n    sql_table = self.find_table(table_name)\n    return self.get_orm_class_for_table(sql_table)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.get_orm_class_for_table","title":"get_orm_class_for_table","text":"<pre><code>get_orm_class_for_table(\n    table: Table | Table | str,\n) -&gt; Any | None\n</code></pre> <p>Get the ORM class for a table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table | Table | str</code> <p>SQLAlchemy Table, Deriva Table, or table name.</p> required <p>Returns:</p> Type Description <code>Any | None</code> <p>SQLAlchemy ORM class, or None if not found.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def get_orm_class_for_table(self, table: SQLTable | DerivaTable | str) -&gt; Any | None:\n    \"\"\"Get the ORM class for a table.\n\n    Args:\n        table: SQLAlchemy Table, Deriva Table, or table name.\n\n    Returns:\n        SQLAlchemy ORM class, or None if not found.\n    \"\"\"\n    if isinstance(table, DerivaTable):\n        # Try schema.table format first (file-based), then schema_table (in-memory)\n        table_key = f\"{table.schema.name}.{table.name}\"\n        table = self.metadata.tables.get(table_key)\n        if table is None and not self._use_schemas:\n            # Try underscore format for in-memory databases\n            table_key = f\"{table.schema.name}_{table.name}\".replace(\"-\", \"_\")\n            table = self.metadata.tables.get(table_key)\n    if isinstance(table, str):\n        table = self.find_table(table)\n    if table is None:\n        return None\n\n    for mapper in self.Base.registry.mappers:\n        if mapper.persist_selectable is table or table in mapper.tables:\n            return mapper.class_\n    return None\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.get_table_contents","title":"get_table_contents","text":"<pre><code>get_table_contents(\n    table: str,\n) -&gt; Generator[\n    dict[str, Any], None, None\n]\n</code></pre> <p>Retrieve all rows from a table as dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name (with or without schema prefix).</p> required <p>Yields:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary for each row with column names as keys.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def get_table_contents(self, table: str) -&gt; Generator[dict[str, Any], None, None]:\n    \"\"\"Retrieve all rows from a table as dictionaries.\n\n    Args:\n        table: Table name (with or without schema prefix).\n\n    Yields:\n        Dictionary for each row with column names as keys.\n    \"\"\"\n    sql_table = self.find_table(table)\n    with self.engine.connect() as conn:\n        result = conn.execute(select(sql_table))\n        for row in result.mappings():\n            yield dict(row)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.is_association_table","title":"is_association_table  <code>staticmethod</code>","text":"<pre><code>is_association_table(\n    table_class,\n    min_arity: int = 2,\n    max_arity: int = 2,\n    unqualified: bool = True,\n    pure: bool = True,\n    no_overlap: bool = True,\n    return_fkeys: bool = False,\n)\n</code></pre> <p>Check if an ORM class represents an association table.</p> <p>An association table links two or more tables through foreign keys, with a composite unique key covering those foreign keys.</p> <p>Parameters:</p> Name Type Description Default <code>table_class</code> <p>SQLAlchemy ORM class to check.</p> required <code>min_arity</code> <code>int</code> <p>Minimum number of foreign keys (default 2).</p> <code>2</code> <code>max_arity</code> <code>int</code> <p>Maximum number of foreign keys (default 2).</p> <code>2</code> <code>unqualified</code> <code>bool</code> <p>If True, reject associations with extra key columns.</p> <code>True</code> <code>pure</code> <code>bool</code> <p>If True, reject associations with extra non-key columns.</p> <code>True</code> <code>no_overlap</code> <code>bool</code> <p>If True, reject associations with shared FK columns.</p> <code>True</code> <code>return_fkeys</code> <code>bool</code> <p>If True, return the foreign keys instead of arity.</p> <code>False</code> <p>Returns:</p> Type Description <p>If return_fkeys=False: Integer arity if association, False otherwise.</p> <p>If return_fkeys=True: Set of foreign keys if association, False otherwise.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>@staticmethod\ndef is_association_table(\n    table_class,\n    min_arity: int = 2,\n    max_arity: int = 2,\n    unqualified: bool = True,\n    pure: bool = True,\n    no_overlap: bool = True,\n    return_fkeys: bool = False,\n):\n    \"\"\"Check if an ORM class represents an association table.\n\n    An association table links two or more tables through foreign keys,\n    with a composite unique key covering those foreign keys.\n\n    Args:\n        table_class: SQLAlchemy ORM class to check.\n        min_arity: Minimum number of foreign keys (default 2).\n        max_arity: Maximum number of foreign keys (default 2).\n        unqualified: If True, reject associations with extra key columns.\n        pure: If True, reject associations with extra non-key columns.\n        no_overlap: If True, reject associations with shared FK columns.\n        return_fkeys: If True, return the foreign keys instead of arity.\n\n    Returns:\n        If return_fkeys=False: Integer arity if association, False otherwise.\n        If return_fkeys=True: Set of foreign keys if association, False otherwise.\n    \"\"\"\n    if min_arity &lt; 2:\n        raise ValueError(\"An association cannot have arity &lt; 2\")\n    if max_arity is not None and max_arity &lt; min_arity:\n        raise ValueError(\"max_arity cannot be less than min_arity\")\n\n    mapper = inspect(table_class).mapper\n    system_cols = {\"RID\", \"RCT\", \"RMT\", \"RCB\", \"RMB\"}\n\n    non_sys_cols = {\n        col.name for col in mapper.columns if col.name not in system_cols\n    }\n\n    unique_columns = [\n        {c.name for c in constraint.columns}\n        for constraint in inspect(table_class).local_table.constraints\n        if isinstance(constraint, SQLUniqueConstraint)\n    ]\n\n    non_sys_key_colsets = {\n        frozenset(uc)\n        for uc in unique_columns\n        if uc.issubset(non_sys_cols) and len(uc) &gt; 1\n    }\n\n    if not non_sys_key_colsets:\n        return False\n\n    # Choose longest compound key\n    row_key = sorted(non_sys_key_colsets, key=lambda s: len(s), reverse=True)[0]\n    foreign_keys = list(inspect(table_class).relationships.values())\n\n    covered_fkeys = {\n        fkey for fkey in foreign_keys\n        if {c.name for c in fkey.local_columns}.issubset(row_key)\n    }\n    covered_fkey_cols = set()\n\n    if len(covered_fkeys) &lt; min_arity:\n        return False\n    if max_arity is not None and len(covered_fkeys) &gt; max_arity:\n        return False\n\n    for fkey in covered_fkeys:\n        fkcols = {c.name for c in fkey.local_columns}\n        if no_overlap and fkcols.intersection(covered_fkey_cols):\n            return False\n        covered_fkey_cols.update(fkcols)\n\n    if unqualified and row_key.difference(covered_fkey_cols):\n        return False\n\n    if pure and non_sys_cols.difference(row_key):\n        return False\n\n    return covered_fkeys if return_fkeys else len(covered_fkeys)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SchemaORM.list_tables","title":"list_tables","text":"<pre><code>list_tables() -&gt; list[str]\n</code></pre> <p>List all tables in the database.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of fully-qualified table names (schema.table), sorted.</p> Source code in <code>src/deriva_ml/model/schema_builder.py</code> <pre><code>def list_tables(self) -&gt; list[str]:\n    \"\"\"List all tables in the database.\n\n    Returns:\n        List of fully-qualified table names (schema.table), sorted.\n    \"\"\"\n    tables = list(self.metadata.tables.keys())\n    tables.sort()\n    return tables\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SortKey","title":"SortKey  <code>dataclass</code>","text":"<p>A sort key for row ordering.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Column name to sort by</p> required <code>descending</code> <code>bool</code> <p>Sort in descending order (default False)</p> <code>False</code> Example <p>SortKey(\"Name\")  # Ascending SortKey(\"Created\", descending=True)  # Descending</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass SortKey:\n    \"\"\"A sort key for row ordering.\n\n    Args:\n        column: Column name to sort by\n        descending: Sort in descending order (default False)\n\n    Example:\n        &gt;&gt;&gt; SortKey(\"Name\")  # Ascending\n        &gt;&gt;&gt; SortKey(\"Created\", descending=True)  # Descending\n    \"\"\"\n    column: str\n    descending: bool = False\n\n    def to_dict(self) -&gt; dict[str, Any] | str:\n        \"\"\"Convert to dict or string (if ascending).\"\"\"\n        if self.descending:\n            return {\"column\": self.column, \"descending\": True}\n        return self.column\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.SortKey.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any] | str\n</code></pre> <p>Convert to dict or string (if ascending).</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any] | str:\n    \"\"\"Convert to dict or string (if ascending).\"\"\"\n    if self.descending:\n        return {\"column\": self.column, \"descending\": True}\n    return self.column\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.TableDisplay","title":"TableDisplay  <code>dataclass</code>","text":"<p>               Bases: <code>AnnotationBuilder</code></p> <p>Table-display annotation builder.</p> <p>Controls table-level display options like row naming and ordering.</p> Example <p>td = TableDisplay() td.row_name(row_markdown_pattern=\"{{{Name}}} ({{{Species}}})\") td.compact(row_order=[SortKey(\"Name\")])</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass TableDisplay(AnnotationBuilder):\n    \"\"\"Table-display annotation builder.\n\n    Controls table-level display options like row naming and ordering.\n\n    Example:\n        &gt;&gt;&gt; td = TableDisplay()\n        &gt;&gt;&gt; td.row_name(row_markdown_pattern=\"{{{Name}}} ({{{Species}}})\")\n        &gt;&gt;&gt; td.compact(row_order=[SortKey(\"Name\")])\n    \"\"\"\n    tag = TAG_TABLE_DISPLAY\n\n    _contexts: dict[str, TableDisplayOptions | str | None] = field(default_factory=dict)\n\n    def set_context(\n        self,\n        context: str,\n        options: TableDisplayOptions | str | None\n    ) -&gt; \"TableDisplay\":\n        \"\"\"Set options for a context.\"\"\"\n        self._contexts[context] = options\n        return self\n\n    def row_name(\n        self,\n        row_markdown_pattern: str,\n        template_engine: TemplateEngine | None = None\n    ) -&gt; \"TableDisplay\":\n        \"\"\"Set row name pattern (used in foreign key dropdowns, etc.).\"\"\"\n        return self.set_context(\n            CONTEXT_ROW_NAME,\n            TableDisplayOptions(\n                row_markdown_pattern=row_markdown_pattern,\n                template_engine=template_engine\n            )\n        )\n\n    def compact(self, options: TableDisplayOptions) -&gt; \"TableDisplay\":\n        \"\"\"Set options for compact (list) view.\"\"\"\n        return self.set_context(CONTEXT_COMPACT, options)\n\n    def detailed(self, options: TableDisplayOptions) -&gt; \"TableDisplay\":\n        \"\"\"Set options for detailed (record) view.\"\"\"\n        return self.set_context(CONTEXT_DETAILED, options)\n\n    def default(self, options: TableDisplayOptions) -&gt; \"TableDisplay\":\n        \"\"\"Set default options.\"\"\"\n        return self.set_context(CONTEXT_DEFAULT, options)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        for context, options in self._contexts.items():\n            if options is None:\n                result[context] = None\n            elif isinstance(options, str):\n                result[context] = options\n            else:\n                result[context] = options.to_dict()\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.TableDisplay.compact","title":"compact","text":"<pre><code>compact(\n    options: TableDisplayOptions,\n) -&gt; \"TableDisplay\"\n</code></pre> <p>Set options for compact (list) view.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def compact(self, options: TableDisplayOptions) -&gt; \"TableDisplay\":\n    \"\"\"Set options for compact (list) view.\"\"\"\n    return self.set_context(CONTEXT_COMPACT, options)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.TableDisplay.default","title":"default","text":"<pre><code>default(\n    options: TableDisplayOptions,\n) -&gt; \"TableDisplay\"\n</code></pre> <p>Set default options.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def default(self, options: TableDisplayOptions) -&gt; \"TableDisplay\":\n    \"\"\"Set default options.\"\"\"\n    return self.set_context(CONTEXT_DEFAULT, options)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.TableDisplay.detailed","title":"detailed","text":"<pre><code>detailed(\n    options: TableDisplayOptions,\n) -&gt; \"TableDisplay\"\n</code></pre> <p>Set options for detailed (record) view.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def detailed(self, options: TableDisplayOptions) -&gt; \"TableDisplay\":\n    \"\"\"Set options for detailed (record) view.\"\"\"\n    return self.set_context(CONTEXT_DETAILED, options)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.TableDisplay.row_name","title":"row_name","text":"<pre><code>row_name(\n    row_markdown_pattern: str,\n    template_engine: TemplateEngine\n    | None = None,\n) -&gt; \"TableDisplay\"\n</code></pre> <p>Set row name pattern (used in foreign key dropdowns, etc.).</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def row_name(\n    self,\n    row_markdown_pattern: str,\n    template_engine: TemplateEngine | None = None\n) -&gt; \"TableDisplay\":\n    \"\"\"Set row name pattern (used in foreign key dropdowns, etc.).\"\"\"\n    return self.set_context(\n        CONTEXT_ROW_NAME,\n        TableDisplayOptions(\n            row_markdown_pattern=row_markdown_pattern,\n            template_engine=template_engine\n        )\n    )\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.TableDisplay.set_context","title":"set_context","text":"<pre><code>set_context(\n    context: str,\n    options: TableDisplayOptions\n    | str\n    | None,\n) -&gt; \"TableDisplay\"\n</code></pre> <p>Set options for a context.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def set_context(\n    self,\n    context: str,\n    options: TableDisplayOptions | str | None\n) -&gt; \"TableDisplay\":\n    \"\"\"Set options for a context.\"\"\"\n    self._contexts[context] = options\n    return self\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.TableDisplayOptions","title":"TableDisplayOptions  <code>dataclass</code>","text":"<p>Options for a single table display context.</p> <p>Parameters:</p> Name Type Description Default <code>row_order</code> <code>list[SortKey] | None</code> <p>Sort order for rows</p> <code>None</code> <code>page_size</code> <code>int | None</code> <p>Number of rows per page</p> <code>None</code> <code>row_markdown_pattern</code> <code>str | None</code> <p>Template for row names</p> <code>None</code> <code>page_markdown_pattern</code> <code>str | None</code> <p>Template for page header</p> <code>None</code> <code>separator_markdown</code> <code>str | None</code> <p>Template between rows</p> <code>None</code> <code>prefix_markdown</code> <code>str | None</code> <p>Template before rows</p> <code>None</code> <code>suffix_markdown</code> <code>str | None</code> <p>Template after rows</p> <code>None</code> <code>template_engine</code> <code>TemplateEngine | None</code> <p>Template engine for patterns</p> <code>None</code> <code>collapse_toc_panel</code> <code>bool | None</code> <p>Collapse TOC panel</p> <code>None</code> <code>hide_column_headers</code> <code>bool | None</code> <p>Hide column headers</p> <code>None</code> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass TableDisplayOptions:\n    \"\"\"Options for a single table display context.\n\n    Args:\n        row_order: Sort order for rows\n        page_size: Number of rows per page\n        row_markdown_pattern: Template for row names\n        page_markdown_pattern: Template for page header\n        separator_markdown: Template between rows\n        prefix_markdown: Template before rows\n        suffix_markdown: Template after rows\n        template_engine: Template engine for patterns\n        collapse_toc_panel: Collapse TOC panel\n        hide_column_headers: Hide column headers\n    \"\"\"\n    row_order: list[SortKey] | None = None\n    page_size: int | None = None\n    row_markdown_pattern: str | None = None\n    page_markdown_pattern: str | None = None\n    separator_markdown: str | None = None\n    prefix_markdown: str | None = None\n    suffix_markdown: str | None = None\n    template_engine: TemplateEngine | None = None\n    collapse_toc_panel: bool | None = None\n    hide_column_headers: bool | None = None\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        if self.row_order is not None:\n            result[\"row_order\"] = [\n                k.to_dict() if isinstance(k, SortKey) else k\n                for k in self.row_order\n            ]\n        if self.page_size is not None:\n            result[\"page_size\"] = self.page_size\n        if self.row_markdown_pattern is not None:\n            result[\"row_markdown_pattern\"] = self.row_markdown_pattern\n        if self.page_markdown_pattern is not None:\n            result[\"page_markdown_pattern\"] = self.page_markdown_pattern\n        if self.separator_markdown is not None:\n            result[\"separator_markdown\"] = self.separator_markdown\n        if self.prefix_markdown is not None:\n            result[\"prefix_markdown\"] = self.prefix_markdown\n        if self.suffix_markdown is not None:\n            result[\"suffix_markdown\"] = self.suffix_markdown\n        if self.template_engine is not None:\n            result[\"template_engine\"] = self.template_engine.value\n        if self.collapse_toc_panel is not None:\n            result[\"collapse_toc_panel\"] = self.collapse_toc_panel\n        if self.hide_column_headers is not None:\n            result[\"hide_column_headers\"] = self.hide_column_headers\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.TemplateEngine","title":"TemplateEngine","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Template engine for markdown patterns.</p> <p>Attributes:</p> Name Type Description <code>HANDLEBARS</code> <p>Use Handlebars.js templating (recommended, more features)</p> <code>MUSTACHE</code> <p>Use Mustache templating (simpler, fewer features)</p> Example <p>display = PseudoColumnDisplay( ...     markdown_pattern=\"{{{Name}}}\", ...     template_engine=TemplateEngine.HANDLEBARS ... )</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>class TemplateEngine(str, Enum):\n    \"\"\"Template engine for markdown patterns.\n\n    Attributes:\n        HANDLEBARS: Use Handlebars.js templating (recommended, more features)\n        MUSTACHE: Use Mustache templating (simpler, fewer features)\n\n    Example:\n        &gt;&gt;&gt; display = PseudoColumnDisplay(\n        ...     markdown_pattern=\"[{{{Name}}}]({{{URL}}})\",\n        ...     template_engine=TemplateEngine.HANDLEBARS\n        ... )\n    \"\"\"\n    HANDLEBARS = \"handlebars\"\n    MUSTACHE = \"mustache\"\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleColumns","title":"VisibleColumns  <code>dataclass</code>","text":"<p>               Bases: <code>AnnotationBuilder</code></p> <p>Visible-columns annotation builder.</p> <p>Controls which columns appear in different UI contexts and their order. This is one of the most commonly used annotations for customizing the Chaise interface.</p> <p>Column entries can be: - Column names (strings): \"Name\", \"RID\", \"Description\" - Foreign key references: fk_constraint(\"schema\", \"constraint_name\") - Pseudo-columns: PseudoColumn(...) for computed/derived values</p> <p>Contexts: - <code>compact</code>: Table/list views (search results, data browser) - <code>detailed</code>: Single record view (full record page) - <code>entry</code>: Create/edit forms - <code>entry/create</code>: Create form only - <code>entry/edit</code>: Edit form only - <code>*</code>: Default for all contexts</p> Example <p>Basic column lists for different contexts::</p> <pre><code>&gt;&gt;&gt; vc = VisibleColumns()\n&gt;&gt;&gt; vc.compact([\"RID\", \"Name\", \"Status\"])\n&gt;&gt;&gt; vc.detailed([\"RID\", \"Name\", \"Status\", \"Description\", \"Created\"])\n&gt;&gt;&gt; vc.entry([\"Name\", \"Status\", \"Description\"])\n&gt;&gt;&gt; handle.set_annotation(vc)\n</code></pre> <p>Method chaining::</p> <pre><code>&gt;&gt;&gt; vc = (VisibleColumns()\n...     .compact([\"RID\", \"Name\"])\n...     .detailed([\"RID\", \"Name\", \"Description\"])\n...     .entry([\"Name\", \"Description\"]))\n</code></pre> <p>Including foreign key references::</p> <pre><code>&gt;&gt;&gt; vc = VisibleColumns()\n&gt;&gt;&gt; vc.compact([\n...     \"RID\",\n...     \"Name\",\n...     fk_constraint(\"domain\", \"Subject_Species_fkey\"),\n... ])\n</code></pre> <p>With pseudo-columns for computed values::</p> <pre><code>&gt;&gt;&gt; vc = VisibleColumns()\n&gt;&gt;&gt; vc.compact([\n...     \"RID\",\n...     \"Name\",\n...     PseudoColumn(\n...         source=[InboundFK(\"domain\", \"Sample_Subject_fkey\"), \"RID\"],\n...         aggregate=Aggregate.CNT,\n...         markdown_name=\"Samples\"\n...     ),\n... ])\n</code></pre> <p>Context inheritance (reference another context)::</p> <pre><code>&gt;&gt;&gt; vc = VisibleColumns()\n&gt;&gt;&gt; vc.compact([\"RID\", \"Name\"])\n&gt;&gt;&gt; vc.set_context(\"compact/brief\", \"compact\")  # Inherit from compact\n</code></pre> <p>With faceted search (filter context)::</p> <pre><code>&gt;&gt;&gt; vc = VisibleColumns()\n&gt;&gt;&gt; vc.compact([\"RID\", \"Name\", \"Status\"])\n&gt;&gt;&gt; facets = FacetList()\n&gt;&gt;&gt; facets.add(Facet(source=\"Status\", open=True))\n&gt;&gt;&gt; vc._contexts[\"filter\"] = facets.to_dict()\n</code></pre> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass VisibleColumns(AnnotationBuilder):\n    \"\"\"Visible-columns annotation builder.\n\n    Controls which columns appear in different UI contexts and their order.\n    This is one of the most commonly used annotations for customizing the\n    Chaise interface.\n\n    Column entries can be:\n    - Column names (strings): \"Name\", \"RID\", \"Description\"\n    - Foreign key references: fk_constraint(\"schema\", \"constraint_name\")\n    - Pseudo-columns: PseudoColumn(...) for computed/derived values\n\n    Contexts:\n    - ``compact``: Table/list views (search results, data browser)\n    - ``detailed``: Single record view (full record page)\n    - ``entry``: Create/edit forms\n    - ``entry/create``: Create form only\n    - ``entry/edit``: Edit form only\n    - ``*``: Default for all contexts\n\n    Example:\n        Basic column lists for different contexts::\n\n            &gt;&gt;&gt; vc = VisibleColumns()\n            &gt;&gt;&gt; vc.compact([\"RID\", \"Name\", \"Status\"])\n            &gt;&gt;&gt; vc.detailed([\"RID\", \"Name\", \"Status\", \"Description\", \"Created\"])\n            &gt;&gt;&gt; vc.entry([\"Name\", \"Status\", \"Description\"])\n            &gt;&gt;&gt; handle.set_annotation(vc)\n\n        Method chaining::\n\n            &gt;&gt;&gt; vc = (VisibleColumns()\n            ...     .compact([\"RID\", \"Name\"])\n            ...     .detailed([\"RID\", \"Name\", \"Description\"])\n            ...     .entry([\"Name\", \"Description\"]))\n\n        Including foreign key references::\n\n            &gt;&gt;&gt; vc = VisibleColumns()\n            &gt;&gt;&gt; vc.compact([\n            ...     \"RID\",\n            ...     \"Name\",\n            ...     fk_constraint(\"domain\", \"Subject_Species_fkey\"),\n            ... ])\n\n        With pseudo-columns for computed values::\n\n            &gt;&gt;&gt; vc = VisibleColumns()\n            &gt;&gt;&gt; vc.compact([\n            ...     \"RID\",\n            ...     \"Name\",\n            ...     PseudoColumn(\n            ...         source=[InboundFK(\"domain\", \"Sample_Subject_fkey\"), \"RID\"],\n            ...         aggregate=Aggregate.CNT,\n            ...         markdown_name=\"Samples\"\n            ...     ),\n            ... ])\n\n        Context inheritance (reference another context)::\n\n            &gt;&gt;&gt; vc = VisibleColumns()\n            &gt;&gt;&gt; vc.compact([\"RID\", \"Name\"])\n            &gt;&gt;&gt; vc.set_context(\"compact/brief\", \"compact\")  # Inherit from compact\n\n        With faceted search (filter context)::\n\n            &gt;&gt;&gt; vc = VisibleColumns()\n            &gt;&gt;&gt; vc.compact([\"RID\", \"Name\", \"Status\"])\n            &gt;&gt;&gt; facets = FacetList()\n            &gt;&gt;&gt; facets.add(Facet(source=\"Status\", open=True))\n            &gt;&gt;&gt; vc._contexts[\"filter\"] = facets.to_dict()\n    \"\"\"\n    tag = TAG_VISIBLE_COLUMNS\n\n    _contexts: dict[str, list[ColumnEntry] | str] = field(default_factory=dict)\n\n    def set_context(\n        self,\n        context: str,\n        columns: list[ColumnEntry] | str\n    ) -&gt; \"VisibleColumns\":\n        \"\"\"Set columns for a context.\n\n        Args:\n            context: Context name (e.g., \"compact\", \"detailed\", \"*\")\n            columns: List of columns, or string referencing another context\n\n        Returns:\n            Self for chaining\n        \"\"\"\n        self._contexts[context] = columns\n        return self\n\n    def compact(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n        \"\"\"Set columns for compact (list) view.\"\"\"\n        return self.set_context(CONTEXT_COMPACT, columns)\n\n    def detailed(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n        \"\"\"Set columns for detailed (record) view.\"\"\"\n        return self.set_context(CONTEXT_DETAILED, columns)\n\n    def entry(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n        \"\"\"Set columns for entry (create/edit) forms.\"\"\"\n        return self.set_context(CONTEXT_ENTRY, columns)\n\n    def entry_create(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n        \"\"\"Set columns for create form only.\"\"\"\n        return self.set_context(CONTEXT_ENTRY_CREATE, columns)\n\n    def entry_edit(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n        \"\"\"Set columns for edit form only.\"\"\"\n        return self.set_context(CONTEXT_ENTRY_EDIT, columns)\n\n    def default(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n        \"\"\"Set default columns for all contexts.\"\"\"\n        return self.set_context(CONTEXT_DEFAULT, columns)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        for context, columns in self._contexts.items():\n            if isinstance(columns, str):\n                result[context] = columns\n            else:\n                result[context] = [\n                    c.to_dict() if isinstance(c, PseudoColumn) else c\n                    for c in columns\n                ]\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleColumns.compact","title":"compact","text":"<pre><code>compact(\n    columns: list[ColumnEntry],\n) -&gt; \"VisibleColumns\"\n</code></pre> <p>Set columns for compact (list) view.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def compact(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n    \"\"\"Set columns for compact (list) view.\"\"\"\n    return self.set_context(CONTEXT_COMPACT, columns)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleColumns.default","title":"default","text":"<pre><code>default(\n    columns: list[ColumnEntry],\n) -&gt; \"VisibleColumns\"\n</code></pre> <p>Set default columns for all contexts.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def default(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n    \"\"\"Set default columns for all contexts.\"\"\"\n    return self.set_context(CONTEXT_DEFAULT, columns)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleColumns.detailed","title":"detailed","text":"<pre><code>detailed(\n    columns: list[ColumnEntry],\n) -&gt; \"VisibleColumns\"\n</code></pre> <p>Set columns for detailed (record) view.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def detailed(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n    \"\"\"Set columns for detailed (record) view.\"\"\"\n    return self.set_context(CONTEXT_DETAILED, columns)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleColumns.entry","title":"entry","text":"<pre><code>entry(\n    columns: list[ColumnEntry],\n) -&gt; \"VisibleColumns\"\n</code></pre> <p>Set columns for entry (create/edit) forms.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def entry(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n    \"\"\"Set columns for entry (create/edit) forms.\"\"\"\n    return self.set_context(CONTEXT_ENTRY, columns)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleColumns.entry_create","title":"entry_create","text":"<pre><code>entry_create(\n    columns: list[ColumnEntry],\n) -&gt; \"VisibleColumns\"\n</code></pre> <p>Set columns for create form only.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def entry_create(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n    \"\"\"Set columns for create form only.\"\"\"\n    return self.set_context(CONTEXT_ENTRY_CREATE, columns)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleColumns.entry_edit","title":"entry_edit","text":"<pre><code>entry_edit(\n    columns: list[ColumnEntry],\n) -&gt; \"VisibleColumns\"\n</code></pre> <p>Set columns for edit form only.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def entry_edit(self, columns: list[ColumnEntry]) -&gt; \"VisibleColumns\":\n    \"\"\"Set columns for edit form only.\"\"\"\n    return self.set_context(CONTEXT_ENTRY_EDIT, columns)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleColumns.set_context","title":"set_context","text":"<pre><code>set_context(\n    context: str,\n    columns: list[ColumnEntry] | str,\n) -&gt; \"VisibleColumns\"\n</code></pre> <p>Set columns for a context.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>str</code> <p>Context name (e.g., \"compact\", \"detailed\", \"*\")</p> required <code>columns</code> <code>list[ColumnEntry] | str</code> <p>List of columns, or string referencing another context</p> required <p>Returns:</p> Type Description <code>'VisibleColumns'</code> <p>Self for chaining</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def set_context(\n    self,\n    context: str,\n    columns: list[ColumnEntry] | str\n) -&gt; \"VisibleColumns\":\n    \"\"\"Set columns for a context.\n\n    Args:\n        context: Context name (e.g., \"compact\", \"detailed\", \"*\")\n        columns: List of columns, or string referencing another context\n\n    Returns:\n        Self for chaining\n    \"\"\"\n    self._contexts[context] = columns\n    return self\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleForeignKeys","title":"VisibleForeignKeys  <code>dataclass</code>","text":"<p>               Bases: <code>AnnotationBuilder</code></p> <p>Visible-foreign-keys annotation builder.</p> <p>Controls which related tables appear in the UI via inbound foreign keys.</p> Example <p>vfk = VisibleForeignKeys() vfk.detailed([ ...     fk_constraint(\"domain\", \"Image_Subject_fkey\"), ...     fk_constraint(\"domain\", \"Diagnosis_Subject_fkey\") ... ])</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>@dataclass\nclass VisibleForeignKeys(AnnotationBuilder):\n    \"\"\"Visible-foreign-keys annotation builder.\n\n    Controls which related tables appear in the UI via inbound foreign keys.\n\n    Example:\n        &gt;&gt;&gt; vfk = VisibleForeignKeys()\n        &gt;&gt;&gt; vfk.detailed([\n        ...     fk_constraint(\"domain\", \"Image_Subject_fkey\"),\n        ...     fk_constraint(\"domain\", \"Diagnosis_Subject_fkey\")\n        ... ])\n    \"\"\"\n    tag = TAG_VISIBLE_FOREIGN_KEYS\n\n    _contexts: dict[str, list[ForeignKeyEntry] | str] = field(default_factory=dict)\n\n    def set_context(\n        self,\n        context: str,\n        foreign_keys: list[ForeignKeyEntry] | str\n    ) -&gt; \"VisibleForeignKeys\":\n        \"\"\"Set foreign keys for a context.\"\"\"\n        self._contexts[context] = foreign_keys\n        return self\n\n    def detailed(self, foreign_keys: list[ForeignKeyEntry]) -&gt; \"VisibleForeignKeys\":\n        \"\"\"Set foreign keys for detailed view.\"\"\"\n        return self.set_context(CONTEXT_DETAILED, foreign_keys)\n\n    def default(self, foreign_keys: list[ForeignKeyEntry]) -&gt; \"VisibleForeignKeys\":\n        \"\"\"Set default foreign keys for all contexts.\"\"\"\n        return self.set_context(CONTEXT_DEFAULT, foreign_keys)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        result = {}\n        for context, fkeys in self._contexts.items():\n            if isinstance(fkeys, str):\n                result[context] = fkeys\n            else:\n                result[context] = [\n                    fk.to_dict() if isinstance(fk, PseudoColumn) else fk\n                    for fk in fkeys\n                ]\n        return result\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleForeignKeys.default","title":"default","text":"<pre><code>default(\n    foreign_keys: list[ForeignKeyEntry],\n) -&gt; \"VisibleForeignKeys\"\n</code></pre> <p>Set default foreign keys for all contexts.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def default(self, foreign_keys: list[ForeignKeyEntry]) -&gt; \"VisibleForeignKeys\":\n    \"\"\"Set default foreign keys for all contexts.\"\"\"\n    return self.set_context(CONTEXT_DEFAULT, foreign_keys)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleForeignKeys.detailed","title":"detailed","text":"<pre><code>detailed(\n    foreign_keys: list[ForeignKeyEntry],\n) -&gt; \"VisibleForeignKeys\"\n</code></pre> <p>Set foreign keys for detailed view.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def detailed(self, foreign_keys: list[ForeignKeyEntry]) -&gt; \"VisibleForeignKeys\":\n    \"\"\"Set foreign keys for detailed view.\"\"\"\n    return self.set_context(CONTEXT_DETAILED, foreign_keys)\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.VisibleForeignKeys.set_context","title":"set_context","text":"<pre><code>set_context(\n    context: str,\n    foreign_keys: list[ForeignKeyEntry]\n    | str,\n) -&gt; \"VisibleForeignKeys\"\n</code></pre> <p>Set foreign keys for a context.</p> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def set_context(\n    self,\n    context: str,\n    foreign_keys: list[ForeignKeyEntry] | str\n) -&gt; \"VisibleForeignKeys\":\n    \"\"\"Set foreign keys for a context.\"\"\"\n    self._contexts[context] = foreign_keys\n    return self\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name: str)\n</code></pre> <p>Lazy import for DatabaseModel and DerivaMLDatabase.</p> Source code in <code>src/deriva_ml/model/__init__.py</code> <pre><code>def __getattr__(name: str):\n    \"\"\"Lazy import for DatabaseModel and DerivaMLDatabase.\"\"\"\n    if name == \"DatabaseModel\":\n        from deriva_ml.model.database import DatabaseModel\n\n        return DatabaseModel\n    if name == \"DerivaMLDatabase\":\n        from deriva_ml.model.deriva_ml_database import DerivaMLDatabase\n\n        return DerivaMLDatabase\n    raise AttributeError(f\"module {__name__!r} has no attribute {name!r}\")\n</code></pre>"},{"location":"code-docs/deriva_model/#deriva_ml.model.fk_constraint","title":"fk_constraint","text":"<pre><code>fk_constraint(\n    schema: str, constraint: str\n) -&gt; list[str]\n</code></pre> <p>Create a foreign key constraint reference for visible-columns.</p> <p>Use this in visible-columns to include a foreign key column (showing the referenced row's name/link). This is different from InboundFK/OutboundFK which are used inside PseudoColumn source paths.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>str</code> <p>Schema name containing the FK constraint</p> required <code>constraint</code> <code>str</code> <p>Foreign key constraint name</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>[schema, constraint] list for use in visible-columns</p> Example <p>Include a foreign key in visible columns::</p> <pre><code>&gt;&gt;&gt; vc = VisibleColumns()\n&gt;&gt;&gt; vc.compact([\n...     \"RID\",\n...     \"Name\",\n...     fk_constraint(\"domain\", \"Subject_Species_fkey\"),  # Shows Species\n... ])\n</code></pre> <p>This is equivalent to the raw format::</p> <pre><code>&gt;&gt;&gt; vc.compact([\"RID\", \"Name\", [\"domain\", \"Subject_Species_fkey\"]])\n</code></pre> Source code in <code>src/deriva_ml/model/annotations.py</code> <pre><code>def fk_constraint(schema: str, constraint: str) -&gt; list[str]:\n    \"\"\"Create a foreign key constraint reference for visible-columns.\n\n    Use this in visible-columns to include a foreign key column (showing the\n    referenced row's name/link). This is different from InboundFK/OutboundFK\n    which are used inside PseudoColumn source paths.\n\n    Args:\n        schema: Schema name containing the FK constraint\n        constraint: Foreign key constraint name\n\n    Returns:\n        [schema, constraint] list for use in visible-columns\n\n    Example:\n        Include a foreign key in visible columns::\n\n            &gt;&gt;&gt; vc = VisibleColumns()\n            &gt;&gt;&gt; vc.compact([\n            ...     \"RID\",\n            ...     \"Name\",\n            ...     fk_constraint(\"domain\", \"Subject_Species_fkey\"),  # Shows Species\n            ... ])\n\n        This is equivalent to the raw format::\n\n            &gt;&gt;&gt; vc.compact([\"RID\", \"Name\", [\"domain\", \"Subject_Species_fkey\"]])\n    \"\"\"\n    return [schema, constraint]\n</code></pre>"},{"location":"code-docs/exceptions/","title":"Exceptions","text":"<p>DerivaML defines custom exceptions to provide clear error messages for common error conditions when working with catalogs, datasets, and executions.</p> <p>Custom exceptions for the DerivaML package.</p> <p>This module defines the exception hierarchy for DerivaML. All DerivaML-specific exceptions inherit from DerivaMLException, making it easy to catch all library errors with a single except clause.</p> Exception Hierarchy <p>DerivaMLException (base class for all DerivaML errors) \u2502 \u251c\u2500\u2500 DerivaMLConfigurationError (configuration and initialization) \u2502   \u251c\u2500\u2500 DerivaMLSchemaError (schema/catalog structure issues) \u2502   \u2514\u2500\u2500 DerivaMLAuthenticationError (authentication failures) \u2502 \u251c\u2500\u2500 DerivaMLDataError (data access and validation) \u2502   \u251c\u2500\u2500 DerivaMLNotFoundError (entity not found) \u2502   \u2502   \u251c\u2500\u2500 DerivaMLDatasetNotFound (dataset lookup failures) \u2502   \u2502   \u251c\u2500\u2500 DerivaMLTableNotFound (table lookup failures) \u2502   \u2502   \u2514\u2500\u2500 DerivaMLInvalidTerm (vocabulary term not found) \u2502   \u251c\u2500\u2500 DerivaMLTableTypeError (wrong table type) \u2502   \u251c\u2500\u2500 DerivaMLValidationError (data validation failures) \u2502   \u2514\u2500\u2500 DerivaMLCycleError (cycle detected in relationships) \u2502 \u251c\u2500\u2500 DerivaMLExecutionError (execution lifecycle) \u2502   \u251c\u2500\u2500 DerivaMLWorkflowError (workflow issues) \u2502   \u2514\u2500\u2500 DerivaMLUploadError (asset upload failures) \u2502 \u2514\u2500\u2500 DerivaMLReadOnlyError (write operation on read-only resource)</p> Example <p>from deriva_ml.core.exceptions import DerivaMLException, DerivaMLNotFoundError try: ...     dataset = ml.lookup_dataset(\"invalid_rid\") ... except DerivaMLDatasetNotFound as e: ...     print(f\"Dataset not found: {e}\") ... except DerivaMLNotFoundError as e: ...     print(f\"Entity not found: {e}\") ... except DerivaMLException as e: ...     print(f\"DerivaML error: {e}\")</p>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLAuthenticationError","title":"DerivaMLAuthenticationError","text":"<p>               Bases: <code>DerivaMLConfigurationError</code></p> <p>Exception raised for authentication failures.</p> <p>Raised when authentication with the catalog fails or credentials are invalid.</p> Example <p>raise DerivaMLAuthenticationError(\"Failed to authenticate with catalog\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLAuthenticationError(DerivaMLConfigurationError):\n    \"\"\"Exception raised for authentication failures.\n\n    Raised when authentication with the catalog fails or credentials are invalid.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLAuthenticationError(\"Failed to authenticate with catalog\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLConfigurationError","title":"DerivaMLConfigurationError","text":"<p>               Bases: <code>DerivaMLException</code></p> <p>Exception raised for configuration and initialization errors.</p> <p>Raised when there are issues with DerivaML configuration, catalog initialization, or schema setup.</p> Example <p>raise DerivaMLConfigurationError(\"Invalid catalog configuration\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLConfigurationError(DerivaMLException):\n    \"\"\"Exception raised for configuration and initialization errors.\n\n    Raised when there are issues with DerivaML configuration, catalog\n    initialization, or schema setup.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLConfigurationError(\"Invalid catalog configuration\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLCycleError","title":"DerivaMLCycleError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when a cycle is detected in relationships.</p> <p>Raised when creating dataset hierarchies or other relationships that would result in a circular dependency.</p> <p>Parameters:</p> Name Type Description Default <code>cycle_nodes</code> <code>list[str]</code> <p>List of nodes involved in the cycle.</p> required <code>msg</code> <code>str</code> <p>Additional context. Defaults to \"Cycle detected\".</p> <code>'Cycle detected'</code> Example <p>raise DerivaMLCycleError([\"Dataset1\", \"Dataset2\", \"Dataset1\"])</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLCycleError(DerivaMLDataError):\n    \"\"\"Exception raised when a cycle is detected in relationships.\n\n    Raised when creating dataset hierarchies or other relationships that\n    would result in a circular dependency.\n\n    Args:\n        cycle_nodes: List of nodes involved in the cycle.\n        msg: Additional context. Defaults to \"Cycle detected\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLCycleError([\"Dataset1\", \"Dataset2\", \"Dataset1\"])\n    \"\"\"\n\n    def __init__(self, cycle_nodes: list[str], msg: str = \"Cycle detected\") -&gt; None:\n        super().__init__(f\"{msg}: {cycle_nodes}\")\n        self.cycle_nodes = cycle_nodes\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLDataError","title":"DerivaMLDataError","text":"<p>               Bases: <code>DerivaMLException</code></p> <p>Exception raised for data access and validation issues.</p> <p>Base class for errors related to data lookup, validation, and integrity.</p> Example <p>raise DerivaMLDataError(\"Invalid data format\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLDataError(DerivaMLException):\n    \"\"\"Exception raised for data access and validation issues.\n\n    Base class for errors related to data lookup, validation, and integrity.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLDataError(\"Invalid data format\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLDatasetNotFound","title":"DerivaMLDatasetNotFound","text":"<p>               Bases: <code>DerivaMLNotFoundError</code></p> <p>Exception raised when a dataset cannot be found.</p> <p>Raised when attempting to look up a dataset that doesn't exist in the catalog or downloaded bag.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_rid</code> <code>str</code> <p>The RID of the dataset that was not found.</p> required <code>msg</code> <code>str</code> <p>Additional context. Defaults to \"Dataset not found\".</p> <code>'Dataset not found'</code> Example <p>raise DerivaMLDatasetNotFound(\"1-ABC\") DerivaMLDatasetNotFound: Dataset 1-ABC not found</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLDatasetNotFound(DerivaMLNotFoundError):\n    \"\"\"Exception raised when a dataset cannot be found.\n\n    Raised when attempting to look up a dataset that doesn't exist in the\n    catalog or downloaded bag.\n\n    Args:\n        dataset_rid: The RID of the dataset that was not found.\n        msg: Additional context. Defaults to \"Dataset not found\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLDatasetNotFound(\"1-ABC\")\n        DerivaMLDatasetNotFound: Dataset 1-ABC not found\n    \"\"\"\n\n    def __init__(self, dataset_rid: str, msg: str = \"Dataset not found\") -&gt; None:\n        super().__init__(f\"{msg}: {dataset_rid}\")\n        self.dataset_rid = dataset_rid\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLException","title":"DerivaMLException","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for all DerivaML errors.</p> <p>This is the root exception for all DerivaML-specific errors. Catching this exception will catch any error raised by the DerivaML library.</p> <p>Attributes:</p> Name Type Description <code>_msg</code> <p>The error message stored for later access.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>Descriptive error message. Defaults to empty string.</p> <code>''</code> Example <p>raise DerivaMLException(\"Failed to connect to catalog\") DerivaMLException: Failed to connect to catalog</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLException(Exception):\n    \"\"\"Base exception class for all DerivaML errors.\n\n    This is the root exception for all DerivaML-specific errors. Catching this\n    exception will catch any error raised by the DerivaML library.\n\n    Attributes:\n        _msg: The error message stored for later access.\n\n    Args:\n        msg: Descriptive error message. Defaults to empty string.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLException(\"Failed to connect to catalog\")\n        DerivaMLException: Failed to connect to catalog\n    \"\"\"\n\n    def __init__(self, msg: str = \"\") -&gt; None:\n        super().__init__(msg)\n        self._msg = msg\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLExecutionError","title":"DerivaMLExecutionError","text":"<p>               Bases: <code>DerivaMLException</code></p> <p>Exception raised for execution lifecycle issues.</p> <p>Base class for errors related to workflow execution, asset management, and provenance tracking.</p> Example <p>raise DerivaMLExecutionError(\"Execution failed to initialize\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLExecutionError(DerivaMLException):\n    \"\"\"Exception raised for execution lifecycle issues.\n\n    Base class for errors related to workflow execution, asset management,\n    and provenance tracking.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLExecutionError(\"Execution failed to initialize\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLInvalidTerm","title":"DerivaMLInvalidTerm","text":"<p>               Bases: <code>DerivaMLNotFoundError</code></p> <p>Exception raised when a vocabulary term is not found or invalid.</p> <p>Raised when attempting to look up or use a term that doesn't exist in a controlled vocabulary table, or when a term name/synonym cannot be resolved.</p> <p>Parameters:</p> Name Type Description Default <code>vocabulary</code> <code>str</code> <p>Name of the vocabulary table being searched.</p> required <code>term</code> <code>str</code> <p>The term name that was not found.</p> required <code>msg</code> <code>str</code> <p>Additional context about the error. Defaults to \"Term doesn't exist\".</p> <code>\"Term doesn't exist\"</code> Example <p>raise DerivaMLInvalidTerm(\"Diagnosis\", \"unknown_condition\") DerivaMLInvalidTerm: Invalid term unknown_condition in vocabulary Diagnosis: Term doesn't exist.</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLInvalidTerm(DerivaMLNotFoundError):\n    \"\"\"Exception raised when a vocabulary term is not found or invalid.\n\n    Raised when attempting to look up or use a term that doesn't exist in\n    a controlled vocabulary table, or when a term name/synonym cannot be resolved.\n\n    Args:\n        vocabulary: Name of the vocabulary table being searched.\n        term: The term name that was not found.\n        msg: Additional context about the error. Defaults to \"Term doesn't exist\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLInvalidTerm(\"Diagnosis\", \"unknown_condition\")\n        DerivaMLInvalidTerm: Invalid term unknown_condition in vocabulary Diagnosis: Term doesn't exist.\n    \"\"\"\n\n    def __init__(self, vocabulary: str, term: str, msg: str = \"Term doesn't exist\") -&gt; None:\n        super().__init__(f\"Invalid term {term} in vocabulary {vocabulary}: {msg}.\")\n        self.vocabulary = vocabulary\n        self.term = term\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLNotFoundError","title":"DerivaMLNotFoundError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when an entity cannot be found.</p> <p>Raised when a lookup operation fails to find the requested entity (dataset, table, term, etc.) in the catalog or bag.</p> Example <p>raise DerivaMLNotFoundError(\"Entity '1-ABC' not found in catalog\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLNotFoundError(DerivaMLDataError):\n    \"\"\"Exception raised when an entity cannot be found.\n\n    Raised when a lookup operation fails to find the requested entity\n    (dataset, table, term, etc.) in the catalog or bag.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLNotFoundError(\"Entity '1-ABC' not found in catalog\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLReadOnlyError","title":"DerivaMLReadOnlyError","text":"<p>               Bases: <code>DerivaMLException</code></p> <p>Exception raised when attempting write operations on read-only resources.</p> <p>Raised when attempting to modify data in a downloaded bag or other read-only context where write operations are not supported.</p> Example <p>raise DerivaMLReadOnlyError(\"Cannot create datasets in a downloaded bag\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLReadOnlyError(DerivaMLException):\n    \"\"\"Exception raised when attempting write operations on read-only resources.\n\n    Raised when attempting to modify data in a downloaded bag or other\n    read-only context where write operations are not supported.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLReadOnlyError(\"Cannot create datasets in a downloaded bag\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLSchemaError","title":"DerivaMLSchemaError","text":"<p>               Bases: <code>DerivaMLConfigurationError</code></p> <p>Exception raised for schema or catalog structure issues.</p> <p>Raised when the catalog schema is invalid, missing required tables, or has structural problems that prevent normal operation.</p> Example <p>raise DerivaMLSchemaError(\"Ambiguous domain schema: ['Schema1', 'Schema2']\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLSchemaError(DerivaMLConfigurationError):\n    \"\"\"Exception raised for schema or catalog structure issues.\n\n    Raised when the catalog schema is invalid, missing required tables,\n    or has structural problems that prevent normal operation.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLSchemaError(\"Ambiguous domain schema: ['Schema1', 'Schema2']\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLTableNotFound","title":"DerivaMLTableNotFound","text":"<p>               Bases: <code>DerivaMLNotFoundError</code></p> <p>Exception raised when a table cannot be found.</p> <p>Raised when attempting to access a table that doesn't exist in the catalog schema or downloaded bag.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table that was not found.</p> required <code>msg</code> <code>str</code> <p>Additional context. Defaults to \"Table not found\".</p> <code>'Table not found'</code> Example <p>raise DerivaMLTableNotFound(\"MyTable\") DerivaMLTableNotFound: Table not found: MyTable</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLTableNotFound(DerivaMLNotFoundError):\n    \"\"\"Exception raised when a table cannot be found.\n\n    Raised when attempting to access a table that doesn't exist in the\n    catalog schema or downloaded bag.\n\n    Args:\n        table_name: The name of the table that was not found.\n        msg: Additional context. Defaults to \"Table not found\".\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLTableNotFound(\"MyTable\")\n        DerivaMLTableNotFound: Table not found: MyTable\n    \"\"\"\n\n    def __init__(self, table_name: str, msg: str = \"Table not found\") -&gt; None:\n        super().__init__(f\"{msg}: {table_name}\")\n        self.table_name = table_name\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLTableTypeError","title":"DerivaMLTableTypeError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when a RID or table is not of the expected type.</p> <p>Raised when an operation requires a specific table type (e.g., Dataset, Execution) but receives a RID or table reference of a different type.</p> <p>Parameters:</p> Name Type Description Default <code>table_type</code> <code>str</code> <p>The expected table type (e.g., \"Dataset\", \"Execution\").</p> required <code>table</code> <code>str</code> <p>The actual table name or RID that was provided.</p> required Example <p>raise DerivaMLTableTypeError(\"Dataset\", \"1-ABC123\") DerivaMLTableTypeError: Table 1-ABC123 is not of type Dataset.</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLTableTypeError(DerivaMLDataError):\n    \"\"\"Exception raised when a RID or table is not of the expected type.\n\n    Raised when an operation requires a specific table type (e.g., Dataset,\n    Execution) but receives a RID or table reference of a different type.\n\n    Args:\n        table_type: The expected table type (e.g., \"Dataset\", \"Execution\").\n        table: The actual table name or RID that was provided.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLTableTypeError(\"Dataset\", \"1-ABC123\")\n        DerivaMLTableTypeError: Table 1-ABC123 is not of type Dataset.\n    \"\"\"\n\n    def __init__(self, table_type: str, table: str) -&gt; None:\n        super().__init__(f\"Table {table} is not of type {table_type}.\")\n        self.table_type = table_type\n        self.table = table\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLUploadError","title":"DerivaMLUploadError","text":"<p>               Bases: <code>DerivaMLExecutionError</code></p> <p>Exception raised for asset upload failures.</p> <p>Raised when uploading assets to the catalog fails, including file uploads, metadata insertion, and provenance recording.</p> Example <p>raise DerivaMLUploadError(\"Failed to upload execution assets\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLUploadError(DerivaMLExecutionError):\n    \"\"\"Exception raised for asset upload failures.\n\n    Raised when uploading assets to the catalog fails, including file\n    uploads, metadata insertion, and provenance recording.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLUploadError(\"Failed to upload execution assets\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLValidationError","title":"DerivaMLValidationError","text":"<p>               Bases: <code>DerivaMLDataError</code></p> <p>Exception raised when data validation fails.</p> <p>Raised when input data fails validation, such as invalid RID format, mismatched metadata, or constraint violations.</p> Example <p>raise DerivaMLValidationError(\"Invalid RID format: ABC\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLValidationError(DerivaMLDataError):\n    \"\"\"Exception raised when data validation fails.\n\n    Raised when input data fails validation, such as invalid RID format,\n    mismatched metadata, or constraint violations.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLValidationError(\"Invalid RID format: ABC\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/exceptions/#deriva_ml.core.exceptions.DerivaMLWorkflowError","title":"DerivaMLWorkflowError","text":"<p>               Bases: <code>DerivaMLExecutionError</code></p> <p>Exception raised for workflow-related issues.</p> <p>Raised when there are problems with workflow lookup, creation, or Git integration for workflow tracking.</p> Example <p>raise DerivaMLWorkflowError(\"Not executing in a Git repository\")</p> Source code in <code>src/deriva_ml/core/exceptions.py</code> <pre><code>class DerivaMLWorkflowError(DerivaMLExecutionError):\n    \"\"\"Exception raised for workflow-related issues.\n\n    Raised when there are problems with workflow lookup, creation, or\n    Git integration for workflow tracking.\n\n    Example:\n        &gt;&gt;&gt; raise DerivaMLWorkflowError(\"Not executing in a Git repository\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"code-docs/execution/","title":"Documentation for Execution class in DerivaML","text":""},{"location":"code-docs/execution/#deriva_ml.execution.AssetRID","title":"AssetRID  <code>dataclass</code>","text":"<p>               Bases: <code>str</code></p> <p>A string subclass representing an asset Resource ID with optional description.</p> <p>.. deprecated::     Use :class:<code>AssetSpec</code> instead for new code. <code>AssetRID</code> is retained     for backward compatibility.</p> <p>Attributes:</p> Name Type Description <code>rid</code> <code>str</code> <p>The Resource ID string identifying the asset in Deriva.</p> <code>description</code> <code>str</code> <p>Optional human-readable description of the asset.</p> Example <p>asset = AssetRID(\"3RA\", \"Pretrained model weights\") print(asset)  # \"3RA\" print(asset.description)  # \"Pretrained model weights\"</p> Source code in <code>src/deriva_ml/execution/execution_configuration.py</code> <pre><code>@dataclass\nclass AssetRID(str):\n    \"\"\"A string subclass representing an asset Resource ID with optional description.\n\n    .. deprecated::\n        Use :class:`AssetSpec` instead for new code. ``AssetRID`` is retained\n        for backward compatibility.\n\n    Attributes:\n        rid: The Resource ID string identifying the asset in Deriva.\n        description: Optional human-readable description of the asset.\n\n    Example:\n        &gt;&gt;&gt; asset = AssetRID(\"3RA\", \"Pretrained model weights\")\n        &gt;&gt;&gt; print(asset)  # \"3RA\"\n        &gt;&gt;&gt; print(asset.description)  # \"Pretrained model weights\"\n    \"\"\"\n\n    rid: str\n    description: str = \"\"\n\n    def __new__(cls, rid: str, description: str = \"\"):\n        obj = super().__new__(cls, rid)\n        obj.description = description\n        return obj\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.AssetSpec","title":"AssetSpec","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specification for an asset in execution configurations.</p> <p>Used to reference assets as inputs to executions, similar to how DatasetSpec is used for datasets. Supports optional checksum-based caching for large assets like model weights.</p> <p>Attributes:</p> Name Type Description <code>rid</code> <code>RID</code> <p>Resource Identifier of the asset.</p> <code>asset_role</code> <code>str</code> <p>Role of the asset (\"Input\" or \"Output\"). Defaults to \"Input\".</p> <code>cache</code> <code>bool</code> <p>If True, cache the downloaded asset by MD5 checksum in the DerivaML cache directory. Cached assets are reused across executions when the checksum matches, avoiding repeated downloads of large files.</p> Example <p>spec = AssetSpec(rid=\"3JSE\") spec = AssetSpec(rid=\"3JSE\", cache=True)  # enable caching</p> Source code in <code>src/deriva_ml/asset/aux_classes.py</code> <pre><code>class AssetSpec(BaseModel):\n    \"\"\"Specification for an asset in execution configurations.\n\n    Used to reference assets as inputs to executions, similar to how\n    DatasetSpec is used for datasets. Supports optional checksum-based\n    caching for large assets like model weights.\n\n    Attributes:\n        rid: Resource Identifier of the asset.\n        asset_role: Role of the asset (\"Input\" or \"Output\"). Defaults to \"Input\".\n        cache: If True, cache the downloaded asset by MD5 checksum in the\n            DerivaML cache directory. Cached assets are reused across executions\n            when the checksum matches, avoiding repeated downloads of large files.\n\n    Example:\n        &gt;&gt;&gt; spec = AssetSpec(rid=\"3JSE\")\n        &gt;&gt;&gt; spec = AssetSpec(rid=\"3JSE\", cache=True)  # enable caching\n    \"\"\"\n\n    rid: RID\n    asset_role: str = \"Input\"\n    cache: bool = False\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def _check_bare_rid(cls, data: Any) -&gt; dict[str, str | bool]:\n        \"\"\"Allow bare RID string as shorthand.\"\"\"\n        return {\"rid\": data} if isinstance(data, str) else data\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.AssetSpecConfig","title":"AssetSpecConfig","text":"<p>Hydra-zen configuration interface for AssetSpec.</p> <p>Use in hydra-zen store definitions to specify assets with caching:</p> <pre><code>&gt;&gt;&gt; from hydra_zen import store\n&gt;&gt;&gt; asset_store = store(group=\"assets\")\n&gt;&gt;&gt; asset_store(\n...     [AssetSpecConfig(rid=\"6-EPNR\", cache=True)],\n...     name=\"cached_weights\",\n... )\n</code></pre> Source code in <code>src/deriva_ml/asset/aux_classes.py</code> <pre><code>@hydrated_dataclass(AssetSpec)\nclass AssetSpecConfig:\n    \"\"\"Hydra-zen configuration interface for AssetSpec.\n\n    Use in hydra-zen store definitions to specify assets with caching:\n\n        &gt;&gt;&gt; from hydra_zen import store\n        &gt;&gt;&gt; asset_store = store(group=\"assets\")\n        &gt;&gt;&gt; asset_store(\n        ...     [AssetSpecConfig(rid=\"6-EPNR\", cache=True)],\n        ...     name=\"cached_weights\",\n        ... )\n    \"\"\"\n\n    rid: str\n    cache: bool = False\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.BaseConfig","title":"BaseConfig  <code>dataclass</code>","text":"<p>Base configuration for DerivaML applications.</p> <p>This dataclass defines the common configuration structure shared by both script execution and notebook modes. Project-specific configs should inherit from this class to get the standard DerivaML fields.</p> Note <p>Fields use <code>Any</code> type annotations because several DerivaML types (DerivaMLConfig, DatasetSpec) are Pydantic models which are not compatible with OmegaConf structured configs. The actual types at runtime are documented below.</p> <p>Attributes:</p> Name Type Description <code>deriva_ml</code> <code>Any</code> <p>DerivaML connection configuration (DerivaMLConfig at runtime).</p> <code>datasets</code> <code>Any</code> <p>List of dataset specifications (list[DatasetSpec] at runtime).</p> <code>assets</code> <code>Any</code> <p>List of asset RIDs to load (list[str] at runtime).</p> <code>dry_run</code> <code>bool</code> <p>If True, skip catalog writes (for testing/debugging).</p> <code>description</code> <code>str</code> <p>Human-readable description of this run.</p> <code>config_choices</code> <code>dict[str, str]</code> <p>Dictionary mapping config group names to selected config names. This is automatically populated by get_notebook_configuration() with the Hydra runtime choices (e.g., {\"model_config\": \"cifar10_quick\", \"assets\": \"roc_quick\"}). Useful for tracking which configurations were used in an execution.</p> Example <p>from dataclasses import dataclass from deriva_ml.execution import BaseConfig</p> <p>@dataclass ... class MyConfig(BaseConfig): ...     learning_rate: float = 0.001 ...     epochs: int = 10</p> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>@dataclass\nclass BaseConfig:\n    \"\"\"Base configuration for DerivaML applications.\n\n    This dataclass defines the common configuration structure shared by\n    both script execution and notebook modes. Project-specific configs\n    should inherit from this class to get the standard DerivaML fields.\n\n    Note:\n        Fields use ``Any`` type annotations because several DerivaML types\n        (DerivaMLConfig, DatasetSpec) are Pydantic models which are not\n        compatible with OmegaConf structured configs. The actual types at\n        runtime are documented below.\n\n    Attributes:\n        deriva_ml: DerivaML connection configuration (DerivaMLConfig at runtime).\n        datasets: List of dataset specifications (list[DatasetSpec] at runtime).\n        assets: List of asset RIDs to load (list[str] at runtime).\n        dry_run: If True, skip catalog writes (for testing/debugging).\n        description: Human-readable description of this run.\n        config_choices: Dictionary mapping config group names to selected config names.\n            This is automatically populated by get_notebook_configuration() with the\n            Hydra runtime choices (e.g., {\"model_config\": \"cifar10_quick\", \"assets\": \"roc_quick\"}).\n            Useful for tracking which configurations were used in an execution.\n\n    Example:\n        &gt;&gt;&gt; from dataclasses import dataclass\n        &gt;&gt;&gt; from deriva_ml.execution import BaseConfig\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; @dataclass\n        ... class MyConfig(BaseConfig):\n        ...     learning_rate: float = 0.001\n        ...     epochs: int = 10\n    \"\"\"\n    deriva_ml: Any = None\n    datasets: Any = None\n    assets: Any = None\n    dry_run: bool = False\n    description: str = \"\"\n    config_choices: dict[str, str] = field(default_factory=dict)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.DerivaMLModel","title":"DerivaMLModel","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for model functions compatible with DerivaML's run_model().</p> <p>A model function must accept keyword arguments <code>ml_instance</code> and <code>execution</code> that are injected at runtime by run_model(). All other parameters are configured via Hydra and passed through the model_config.</p> <p>The model function is responsible for: 1. Downloading input datasets via execution.download_dataset_bag() 2. Performing the ML computation (training, inference, etc.) 3. Registering output files via execution.asset_file_path()</p> <p>Output files registered with asset_file_path() are automatically uploaded to the catalog after the model completes.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.DerivaMLModel--attributes","title":"Attributes","text":"<p>This protocol defines a callable signature, not attributes.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.DerivaMLModel--examples","title":"Examples","text":"<p>Basic model function:</p> <pre><code>def my_model(\n    epochs: int = 10,\n    ml_instance: DerivaML = None,\n    execution: Execution = None,\n) -&gt; None:\n    # Training logic here\n    pass\n</code></pre> <p>With domain-specific DerivaML subclass:</p> <pre><code>def eyeai_model(\n    threshold: float = 0.5,\n    ml_instance: EyeAI = None,  # EyeAI is a DerivaML subclass\n    execution: Execution = None,\n) -&gt; None:\n    # Can use EyeAI-specific methods\n    ml_instance.some_eyeai_method()\n</code></pre> <p>Checking protocol compliance:</p> <pre><code>&gt;&gt;&gt; from deriva_ml.execution.model_protocol import DerivaMLModel\n&gt;&gt;&gt; isinstance(my_model, DerivaMLModel)\nTrue\n</code></pre> Source code in <code>src/deriva_ml/execution/model_protocol.py</code> <pre><code>@runtime_checkable\nclass DerivaMLModel(Protocol):\n    \"\"\"Protocol for model functions compatible with DerivaML's run_model().\n\n    A model function must accept keyword arguments `ml_instance` and `execution`\n    that are injected at runtime by run_model(). All other parameters are\n    configured via Hydra and passed through the model_config.\n\n    The model function is responsible for:\n    1. Downloading input datasets via execution.download_dataset_bag()\n    2. Performing the ML computation (training, inference, etc.)\n    3. Registering output files via execution.asset_file_path()\n\n    Output files registered with asset_file_path() are automatically uploaded\n    to the catalog after the model completes.\n\n    Attributes\n    ----------\n    This protocol defines a callable signature, not attributes.\n\n    Examples\n    --------\n    Basic model function:\n\n        def my_model(\n            epochs: int = 10,\n            ml_instance: DerivaML = None,\n            execution: Execution = None,\n        ) -&gt; None:\n            # Training logic here\n            pass\n\n    With domain-specific DerivaML subclass:\n\n        def eyeai_model(\n            threshold: float = 0.5,\n            ml_instance: EyeAI = None,  # EyeAI is a DerivaML subclass\n            execution: Execution = None,\n        ) -&gt; None:\n            # Can use EyeAI-specific methods\n            ml_instance.some_eyeai_method()\n\n    Checking protocol compliance:\n\n        &gt;&gt;&gt; from deriva_ml.execution.model_protocol import DerivaMLModel\n        &gt;&gt;&gt; isinstance(my_model, DerivaMLModel)\n        True\n    \"\"\"\n\n    def __call__(\n        self,\n        *args: Any,\n        ml_instance: \"DerivaML\",\n        execution: \"Execution\",\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Execute the model within a DerivaML execution context.\n\n        Parameters\n        ----------\n        *args : Any\n            Positional arguments (typically not used; prefer keyword args).\n        ml_instance : DerivaML\n            The DerivaML instance (or subclass like EyeAI) connected to the\n            catalog. Use this for catalog operations not available through\n            the execution context.\n        execution : Execution\n            The execution context manager. Provides:\n            - execution.datasets: List of input DatasetSpec objects\n            - execution.download_dataset_bag(): Download dataset as BDBag\n            - execution.asset_file_path(): Register output file for upload\n            - execution.working_dir: Path to local working directory\n        **kwargs : Any\n            Model-specific parameters configured via Hydra.\n\n        Returns\n        -------\n        None\n            Models should not return values. Results are captured through:\n            - Files registered with asset_file_path() (uploaded to catalog)\n            - Datasets created with execution.create_dataset()\n            - Status updates via execution.update_status()\n        \"\"\"\n        ...\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.DerivaMLModel.__call__","title":"__call__","text":"<pre><code>__call__(\n    *args: Any,\n    ml_instance: \"DerivaML\",\n    execution: \"Execution\",\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Execute the model within a DerivaML execution context.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.DerivaMLModel.__call__--parameters","title":"Parameters","text":"<p>args : Any     Positional arguments (typically not used; prefer keyword args). ml_instance : DerivaML     The DerivaML instance (or subclass like EyeAI) connected to the     catalog. Use this for catalog operations not available through     the execution context. execution : Execution     The execution context manager. Provides:     - execution.datasets: List of input DatasetSpec objects     - execution.download_dataset_bag(): Download dataset as BDBag     - execution.asset_file_path(): Register output file for upload     - execution.working_dir: Path to local working directory *kwargs : Any     Model-specific parameters configured via Hydra.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.DerivaMLModel.__call__--returns","title":"Returns","text":"<p>None     Models should not return values. Results are captured through:     - Files registered with asset_file_path() (uploaded to catalog)     - Datasets created with execution.create_dataset()     - Status updates via execution.update_status()</p> Source code in <code>src/deriva_ml/execution/model_protocol.py</code> <pre><code>def __call__(\n    self,\n    *args: Any,\n    ml_instance: \"DerivaML\",\n    execution: \"Execution\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Execute the model within a DerivaML execution context.\n\n    Parameters\n    ----------\n    *args : Any\n        Positional arguments (typically not used; prefer keyword args).\n    ml_instance : DerivaML\n        The DerivaML instance (or subclass like EyeAI) connected to the\n        catalog. Use this for catalog operations not available through\n        the execution context.\n    execution : Execution\n        The execution context manager. Provides:\n        - execution.datasets: List of input DatasetSpec objects\n        - execution.download_dataset_bag(): Download dataset as BDBag\n        - execution.asset_file_path(): Register output file for upload\n        - execution.working_dir: Path to local working directory\n    **kwargs : Any\n        Model-specific parameters configured via Hydra.\n\n    Returns\n    -------\n    None\n        Models should not return values. Results are captured through:\n        - Files registered with asset_file_path() (uploaded to catalog)\n        - Datasets created with execution.create_dataset()\n        - Status updates via execution.update_status()\n    \"\"\"\n    ...\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.DescribedList","title":"DescribedList","text":"<p>               Bases: <code>list</code></p> <p>A list with an attached description.</p> <p>This class extends list to add a <code>description</code> attribute while maintaining full list compatibility. This allows configuration values (like asset RIDs or dataset specs) to carry documentation without changing how they're used.</p> <p>When stored in hydra-zen and resolved via <code>instantiate()</code>, the result is a DescribedList that behaves like a regular list but has a <code>description</code> attribute.</p> <p>Attributes:</p> Name Type Description <code>description</code> <p>Human-readable description of this configuration.</p> Example <p>from hydra_zen import store from deriva_ml.execution import with_description</p> <p>asset_store = store(group=\"assets\") asset_store( ...     with_description( ...         [\"3WMG\", \"3XPA\"], ...         \"Model weights from quick and extended training\", ...     ), ...     name=\"comparison_weights\", ... )</p> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>class DescribedList(list):\n    \"\"\"A list with an attached description.\n\n    This class extends list to add a `description` attribute while maintaining\n    full list compatibility. This allows configuration values (like asset RIDs\n    or dataset specs) to carry documentation without changing how they're used.\n\n    When stored in hydra-zen and resolved via `instantiate()`, the result is a\n    DescribedList that behaves like a regular list but has a `description` attribute.\n\n    Attributes:\n        description: Human-readable description of this configuration.\n\n    Example:\n        &gt;&gt;&gt; from hydra_zen import store\n        &gt;&gt;&gt; from deriva_ml.execution import with_description\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; asset_store = store(group=\"assets\")\n        &gt;&gt;&gt; asset_store(\n        ...     with_description(\n        ...         [\"3WMG\", \"3XPA\"],\n        ...         \"Model weights from quick and extended training\",\n        ...     ),\n        ...     name=\"comparison_weights\",\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # After instantiation, usage is identical to a regular list:\n        &gt;&gt;&gt; # config.assets[0]  # \"3WMG\"\n        &gt;&gt;&gt; # len(config.assets)  # 2\n        &gt;&gt;&gt; # for rid in config.assets: ...\n        &gt;&gt;&gt; # config.assets.description  # \"Model weights from...\"\n    \"\"\"\n\n    def __init__(self, items: list | None = None, description: str = \"\"):\n        \"\"\"Initialize a DescribedList.\n\n        Args:\n            items: Initial list items. If None, creates empty list.\n            description: Human-readable description of this list.\n        \"\"\"\n        super().__init__(items or [])\n        self.description = description\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation including description.\"\"\"\n        if self.description:\n            return f\"DescribedList({list(self)!r}, description={self.description!r})\"\n        return f\"DescribedList({list(self)!r})\"\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.DescribedList--after-instantiation-usage-is-identical-to-a-regular-list","title":"After instantiation, usage is identical to a regular list:","text":""},{"location":"code-docs/execution/#deriva_ml.execution.DescribedList--configassets0-3wmg","title":"config.assets[0]  # \"3WMG\"","text":""},{"location":"code-docs/execution/#deriva_ml.execution.DescribedList--lenconfigassets-2","title":"len(config.assets)  # 2","text":""},{"location":"code-docs/execution/#deriva_ml.execution.DescribedList--for-rid-in-configassets","title":"for rid in config.assets: ...","text":""},{"location":"code-docs/execution/#deriva_ml.execution.DescribedList--configassetsdescription-model-weights-from","title":"config.assets.description  # \"Model weights from...\"","text":""},{"location":"code-docs/execution/#deriva_ml.execution.DescribedList.__init__","title":"__init__","text":"<pre><code>__init__(\n    items: list | None = None,\n    description: str = \"\",\n)\n</code></pre> <p>Initialize a DescribedList.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list | None</code> <p>Initial list items. If None, creates empty list.</p> <code>None</code> <code>description</code> <code>str</code> <p>Human-readable description of this list.</p> <code>''</code> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>def __init__(self, items: list | None = None, description: str = \"\"):\n    \"\"\"Initialize a DescribedList.\n\n    Args:\n        items: Initial list items. If None, creates empty list.\n        description: Human-readable description of this list.\n    \"\"\"\n    super().__init__(items or [])\n    self.description = description\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.DescribedList.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Return string representation including description.</p> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation including description.\"\"\"\n    if self.description:\n        return f\"DescribedList({list(self)!r}, description={self.description!r})\"\n    return f\"DescribedList({list(self)!r})\"\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution","title":"Execution","text":"<p>Manages the lifecycle and context of a DerivaML execution.</p> <p>An Execution represents a computational or manual process within DerivaML. It provides: - Dataset materialization and access - Asset management (inputs and outputs) - Status tracking and updates - Provenance recording - Result upload and cataloging</p> <p>The class handles downloading required datasets and assets, tracking execution state, and managing the upload of results. Every dataset and file generated is associated with an execution record for provenance tracking.</p> <p>Attributes:</p> Name Type Description <code>dataset_rids</code> <code>list[RID]</code> <p>RIDs of datasets used in the execution.</p> <code>datasets</code> <code>list[DatasetBag]</code> <p>Materialized dataset objects.</p> <code>configuration</code> <code>ExecutionConfiguration</code> <p>Execution settings and parameters.</p> <code>workflow_rid</code> <code>RID</code> <p>RID of the associated workflow.</p> <code>status</code> <code>Status</code> <p>Current execution status.</p> <code>asset_paths</code> <code>list[AssetFilePath]</code> <p>Paths to execution assets.</p> <code>start_time</code> <code>datetime | None</code> <p>When execution started.</p> <code>stop_time</code> <code>datetime | None</code> <p>When execution completed.</p> Example <p>The context manager handles start/stop timing. Upload must be called AFTER the context manager exits::</p> <pre><code>&gt;&gt;&gt; config = ExecutionConfiguration(\n...     workflow=\"analysis\",\n...     description=\"Process samples\",\n... )\n&gt;&gt;&gt; with ml.create_execution(config) as execution:\n...     bag = execution.download_dataset_bag(dataset_spec)\n...     # Run analysis using bag.path\n...     output_path = execution.asset_file_path(\"Model\", \"model.pt\")\n...     # Write results to output_path\n...\n&gt;&gt;&gt; # IMPORTANT: Call upload AFTER exiting the context manager\n&gt;&gt;&gt; execution.upload_execution_outputs()\n</code></pre> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>class Execution:\n    \"\"\"Manages the lifecycle and context of a DerivaML execution.\n\n    An Execution represents a computational or manual process within DerivaML. It provides:\n    - Dataset materialization and access\n    - Asset management (inputs and outputs)\n    - Status tracking and updates\n    - Provenance recording\n    - Result upload and cataloging\n\n    The class handles downloading required datasets and assets, tracking execution state,\n    and managing the upload of results. Every dataset and file generated is associated\n    with an execution record for provenance tracking.\n\n    Attributes:\n        dataset_rids (list[RID]): RIDs of datasets used in the execution.\n        datasets (list[DatasetBag]): Materialized dataset objects.\n        configuration (ExecutionConfiguration): Execution settings and parameters.\n        workflow_rid (RID): RID of the associated workflow.\n        status (Status): Current execution status.\n        asset_paths (list[AssetFilePath]): Paths to execution assets.\n        start_time (datetime | None): When execution started.\n        stop_time (datetime | None): When execution completed.\n\n    Example:\n        The context manager handles start/stop timing. Upload must be called AFTER\n        the context manager exits::\n\n            &gt;&gt;&gt; config = ExecutionConfiguration(\n            ...     workflow=\"analysis\",\n            ...     description=\"Process samples\",\n            ... )\n            &gt;&gt;&gt; with ml.create_execution(config) as execution:\n            ...     bag = execution.download_dataset_bag(dataset_spec)\n            ...     # Run analysis using bag.path\n            ...     output_path = execution.asset_file_path(\"Model\", \"model.pt\")\n            ...     # Write results to output_path\n            ...\n            &gt;&gt;&gt; # IMPORTANT: Call upload AFTER exiting the context manager\n            &gt;&gt;&gt; execution.upload_execution_outputs()\n    \"\"\"\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def __init__(\n        self,\n        configuration: ExecutionConfiguration,\n        ml_object: DerivaML,\n        workflow: Workflow | None = None,\n        reload: RID | None = None,\n        dry_run: bool = False,\n    ):\n        \"\"\"Initializes an Execution instance.\n\n        Creates a new execution or reloads an existing one. Initializes the execution\n        environment, downloads required datasets, and sets up asset tracking.\n\n        Args:\n            configuration: Settings and parameters for the execution.\n            ml_object: DerivaML instance managing the execution.\n            workflow: Optional Workflow object. If not specified, the workflow is taken from\n                the ExecutionConfiguration object. Must be a Workflow object, not a RID.\n            reload: Optional RID of existing execution to reload.\n            dry_run: If True, don't create catalog records or upload results.\n\n        Raises:\n            DerivaMLException: If initialization fails, configuration is invalid,\n                or workflow is not a Workflow object.\n\n        Example:\n            Create an execution with a workflow::\n\n                &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n                &gt;&gt;&gt; config = ExecutionConfiguration(\n                ...     workflow=workflow,\n                ...     description=\"Process data\"\n                ... )\n                &gt;&gt;&gt; execution = Execution(config, ml)\n\n            Or pass workflow separately::\n\n                &gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(\n                ...     \"https://github.com/org/repo/blob/abc123/analysis.py\"\n                ... )\n                &gt;&gt;&gt; config = ExecutionConfiguration(description=\"Run analysis\")\n                &gt;&gt;&gt; execution = Execution(config, ml, workflow=workflow)\n        \"\"\"\n\n        self.asset_paths: dict[str, list[AssetFilePath]] = {}\n        self.configuration = configuration\n        self._ml_object = ml_object\n        self._model = ml_object.model\n        self._logger = ml_object._logger\n        self.start_time = None\n        self.stop_time = None\n        self._status = Status.created\n        self.uploaded_assets: dict[str, list[AssetFilePath]] | None = None\n        self.configuration.argv = sys.argv\n        self._execution_record: ExecutionRecord | None = None  # Lazily created after RID is assigned\n\n        self.dataset_rids: List[RID] = []\n        self.datasets: list[DatasetBag] = []\n\n        self._working_dir = self._ml_object.working_dir\n        self._cache_dir = self._ml_object.cache_dir\n        if self._working_dir is None:\n            raise DerivaMLException(\n                \"DerivaML working_dir is not set. \"\n                \"Ensure the DerivaML instance was initialized with a valid working_dir.\"\n            )\n        self._dry_run = dry_run\n\n        # Make sure we have a valid Workflow object.\n        if workflow:\n            self.configuration.workflow = workflow\n\n        if self.configuration.workflow is None:\n            raise DerivaMLException(\"Workflow must be specified either in configuration or as a parameter\")\n\n        if not isinstance(self.configuration.workflow, Workflow):\n            raise DerivaMLException(\n                f\"Workflow must be a Workflow object, not {type(self.configuration.workflow).__name__}. \"\n                \"Use ml.lookup_workflow(rid) or ml.lookup_workflow_by_url(url) to get a Workflow object.\"\n            )\n\n        # Validate workflow type and register in catalog\n        self._ml_object.lookup_term(MLVocab.workflow_type, self.configuration.workflow.workflow_type)\n        self.workflow_rid = (\n            self._ml_object.add_workflow(self.configuration.workflow) if not self._dry_run else DRY_RUN_RID\n        )\n\n        # Validate the datasets and assets to be valid.\n        for d in self.configuration.datasets:\n            if self._ml_object.resolve_rid(d.rid).table.name != \"Dataset\":\n                raise DerivaMLException(\"Dataset specified in execution configuration is not a dataset\")\n\n        for a in self.configuration.assets:\n            if not self._model.is_asset(self._ml_object.resolve_rid(a.rid).table.name):\n                raise DerivaMLException(\"Asset specified in execution configuration is not an asset table\")\n\n        schema_path = self._ml_object.pathBuilder().schemas[self._ml_object.ml_schema]\n        if reload:\n            self.execution_rid = reload\n            if self.execution_rid == DRY_RUN_RID:\n                self._dry_run = True\n        elif self._dry_run:\n            self.execution_rid = DRY_RUN_RID\n        else:\n            self.execution_rid = schema_path.Execution.insert(\n                [\n                    {\n                        \"Description\": self.configuration.description,\n                        \"Workflow\": self.workflow_rid,\n                    }\n                ]\n            )[0][\"RID\"]\n\n        if rid_path := os.environ.get(\"DERIVA_ML_SAVE_EXECUTION_RID\", None):\n            # Put execution_rid into the provided file path so we can find it later.\n            with Path(rid_path).open(\"w\") as f:\n                json.dump(\n                    {\n                        \"hostname\": self._ml_object.host_name,\n                        \"catalog_id\": self._ml_object.catalog_id,\n                        \"workflow_rid\": self.workflow_rid,\n                        \"execution_rid\": self.execution_rid,\n                    },\n                    f,\n                )\n\n        # Create a directory for execution rid so we can recover the state in case of a crash.\n        execution_root(prefix=self._ml_object.working_dir, exec_rid=self.execution_rid)\n\n        # Create the ExecutionRecord to handle catalog state operations\n        if not self._dry_run:\n            self._execution_record = ExecutionRecord(\n                execution_rid=self.execution_rid,\n                workflow=self.configuration.workflow,\n                status=Status.created,\n                description=self.configuration.description,\n                _ml_instance=self._ml_object,\n                _logger=self._logger,\n            )\n\n        self._initialize_execution(reload)\n\n    def _save_runtime_environment(self):\n        runtime_env_path = self.asset_file_path(\n            asset_name=\"Execution_Metadata\",\n            file_name=f\"environment_snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\",\n            asset_types=ExecMetadataType.runtime_env.value,\n        )\n        with Path(runtime_env_path).open(\"w\") as fp:\n            json.dump(get_execution_environment(), fp)\n\n    def _upload_hydra_config_assets(self):\n        \"\"\"Upload hydra assets to the catalog with Hydra_Config type.\"\"\"\n        hydra_runtime_output_dir = self._ml_object.hydra_runtime_output_dir\n        if hydra_runtime_output_dir:\n            timestamp = hydra_runtime_output_dir.parts[-1]\n            for hydra_asset in hydra_runtime_output_dir.rglob(\"*\"):\n                if hydra_asset.is_dir():\n                    continue\n                # Register file for upload (side effect); result intentionally unused\n                # Use Hydra_Config type for Hydra YAML configuration files\n                self.asset_file_path(\n                    asset_name=MLAsset.execution_metadata,\n                    file_name=hydra_runtime_output_dir / hydra_asset,\n                    rename_file=f\"hydra-{timestamp}-{hydra_asset.name}\",\n                    asset_types=ExecMetadataType.hydra_config.value,\n                )\n\n    def _initialize_execution(self, reload: RID | None = None) -&gt; None:\n        \"\"\"Initialize the execution environment.\n\n        Sets up the working directory, downloads required datasets and assets,\n        and saves initial configuration metadata.\n\n        Args:\n            reload: Optional RID of a previously initialized execution to reload.\n\n        Raises:\n            DerivaMLException: If initialization fails.\n        \"\"\"\n        # Materialize bdbag\n        for dataset in self.configuration.datasets:\n            self.update_status(Status.initializing, f\"Materialize bag {dataset.rid}... \")\n            self.datasets.append(self.download_dataset_bag(dataset))\n            self.dataset_rids.append(dataset.rid)\n\n        # Update execution info\n        schema_path = self._ml_object.pathBuilder().schemas[self._ml_object.ml_schema]\n        if self.dataset_rids and not (reload or self._dry_run):\n            schema_path.Dataset_Execution.insert(\n                [{\"Dataset\": d, \"Execution\": self.execution_rid} for d in self.dataset_rids]\n            )\n\n        # Download assets....\n        self.update_status(Status.running, \"Downloading assets ...\")\n        self.asset_paths = {}\n        for asset_spec in self.configuration.assets:\n            asset_rid = asset_spec.rid\n            use_cache = asset_spec.cache\n            asset_table = self._ml_object.resolve_rid(asset_rid).table.name\n            dest_dir = (\n                execution_root(self._ml_object.working_dir, self.execution_rid) / \"downloaded-assets\" / asset_table\n            )\n            dest_dir.mkdir(parents=True, exist_ok=True)\n            self.asset_paths.setdefault(asset_table, []).append(\n                self.download_asset(\n                    asset_rid=asset_rid,\n                    dest_dir=dest_dir,\n                    update_catalog=not (reload or self._dry_run),\n                    use_cache=use_cache,\n                )\n            )\n\n        # Save configuration details and upload (skip in dry_run mode)\n        if not reload and not self._dry_run:\n            # Save DerivaML configuration with Deriva_Config type\n            cfile = self.asset_file_path(\n                asset_name=MLAsset.execution_metadata,\n                file_name=\"configuration.json\",\n                asset_types=ExecMetadataType.deriva_config.value,\n            )\n\n            with Path(cfile).open(\"w\", encoding=\"utf-8\") as config_file:\n                json.dump(self.configuration.model_dump(mode=\"json\"), config_file)\n            # Only try to copy uv.lock if git_root is available (local workflow)\n            if self.configuration.workflow.git_root:\n                lock_file = Path(self.configuration.workflow.git_root) / \"uv.lock\"\n            else:\n                lock_file = None\n            if lock_file and lock_file.exists():\n                _ = self.asset_file_path(\n                    asset_name=MLAsset.execution_metadata,\n                    file_name=lock_file,\n                    asset_types=ExecMetadataType.execution_config.value,\n                )\n\n            self._upload_hydra_config_assets()\n\n            # save runtime env\n            self._save_runtime_environment()\n\n            # Now upload the files so we have the info in case the execution fails.\n            self.uploaded_assets = self._upload_execution_dirs()\n        self.start_time = datetime.now()\n        self.update_status(Status.pending, \"Initialize status finished.\")\n\n    @property\n    def status(self) -&gt; Status:\n        \"\"\"Get the current execution status.\n\n        Returns:\n            Status: The current status (Created, Running, Completed, Failed, etc.).\n        \"\"\"\n        if self._execution_record is not None:\n            return self._execution_record.status\n        return self._status\n\n    @status.setter\n    def status(self, value: Status) -&gt; None:\n        \"\"\"Set the execution status.\n\n        Args:\n            value: The new status value.\n        \"\"\"\n        self._status = value\n        if self._execution_record is not None:\n            self._execution_record._status = value\n\n    @property\n    def execution_record(self) -&gt; ExecutionRecord | None:\n        \"\"\"Get the ExecutionRecord for catalog operations.\n\n        Returns:\n            ExecutionRecord if not in dry_run mode, None otherwise.\n        \"\"\"\n        return self._execution_record\n\n    @property\n    def working_dir(self) -&gt; Path:\n        \"\"\"Return the working directory for the execution.\"\"\"\n        return self._execution_root\n\n    @property\n    def _execution_root(self) -&gt; Path:\n        \"\"\"Get the root directory for this execution's files.\n\n        Returns:\n            Path to the execution-specific directory.\n        \"\"\"\n        return execution_root(self._working_dir, self.execution_rid)\n\n    @property\n    def _feature_root(self) -&gt; Path:\n        \"\"\"Get the root directory for feature files.\n\n        Returns:\n            Path to the feature directory within the execution.\n        \"\"\"\n        return feature_root(self._working_dir, self.execution_rid)\n\n    @property\n    def _asset_root(self) -&gt; Path:\n        \"\"\"Get the root directory for asset files.\n\n        Returns:\n            Path to the asset directory within the execution.\n        \"\"\"\n        return asset_root(self._working_dir, self.execution_rid)\n\n    @property\n    def database_catalog(self) -&gt; DerivaMLDatabase | None:\n        \"\"\"Get a catalog-like interface for downloaded datasets.\n\n        Returns a DerivaMLDatabase that implements the DerivaMLCatalog\n        protocol, allowing the same code to work with both live catalogs\n        and downloaded bags.\n\n        This is useful for writing code that can operate on either a live\n        catalog (via DerivaML) or on downloaded bags (via DerivaMLDatabase).\n\n        Returns:\n            DerivaMLDatabase wrapping the primary downloaded dataset's model,\n            or None if no datasets have been downloaded.\n\n        Example:\n            &gt;&gt;&gt; with ml.create_execution(config) as exe:\n            ...     if exe.database_catalog:\n            ...         db = exe.database_catalog\n            ...         # Use same interface as DerivaML\n            ...         dataset = db.lookup_dataset(\"4HM\")\n            ...         term = db.lookup_term(\"Diagnosis\", \"cancer\")\n            ...     else:\n            ...         # No datasets downloaded, use live catalog\n            ...         pass\n        \"\"\"\n        if not self.datasets:\n            return None\n        # Use the first dataset's model as the primary\n        return DerivaMLDatabase(self.datasets[0].model)\n\n    @property\n    def catalog(self) -&gt; \"DerivaML\":\n        \"\"\"Get the live catalog (DerivaML) instance for this execution.\n\n        This provides access to the live catalog for operations that require\n        catalog connectivity, such as looking up datasets or other read operations.\n\n        Returns:\n            DerivaML: The live catalog instance.\n\n        Example:\n            &gt;&gt;&gt; with ml.create_execution(config) as exe:\n            ...     # Use live catalog for lookups\n            ...     existing_dataset = exe.catalog.lookup_dataset(\"1-ABC\")\n        \"\"\"\n        return self._ml_object\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def download_dataset_bag(self, dataset: DatasetSpec) -&gt; DatasetBag:\n        \"\"\"Downloads and materializes a dataset for use in the execution.\n\n        Downloads the specified dataset as a BDBag and materializes it in the execution's\n        working directory. The dataset version is determined by the DatasetSpec.\n\n        Args:\n            dataset: Specification of the dataset to download, including version and\n                materialization options.\n\n        Returns:\n            DatasetBag: Object containing:\n                - path: Local filesystem path to downloaded dataset\n                - rid: Dataset's Resource Identifier\n                - minid: Dataset's Minimal Viable Identifier\n\n        Raises:\n            DerivaMLException: If download or materialization fails.\n\n        Example:\n            &gt;&gt;&gt; spec = DatasetSpec(rid=\"1-abc123\", version=\"1.2.0\")\n            &gt;&gt;&gt; bag = execution.download_dataset_bag(spec)\n            &gt;&gt;&gt; print(f\"Downloaded to {bag.path}\")\n        \"\"\"\n        return self._ml_object.download_dataset_bag(dataset)\n\n    @validate_call\n    def update_status(self, status: Status, msg: str) -&gt; None:\n        \"\"\"Updates the execution's status in the catalog.\n\n        Records a new status and associated message in the catalog, allowing remote\n        tracking of execution progress.\n\n        Args:\n            status: New status value (e.g., running, completed, failed).\n            msg: Description of the status change or current state.\n\n        Raises:\n            DerivaMLException: If status update fails.\n\n        Example:\n            &gt;&gt;&gt; execution.update_status(Status.running, \"Processing sample 1 of 10\")\n        \"\"\"\n        self._status = status\n        self._logger.info(msg)\n\n        if self._dry_run:\n            return\n\n        # Delegate to ExecutionRecord for catalog updates\n        if self._execution_record is not None:\n            self._execution_record.update_status(status, msg)\n        else:\n            # Fallback for cases where ExecutionRecord isn't available\n            self._ml_object.pathBuilder().schemas[self._ml_object.ml_schema].Execution.update(\n                [\n                    {\n                        \"RID\": self.execution_rid,\n                        \"Status\": status.value,\n                        \"Status_Detail\": msg,\n                    }\n                ]\n            )\n\n    def execution_start(self) -&gt; None:\n        \"\"\"Marks the execution as started.\n\n        Records the start time and updates the execution's status to 'running'.\n        This should be called before beginning the main execution work.\n\n        Example:\n            &gt;&gt;&gt; execution.execution_start()\n            &gt;&gt;&gt; try:\n            ...     # Run analysis\n            ...     execution.execution_stop()\n            ... except Exception:\n            ...     execution.update_status(Status.failed, \"Analysis error\")\n        \"\"\"\n        self.start_time = datetime.now()\n        self.uploaded_assets = None\n        self.update_status(Status.initializing, \"Start execution  ...\")\n\n    def execution_stop(self) -&gt; None:\n        \"\"\"Marks the execution as completed.\n\n        Records the stop time and updates the execution's status to 'completed'.\n        This should be called after all execution work is finished.\n\n        Example:\n            &gt;&gt;&gt; try:\n            ...     # Run analysis\n            ...     execution.execution_stop()\n            ... except Exception:\n            ...     execution.update_status(Status.failed, \"Analysis error\")\n        \"\"\"\n        self.stop_time = datetime.now()\n        duration = self.stop_time - self.start_time\n        hours, remainder = divmod(duration.total_seconds(), 3600)\n        minutes, seconds = divmod(remainder, 60)\n        duration = f\"{round(hours, 0)}H {round(minutes, 0)}min {round(seconds, 4)}sec\"\n\n        self.update_status(Status.completed, \"Algorithm execution ended.\")\n        if not self._dry_run:\n            self._ml_object.pathBuilder().schemas[self._ml_object.ml_schema].Execution.update(\n                [{\"RID\": self.execution_rid, \"Duration\": duration}]\n            )\n\n    def _upload_execution_dirs(\n        self,\n        progress_callback: Callable[[UploadProgress], None] | None = None,\n        max_retries: int = 3,\n        retry_delay: float = 5.0,\n        timeout: tuple[int, int] | None = None,\n        chunk_size: int | None = None,\n    ) -&gt; dict[str, list[AssetFilePath]]:\n        \"\"\"Upload execution assets at _working_dir/Execution_asset.\n\n        This routine uploads the contents of the\n        Execution_Asset directory and then updates the execution_asset table in the ML schema to have references\n        to these newly uploaded files.\n\n        Args:\n            progress_callback: Optional callback function to receive upload progress updates.\n                Called with UploadProgress objects containing file information and progress.\n            max_retries: Maximum number of retry attempts for failed uploads (default: 3).\n            retry_delay: Initial delay in seconds between retries, doubles with each attempt (default: 5.0).\n            timeout: Tuple of (connect_timeout, read_timeout) in seconds. Default is (600, 600).\n                Note: urllib3 uses connect_timeout as the socket timeout during request body\n                writes, so it must be large enough for a full chunk upload.\n            chunk_size: Optional chunk size in bytes for hatrac uploads. If provided,\n                large files will be uploaded in chunks of this size.\n\n        Returns:\n          dict: Results of the upload operation.\n\n        Raises:\n          DerivaMLException: If there is an issue when uploading the assets.\n        \"\"\"\n\n        try:\n            self.update_status(Status.running, \"Uploading execution files...\")\n            results = upload_directory(\n                self._model,\n                self._asset_root,\n                progress_callback=progress_callback,\n                max_retries=max_retries,\n                retry_delay=retry_delay,\n                timeout=timeout,\n                chunk_size=chunk_size,\n            )\n        except (RuntimeError, DerivaMLException) as e:\n            error = format_exception(e)\n            self.update_status(Status.failed, error)\n            raise DerivaMLException(f\"Failed to upload execution_assets: {error}\")\n\n        asset_map = {}\n        for path, status in results.items():\n            asset_table, file_name = normalize_asset_dir(path)\n\n            asset_map.setdefault(asset_table, []).append(\n                AssetFilePath(\n                    asset_path=path,\n                    asset_table=asset_table,\n                    file_name=file_name,\n                    asset_metadata={\n                        k: v\n                        for k, v in status.result.items()\n                        if k in self._model.asset_metadata(asset_table.split(\"/\")[1])\n                    },\n                    asset_types=[],\n                    asset_rid=status.result[\"RID\"],\n                )\n            )\n        self._update_asset_execution_table(asset_map)\n        self.update_status(Status.running, \"Updating features...\")\n\n        for p in self._feature_root.glob(\"**/*.jsonl\"):\n            m = is_feature_dir(p.parent)\n            self._update_feature_table(\n                target_table=m[\"target_table\"],\n                feature_name=m[\"feature_name\"],\n                feature_file=p,\n                uploaded_files=asset_map,\n            )\n\n        self.update_status(Status.running, \"Upload assets complete\")\n        return asset_map\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def download_asset(\n        self, asset_rid: RID, dest_dir: Path, update_catalog: bool = True, use_cache: bool = False\n    ) -&gt; AssetFilePath:\n        \"\"\"Download an asset from a URL and place it in a local directory.\n\n        Args:\n            asset_rid: RID of the asset.\n            dest_dir: Destination directory for the asset.\n            update_catalog: Whether to update the catalog execution information after downloading.\n            use_cache: If True, check the cache directory for a previously downloaded copy\n                with a matching MD5 checksum before downloading. Cached copies are stored\n                in ``cache_dir/assets/{rid}_{md5}/`` and symlinked into the destination.\n\n        Returns:\n            An AssetFilePath with the path to the downloaded (or cached) asset file.\n        \"\"\"\n\n        asset_table = self._ml_object.resolve_rid(asset_rid).table\n        if not self._model.is_asset(asset_table):\n            raise DerivaMLException(f\"RID {asset_rid}  is not for an asset table.\")\n\n        asset_record = self._ml_object.retrieve_rid(asset_rid)\n        asset_metadata = {k: v for k, v in asset_record.items() if k in self._model.asset_metadata(asset_table)}\n        asset_url = asset_record[\"URL\"]\n        asset_filename = dest_dir / asset_record[\"Filename\"]\n\n        # Check cache before downloading\n        cache_hit = False\n        if use_cache:\n            md5 = asset_record.get(\"MD5\")\n            if md5:\n                asset_cache_dir = self._ml_object.cache_dir / \"assets\"\n                asset_cache_dir.mkdir(parents=True, exist_ok=True)\n                cache_key = f\"{asset_rid}_{md5}\"\n                cached_file = asset_cache_dir / cache_key / asset_record[\"Filename\"]\n                if cached_file.exists():\n                    # Cache hit \u2014 symlink from cache to destination\n                    self._logger.info(f\"Using cached asset {asset_rid} (MD5: {md5})\")\n                    if asset_filename.exists() or asset_filename.is_symlink():\n                        asset_filename.unlink()\n                    asset_filename.symlink_to(cached_file)\n                    cache_hit = True\n\n        if not cache_hit:\n            hs = HatracStore(\"https\", self._ml_object.host_name, self._ml_object.credential)\n            hs.get_obj(path=asset_url, destfilename=asset_filename.as_posix())\n\n            # Store in cache for future use\n            if use_cache:\n                md5 = asset_record.get(\"MD5\")\n                if md5:\n                    asset_cache_dir = self._ml_object.cache_dir / \"assets\"\n                    asset_cache_dir.mkdir(parents=True, exist_ok=True)\n                    cache_key = f\"{asset_rid}_{md5}\"\n                    cache_entry_dir = asset_cache_dir / cache_key\n                    cache_entry_dir.mkdir(parents=True, exist_ok=True)\n                    cached_file = cache_entry_dir / asset_record[\"Filename\"]\n                    # Move file to cache, then symlink back\n                    shutil.move(str(asset_filename), str(cached_file))\n                    asset_filename.symlink_to(cached_file)\n                    self._logger.info(f\"Cached asset {asset_rid} (MD5: {md5})\")\n\n        asset_type_table, _col_l, _col_r = self._model.find_association(asset_table, MLVocab.asset_type)\n        type_path = self._ml_object.pathBuilder().schemas[asset_type_table.schema.name].tables[asset_type_table.name]\n        asset_types = [\n            asset_type[MLVocab.asset_type.value]\n            for asset_type in type_path.filter(type_path.columns[asset_table.name] == asset_rid)\n            .attributes(type_path.Asset_Type)\n            .fetch()\n        ]\n\n        asset_path = AssetFilePath(\n            file_name=asset_filename,\n            asset_rid=asset_rid,\n            asset_path=asset_filename,\n            asset_metadata=asset_metadata,\n            asset_table=asset_table.name,\n            asset_types=asset_types,\n        )\n\n        if update_catalog:\n            self._update_asset_execution_table(\n                {f\"{asset_table.schema.name}/{asset_table.name}\": [asset_path]},\n                asset_role=\"Input\",\n            )\n        return asset_path\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def upload_assets(\n        self,\n        assets_dir: str | Path,\n    ) -&gt; dict[Any, FileUploadState] | None:\n        \"\"\"Uploads assets from a directory to the catalog.\n\n        Scans the specified directory for assets and uploads them to the catalog,\n        recording their metadata and types. Assets are organized by their types\n        and associated with the execution.\n\n        Args:\n            assets_dir: Directory containing assets to upload.\n\n        Returns:\n            dict[Any, FileUploadState] | None: Mapping of assets to their upload states,\n                or None if no assets were found.\n\n        Raises:\n            DerivaMLException: If upload fails or assets are invalid.\n\n        Example:\n            &gt;&gt;&gt; states = execution.upload_assets(\"output/results\")\n            &gt;&gt;&gt; for asset, state in states.items():\n            ...     print(f\"{asset}: {state}\")\n        \"\"\"\n\n        def path_to_asset(path: str) -&gt; str:\n            \"\"\"Pull the asset name out of a path to that asset in the filesystem\"\"\"\n            components = path.split(\"/\")\n            return components[components.index(\"asset\") + 2]  # Look for asset in the path to find the name\n\n        if not self._model.is_asset(Path(assets_dir).name):\n            raise DerivaMLException(\"Directory does not have name of an asset table.\")\n        results = upload_directory(self._model, assets_dir)\n        return {path_to_asset(p): r for p, r in results.items()}\n\n    def upload_execution_outputs(\n        self,\n        clean_folder: bool | None = None,\n        progress_callback: Callable[[UploadProgress], None] | None = None,\n        max_retries: int = 3,\n        retry_delay: float = 5.0,\n        timeout: tuple[int, int] | None = None,\n        chunk_size: int | None = None,\n    ) -&gt; dict[str, list[AssetFilePath]]:\n        \"\"\"Uploads all outputs from the execution to the catalog.\n\n        Scans the execution's output directories for assets, features, and other results,\n        then uploads them to the catalog. Can optionally clean up the output folders\n        after successful upload.\n\n        IMPORTANT: This method must be called AFTER exiting the context manager, not inside it.\n        The context manager handles execution timing (start/stop), while this method handles\n        the separate upload step.\n\n        Args:\n            clean_folder: Whether to delete output folders after upload. If None (default),\n                uses the DerivaML instance's clean_execution_dir setting. Pass True/False\n                to override for this specific execution.\n            progress_callback: Optional callback function to receive upload progress updates.\n                Called with UploadProgress objects containing file name, bytes uploaded,\n                total bytes, percent complete, phase, and status message.\n            max_retries: Maximum number of retry attempts for failed uploads (default: 3).\n            retry_delay: Initial delay in seconds between retries, doubles with each attempt (default: 5.0).\n            timeout: Tuple of (connect_timeout, read_timeout) in seconds. Default is (600, 600).\n                Note: urllib3 uses connect_timeout as the socket timeout during request body\n                writes, so it must be large enough for a full chunk upload.\n            chunk_size: Optional chunk size in bytes for hatrac uploads. If provided,\n                large files will be uploaded in chunks of this size.\n\n        Returns:\n            dict[str, list[AssetFilePath]]: Mapping of asset types to their file paths.\n\n        Raises:\n            DerivaMLException: If upload fails or outputs are invalid.\n\n        Example:\n            &gt;&gt;&gt; with ml.create_execution(config) as execution:\n            ...     # Do ML work, register output files with asset_file_path()\n            ...     path = execution.asset_file_path(\"Model\", \"model.pt\")\n            ...     # Write to path...\n            ...\n            &gt;&gt;&gt; # Upload AFTER the context manager exits\n            &gt;&gt;&gt; def my_callback(progress):\n            ...     print(f\"Uploading {progress.file_name}: {progress.percent_complete:.1f}%\")\n            &gt;&gt;&gt; outputs = execution.upload_execution_outputs(progress_callback=my_callback)\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Upload large files with increased timeout (30 min per chunk)\n            &gt;&gt;&gt; outputs = execution.upload_execution_outputs(timeout=(6, 1800))\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Override cleanup setting for this execution\n            &gt;&gt;&gt; outputs = execution.upload_execution_outputs(clean_folder=False)  # Keep files\n        \"\"\"\n        if self._dry_run:\n            return {}\n\n        # Use DerivaML instance setting if not explicitly provided\n        if clean_folder is None:\n            clean_folder = getattr(self._ml_object, 'clean_execution_dir', True)\n\n        try:\n            self.uploaded_assets = self._upload_execution_dirs(\n                progress_callback=progress_callback,\n                max_retries=max_retries,\n                retry_delay=retry_delay,\n                timeout=timeout,\n                chunk_size=chunk_size,\n            )\n            self.update_status(Status.completed, \"Successfully end the execution.\")\n            if clean_folder:\n                self._clean_folder_contents(self._execution_root)\n            return self.uploaded_assets\n        except Exception as e:\n            error = format_exception(e)\n            self.update_status(Status.failed, error)\n            raise e\n\n    def _clean_folder_contents(self, folder_path: Path, remove_folder: bool = True):\n        \"\"\"Clean up folder contents and optionally the folder itself.\n\n        Removes all files and subdirectories within the specified folder.\n        Uses retry logic for Windows compatibility where files may be temporarily locked.\n\n        Args:\n            folder_path: Path to the folder to clean.\n            remove_folder: If True (default), also remove the folder itself after\n                cleaning its contents. If False, only remove contents.\n        \"\"\"\n        MAX_RETRIES = 3\n        RETRY_DELAY = 1  # seconds\n\n        def remove_with_retry(path: Path, is_dir: bool = False) -&gt; bool:\n            for attempt in range(MAX_RETRIES):\n                try:\n                    if is_dir:\n                        shutil.rmtree(path)\n                    else:\n                        Path(path).unlink()\n                    return True\n                except (OSError, PermissionError) as e:\n                    if attempt == MAX_RETRIES - 1:\n                        logging.warning(f\"Failed to remove {path}: {e}\")\n                        return False\n                    time.sleep(RETRY_DELAY)\n            return False\n\n        try:\n            # First remove all contents\n            with os.scandir(folder_path) as entries:\n                for entry in entries:\n                    if entry.is_dir() and not entry.is_symlink():\n                        remove_with_retry(Path(entry.path), is_dir=True)\n                    else:\n                        remove_with_retry(Path(entry.path))\n\n            # Then remove the folder itself if requested\n            if remove_folder:\n                remove_with_retry(folder_path, is_dir=True)\n\n        except OSError as e:\n            logging.warning(f\"Failed to clean folder {folder_path}: {e}\")\n\n    def _update_feature_table(\n        self,\n        target_table: str,\n        feature_name: str,\n        feature_file: str | Path,\n        uploaded_files: dict[str, list[AssetFilePath]],\n    ) -&gt; None:\n        \"\"\"Update the feature table with values from a JSONL file.\n\n        Reads feature values from a file and inserts them into the catalog,\n        replacing file paths with the RIDs of uploaded assets.\n\n        Args:\n            target_table: Name of the table the feature is defined on.\n            feature_name: Name of the feature to update.\n            feature_file: Path to JSONL file containing feature values.\n            uploaded_files: Map from asset table names to their uploaded AssetFilePath objects.\n        \"\"\"\n\n        # Get the column names of all the Feature columns that should be the RID of an asset\n        asset_columns = [\n            c.name for c in self._ml_object.feature_record_class(target_table, feature_name).feature.asset_columns\n        ]\n\n        # Get the names of the columns in the feature that are assets.\n        asset_columns = [\n            c.name for c in self._ml_object.feature_record_class(target_table, feature_name).feature.asset_columns\n        ]\n\n        feature_table = self._ml_object.feature_record_class(target_table, feature_name).feature.feature_table.name\n        asset_map = {\n            (asset_table, asset.file_name): asset.asset_rid\n            for asset_table, assets in uploaded_files.items()\n            for asset in assets\n        }\n\n        def map_path(e):\n            \"\"\"Go through the asset columns and replace the file name with the RID for the uploaded file.\"\"\"\n            for c in asset_columns:\n                e[c] = asset_map[normalize_asset_dir(e[c])]\n            return e\n\n        # Load the JSON file that has the set of records that contain the feature values.\n        with Path(feature_file).open(\"r\") as feature_values:\n            entities = [json.loads(line.strip()) for line in feature_values]\n        # Update the asset columns in the feature and add to the catalog.\n        self._ml_object.domain_path().tables[feature_table].insert([map_path(e) for e in entities], on_conflict_skip=True)\n\n    def _update_asset_execution_table(\n        self,\n        uploaded_assets: dict[str, list[AssetFilePath]],\n        asset_role: str = \"Output\",\n    ) -&gt; None:\n        \"\"\"Add entry to the association table connecting an asset to an execution RID\n\n        Args:\n            uploaded_assets: Dictionary whose key is the name of an asset table and whose value is a list of RIDs for\n                newly added assets to that table.\n             asset_role: A term or list of terms from the Asset_Role vocabulary.\n        \"\"\"\n        # Make sure the asset role is in the controlled vocabulary table.\n        if self._dry_run:\n            # Don't do any updates of we are doing a dry run.\n            return\n        self._ml_object.lookup_term(MLVocab.asset_role, asset_role)\n\n        pb = self._ml_object.pathBuilder()\n        for asset_table, asset_list in uploaded_assets.items():\n            asset_table_name = asset_table.split(\"/\")[1]  # Peel off the schema from the asset table\n            asset_exe, asset_fk, execution_fk = self._model.find_association(asset_table_name, \"Execution\")\n            asset_exe_path = pb.schemas[asset_exe.schema.name].tables[asset_exe.name]\n\n            asset_exe_path.insert(\n                [\n                    {\n                        asset_fk: asset_path.asset_rid,\n                        execution_fk: self.execution_rid,\n                        \"Asset_Role\": asset_role,\n                    }\n                    for asset_path in asset_list\n                ],\n                on_conflict_skip=True,\n            )\n\n            # Now add in the type names via the asset_asset_type association table.\n            # Get the list of types for each file in the asset.\n            if asset_role == \"Input\":\n                return\n            asset_type_map = {}\n            with Path(\n                asset_type_path(\n                    self._working_dir,\n                    self.execution_rid,\n                    self._model.name_to_table(asset_table_name),\n                )\n            ).open(\"r\") as asset_type_file:\n                for line in asset_type_file:\n                    asset_type_map.update(json.loads(line.strip()))\n            for asset_path in asset_list:\n                asset_path.asset_types = asset_type_map[asset_path.file_name]\n\n            asset_asset_type, _, _ = self._model.find_association(asset_table_name, \"Asset_Type\")\n            type_path = pb.schemas[asset_asset_type.schema.name].tables[asset_asset_type.name]\n\n            type_path.insert(\n                [\n                    {asset_table_name: asset.asset_rid, \"Asset_Type\": t}\n                    for asset in asset_list\n                    for t in asset_type_map[asset.file_name]\n                ],\n                on_conflict_skip=True,\n            )\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def asset_file_path(\n        self,\n        asset_name: str,\n        file_name: str | Path,\n        asset_types: list[str] | str | None = None,\n        copy_file=False,\n        rename_file: str | None = None,\n        **kwargs,\n    ) -&gt; AssetFilePath:\n        \"\"\"Return a pathlib Path to the directory in which to place files for the specified execution_asset type.\n\n        Given the name of an asset table, and a file name, register the file for upload and return a path to that\n        file in the upload directory.  In addition to the filename, additional asset metadata and file asset types may\n        be specified.\n\n        This routine has three modes, depending on if file_name refers to an existing file.  If it doesn't, a path\n        to a new file with the specified name is returned.  The caller can then open that file for writing.\n\n        If the provided filename refers to an existing file and the copy_file argument is False (the default), then the\n        returned path contains a symbolic link to that file.  If the copy_file argument is True, then the contents of\n        file_name are copied into the target directory.\n\n        Args:\n            asset_name: Type of asset to be uploaded.  Must be a term in Asset_Type controlled vocabulary.\n            file_name: Name of file to be uploaded.\n            asset_types: Type of asset to be uploaded.  Defaults to the name of the asset.\n            copy_file: Whether to copy the file rather than creating a symbolic link.\n            rename_file: If provided, the file will be renamed to this name if the file already exists..\n            **kwargs: Any additional metadata values that may be part of the asset table.\n\n        Returns:\n            Path in which to place asset files.\n\n        Raises:\n            DerivaException: If the asset type is not defined.\n        \"\"\"\n        if not self._model.is_asset(asset_name):\n            DerivaMLException(f\"Table {asset_name} is not an asset\")\n\n        asset_table = self._model.name_to_table(asset_name)\n\n        asset_types = asset_types or kwargs.get(\"Asset_Type\", None) or asset_name\n        asset_types = [asset_types] if isinstance(asset_types, str) else asset_types\n        for t in asset_types:\n            self._ml_object.lookup_term(MLVocab.asset_type, t)\n\n        # Determine if we will need to rename an existing file as the asset.\n        file_name = Path(file_name)\n        if file_name.name == \"_implementations.log\":\n            # There is a funny bug with S3 hatrac if we have the leading _ in the filename.\n            file_name = file_name.with_name(\"-implementations.log\")\n\n        # Resolve relative paths to absolute paths to ensure exists() and symlink work correctly\n        # regardless of the current working directory\n        if not file_name.is_absolute():\n            file_name = file_name.resolve()\n\n        target_name = Path(rename_file) if file_name.exists() and rename_file else file_name\n        asset_path = asset_file_path(\n            prefix=self._working_dir,\n            exec_rid=self.execution_rid,\n            asset_table=self._model.name_to_table(asset_name),\n            file_name=target_name.name,\n            metadata=kwargs,\n        )\n\n        if file_name.exists():\n            if copy_file:\n                asset_path.write_bytes(file_name.read_bytes())\n            else:\n                try:\n                    asset_path.symlink_to(file_name)\n                except (OSError, PermissionError):\n                    # Fallback to copy if symlink fails (common on Windows)\n                    asset_path.write_bytes(file_name.read_bytes())\n\n        # Persist the asset types into a file\n        with Path(asset_type_path(self._working_dir, self.execution_rid, asset_table)).open(\"a\") as asset_type_file:\n            asset_type_file.write(json.dumps({target_name.name: asset_types}) + \"\\n\")\n\n        return AssetFilePath(\n            asset_path=asset_path,\n            asset_table=asset_name,\n            file_name=target_name.name,\n            asset_metadata=kwargs,\n            asset_types=asset_types,\n        )\n\n    def table_path(self, table: str) -&gt; Path:\n        \"\"\"Return a local file path to a CSV to add values to a table on upload.\n\n        Args:\n            table: Name of table to be uploaded.\n\n        Returns:\n            Pathlib path to the file in which to place table values.\n        \"\"\"\n        # Find which domain schema contains this table\n        table_schema = None\n        for domain_schema in self._ml_object.domain_schemas:\n            if domain_schema in self._model.schemas:\n                if table in self._model.schemas[domain_schema].tables:\n                    table_schema = domain_schema\n                    break\n\n        if table_schema is None:\n            raise DerivaMLException(\"Table '{}' not found in any domain schema\".format(table))\n\n        return table_path(self._working_dir, schema=table_schema, table=table)\n\n    def execute(self) -&gt; Execution:\n        \"\"\"Initiate an execution with the provided configuration. Can be used in a context manager.\"\"\"\n        self.execution_start()\n        return self\n\n    @validate_call\n    def add_features(self, features: Iterable[FeatureRecord]) -&gt; None:\n        \"\"\"Adds feature records to the catalog.\n\n        Associates feature records with this execution and uploads them to the catalog.\n        Features represent measurable properties or characteristics of records.\n\n        NOTE: The catalog is not updated until upload_execution_outputs() is called.\n\n        Args:\n            features: Feature records to add, each containing a value and metadata.\n\n        Raises:\n            DerivaMLException: If feature addition fails or features are invalid.\n\n        Example:\n            &gt;&gt;&gt; feature = FeatureRecord(value=\"high\", confidence=0.95)\n            &gt;&gt;&gt; execution.add_features([feature])\n        \"\"\"\n\n        # Make sure feature list is homogeneous:\n        sorted_features = defaultdict(list)\n        for f in features:\n            sorted_features[type(f)].append(f)\n        for fs in sorted_features.values():\n            self._add_features(fs)\n\n    def _add_features(self, features: list[FeatureRecord]) -&gt; None:\n        # Update feature records to include current execution_rid\n        first_row = features[0]\n        feature = first_row.feature\n        # Use the schema from the feature table\n        feature_schema = feature.feature_table.schema.name\n        json_path = feature_value_path(\n            self._working_dir,\n            schema=feature_schema,\n            target_table=feature.target_table.name,\n            feature_name=feature.feature_name,\n            exec_rid=self.execution_rid,\n        )\n        with Path(json_path).open(\"a\", encoding=\"utf-8\") as file:\n            for feature in features:\n                feature.Execution = self.execution_rid\n                file.write(json.dumps(feature.model_dump(mode=\"json\")) + \"\\n\")\n\n    def list_input_datasets(self) -&gt; list[Dataset]:\n        \"\"\"List all datasets that were inputs to this execution.\n\n        Returns:\n            List of Dataset objects that were used as inputs.\n\n        Example:\n            &gt;&gt;&gt; for ds in execution.list_input_datasets():\n            ...     print(f\"Input: {ds.dataset_rid} - {ds.description}\")\n        \"\"\"\n        if self._execution_record is not None:\n            return self._execution_record.list_input_datasets()\n\n        # Fallback for dry_run mode\n        pb = self._ml_object.pathBuilder()\n        dataset_exec = pb.schemas[self._ml_object.ml_schema].Dataset_Execution\n\n        records = list(\n            dataset_exec.filter(dataset_exec.Execution == self.execution_rid)\n            .entities()\n            .fetch()\n        )\n\n        return [self._ml_object.lookup_dataset(r[\"Dataset\"]) for r in records]\n\n    def list_assets(self, asset_role: str | None = None) -&gt; list[\"Asset\"]:\n        \"\"\"List all assets that were inputs or outputs of this execution.\n\n        Args:\n            asset_role: Optional filter: \"Input\" or \"Output\". If None, returns all.\n\n        Returns:\n            List of Asset objects associated with this execution.\n\n        Example:\n            &gt;&gt;&gt; inputs = execution.list_assets(asset_role=\"Input\")\n            &gt;&gt;&gt; outputs = execution.list_assets(asset_role=\"Output\")\n        \"\"\"\n        if self._execution_record is not None:\n            return self._execution_record.list_assets(asset_role=asset_role)\n\n        # Fallback for dry_run mode\n\n        pb = self._ml_object.pathBuilder()\n        asset_exec = pb.schemas[self._ml_object.ml_schema].Execution_Asset_Execution\n\n        query = asset_exec.filter(asset_exec.Execution == self.execution_rid)\n        if asset_role:\n            query = query.filter(asset_exec.Asset_Role == asset_role)\n\n        records = list(query.entities().fetch())\n\n        assets = []\n        for r in records:\n            try:\n                asset = self._ml_object.lookup_asset(r[\"Execution_Asset\"])\n                assets.append(asset)\n            except Exception:\n                pass  # Skip assets that can't be looked up\n        return assets\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def create_dataset(\n        self,\n        dataset_types: str | list[str] | None = None,\n        version: DatasetVersion | str | None = None,\n        description: str = \"\",\n    ) -&gt; Dataset:\n        \"\"\"Create a new dataset with specified types.\n\n        Creates a dataset associated with this execution for provenance tracking.\n\n        Args:\n            dataset_types: One or more dataset type terms from Dataset_Type vocabulary.\n            description: Markdown description of the dataset being created.\n            version: Dataset version. Defaults to 0.1.0.\n\n        Returns:\n            The newly created Dataset.\n        \"\"\"\n        return Dataset.create_dataset(\n            ml_instance=self._ml_object,\n            execution_rid=self.execution_rid,\n            dataset_types=dataset_types,\n            version=version,\n            description=description,\n        )\n\n    @validate_call(config=ConfigDict(arbitrary_types_allowed=True))\n    def add_files(\n        self,\n        files: Iterable[FileSpec],\n        dataset_types: str | list[str] | None = None,\n        description: str = \"\",\n    ) -&gt; \"Dataset\":\n        \"\"\"Adds files to the catalog with their metadata.\n\n        Registers files in the catalog along with their metadata (MD5, length, URL) and associates them with\n        specified file types.\n\n        Args:\n            files: File specifications containing MD5 checksum, length, and URL.\n            dataset_types: One or more dataset type terms from File_Type vocabulary.\n            description: Description of the files.\n\n        Returns:\n            RID: Dataset  that identifies newly added files. Will be nested to mirror original directory structure\n            of the files.\n\n        Raises:\n            DerivaMLInvalidTerm: If file_types are invalid or execution_rid is not an execution record.\n\n        Examples:\n            Add a single file type:\n                &gt;&gt;&gt; files = [FileSpec(url=\"path/to/file.txt\", md5=\"abc123\", length=1000)]\n                &gt;&gt;&gt; rids = exe.add_files(files, file_types=\"text\")\n\n            Add multiple file types:\n                &gt;&gt;&gt; rids = exe.add_files(\n                ...     files=[FileSpec(url=\"image.png\", md5=\"def456\", length=2000)],\n                ...     file_types=[\"image\", \"png\"],\n                ... )\n        \"\"\"\n        return self._ml_object.add_files(\n            files=files,\n            execution_rid=self.execution_rid,\n            dataset_types=dataset_types,\n            description=description,\n        )\n\n    # =========================================================================\n    # Execution Nesting Methods\n    # =========================================================================\n\n    def add_nested_execution(\n        self,\n        nested_execution: \"Execution | ExecutionRecord | RID\",\n        sequence: int | None = None,\n    ) -&gt; None:\n        \"\"\"Add a nested (child) execution to this execution.\n\n        Creates a parent-child relationship between this execution and another.\n        This is useful for grouping related executions, such as parameter sweeps\n        or pipeline stages.\n\n        Args:\n            nested_execution: The child execution to add (Execution, ExecutionRecord, or RID).\n            sequence: Optional ordering index (0, 1, 2...). Use None for parallel executions.\n\n        Raises:\n            DerivaMLException: If the association cannot be created.\n\n        Example:\n            &gt;&gt;&gt; parent_exec = ml.create_execution(parent_config)\n            &gt;&gt;&gt; child_exec = ml.create_execution(child_config)\n            &gt;&gt;&gt; parent_exec.add_nested_execution(child_exec, sequence=0)\n        \"\"\"\n        if self._dry_run:\n            return\n\n        # Get the RID from the nested execution\n        if isinstance(nested_execution, Execution):\n            nested_rid = nested_execution.execution_rid\n        elif isinstance(nested_execution, ExecutionRecord):\n            nested_rid = nested_execution.execution_rid\n        else:\n            nested_rid = nested_execution\n\n        # Delegate to ExecutionRecord if available\n        if self._execution_record is not None:\n            self._execution_record.add_nested_execution(nested_rid, sequence=sequence)\n        else:\n            # Fallback for cases without execution record\n            pb = self._ml_object.pathBuilder()\n            execution_execution = pb.schemas[self._ml_object.ml_schema].Execution_Execution\n\n            record = {\n                \"Execution\": self.execution_rid,\n                \"Nested_Execution\": nested_rid,\n            }\n            if sequence is not None:\n                record[\"Sequence\"] = sequence\n\n            execution_execution.insert([record])\n\n    def list_nested_executions(\n        self,\n        recurse: bool = False,\n        _visited: set[RID] | None = None,\n    ) -&gt; list[\"ExecutionRecord\"]:\n        \"\"\"List all nested (child) executions of this execution.\n\n        Args:\n            recurse: If True, recursively return all descendant executions.\n            _visited: Internal parameter to track visited executions and prevent infinite recursion.\n\n        Returns:\n            List of nested ExecutionRecord objects, ordered by sequence if available.\n            To get full Execution objects with lifecycle management, use restore_execution().\n\n        Example:\n            &gt;&gt;&gt; children = parent_exec.list_nested_executions()\n            &gt;&gt;&gt; all_descendants = parent_exec.list_nested_executions(recurse=True)\n        \"\"\"\n        if self._execution_record is not None:\n            return list(self._execution_record.list_nested_executions(recurse=recurse, _visited=_visited))\n\n        # Fallback for dry_run mode\n        if _visited is None:\n            _visited = set()\n\n        if self.execution_rid in _visited:\n            return []\n        _visited.add(self.execution_rid)\n\n        pb = self._ml_object.pathBuilder()\n        execution_execution = pb.schemas[self._ml_object.ml_schema].Execution_Execution\n\n        # Query for nested executions, ordered by sequence\n        nested = list(\n            execution_execution.filter(execution_execution.Execution == self.execution_rid)\n            .entities()\n            .fetch()\n        )\n\n        # Sort by sequence (None values at the end)\n        nested.sort(key=lambda x: (x.get(\"Sequence\") is None, x.get(\"Sequence\")))\n\n        children = []\n        for record in nested:\n            child = self._ml_object.lookup_execution(record[\"Nested_Execution\"])\n            children.append(child)\n            if recurse:\n                children.extend(child.list_nested_executions(recurse=True, _visited=_visited))\n\n        return children\n\n    def list_parent_executions(\n        self,\n        recurse: bool = False,\n        _visited: set[RID] | None = None,\n    ) -&gt; list[\"ExecutionRecord\"]:\n        \"\"\"List all parent executions that contain this execution as a nested child.\n\n        Args:\n            recurse: If True, recursively return all ancestor executions.\n            _visited: Internal parameter to track visited executions and prevent infinite recursion.\n\n        Returns:\n            List of parent ExecutionRecord objects.\n            To get full Execution objects with lifecycle management, use restore_execution().\n\n        Example:\n            &gt;&gt;&gt; parents = child_exec.list_parent_executions()\n            &gt;&gt;&gt; all_ancestors = child_exec.list_parent_executions(recurse=True)\n        \"\"\"\n        if self._execution_record is not None:\n            return list(self._execution_record.list_parent_executions(recurse=recurse, _visited=_visited))\n\n        # Fallback for dry_run mode\n        if _visited is None:\n            _visited = set()\n\n        if self.execution_rid in _visited:\n            return []\n        _visited.add(self.execution_rid)\n\n        pb = self._ml_object.pathBuilder()\n        execution_execution = pb.schemas[self._ml_object.ml_schema].Execution_Execution\n\n        parent_records = list(\n            execution_execution.filter(execution_execution.Nested_Execution == self.execution_rid)\n            .entities()\n            .fetch()\n        )\n\n        parents = []\n        for record in parent_records:\n            parent = self._ml_object.lookup_execution(record[\"Execution\"])\n            parents.append(parent)\n            if recurse:\n                parents.extend(parent.list_parent_executions(recurse=True, _visited=_visited))\n\n        return parents\n\n    def is_nested(self) -&gt; bool:\n        \"\"\"Check if this execution is nested within another execution.\n\n        Returns:\n            True if this execution has at least one parent execution.\n        \"\"\"\n        if self._execution_record is not None:\n            return self._execution_record.is_nested()\n        return len(self.list_parent_executions()) &gt; 0\n\n    def is_parent(self) -&gt; bool:\n        \"\"\"Check if this execution has nested child executions.\n\n        Returns:\n            True if this execution has at least one nested execution.\n        \"\"\"\n        if self._execution_record is not None:\n            return self._execution_record.is_parent()\n        return len(self.list_nested_executions()) &gt; 0\n\n    def __str__(self):\n        items = [\n            f\"caching_dir: {self._cache_dir}\",\n            f\"_working_dir: {self._working_dir}\",\n            f\"execution_rid: {self.execution_rid}\",\n            f\"workflow_rid: {self.workflow_rid}\",\n            f\"asset_paths: {self.asset_paths}\",\n            f\"configuration: {self.configuration}\",\n        ]\n        return \"\\n\".join(items)\n\n    def __enter__(self):\n        \"\"\"\n        Method invoked when entering the context.\n\n        Returns:\n        - self: The instance itself.\n\n        \"\"\"\n        self.execution_start()\n        return self\n\n    def __exit__(self, exc_type: Any, exc_value: Any, exc_tb: Any) -&gt; bool:\n        \"\"\"\n        Method invoked when exiting the context.\n\n        Args:\n           exc_type: Exception type.\n           exc_value: Exception value.\n           exc_tb: Exception traceback.\n\n        Returns:\n           bool: True if execution completed successfully, False otherwise.\n        \"\"\"\n        if not exc_type:\n            self.update_status(Status.running, \"Successfully run Ml.\")\n            self.execution_stop()\n            return True\n        else:\n            self.update_status(\n                Status.failed,\n                f\"Exception type: {exc_type}, Exception value: {exc_value}\",\n            )\n            logging.error(f\"Exception type: {exc_type}, Exception value: {exc_value}, Exception traceback: {exc_tb}\")\n            return False\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.catalog","title":"catalog  <code>property</code>","text":"<pre><code>catalog: 'DerivaML'\n</code></pre> <p>Get the live catalog (DerivaML) instance for this execution.</p> <p>This provides access to the live catalog for operations that require catalog connectivity, such as looking up datasets or other read operations.</p> <p>Returns:</p> Name Type Description <code>DerivaML</code> <code>'DerivaML'</code> <p>The live catalog instance.</p> Example <p>with ml.create_execution(config) as exe: ...     # Use live catalog for lookups ...     existing_dataset = exe.catalog.lookup_dataset(\"1-ABC\")</p>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.database_catalog","title":"database_catalog  <code>property</code>","text":"<pre><code>database_catalog: (\n    DerivaMLDatabase | None\n)\n</code></pre> <p>Get a catalog-like interface for downloaded datasets.</p> <p>Returns a DerivaMLDatabase that implements the DerivaMLCatalog protocol, allowing the same code to work with both live catalogs and downloaded bags.</p> <p>This is useful for writing code that can operate on either a live catalog (via DerivaML) or on downloaded bags (via DerivaMLDatabase).</p> <p>Returns:</p> Type Description <code>DerivaMLDatabase | None</code> <p>DerivaMLDatabase wrapping the primary downloaded dataset's model,</p> <code>DerivaMLDatabase | None</code> <p>or None if no datasets have been downloaded.</p> Example <p>with ml.create_execution(config) as exe: ...     if exe.database_catalog: ...         db = exe.database_catalog ...         # Use same interface as DerivaML ...         dataset = db.lookup_dataset(\"4HM\") ...         term = db.lookup_term(\"Diagnosis\", \"cancer\") ...     else: ...         # No datasets downloaded, use live catalog ...         pass</p>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.execution_record","title":"execution_record  <code>property</code>","text":"<pre><code>execution_record: ExecutionRecord | None\n</code></pre> <p>Get the ExecutionRecord for catalog operations.</p> <p>Returns:</p> Type Description <code>ExecutionRecord | None</code> <p>ExecutionRecord if not in dry_run mode, None otherwise.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.status","title":"status  <code>property</code> <code>writable</code>","text":"<pre><code>status: Status\n</code></pre> <p>Get the current execution status.</p> <p>Returns:</p> Name Type Description <code>Status</code> <code>Status</code> <p>The current status (Created, Running, Completed, Failed, etc.).</p>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.working_dir","title":"working_dir  <code>property</code>","text":"<pre><code>working_dir: Path\n</code></pre> <p>Return the working directory for the execution.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.__enter__","title":"__enter__","text":"<pre><code>__enter__()\n</code></pre> <p>Method invoked when entering the context.</p> <p>Returns: - self: The instance itself.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def __enter__(self):\n    \"\"\"\n    Method invoked when entering the context.\n\n    Returns:\n    - self: The instance itself.\n\n    \"\"\"\n    self.execution_start()\n    return self\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.__exit__","title":"__exit__","text":"<pre><code>__exit__(\n    exc_type: Any,\n    exc_value: Any,\n    exc_tb: Any,\n) -&gt; bool\n</code></pre> <p>Method invoked when exiting the context.</p> <p>Parameters:</p> Name Type Description Default <code>exc_type</code> <code>Any</code> <p>Exception type.</p> required <code>exc_value</code> <code>Any</code> <p>Exception value.</p> required <code>exc_tb</code> <code>Any</code> <p>Exception traceback.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if execution completed successfully, False otherwise.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def __exit__(self, exc_type: Any, exc_value: Any, exc_tb: Any) -&gt; bool:\n    \"\"\"\n    Method invoked when exiting the context.\n\n    Args:\n       exc_type: Exception type.\n       exc_value: Exception value.\n       exc_tb: Exception traceback.\n\n    Returns:\n       bool: True if execution completed successfully, False otherwise.\n    \"\"\"\n    if not exc_type:\n        self.update_status(Status.running, \"Successfully run Ml.\")\n        self.execution_stop()\n        return True\n    else:\n        self.update_status(\n            Status.failed,\n            f\"Exception type: {exc_type}, Exception value: {exc_value}\",\n        )\n        logging.error(f\"Exception type: {exc_type}, Exception value: {exc_value}, Exception traceback: {exc_tb}\")\n        return False\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.__init__","title":"__init__","text":"<pre><code>__init__(\n    configuration: ExecutionConfiguration,\n    ml_object: DerivaML,\n    workflow: Workflow | None = None,\n    reload: RID | None = None,\n    dry_run: bool = False,\n)\n</code></pre> <p>Initializes an Execution instance.</p> <p>Creates a new execution or reloads an existing one. Initializes the execution environment, downloads required datasets, and sets up asset tracking.</p> <p>Parameters:</p> Name Type Description Default <code>configuration</code> <code>ExecutionConfiguration</code> <p>Settings and parameters for the execution.</p> required <code>ml_object</code> <code>DerivaML</code> <p>DerivaML instance managing the execution.</p> required <code>workflow</code> <code>Workflow | None</code> <p>Optional Workflow object. If not specified, the workflow is taken from the ExecutionConfiguration object. Must be a Workflow object, not a RID.</p> <code>None</code> <code>reload</code> <code>RID | None</code> <p>Optional RID of existing execution to reload.</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>If True, don't create catalog records or upload results.</p> <code>False</code> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If initialization fails, configuration is invalid, or workflow is not a Workflow object.</p> Example <p>Create an execution with a workflow::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; config = ExecutionConfiguration(\n...     workflow=workflow,\n...     description=\"Process data\"\n... )\n&gt;&gt;&gt; execution = Execution(config, ml)\n</code></pre> <p>Or pass workflow separately::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(\n...     \"https://github.com/org/repo/blob/abc123/analysis.py\"\n... )\n&gt;&gt;&gt; config = ExecutionConfiguration(description=\"Run analysis\")\n&gt;&gt;&gt; execution = Execution(config, ml, workflow=workflow)\n</code></pre> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef __init__(\n    self,\n    configuration: ExecutionConfiguration,\n    ml_object: DerivaML,\n    workflow: Workflow | None = None,\n    reload: RID | None = None,\n    dry_run: bool = False,\n):\n    \"\"\"Initializes an Execution instance.\n\n    Creates a new execution or reloads an existing one. Initializes the execution\n    environment, downloads required datasets, and sets up asset tracking.\n\n    Args:\n        configuration: Settings and parameters for the execution.\n        ml_object: DerivaML instance managing the execution.\n        workflow: Optional Workflow object. If not specified, the workflow is taken from\n            the ExecutionConfiguration object. Must be a Workflow object, not a RID.\n        reload: Optional RID of existing execution to reload.\n        dry_run: If True, don't create catalog records or upload results.\n\n    Raises:\n        DerivaMLException: If initialization fails, configuration is invalid,\n            or workflow is not a Workflow object.\n\n    Example:\n        Create an execution with a workflow::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; config = ExecutionConfiguration(\n            ...     workflow=workflow,\n            ...     description=\"Process data\"\n            ... )\n            &gt;&gt;&gt; execution = Execution(config, ml)\n\n        Or pass workflow separately::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(\n            ...     \"https://github.com/org/repo/blob/abc123/analysis.py\"\n            ... )\n            &gt;&gt;&gt; config = ExecutionConfiguration(description=\"Run analysis\")\n            &gt;&gt;&gt; execution = Execution(config, ml, workflow=workflow)\n    \"\"\"\n\n    self.asset_paths: dict[str, list[AssetFilePath]] = {}\n    self.configuration = configuration\n    self._ml_object = ml_object\n    self._model = ml_object.model\n    self._logger = ml_object._logger\n    self.start_time = None\n    self.stop_time = None\n    self._status = Status.created\n    self.uploaded_assets: dict[str, list[AssetFilePath]] | None = None\n    self.configuration.argv = sys.argv\n    self._execution_record: ExecutionRecord | None = None  # Lazily created after RID is assigned\n\n    self.dataset_rids: List[RID] = []\n    self.datasets: list[DatasetBag] = []\n\n    self._working_dir = self._ml_object.working_dir\n    self._cache_dir = self._ml_object.cache_dir\n    if self._working_dir is None:\n        raise DerivaMLException(\n            \"DerivaML working_dir is not set. \"\n            \"Ensure the DerivaML instance was initialized with a valid working_dir.\"\n        )\n    self._dry_run = dry_run\n\n    # Make sure we have a valid Workflow object.\n    if workflow:\n        self.configuration.workflow = workflow\n\n    if self.configuration.workflow is None:\n        raise DerivaMLException(\"Workflow must be specified either in configuration or as a parameter\")\n\n    if not isinstance(self.configuration.workflow, Workflow):\n        raise DerivaMLException(\n            f\"Workflow must be a Workflow object, not {type(self.configuration.workflow).__name__}. \"\n            \"Use ml.lookup_workflow(rid) or ml.lookup_workflow_by_url(url) to get a Workflow object.\"\n        )\n\n    # Validate workflow type and register in catalog\n    self._ml_object.lookup_term(MLVocab.workflow_type, self.configuration.workflow.workflow_type)\n    self.workflow_rid = (\n        self._ml_object.add_workflow(self.configuration.workflow) if not self._dry_run else DRY_RUN_RID\n    )\n\n    # Validate the datasets and assets to be valid.\n    for d in self.configuration.datasets:\n        if self._ml_object.resolve_rid(d.rid).table.name != \"Dataset\":\n            raise DerivaMLException(\"Dataset specified in execution configuration is not a dataset\")\n\n    for a in self.configuration.assets:\n        if not self._model.is_asset(self._ml_object.resolve_rid(a.rid).table.name):\n            raise DerivaMLException(\"Asset specified in execution configuration is not an asset table\")\n\n    schema_path = self._ml_object.pathBuilder().schemas[self._ml_object.ml_schema]\n    if reload:\n        self.execution_rid = reload\n        if self.execution_rid == DRY_RUN_RID:\n            self._dry_run = True\n    elif self._dry_run:\n        self.execution_rid = DRY_RUN_RID\n    else:\n        self.execution_rid = schema_path.Execution.insert(\n            [\n                {\n                    \"Description\": self.configuration.description,\n                    \"Workflow\": self.workflow_rid,\n                }\n            ]\n        )[0][\"RID\"]\n\n    if rid_path := os.environ.get(\"DERIVA_ML_SAVE_EXECUTION_RID\", None):\n        # Put execution_rid into the provided file path so we can find it later.\n        with Path(rid_path).open(\"w\") as f:\n            json.dump(\n                {\n                    \"hostname\": self._ml_object.host_name,\n                    \"catalog_id\": self._ml_object.catalog_id,\n                    \"workflow_rid\": self.workflow_rid,\n                    \"execution_rid\": self.execution_rid,\n                },\n                f,\n            )\n\n    # Create a directory for execution rid so we can recover the state in case of a crash.\n    execution_root(prefix=self._ml_object.working_dir, exec_rid=self.execution_rid)\n\n    # Create the ExecutionRecord to handle catalog state operations\n    if not self._dry_run:\n        self._execution_record = ExecutionRecord(\n            execution_rid=self.execution_rid,\n            workflow=self.configuration.workflow,\n            status=Status.created,\n            description=self.configuration.description,\n            _ml_instance=self._ml_object,\n            _logger=self._logger,\n        )\n\n    self._initialize_execution(reload)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.add_features","title":"add_features","text":"<pre><code>add_features(\n    features: Iterable[FeatureRecord],\n) -&gt; None\n</code></pre> <p>Adds feature records to the catalog.</p> <p>Associates feature records with this execution and uploads them to the catalog. Features represent measurable properties or characteristics of records.</p> <p>NOTE: The catalog is not updated until upload_execution_outputs() is called.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>Iterable[FeatureRecord]</code> <p>Feature records to add, each containing a value and metadata.</p> required <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If feature addition fails or features are invalid.</p> Example <p>feature = FeatureRecord(value=\"high\", confidence=0.95) execution.add_features([feature])</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call\ndef add_features(self, features: Iterable[FeatureRecord]) -&gt; None:\n    \"\"\"Adds feature records to the catalog.\n\n    Associates feature records with this execution and uploads them to the catalog.\n    Features represent measurable properties or characteristics of records.\n\n    NOTE: The catalog is not updated until upload_execution_outputs() is called.\n\n    Args:\n        features: Feature records to add, each containing a value and metadata.\n\n    Raises:\n        DerivaMLException: If feature addition fails or features are invalid.\n\n    Example:\n        &gt;&gt;&gt; feature = FeatureRecord(value=\"high\", confidence=0.95)\n        &gt;&gt;&gt; execution.add_features([feature])\n    \"\"\"\n\n    # Make sure feature list is homogeneous:\n    sorted_features = defaultdict(list)\n    for f in features:\n        sorted_features[type(f)].append(f)\n    for fs in sorted_features.values():\n        self._add_features(fs)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.add_files","title":"add_files","text":"<pre><code>add_files(\n    files: Iterable[FileSpec],\n    dataset_types: str\n    | list[str]\n    | None = None,\n    description: str = \"\",\n) -&gt; \"Dataset\"\n</code></pre> <p>Adds files to the catalog with their metadata.</p> <p>Registers files in the catalog along with their metadata (MD5, length, URL) and associates them with specified file types.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>Iterable[FileSpec]</code> <p>File specifications containing MD5 checksum, length, and URL.</p> required <code>dataset_types</code> <code>str | list[str] | None</code> <p>One or more dataset type terms from File_Type vocabulary.</p> <code>None</code> <code>description</code> <code>str</code> <p>Description of the files.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>RID</code> <code>'Dataset'</code> <p>Dataset  that identifies newly added files. Will be nested to mirror original directory structure</p> <code>'Dataset'</code> <p>of the files.</p> <p>Raises:</p> Type Description <code>DerivaMLInvalidTerm</code> <p>If file_types are invalid or execution_rid is not an execution record.</p> <p>Examples:</p> <p>Add a single file type:     &gt;&gt;&gt; files = [FileSpec(url=\"path/to/file.txt\", md5=\"abc123\", length=1000)]     &gt;&gt;&gt; rids = exe.add_files(files, file_types=\"text\")</p> <p>Add multiple file types:     &gt;&gt;&gt; rids = exe.add_files(     ...     files=[FileSpec(url=\"image.png\", md5=\"def456\", length=2000)],     ...     file_types=[\"image\", \"png\"],     ... )</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef add_files(\n    self,\n    files: Iterable[FileSpec],\n    dataset_types: str | list[str] | None = None,\n    description: str = \"\",\n) -&gt; \"Dataset\":\n    \"\"\"Adds files to the catalog with their metadata.\n\n    Registers files in the catalog along with their metadata (MD5, length, URL) and associates them with\n    specified file types.\n\n    Args:\n        files: File specifications containing MD5 checksum, length, and URL.\n        dataset_types: One or more dataset type terms from File_Type vocabulary.\n        description: Description of the files.\n\n    Returns:\n        RID: Dataset  that identifies newly added files. Will be nested to mirror original directory structure\n        of the files.\n\n    Raises:\n        DerivaMLInvalidTerm: If file_types are invalid or execution_rid is not an execution record.\n\n    Examples:\n        Add a single file type:\n            &gt;&gt;&gt; files = [FileSpec(url=\"path/to/file.txt\", md5=\"abc123\", length=1000)]\n            &gt;&gt;&gt; rids = exe.add_files(files, file_types=\"text\")\n\n        Add multiple file types:\n            &gt;&gt;&gt; rids = exe.add_files(\n            ...     files=[FileSpec(url=\"image.png\", md5=\"def456\", length=2000)],\n            ...     file_types=[\"image\", \"png\"],\n            ... )\n    \"\"\"\n    return self._ml_object.add_files(\n        files=files,\n        execution_rid=self.execution_rid,\n        dataset_types=dataset_types,\n        description=description,\n    )\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.add_nested_execution","title":"add_nested_execution","text":"<pre><code>add_nested_execution(\n    nested_execution: \"Execution | ExecutionRecord | RID\",\n    sequence: int | None = None,\n) -&gt; None\n</code></pre> <p>Add a nested (child) execution to this execution.</p> <p>Creates a parent-child relationship between this execution and another. This is useful for grouping related executions, such as parameter sweeps or pipeline stages.</p> <p>Parameters:</p> Name Type Description Default <code>nested_execution</code> <code>'Execution | ExecutionRecord | RID'</code> <p>The child execution to add (Execution, ExecutionRecord, or RID).</p> required <code>sequence</code> <code>int | None</code> <p>Optional ordering index (0, 1, 2...). Use None for parallel executions.</p> <code>None</code> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If the association cannot be created.</p> Example <p>parent_exec = ml.create_execution(parent_config) child_exec = ml.create_execution(child_config) parent_exec.add_nested_execution(child_exec, sequence=0)</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def add_nested_execution(\n    self,\n    nested_execution: \"Execution | ExecutionRecord | RID\",\n    sequence: int | None = None,\n) -&gt; None:\n    \"\"\"Add a nested (child) execution to this execution.\n\n    Creates a parent-child relationship between this execution and another.\n    This is useful for grouping related executions, such as parameter sweeps\n    or pipeline stages.\n\n    Args:\n        nested_execution: The child execution to add (Execution, ExecutionRecord, or RID).\n        sequence: Optional ordering index (0, 1, 2...). Use None for parallel executions.\n\n    Raises:\n        DerivaMLException: If the association cannot be created.\n\n    Example:\n        &gt;&gt;&gt; parent_exec = ml.create_execution(parent_config)\n        &gt;&gt;&gt; child_exec = ml.create_execution(child_config)\n        &gt;&gt;&gt; parent_exec.add_nested_execution(child_exec, sequence=0)\n    \"\"\"\n    if self._dry_run:\n        return\n\n    # Get the RID from the nested execution\n    if isinstance(nested_execution, Execution):\n        nested_rid = nested_execution.execution_rid\n    elif isinstance(nested_execution, ExecutionRecord):\n        nested_rid = nested_execution.execution_rid\n    else:\n        nested_rid = nested_execution\n\n    # Delegate to ExecutionRecord if available\n    if self._execution_record is not None:\n        self._execution_record.add_nested_execution(nested_rid, sequence=sequence)\n    else:\n        # Fallback for cases without execution record\n        pb = self._ml_object.pathBuilder()\n        execution_execution = pb.schemas[self._ml_object.ml_schema].Execution_Execution\n\n        record = {\n            \"Execution\": self.execution_rid,\n            \"Nested_Execution\": nested_rid,\n        }\n        if sequence is not None:\n            record[\"Sequence\"] = sequence\n\n        execution_execution.insert([record])\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.asset_file_path","title":"asset_file_path","text":"<pre><code>asset_file_path(\n    asset_name: str,\n    file_name: str | Path,\n    asset_types: list[str]\n    | str\n    | None = None,\n    copy_file=False,\n    rename_file: str | None = None,\n    **kwargs,\n) -&gt; AssetFilePath\n</code></pre> <p>Return a pathlib Path to the directory in which to place files for the specified execution_asset type.</p> <p>Given the name of an asset table, and a file name, register the file for upload and return a path to that file in the upload directory.  In addition to the filename, additional asset metadata and file asset types may be specified.</p> <p>This routine has three modes, depending on if file_name refers to an existing file.  If it doesn't, a path to a new file with the specified name is returned.  The caller can then open that file for writing.</p> <p>If the provided filename refers to an existing file and the copy_file argument is False (the default), then the returned path contains a symbolic link to that file.  If the copy_file argument is True, then the contents of file_name are copied into the target directory.</p> <p>Parameters:</p> Name Type Description Default <code>asset_name</code> <code>str</code> <p>Type of asset to be uploaded.  Must be a term in Asset_Type controlled vocabulary.</p> required <code>file_name</code> <code>str | Path</code> <p>Name of file to be uploaded.</p> required <code>asset_types</code> <code>list[str] | str | None</code> <p>Type of asset to be uploaded.  Defaults to the name of the asset.</p> <code>None</code> <code>copy_file</code> <p>Whether to copy the file rather than creating a symbolic link.</p> <code>False</code> <code>rename_file</code> <code>str | None</code> <p>If provided, the file will be renamed to this name if the file already exists..</p> <code>None</code> <code>**kwargs</code> <p>Any additional metadata values that may be part of the asset table.</p> <code>{}</code> <p>Returns:</p> Type Description <code>AssetFilePath</code> <p>Path in which to place asset files.</p> <p>Raises:</p> Type Description <code>DerivaException</code> <p>If the asset type is not defined.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef asset_file_path(\n    self,\n    asset_name: str,\n    file_name: str | Path,\n    asset_types: list[str] | str | None = None,\n    copy_file=False,\n    rename_file: str | None = None,\n    **kwargs,\n) -&gt; AssetFilePath:\n    \"\"\"Return a pathlib Path to the directory in which to place files for the specified execution_asset type.\n\n    Given the name of an asset table, and a file name, register the file for upload and return a path to that\n    file in the upload directory.  In addition to the filename, additional asset metadata and file asset types may\n    be specified.\n\n    This routine has three modes, depending on if file_name refers to an existing file.  If it doesn't, a path\n    to a new file with the specified name is returned.  The caller can then open that file for writing.\n\n    If the provided filename refers to an existing file and the copy_file argument is False (the default), then the\n    returned path contains a symbolic link to that file.  If the copy_file argument is True, then the contents of\n    file_name are copied into the target directory.\n\n    Args:\n        asset_name: Type of asset to be uploaded.  Must be a term in Asset_Type controlled vocabulary.\n        file_name: Name of file to be uploaded.\n        asset_types: Type of asset to be uploaded.  Defaults to the name of the asset.\n        copy_file: Whether to copy the file rather than creating a symbolic link.\n        rename_file: If provided, the file will be renamed to this name if the file already exists..\n        **kwargs: Any additional metadata values that may be part of the asset table.\n\n    Returns:\n        Path in which to place asset files.\n\n    Raises:\n        DerivaException: If the asset type is not defined.\n    \"\"\"\n    if not self._model.is_asset(asset_name):\n        DerivaMLException(f\"Table {asset_name} is not an asset\")\n\n    asset_table = self._model.name_to_table(asset_name)\n\n    asset_types = asset_types or kwargs.get(\"Asset_Type\", None) or asset_name\n    asset_types = [asset_types] if isinstance(asset_types, str) else asset_types\n    for t in asset_types:\n        self._ml_object.lookup_term(MLVocab.asset_type, t)\n\n    # Determine if we will need to rename an existing file as the asset.\n    file_name = Path(file_name)\n    if file_name.name == \"_implementations.log\":\n        # There is a funny bug with S3 hatrac if we have the leading _ in the filename.\n        file_name = file_name.with_name(\"-implementations.log\")\n\n    # Resolve relative paths to absolute paths to ensure exists() and symlink work correctly\n    # regardless of the current working directory\n    if not file_name.is_absolute():\n        file_name = file_name.resolve()\n\n    target_name = Path(rename_file) if file_name.exists() and rename_file else file_name\n    asset_path = asset_file_path(\n        prefix=self._working_dir,\n        exec_rid=self.execution_rid,\n        asset_table=self._model.name_to_table(asset_name),\n        file_name=target_name.name,\n        metadata=kwargs,\n    )\n\n    if file_name.exists():\n        if copy_file:\n            asset_path.write_bytes(file_name.read_bytes())\n        else:\n            try:\n                asset_path.symlink_to(file_name)\n            except (OSError, PermissionError):\n                # Fallback to copy if symlink fails (common on Windows)\n                asset_path.write_bytes(file_name.read_bytes())\n\n    # Persist the asset types into a file\n    with Path(asset_type_path(self._working_dir, self.execution_rid, asset_table)).open(\"a\") as asset_type_file:\n        asset_type_file.write(json.dumps({target_name.name: asset_types}) + \"\\n\")\n\n    return AssetFilePath(\n        asset_path=asset_path,\n        asset_table=asset_name,\n        file_name=target_name.name,\n        asset_metadata=kwargs,\n        asset_types=asset_types,\n    )\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.create_dataset","title":"create_dataset","text":"<pre><code>create_dataset(\n    dataset_types: str\n    | list[str]\n    | None = None,\n    version: DatasetVersion\n    | str\n    | None = None,\n    description: str = \"\",\n) -&gt; Dataset\n</code></pre> <p>Create a new dataset with specified types.</p> <p>Creates a dataset associated with this execution for provenance tracking.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_types</code> <code>str | list[str] | None</code> <p>One or more dataset type terms from Dataset_Type vocabulary.</p> <code>None</code> <code>description</code> <code>str</code> <p>Markdown description of the dataset being created.</p> <code>''</code> <code>version</code> <code>DatasetVersion | str | None</code> <p>Dataset version. Defaults to 0.1.0.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>The newly created Dataset.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef create_dataset(\n    self,\n    dataset_types: str | list[str] | None = None,\n    version: DatasetVersion | str | None = None,\n    description: str = \"\",\n) -&gt; Dataset:\n    \"\"\"Create a new dataset with specified types.\n\n    Creates a dataset associated with this execution for provenance tracking.\n\n    Args:\n        dataset_types: One or more dataset type terms from Dataset_Type vocabulary.\n        description: Markdown description of the dataset being created.\n        version: Dataset version. Defaults to 0.1.0.\n\n    Returns:\n        The newly created Dataset.\n    \"\"\"\n    return Dataset.create_dataset(\n        ml_instance=self._ml_object,\n        execution_rid=self.execution_rid,\n        dataset_types=dataset_types,\n        version=version,\n        description=description,\n    )\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.download_asset","title":"download_asset","text":"<pre><code>download_asset(\n    asset_rid: RID,\n    dest_dir: Path,\n    update_catalog: bool = True,\n    use_cache: bool = False,\n) -&gt; AssetFilePath\n</code></pre> <p>Download an asset from a URL and place it in a local directory.</p> <p>Parameters:</p> Name Type Description Default <code>asset_rid</code> <code>RID</code> <p>RID of the asset.</p> required <code>dest_dir</code> <code>Path</code> <p>Destination directory for the asset.</p> required <code>update_catalog</code> <code>bool</code> <p>Whether to update the catalog execution information after downloading.</p> <code>True</code> <code>use_cache</code> <code>bool</code> <p>If True, check the cache directory for a previously downloaded copy with a matching MD5 checksum before downloading. Cached copies are stored in <code>cache_dir/assets/{rid}_{md5}/</code> and symlinked into the destination.</p> <code>False</code> <p>Returns:</p> Type Description <code>AssetFilePath</code> <p>An AssetFilePath with the path to the downloaded (or cached) asset file.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef download_asset(\n    self, asset_rid: RID, dest_dir: Path, update_catalog: bool = True, use_cache: bool = False\n) -&gt; AssetFilePath:\n    \"\"\"Download an asset from a URL and place it in a local directory.\n\n    Args:\n        asset_rid: RID of the asset.\n        dest_dir: Destination directory for the asset.\n        update_catalog: Whether to update the catalog execution information after downloading.\n        use_cache: If True, check the cache directory for a previously downloaded copy\n            with a matching MD5 checksum before downloading. Cached copies are stored\n            in ``cache_dir/assets/{rid}_{md5}/`` and symlinked into the destination.\n\n    Returns:\n        An AssetFilePath with the path to the downloaded (or cached) asset file.\n    \"\"\"\n\n    asset_table = self._ml_object.resolve_rid(asset_rid).table\n    if not self._model.is_asset(asset_table):\n        raise DerivaMLException(f\"RID {asset_rid}  is not for an asset table.\")\n\n    asset_record = self._ml_object.retrieve_rid(asset_rid)\n    asset_metadata = {k: v for k, v in asset_record.items() if k in self._model.asset_metadata(asset_table)}\n    asset_url = asset_record[\"URL\"]\n    asset_filename = dest_dir / asset_record[\"Filename\"]\n\n    # Check cache before downloading\n    cache_hit = False\n    if use_cache:\n        md5 = asset_record.get(\"MD5\")\n        if md5:\n            asset_cache_dir = self._ml_object.cache_dir / \"assets\"\n            asset_cache_dir.mkdir(parents=True, exist_ok=True)\n            cache_key = f\"{asset_rid}_{md5}\"\n            cached_file = asset_cache_dir / cache_key / asset_record[\"Filename\"]\n            if cached_file.exists():\n                # Cache hit \u2014 symlink from cache to destination\n                self._logger.info(f\"Using cached asset {asset_rid} (MD5: {md5})\")\n                if asset_filename.exists() or asset_filename.is_symlink():\n                    asset_filename.unlink()\n                asset_filename.symlink_to(cached_file)\n                cache_hit = True\n\n    if not cache_hit:\n        hs = HatracStore(\"https\", self._ml_object.host_name, self._ml_object.credential)\n        hs.get_obj(path=asset_url, destfilename=asset_filename.as_posix())\n\n        # Store in cache for future use\n        if use_cache:\n            md5 = asset_record.get(\"MD5\")\n            if md5:\n                asset_cache_dir = self._ml_object.cache_dir / \"assets\"\n                asset_cache_dir.mkdir(parents=True, exist_ok=True)\n                cache_key = f\"{asset_rid}_{md5}\"\n                cache_entry_dir = asset_cache_dir / cache_key\n                cache_entry_dir.mkdir(parents=True, exist_ok=True)\n                cached_file = cache_entry_dir / asset_record[\"Filename\"]\n                # Move file to cache, then symlink back\n                shutil.move(str(asset_filename), str(cached_file))\n                asset_filename.symlink_to(cached_file)\n                self._logger.info(f\"Cached asset {asset_rid} (MD5: {md5})\")\n\n    asset_type_table, _col_l, _col_r = self._model.find_association(asset_table, MLVocab.asset_type)\n    type_path = self._ml_object.pathBuilder().schemas[asset_type_table.schema.name].tables[asset_type_table.name]\n    asset_types = [\n        asset_type[MLVocab.asset_type.value]\n        for asset_type in type_path.filter(type_path.columns[asset_table.name] == asset_rid)\n        .attributes(type_path.Asset_Type)\n        .fetch()\n    ]\n\n    asset_path = AssetFilePath(\n        file_name=asset_filename,\n        asset_rid=asset_rid,\n        asset_path=asset_filename,\n        asset_metadata=asset_metadata,\n        asset_table=asset_table.name,\n        asset_types=asset_types,\n    )\n\n    if update_catalog:\n        self._update_asset_execution_table(\n            {f\"{asset_table.schema.name}/{asset_table.name}\": [asset_path]},\n            asset_role=\"Input\",\n        )\n    return asset_path\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.download_dataset_bag","title":"download_dataset_bag","text":"<pre><code>download_dataset_bag(\n    dataset: DatasetSpec,\n) -&gt; DatasetBag\n</code></pre> <p>Downloads and materializes a dataset for use in the execution.</p> <p>Downloads the specified dataset as a BDBag and materializes it in the execution's working directory. The dataset version is determined by the DatasetSpec.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DatasetSpec</code> <p>Specification of the dataset to download, including version and materialization options.</p> required <p>Returns:</p> Name Type Description <code>DatasetBag</code> <code>DatasetBag</code> <p>Object containing: - path: Local filesystem path to downloaded dataset - rid: Dataset's Resource Identifier - minid: Dataset's Minimal Viable Identifier</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If download or materialization fails.</p> Example <p>spec = DatasetSpec(rid=\"1-abc123\", version=\"1.2.0\") bag = execution.download_dataset_bag(spec) print(f\"Downloaded to {bag.path}\")</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef download_dataset_bag(self, dataset: DatasetSpec) -&gt; DatasetBag:\n    \"\"\"Downloads and materializes a dataset for use in the execution.\n\n    Downloads the specified dataset as a BDBag and materializes it in the execution's\n    working directory. The dataset version is determined by the DatasetSpec.\n\n    Args:\n        dataset: Specification of the dataset to download, including version and\n            materialization options.\n\n    Returns:\n        DatasetBag: Object containing:\n            - path: Local filesystem path to downloaded dataset\n            - rid: Dataset's Resource Identifier\n            - minid: Dataset's Minimal Viable Identifier\n\n    Raises:\n        DerivaMLException: If download or materialization fails.\n\n    Example:\n        &gt;&gt;&gt; spec = DatasetSpec(rid=\"1-abc123\", version=\"1.2.0\")\n        &gt;&gt;&gt; bag = execution.download_dataset_bag(spec)\n        &gt;&gt;&gt; print(f\"Downloaded to {bag.path}\")\n    \"\"\"\n    return self._ml_object.download_dataset_bag(dataset)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.execute","title":"execute","text":"<pre><code>execute() -&gt; Execution\n</code></pre> <p>Initiate an execution with the provided configuration. Can be used in a context manager.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def execute(self) -&gt; Execution:\n    \"\"\"Initiate an execution with the provided configuration. Can be used in a context manager.\"\"\"\n    self.execution_start()\n    return self\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.execution_start","title":"execution_start","text":"<pre><code>execution_start() -&gt; None\n</code></pre> <p>Marks the execution as started.</p> <p>Records the start time and updates the execution's status to 'running'. This should be called before beginning the main execution work.</p> Example <p>execution.execution_start() try: ...     # Run analysis ...     execution.execution_stop() ... except Exception: ...     execution.update_status(Status.failed, \"Analysis error\")</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def execution_start(self) -&gt; None:\n    \"\"\"Marks the execution as started.\n\n    Records the start time and updates the execution's status to 'running'.\n    This should be called before beginning the main execution work.\n\n    Example:\n        &gt;&gt;&gt; execution.execution_start()\n        &gt;&gt;&gt; try:\n        ...     # Run analysis\n        ...     execution.execution_stop()\n        ... except Exception:\n        ...     execution.update_status(Status.failed, \"Analysis error\")\n    \"\"\"\n    self.start_time = datetime.now()\n    self.uploaded_assets = None\n    self.update_status(Status.initializing, \"Start execution  ...\")\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.execution_stop","title":"execution_stop","text":"<pre><code>execution_stop() -&gt; None\n</code></pre> <p>Marks the execution as completed.</p> <p>Records the stop time and updates the execution's status to 'completed'. This should be called after all execution work is finished.</p> Example <p>try: ...     # Run analysis ...     execution.execution_stop() ... except Exception: ...     execution.update_status(Status.failed, \"Analysis error\")</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def execution_stop(self) -&gt; None:\n    \"\"\"Marks the execution as completed.\n\n    Records the stop time and updates the execution's status to 'completed'.\n    This should be called after all execution work is finished.\n\n    Example:\n        &gt;&gt;&gt; try:\n        ...     # Run analysis\n        ...     execution.execution_stop()\n        ... except Exception:\n        ...     execution.update_status(Status.failed, \"Analysis error\")\n    \"\"\"\n    self.stop_time = datetime.now()\n    duration = self.stop_time - self.start_time\n    hours, remainder = divmod(duration.total_seconds(), 3600)\n    minutes, seconds = divmod(remainder, 60)\n    duration = f\"{round(hours, 0)}H {round(minutes, 0)}min {round(seconds, 4)}sec\"\n\n    self.update_status(Status.completed, \"Algorithm execution ended.\")\n    if not self._dry_run:\n        self._ml_object.pathBuilder().schemas[self._ml_object.ml_schema].Execution.update(\n            [{\"RID\": self.execution_rid, \"Duration\": duration}]\n        )\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.is_nested","title":"is_nested","text":"<pre><code>is_nested() -&gt; bool\n</code></pre> <p>Check if this execution is nested within another execution.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if this execution has at least one parent execution.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def is_nested(self) -&gt; bool:\n    \"\"\"Check if this execution is nested within another execution.\n\n    Returns:\n        True if this execution has at least one parent execution.\n    \"\"\"\n    if self._execution_record is not None:\n        return self._execution_record.is_nested()\n    return len(self.list_parent_executions()) &gt; 0\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.is_parent","title":"is_parent","text":"<pre><code>is_parent() -&gt; bool\n</code></pre> <p>Check if this execution has nested child executions.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if this execution has at least one nested execution.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def is_parent(self) -&gt; bool:\n    \"\"\"Check if this execution has nested child executions.\n\n    Returns:\n        True if this execution has at least one nested execution.\n    \"\"\"\n    if self._execution_record is not None:\n        return self._execution_record.is_parent()\n    return len(self.list_nested_executions()) &gt; 0\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.list_assets","title":"list_assets","text":"<pre><code>list_assets(\n    asset_role: str | None = None,\n) -&gt; list[\"Asset\"]\n</code></pre> <p>List all assets that were inputs or outputs of this execution.</p> <p>Parameters:</p> Name Type Description Default <code>asset_role</code> <code>str | None</code> <p>Optional filter: \"Input\" or \"Output\". If None, returns all.</p> <code>None</code> <p>Returns:</p> Type Description <code>list['Asset']</code> <p>List of Asset objects associated with this execution.</p> Example <p>inputs = execution.list_assets(asset_role=\"Input\") outputs = execution.list_assets(asset_role=\"Output\")</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def list_assets(self, asset_role: str | None = None) -&gt; list[\"Asset\"]:\n    \"\"\"List all assets that were inputs or outputs of this execution.\n\n    Args:\n        asset_role: Optional filter: \"Input\" or \"Output\". If None, returns all.\n\n    Returns:\n        List of Asset objects associated with this execution.\n\n    Example:\n        &gt;&gt;&gt; inputs = execution.list_assets(asset_role=\"Input\")\n        &gt;&gt;&gt; outputs = execution.list_assets(asset_role=\"Output\")\n    \"\"\"\n    if self._execution_record is not None:\n        return self._execution_record.list_assets(asset_role=asset_role)\n\n    # Fallback for dry_run mode\n\n    pb = self._ml_object.pathBuilder()\n    asset_exec = pb.schemas[self._ml_object.ml_schema].Execution_Asset_Execution\n\n    query = asset_exec.filter(asset_exec.Execution == self.execution_rid)\n    if asset_role:\n        query = query.filter(asset_exec.Asset_Role == asset_role)\n\n    records = list(query.entities().fetch())\n\n    assets = []\n    for r in records:\n        try:\n            asset = self._ml_object.lookup_asset(r[\"Execution_Asset\"])\n            assets.append(asset)\n        except Exception:\n            pass  # Skip assets that can't be looked up\n    return assets\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.list_input_datasets","title":"list_input_datasets","text":"<pre><code>list_input_datasets() -&gt; list[Dataset]\n</code></pre> <p>List all datasets that were inputs to this execution.</p> <p>Returns:</p> Type Description <code>list[Dataset]</code> <p>List of Dataset objects that were used as inputs.</p> Example <p>for ds in execution.list_input_datasets(): ...     print(f\"Input: {ds.dataset_rid} - {ds.description}\")</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def list_input_datasets(self) -&gt; list[Dataset]:\n    \"\"\"List all datasets that were inputs to this execution.\n\n    Returns:\n        List of Dataset objects that were used as inputs.\n\n    Example:\n        &gt;&gt;&gt; for ds in execution.list_input_datasets():\n        ...     print(f\"Input: {ds.dataset_rid} - {ds.description}\")\n    \"\"\"\n    if self._execution_record is not None:\n        return self._execution_record.list_input_datasets()\n\n    # Fallback for dry_run mode\n    pb = self._ml_object.pathBuilder()\n    dataset_exec = pb.schemas[self._ml_object.ml_schema].Dataset_Execution\n\n    records = list(\n        dataset_exec.filter(dataset_exec.Execution == self.execution_rid)\n        .entities()\n        .fetch()\n    )\n\n    return [self._ml_object.lookup_dataset(r[\"Dataset\"]) for r in records]\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.list_nested_executions","title":"list_nested_executions","text":"<pre><code>list_nested_executions(\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n) -&gt; list[\"ExecutionRecord\"]\n</code></pre> <p>List all nested (child) executions of this execution.</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>If True, recursively return all descendant executions.</p> <code>False</code> <code>_visited</code> <code>set[RID] | None</code> <p>Internal parameter to track visited executions and prevent infinite recursion.</p> <code>None</code> <p>Returns:</p> Type Description <code>list['ExecutionRecord']</code> <p>List of nested ExecutionRecord objects, ordered by sequence if available.</p> <code>list['ExecutionRecord']</code> <p>To get full Execution objects with lifecycle management, use restore_execution().</p> Example <p>children = parent_exec.list_nested_executions() all_descendants = parent_exec.list_nested_executions(recurse=True)</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def list_nested_executions(\n    self,\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n) -&gt; list[\"ExecutionRecord\"]:\n    \"\"\"List all nested (child) executions of this execution.\n\n    Args:\n        recurse: If True, recursively return all descendant executions.\n        _visited: Internal parameter to track visited executions and prevent infinite recursion.\n\n    Returns:\n        List of nested ExecutionRecord objects, ordered by sequence if available.\n        To get full Execution objects with lifecycle management, use restore_execution().\n\n    Example:\n        &gt;&gt;&gt; children = parent_exec.list_nested_executions()\n        &gt;&gt;&gt; all_descendants = parent_exec.list_nested_executions(recurse=True)\n    \"\"\"\n    if self._execution_record is not None:\n        return list(self._execution_record.list_nested_executions(recurse=recurse, _visited=_visited))\n\n    # Fallback for dry_run mode\n    if _visited is None:\n        _visited = set()\n\n    if self.execution_rid in _visited:\n        return []\n    _visited.add(self.execution_rid)\n\n    pb = self._ml_object.pathBuilder()\n    execution_execution = pb.schemas[self._ml_object.ml_schema].Execution_Execution\n\n    # Query for nested executions, ordered by sequence\n    nested = list(\n        execution_execution.filter(execution_execution.Execution == self.execution_rid)\n        .entities()\n        .fetch()\n    )\n\n    # Sort by sequence (None values at the end)\n    nested.sort(key=lambda x: (x.get(\"Sequence\") is None, x.get(\"Sequence\")))\n\n    children = []\n    for record in nested:\n        child = self._ml_object.lookup_execution(record[\"Nested_Execution\"])\n        children.append(child)\n        if recurse:\n            children.extend(child.list_nested_executions(recurse=True, _visited=_visited))\n\n    return children\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.list_parent_executions","title":"list_parent_executions","text":"<pre><code>list_parent_executions(\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n) -&gt; list[\"ExecutionRecord\"]\n</code></pre> <p>List all parent executions that contain this execution as a nested child.</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>If True, recursively return all ancestor executions.</p> <code>False</code> <code>_visited</code> <code>set[RID] | None</code> <p>Internal parameter to track visited executions and prevent infinite recursion.</p> <code>None</code> <p>Returns:</p> Type Description <code>list['ExecutionRecord']</code> <p>List of parent ExecutionRecord objects.</p> <code>list['ExecutionRecord']</code> <p>To get full Execution objects with lifecycle management, use restore_execution().</p> Example <p>parents = child_exec.list_parent_executions() all_ancestors = child_exec.list_parent_executions(recurse=True)</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def list_parent_executions(\n    self,\n    recurse: bool = False,\n    _visited: set[RID] | None = None,\n) -&gt; list[\"ExecutionRecord\"]:\n    \"\"\"List all parent executions that contain this execution as a nested child.\n\n    Args:\n        recurse: If True, recursively return all ancestor executions.\n        _visited: Internal parameter to track visited executions and prevent infinite recursion.\n\n    Returns:\n        List of parent ExecutionRecord objects.\n        To get full Execution objects with lifecycle management, use restore_execution().\n\n    Example:\n        &gt;&gt;&gt; parents = child_exec.list_parent_executions()\n        &gt;&gt;&gt; all_ancestors = child_exec.list_parent_executions(recurse=True)\n    \"\"\"\n    if self._execution_record is not None:\n        return list(self._execution_record.list_parent_executions(recurse=recurse, _visited=_visited))\n\n    # Fallback for dry_run mode\n    if _visited is None:\n        _visited = set()\n\n    if self.execution_rid in _visited:\n        return []\n    _visited.add(self.execution_rid)\n\n    pb = self._ml_object.pathBuilder()\n    execution_execution = pb.schemas[self._ml_object.ml_schema].Execution_Execution\n\n    parent_records = list(\n        execution_execution.filter(execution_execution.Nested_Execution == self.execution_rid)\n        .entities()\n        .fetch()\n    )\n\n    parents = []\n    for record in parent_records:\n        parent = self._ml_object.lookup_execution(record[\"Execution\"])\n        parents.append(parent)\n        if recurse:\n            parents.extend(parent.list_parent_executions(recurse=True, _visited=_visited))\n\n    return parents\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.table_path","title":"table_path","text":"<pre><code>table_path(table: str) -&gt; Path\n</code></pre> <p>Return a local file path to a CSV to add values to a table on upload.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Name of table to be uploaded.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Pathlib path to the file in which to place table values.</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def table_path(self, table: str) -&gt; Path:\n    \"\"\"Return a local file path to a CSV to add values to a table on upload.\n\n    Args:\n        table: Name of table to be uploaded.\n\n    Returns:\n        Pathlib path to the file in which to place table values.\n    \"\"\"\n    # Find which domain schema contains this table\n    table_schema = None\n    for domain_schema in self._ml_object.domain_schemas:\n        if domain_schema in self._model.schemas:\n            if table in self._model.schemas[domain_schema].tables:\n                table_schema = domain_schema\n                break\n\n    if table_schema is None:\n        raise DerivaMLException(\"Table '{}' not found in any domain schema\".format(table))\n\n    return table_path(self._working_dir, schema=table_schema, table=table)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.update_status","title":"update_status","text":"<pre><code>update_status(\n    status: Status, msg: str\n) -&gt; None\n</code></pre> <p>Updates the execution's status in the catalog.</p> <p>Records a new status and associated message in the catalog, allowing remote tracking of execution progress.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>Status</code> <p>New status value (e.g., running, completed, failed).</p> required <code>msg</code> <code>str</code> <p>Description of the status change or current state.</p> required <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If status update fails.</p> Example <p>execution.update_status(Status.running, \"Processing sample 1 of 10\")</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call\ndef update_status(self, status: Status, msg: str) -&gt; None:\n    \"\"\"Updates the execution's status in the catalog.\n\n    Records a new status and associated message in the catalog, allowing remote\n    tracking of execution progress.\n\n    Args:\n        status: New status value (e.g., running, completed, failed).\n        msg: Description of the status change or current state.\n\n    Raises:\n        DerivaMLException: If status update fails.\n\n    Example:\n        &gt;&gt;&gt; execution.update_status(Status.running, \"Processing sample 1 of 10\")\n    \"\"\"\n    self._status = status\n    self._logger.info(msg)\n\n    if self._dry_run:\n        return\n\n    # Delegate to ExecutionRecord for catalog updates\n    if self._execution_record is not None:\n        self._execution_record.update_status(status, msg)\n    else:\n        # Fallback for cases where ExecutionRecord isn't available\n        self._ml_object.pathBuilder().schemas[self._ml_object.ml_schema].Execution.update(\n            [\n                {\n                    \"RID\": self.execution_rid,\n                    \"Status\": status.value,\n                    \"Status_Detail\": msg,\n                }\n            ]\n        )\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.upload_assets","title":"upload_assets","text":"<pre><code>upload_assets(\n    assets_dir: str | Path,\n) -&gt; dict[Any, FileUploadState] | None\n</code></pre> <p>Uploads assets from a directory to the catalog.</p> <p>Scans the specified directory for assets and uploads them to the catalog, recording their metadata and types. Assets are organized by their types and associated with the execution.</p> <p>Parameters:</p> Name Type Description Default <code>assets_dir</code> <code>str | Path</code> <p>Directory containing assets to upload.</p> required <p>Returns:</p> Type Description <code>dict[Any, FileUploadState] | None</code> <p>dict[Any, FileUploadState] | None: Mapping of assets to their upload states, or None if no assets were found.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If upload fails or assets are invalid.</p> Example <p>states = execution.upload_assets(\"output/results\") for asset, state in states.items(): ...     print(f\"{asset}: {state}\")</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef upload_assets(\n    self,\n    assets_dir: str | Path,\n) -&gt; dict[Any, FileUploadState] | None:\n    \"\"\"Uploads assets from a directory to the catalog.\n\n    Scans the specified directory for assets and uploads them to the catalog,\n    recording their metadata and types. Assets are organized by their types\n    and associated with the execution.\n\n    Args:\n        assets_dir: Directory containing assets to upload.\n\n    Returns:\n        dict[Any, FileUploadState] | None: Mapping of assets to their upload states,\n            or None if no assets were found.\n\n    Raises:\n        DerivaMLException: If upload fails or assets are invalid.\n\n    Example:\n        &gt;&gt;&gt; states = execution.upload_assets(\"output/results\")\n        &gt;&gt;&gt; for asset, state in states.items():\n        ...     print(f\"{asset}: {state}\")\n    \"\"\"\n\n    def path_to_asset(path: str) -&gt; str:\n        \"\"\"Pull the asset name out of a path to that asset in the filesystem\"\"\"\n        components = path.split(\"/\")\n        return components[components.index(\"asset\") + 2]  # Look for asset in the path to find the name\n\n    if not self._model.is_asset(Path(assets_dir).name):\n        raise DerivaMLException(\"Directory does not have name of an asset table.\")\n    results = upload_directory(self._model, assets_dir)\n    return {path_to_asset(p): r for p, r in results.items()}\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.upload_execution_outputs","title":"upload_execution_outputs","text":"<pre><code>upload_execution_outputs(\n    clean_folder: bool | None = None,\n    progress_callback: Callable[\n        [UploadProgress], None\n    ]\n    | None = None,\n    max_retries: int = 3,\n    retry_delay: float = 5.0,\n    timeout: tuple[int, int]\n    | None = None,\n    chunk_size: int | None = None,\n) -&gt; dict[str, list[AssetFilePath]]\n</code></pre> <p>Uploads all outputs from the execution to the catalog.</p> <p>Scans the execution's output directories for assets, features, and other results, then uploads them to the catalog. Can optionally clean up the output folders after successful upload.</p> <p>IMPORTANT: This method must be called AFTER exiting the context manager, not inside it. The context manager handles execution timing (start/stop), while this method handles the separate upload step.</p> <p>Parameters:</p> Name Type Description Default <code>clean_folder</code> <code>bool | None</code> <p>Whether to delete output folders after upload. If None (default), uses the DerivaML instance's clean_execution_dir setting. Pass True/False to override for this specific execution.</p> <code>None</code> <code>progress_callback</code> <code>Callable[[UploadProgress], None] | None</code> <p>Optional callback function to receive upload progress updates. Called with UploadProgress objects containing file name, bytes uploaded, total bytes, percent complete, phase, and status message.</p> <code>None</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed uploads (default: 3).</p> <code>3</code> <code>retry_delay</code> <code>float</code> <p>Initial delay in seconds between retries, doubles with each attempt (default: 5.0).</p> <code>5.0</code> <code>timeout</code> <code>tuple[int, int] | None</code> <p>Tuple of (connect_timeout, read_timeout) in seconds. Default is (600, 600). Note: urllib3 uses connect_timeout as the socket timeout during request body writes, so it must be large enough for a full chunk upload.</p> <code>None</code> <code>chunk_size</code> <code>int | None</code> <p>Optional chunk size in bytes for hatrac uploads. If provided, large files will be uploaded in chunks of this size.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, list[AssetFilePath]]</code> <p>dict[str, list[AssetFilePath]]: Mapping of asset types to their file paths.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If upload fails or outputs are invalid.</p> Example <p>with ml.create_execution(config) as execution: ...     # Do ML work, register output files with asset_file_path() ...     path = execution.asset_file_path(\"Model\", \"model.pt\") ...     # Write to path... ...</p> Source code in <code>src/deriva_ml/execution/execution.py</code> <pre><code>def upload_execution_outputs(\n    self,\n    clean_folder: bool | None = None,\n    progress_callback: Callable[[UploadProgress], None] | None = None,\n    max_retries: int = 3,\n    retry_delay: float = 5.0,\n    timeout: tuple[int, int] | None = None,\n    chunk_size: int | None = None,\n) -&gt; dict[str, list[AssetFilePath]]:\n    \"\"\"Uploads all outputs from the execution to the catalog.\n\n    Scans the execution's output directories for assets, features, and other results,\n    then uploads them to the catalog. Can optionally clean up the output folders\n    after successful upload.\n\n    IMPORTANT: This method must be called AFTER exiting the context manager, not inside it.\n    The context manager handles execution timing (start/stop), while this method handles\n    the separate upload step.\n\n    Args:\n        clean_folder: Whether to delete output folders after upload. If None (default),\n            uses the DerivaML instance's clean_execution_dir setting. Pass True/False\n            to override for this specific execution.\n        progress_callback: Optional callback function to receive upload progress updates.\n            Called with UploadProgress objects containing file name, bytes uploaded,\n            total bytes, percent complete, phase, and status message.\n        max_retries: Maximum number of retry attempts for failed uploads (default: 3).\n        retry_delay: Initial delay in seconds between retries, doubles with each attempt (default: 5.0).\n        timeout: Tuple of (connect_timeout, read_timeout) in seconds. Default is (600, 600).\n            Note: urllib3 uses connect_timeout as the socket timeout during request body\n            writes, so it must be large enough for a full chunk upload.\n        chunk_size: Optional chunk size in bytes for hatrac uploads. If provided,\n            large files will be uploaded in chunks of this size.\n\n    Returns:\n        dict[str, list[AssetFilePath]]: Mapping of asset types to their file paths.\n\n    Raises:\n        DerivaMLException: If upload fails or outputs are invalid.\n\n    Example:\n        &gt;&gt;&gt; with ml.create_execution(config) as execution:\n        ...     # Do ML work, register output files with asset_file_path()\n        ...     path = execution.asset_file_path(\"Model\", \"model.pt\")\n        ...     # Write to path...\n        ...\n        &gt;&gt;&gt; # Upload AFTER the context manager exits\n        &gt;&gt;&gt; def my_callback(progress):\n        ...     print(f\"Uploading {progress.file_name}: {progress.percent_complete:.1f}%\")\n        &gt;&gt;&gt; outputs = execution.upload_execution_outputs(progress_callback=my_callback)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Upload large files with increased timeout (30 min per chunk)\n        &gt;&gt;&gt; outputs = execution.upload_execution_outputs(timeout=(6, 1800))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Override cleanup setting for this execution\n        &gt;&gt;&gt; outputs = execution.upload_execution_outputs(clean_folder=False)  # Keep files\n    \"\"\"\n    if self._dry_run:\n        return {}\n\n    # Use DerivaML instance setting if not explicitly provided\n    if clean_folder is None:\n        clean_folder = getattr(self._ml_object, 'clean_execution_dir', True)\n\n    try:\n        self.uploaded_assets = self._upload_execution_dirs(\n            progress_callback=progress_callback,\n            max_retries=max_retries,\n            retry_delay=retry_delay,\n            timeout=timeout,\n            chunk_size=chunk_size,\n        )\n        self.update_status(Status.completed, \"Successfully end the execution.\")\n        if clean_folder:\n            self._clean_folder_contents(self._execution_root)\n        return self.uploaded_assets\n    except Exception as e:\n        error = format_exception(e)\n        self.update_status(Status.failed, error)\n        raise e\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.upload_execution_outputs--upload-after-the-context-manager-exits","title":"Upload AFTER the context manager exits","text":"<p>def my_callback(progress): ...     print(f\"Uploading {progress.file_name}: {progress.percent_complete:.1f}%\") outputs = execution.upload_execution_outputs(progress_callback=my_callback)</p>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.upload_execution_outputs--upload-large-files-with-increased-timeout-30-min-per-chunk","title":"Upload large files with increased timeout (30 min per chunk)","text":"<p>outputs = execution.upload_execution_outputs(timeout=(6, 1800))</p>"},{"location":"code-docs/execution/#deriva_ml.execution.Execution.upload_execution_outputs--override-cleanup-setting-for-this-execution","title":"Override cleanup setting for this execution","text":"<p>outputs = execution.upload_execution_outputs(clean_folder=False)  # Keep files</p>"},{"location":"code-docs/execution/#deriva_ml.execution.ExecutionConfiguration","title":"ExecutionConfiguration","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a DerivaML execution.</p> <p>Defines the complete configuration for a computational or manual process in DerivaML, including required datasets, input assets, workflow definition, and parameters.</p> <p>Attributes:</p> Name Type Description <code>datasets</code> <code>list[DatasetSpec]</code> <p>Dataset specifications, each containing: - rid: Dataset Resource Identifier - version: Version to use - materialize: Whether to extract dataset contents</p> <code>assets</code> <code>list[AssetSpec]</code> <p>Asset specifications. Each element can be: - A plain RID string (no caching) - An <code>AssetSpec(rid=..., cache=True)</code> for checksum-based caching</p> <code>workflow</code> <code>Workflow | None</code> <p>Workflow object defining the computational process. Use <code>ml.lookup_workflow(rid)</code> or <code>ml.lookup_workflow_by_url(url)</code> to get a Workflow object from a RID or URL. Defaults to <code>None</code>, which means the workflow must be provided via the <code>workflow</code> parameter of <code>ml.create_execution()</code> instead. If no workflow is specified in either place, a <code>DerivaMLException</code> is raised at execution creation time.</p> <code>description</code> <code>str</code> <p>Description of execution purpose (supports Markdown).</p> <code>argv</code> <code>list[str]</code> <p>Command line arguments used to start execution.</p> <code>config_choices</code> <code>dict[str, str]</code> <p>Hydra config group choices that were selected. Maps group names to selected config names (e.g., {\"model_config\": \"cifar10_quick\"}). Automatically populated by run_model() and get_notebook_configuration().</p> Example Source code in <code>src/deriva_ml/execution/execution_configuration.py</code> <pre><code>class ExecutionConfiguration(BaseModel):\n    \"\"\"Configuration for a DerivaML execution.\n\n    Defines the complete configuration for a computational or manual process in DerivaML,\n    including required datasets, input assets, workflow definition, and parameters.\n\n    Attributes:\n        datasets (list[DatasetSpec]): Dataset specifications, each containing:\n            - rid: Dataset Resource Identifier\n            - version: Version to use\n            - materialize: Whether to extract dataset contents\n        assets (list[AssetSpec]): Asset specifications. Each element can be:\n            - A plain RID string (no caching)\n            - An ``AssetSpec(rid=..., cache=True)`` for checksum-based caching\n        workflow (Workflow | None): Workflow object defining the computational process.\n            Use ``ml.lookup_workflow(rid)`` or ``ml.lookup_workflow_by_url(url)`` to get\n            a Workflow object from a RID or URL. Defaults to ``None``, which means the\n            workflow must be provided via the ``workflow`` parameter of\n            ``ml.create_execution()`` instead. If no workflow is specified in either\n            place, a ``DerivaMLException`` is raised at execution creation time.\n        description (str): Description of execution purpose (supports Markdown).\n        argv (list[str]): Command line arguments used to start execution.\n        config_choices (dict[str, str]): Hydra config group choices that were selected.\n            Maps group names to selected config names (e.g., {\"model_config\": \"cifar10_quick\"}).\n            Automatically populated by run_model() and get_notebook_configuration().\n\n    Example:\n        &gt;&gt;&gt; # Plain RIDs (backward compatible)\n        &gt;&gt;&gt; config = ExecutionConfiguration(assets=[\"6-EPNR\", \"6-EP56\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Mixed: cached model weights + uncached embeddings\n        &gt;&gt;&gt; config = ExecutionConfiguration(\n        ...     assets=[\n        ...         AssetSpec(rid=\"6-EPNR\", cache=True),\n        ...         \"6-EP56\",\n        ...     ]\n        ... )\n    \"\"\"\n\n    datasets: list[DatasetSpec] = []\n    assets: list[AssetSpec] = []\n    workflow: Workflow | None = None\n    description: str = \"\"\n    argv: list[str] = Field(default_factory=lambda: sys.argv)\n    config_choices: dict[str, str] = Field(default_factory=dict)\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @field_validator(\"assets\", mode=\"before\")\n    @classmethod\n    def validate_assets(cls, value: Any) -&gt; Any:\n        \"\"\"Normalize asset entries to AssetSpec objects.\n\n        Accepts plain RID strings, AssetRID objects, DictConfig from Hydra,\n        AssetSpec objects, or dicts with 'rid' and optional 'cache' keys.\n        \"\"\"\n        result = []\n        for v in value:\n            if isinstance(v, AssetSpec):\n                result.append(v)\n            elif isinstance(v, dict):\n                # Dict with rid/cache keys (e.g., from JSON config)\n                result.append(AssetSpec(**v))\n            elif isinstance(v, DictConfig):\n                # OmegaConf DictConfig from Hydra \u2014 may have rid+cache or just rid\n                d = dict(v)\n                if \"rid\" in d:\n                    result.append(AssetSpec(**d))\n                else:\n                    # Legacy DictConfig with just .rid attribute (AssetRID-style)\n                    result.append(AssetSpec(rid=v.rid, cache=getattr(v, \"cache\", False)))\n            elif isinstance(v, AssetRID):\n                result.append(AssetSpec(rid=v.rid))\n            elif isinstance(v, str):\n                result.append(AssetSpec(rid=v))\n            else:\n                # Unknown type \u2014 try string coercion\n                result.append(AssetSpec(rid=str(v)))\n        return result\n\n    @staticmethod\n    def load_configuration(path: Path) -&gt; ExecutionConfiguration:\n        \"\"\"Creates an ExecutionConfiguration from a JSON file.\n\n        Loads and parses a JSON configuration file into an ExecutionConfiguration\n        instance. The file should contain a valid configuration specification.\n\n        Args:\n            path: Path to JSON configuration file.\n\n        Returns:\n            ExecutionConfiguration: Loaded configuration instance.\n\n        Raises:\n            ValueError: If JSON file is invalid or missing required fields.\n            FileNotFoundError: If configuration file doesn't exist.\n\n        Example:\n            &gt;&gt;&gt; config = ExecutionConfiguration.load_configuration(Path(\"config.json\"))\n            &gt;&gt;&gt; print(f\"Workflow: {config.workflow}\")\n            &gt;&gt;&gt; print(f\"Datasets: {len(config.datasets)}\")\n        \"\"\"\n        with Path(path).open() as fd:\n            config = json.load(fd)\n        return ExecutionConfiguration.model_validate(config)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.ExecutionConfiguration--plain-rids-backward-compatible","title":"Plain RIDs (backward compatible)","text":"<p>config = ExecutionConfiguration(assets=[\"6-EPNR\", \"6-EP56\"])</p>"},{"location":"code-docs/execution/#deriva_ml.execution.ExecutionConfiguration--mixed-cached-model-weights-uncached-embeddings","title":"Mixed: cached model weights + uncached embeddings","text":"<p>config = ExecutionConfiguration( ...     assets=[ ...         AssetSpec(rid=\"6-EPNR\", cache=True), ...         \"6-EP56\", ...     ] ... )</p>"},{"location":"code-docs/execution/#deriva_ml.execution.ExecutionConfiguration.load_configuration","title":"load_configuration  <code>staticmethod</code>","text":"<pre><code>load_configuration(\n    path: Path,\n) -&gt; ExecutionConfiguration\n</code></pre> <p>Creates an ExecutionConfiguration from a JSON file.</p> <p>Loads and parses a JSON configuration file into an ExecutionConfiguration instance. The file should contain a valid configuration specification.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to JSON configuration file.</p> required <p>Returns:</p> Name Type Description <code>ExecutionConfiguration</code> <code>ExecutionConfiguration</code> <p>Loaded configuration instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If JSON file is invalid or missing required fields.</p> <code>FileNotFoundError</code> <p>If configuration file doesn't exist.</p> Example <p>config = ExecutionConfiguration.load_configuration(Path(\"config.json\")) print(f\"Workflow: {config.workflow}\") print(f\"Datasets: {len(config.datasets)}\")</p> Source code in <code>src/deriva_ml/execution/execution_configuration.py</code> <pre><code>@staticmethod\ndef load_configuration(path: Path) -&gt; ExecutionConfiguration:\n    \"\"\"Creates an ExecutionConfiguration from a JSON file.\n\n    Loads and parses a JSON configuration file into an ExecutionConfiguration\n    instance. The file should contain a valid configuration specification.\n\n    Args:\n        path: Path to JSON configuration file.\n\n    Returns:\n        ExecutionConfiguration: Loaded configuration instance.\n\n    Raises:\n        ValueError: If JSON file is invalid or missing required fields.\n        FileNotFoundError: If configuration file doesn't exist.\n\n    Example:\n        &gt;&gt;&gt; config = ExecutionConfiguration.load_configuration(Path(\"config.json\"))\n        &gt;&gt;&gt; print(f\"Workflow: {config.workflow}\")\n        &gt;&gt;&gt; print(f\"Datasets: {len(config.datasets)}\")\n    \"\"\"\n    with Path(path).open() as fd:\n        config = json.load(fd)\n    return ExecutionConfiguration.model_validate(config)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.ExecutionConfiguration.validate_assets","title":"validate_assets  <code>classmethod</code>","text":"<pre><code>validate_assets(value: Any) -&gt; Any\n</code></pre> <p>Normalize asset entries to AssetSpec objects.</p> <p>Accepts plain RID strings, AssetRID objects, DictConfig from Hydra, AssetSpec objects, or dicts with 'rid' and optional 'cache' keys.</p> Source code in <code>src/deriva_ml/execution/execution_configuration.py</code> <pre><code>@field_validator(\"assets\", mode=\"before\")\n@classmethod\ndef validate_assets(cls, value: Any) -&gt; Any:\n    \"\"\"Normalize asset entries to AssetSpec objects.\n\n    Accepts plain RID strings, AssetRID objects, DictConfig from Hydra,\n    AssetSpec objects, or dicts with 'rid' and optional 'cache' keys.\n    \"\"\"\n    result = []\n    for v in value:\n        if isinstance(v, AssetSpec):\n            result.append(v)\n        elif isinstance(v, dict):\n            # Dict with rid/cache keys (e.g., from JSON config)\n            result.append(AssetSpec(**v))\n        elif isinstance(v, DictConfig):\n            # OmegaConf DictConfig from Hydra \u2014 may have rid+cache or just rid\n            d = dict(v)\n            if \"rid\" in d:\n                result.append(AssetSpec(**d))\n            else:\n                # Legacy DictConfig with just .rid attribute (AssetRID-style)\n                result.append(AssetSpec(rid=v.rid, cache=getattr(v, \"cache\", False)))\n        elif isinstance(v, AssetRID):\n            result.append(AssetSpec(rid=v.rid))\n        elif isinstance(v, str):\n            result.append(AssetSpec(rid=v))\n        else:\n            # Unknown type \u2014 try string coercion\n            result.append(AssetSpec(rid=str(v)))\n    return result\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.MultirunSpec","title":"MultirunSpec  <code>dataclass</code>","text":"<p>Specification for a multirun experiment.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Unique identifier for this multirun configuration.</p> <code>overrides</code> <code>list[str]</code> <p>List of Hydra override strings (same syntax as command line). Examples: - \"+experiment=cifar10_quick,cifar10_extended\" - \"model_config.learning_rate=0.0001,0.001,0.01\" - \"model_config.epochs=5,10,25,50\"</p> <code>description</code> <code>str</code> <p>Rich description for the parent execution. Supports full markdown formatting (headers, tables, bold, etc.).</p> Source code in <code>src/deriva_ml/execution/multirun_config.py</code> <pre><code>@dataclass\nclass MultirunSpec:\n    \"\"\"Specification for a multirun experiment.\n\n    Attributes:\n        name: Unique identifier for this multirun configuration.\n        overrides: List of Hydra override strings (same syntax as command line).\n            Examples:\n            - \"+experiment=cifar10_quick,cifar10_extended\"\n            - \"model_config.learning_rate=0.0001,0.001,0.01\"\n            - \"model_config.epochs=5,10,25,50\"\n        description: Rich description for the parent execution. Supports full\n            markdown formatting (headers, tables, bold, etc.).\n    \"\"\"\n    name: str\n    overrides: list[str] = field(default_factory=list)\n    description: str = \"\"\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Workflow","title":"Workflow","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a computational workflow in DerivaML.</p> <p>A workflow defines a computational process or analysis pipeline. Each workflow has a unique identifier, source code location, and type. Workflows are typically associated with Git repositories for version control.</p> <p>When a Workflow is retrieved via <code>lookup_workflow(rid)</code> or <code>lookup_workflow_by_url()</code>, it is bound to a catalog and its <code>description</code> and <code>workflow_type</code> properties become writable. Setting these properties will update the catalog record. If the catalog is read-only (a snapshot), attempting to set them will raise a <code>DerivaMLException</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Human-readable name of the workflow.</p> <code>url</code> <code>str</code> <p>URI to the workflow source code (typically a GitHub URL).</p> <code>workflow_type</code> <code>str</code> <p>Type of workflow (must be a controlled vocabulary term). When the workflow is bound to a writable catalog, setting this property will update the catalog record. The new value must be a valid term from the Workflow_Type vocabulary.</p> <code>version</code> <code>str | None</code> <p>Version identifier (semantic versioning).</p> <code>description</code> <code>str | None</code> <p>Description of workflow purpose and behavior. When the workflow is bound to a writable catalog, setting this property will update the catalog record.</p> <code>rid</code> <code>RID | None</code> <p>Resource Identifier if registered in catalog.</p> <code>checksum</code> <code>str | None</code> <p>Git hash of workflow source code.</p> <code>is_notebook</code> <code>bool</code> <p>Whether workflow is a Jupyter notebook.</p> Note <p>The recommended way to create a Workflow is via :meth:<code>DerivaML.create_workflow() &lt;deriva_ml.DerivaML.create_workflow&gt;</code>, which validates the workflow type against the catalog vocabulary::</p> <pre><code>&gt;&gt;&gt; workflow = ml.create_workflow(\n...     name=\"RNA Analysis\",\n...     workflow_type=\"python_notebook\",\n...     description=\"RNA sequence analysis\"\n... )\n</code></pre> Example <p>Create a workflow directly (without catalog validation)::</p> <pre><code>&gt;&gt;&gt; workflow = Workflow(\n...     name=\"RNA Analysis\",\n...     url=\"https://github.com/org/repo/analysis.ipynb\",\n...     workflow_type=\"python_notebook\",\n...     version=\"1.0.0\",\n...     description=\"RNA sequence analysis\"\n... )\n</code></pre> <p>Look up an existing workflow by RID and update its properties::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.description = \"Updated description for RNA analysis\"\n&gt;&gt;&gt; workflow.workflow_type = \"python_script\"\n&gt;&gt;&gt; print(workflow.description)\nUpdated description for RNA analysis\n</code></pre> <p>Look up by URL and update::</p> <pre><code>&gt;&gt;&gt; url = \"https://github.com/org/repo/blob/abc123/analysis.py\"\n&gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(url)\n&gt;&gt;&gt; workflow.description = \"New description\"\n</code></pre> <p>Attempting to update on a read-only catalog raises an error::</p> <pre><code>&gt;&gt;&gt; snapshot_ml = ml.catalog_snapshot(\"2023-01-15T10:30:00\")\n&gt;&gt;&gt; workflow = snapshot_ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.description = \"New description\"  # Raises DerivaMLException\n</code></pre> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>class Workflow(BaseModel):\n    \"\"\"Represents a computational workflow in DerivaML.\n\n    A workflow defines a computational process or analysis pipeline. Each workflow has\n    a unique identifier, source code location, and type. Workflows are typically\n    associated with Git repositories for version control.\n\n    When a Workflow is retrieved via ``lookup_workflow(rid)`` or ``lookup_workflow_by_url()``,\n    it is bound to a catalog and its ``description`` and ``workflow_type`` properties become\n    writable. Setting these properties will update the catalog record. If the catalog is\n    read-only (a snapshot), attempting to set them will raise a ``DerivaMLException``.\n\n    Attributes:\n        name (str): Human-readable name of the workflow.\n        url (str): URI to the workflow source code (typically a GitHub URL).\n        workflow_type (str): Type of workflow (must be a controlled vocabulary term).\n            When the workflow is bound to a writable catalog, setting this property\n            will update the catalog record. The new value must be a valid term from\n            the Workflow_Type vocabulary.\n        version (str | None): Version identifier (semantic versioning).\n        description (str | None): Description of workflow purpose and behavior.\n            When the workflow is bound to a writable catalog, setting this property\n            will update the catalog record.\n        rid (RID | None): Resource Identifier if registered in catalog.\n        checksum (str | None): Git hash of workflow source code.\n        is_notebook (bool): Whether workflow is a Jupyter notebook.\n\n    Note:\n        The recommended way to create a Workflow is via :meth:`DerivaML.create_workflow()\n        &lt;deriva_ml.DerivaML.create_workflow&gt;`, which validates the workflow type against\n        the catalog vocabulary::\n\n            &gt;&gt;&gt; workflow = ml.create_workflow(\n            ...     name=\"RNA Analysis\",\n            ...     workflow_type=\"python_notebook\",\n            ...     description=\"RNA sequence analysis\"\n            ... )\n\n    Example:\n        Create a workflow directly (without catalog validation)::\n\n            &gt;&gt;&gt; workflow = Workflow(\n            ...     name=\"RNA Analysis\",\n            ...     url=\"https://github.com/org/repo/analysis.ipynb\",\n            ...     workflow_type=\"python_notebook\",\n            ...     version=\"1.0.0\",\n            ...     description=\"RNA sequence analysis\"\n            ... )\n\n        Look up an existing workflow by RID and update its properties::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.description = \"Updated description for RNA analysis\"\n            &gt;&gt;&gt; workflow.workflow_type = \"python_script\"\n            &gt;&gt;&gt; print(workflow.description)\n            Updated description for RNA analysis\n\n        Look up by URL and update::\n\n            &gt;&gt;&gt; url = \"https://github.com/org/repo/blob/abc123/analysis.py\"\n            &gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(url)\n            &gt;&gt;&gt; workflow.description = \"New description\"\n\n        Attempting to update on a read-only catalog raises an error::\n\n            &gt;&gt;&gt; snapshot_ml = ml.catalog_snapshot(\"2023-01-15T10:30:00\")\n            &gt;&gt;&gt; workflow = snapshot_ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.description = \"New description\"  # Raises DerivaMLException\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str\n    workflow_type: str\n    description: str | None = None\n    url: str | None = None\n    version: str | None = None\n    rid: RID | None = None\n    checksum: str | None = None\n    is_notebook: bool = False\n    git_root: Path | None = None\n\n    _ml_instance: \"DerivaMLCatalog | None\" = PrivateAttr(default=None)\n    _logger: logging.Logger = PrivateAttr(default=10)\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Override setattr to intercept description and workflow_type updates.\n\n        When the workflow is bound to a catalog (via lookup_workflow), setting\n        the ``description`` or ``workflow_type`` properties will update the catalog\n        record. If the catalog is read-only (a snapshot), a DerivaMLException is raised.\n\n        Args:\n            name: The attribute name being set.\n            value: The value to set.\n\n        Raises:\n            DerivaMLException: If attempting to set properties on a read-only\n                catalog (snapshot), or if workflow_type is not a valid vocabulary term.\n\n        Examples:\n            Update description::\n\n                &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n                &gt;&gt;&gt; workflow.description = \"Updated description\"\n\n            Update workflow type::\n\n                &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n                &gt;&gt;&gt; workflow.workflow_type = \"python_notebook\"\n        \"\"\"\n        # Only intercept updates after full initialization\n        # Use __dict__ check to avoid recursion during Pydantic model construction\n        if (\n            \"__pydantic_private__\" in self.__dict__\n            and self.__dict__.get(\"__pydantic_private__\", {}).get(\"_ml_instance\") is not None\n        ):\n            if name == \"description\":\n                self._update_description_in_catalog(value)\n            elif name == \"workflow_type\":\n                self._update_workflow_type_in_catalog(value)\n        super().__setattr__(name, value)\n\n    def _check_writable_catalog(self, operation: str) -&gt; None:\n        \"\"\"Check that the catalog is writable and workflow is registered.\n\n        Args:\n            operation: Description of the operation being attempted.\n\n        Raises:\n            DerivaMLException: If the workflow is not registered (no RID),\n                or if the catalog is read-only (a snapshot).\n        \"\"\"\n        # Import here to avoid circular dependency at module load\n        import importlib\n        _deriva_core = importlib.import_module(\"deriva.core\")\n        ErmrestSnapshot = _deriva_core.ErmrestSnapshot\n\n        if self.rid is None:\n            raise DerivaMLException(\n                f\"Cannot {operation}: Workflow is not registered in the catalog (no RID)\"\n            )\n\n        if isinstance(self._ml_instance.catalog, ErmrestSnapshot):\n            raise DerivaMLException(\n                f\"Cannot {operation} on a read-only catalog snapshot. \"\n                \"Use a writable catalog connection instead.\"\n            )\n\n    def _update_description_in_catalog(self, new_description: str | None) -&gt; None:\n        \"\"\"Update the description field in the catalog.\n\n        This internal method is called when the description property is set\n        on a catalog-bound Workflow object.\n\n        Args:\n            new_description: The new description value.\n\n        Raises:\n            DerivaMLException: If the workflow is not registered (no RID),\n                or if the catalog is read-only (a snapshot).\n        \"\"\"\n        self._check_writable_catalog(\"update description\")\n\n        # Update the catalog record\n        pb = self._ml_instance.pathBuilder()\n        workflow_path = pb.schemas[self._ml_instance.ml_schema].Workflow\n        workflow_path.update([{\"RID\": self.rid, \"Description\": new_description}])\n\n    def _update_workflow_type_in_catalog(self, new_workflow_type: str) -&gt; None:\n        \"\"\"Update the workflow_type field in the catalog.\n\n        This internal method is called when the workflow_type property is set\n        on a catalog-bound Workflow object. The new workflow type must be a valid\n        term from the Workflow_Type vocabulary.\n\n        Args:\n            new_workflow_type: The new workflow type (must be a valid vocabulary term).\n\n        Raises:\n            DerivaMLException: If the workflow is not registered (no RID),\n                the catalog is read-only (a snapshot), or the workflow_type\n                is not a valid vocabulary term.\n        \"\"\"\n        self._check_writable_catalog(\"update workflow_type\")\n\n        # Validate that the new workflow type exists in vocabulary\n        from deriva_ml.core.definitions import MLVocab\n        self._ml_instance.lookup_term(MLVocab.workflow_type, new_workflow_type)\n\n        # Update the catalog record\n        pb = self._ml_instance.pathBuilder()\n        workflow_path = pb.schemas[self._ml_instance.ml_schema].Workflow\n        workflow_path.update([{\"RID\": self.rid, \"Workflow_Type\": new_workflow_type}])\n\n    @model_validator(mode=\"after\")\n    def setup_url_checksum(self) -&gt; \"Workflow\":\n        \"\"\"Creates a workflow from the current execution context.\n\n        Identifies the currently executing program (script or notebook) and creates\n        a workflow definition. Automatically determines the Git repository information\n        and source code checksum.\n\n        The behavior can be configured using environment variables:\n            - DERIVA_ML_WORKFLOW_URL: Override the detected workflow URL\n            - DERIVA_ML_WORKFLOW_CHECKSUM: Override the computed checksum\n            - DERIVA_MCP_IN_DOCKER: Set to \"true\" to use Docker metadata instead of git\n\n        Docker environment variables (used when DERIVA_MCP_IN_DOCKER=true):\n            - DERIVA_MCP_VERSION: Semantic version of the Docker image\n            - DERIVA_MCP_GIT_COMMIT: Git commit hash at build time\n            - DERIVA_MCP_IMAGE_DIGEST: Docker image digest (unique identifier)\n            - DERIVA_MCP_IMAGE_NAME: Docker image name (e.g., ghcr.io/org/repo)\n\n        Args:\n\n        Returns:\n            Workflow: New workflow instance with detected Git information.\n\n        Raises:\n            DerivaMLException: If not in a Git repository or detection fails (non-Docker).\n\n        Example:\n            &gt;&gt;&gt; workflow = Workflow.create_workflow(\n            ...     name=\"Sample Analysis\",\n            ...     workflow_type=\"python_script\",\n            ...     description=\"Process sample data\"\n            ... )\n        \"\"\"\n        self._logger = logging.getLogger(\"deriva_ml\")\n\n        # Check if running in Docker container (no git repo available)\n        if os.environ.get(\"DERIVA_MCP_IN_DOCKER\", \"\").lower() == \"true\":\n            # Use Docker image metadata for provenance\n            self.version = self.version or os.environ.get(\"DERIVA_MCP_VERSION\", \"\")\n\n            # Use image digest as checksum (unique identifier for the container)\n            # Fall back to git commit if digest not available\n            self.checksum = self.checksum or (\n                os.environ.get(\"DERIVA_MCP_IMAGE_DIGEST\", \"\")\n                or os.environ.get(\"DERIVA_MCP_GIT_COMMIT\", \"\")\n            )\n\n            # Build URL pointing to the Docker image or source repo\n            if not self.url:\n                image_name = os.environ.get(\n                    \"DERIVA_MCP_IMAGE_NAME\",\n                    \"ghcr.io/informatics-isi-edu/deriva-ml-mcp\",\n                )\n                image_digest = os.environ.get(\"DERIVA_MCP_IMAGE_DIGEST\", \"\")\n                if image_digest:\n                    # URL format: image@sha256:digest\n                    self.url = f\"{image_name}@{image_digest}\"\n                else:\n                    # Fall back to source repo with git commit\n                    source_url = \"https://github.com/informatics-isi-edu/deriva-ml-mcp\"\n                    git_commit = os.environ.get(\"DERIVA_MCP_GIT_COMMIT\", \"\")\n                    self.url = f\"{source_url}/commit/{git_commit}\" if git_commit else source_url\n\n            return self\n\n        # Check to see if execution file info is being passed in by calling program (notebook runner)\n        if \"DERIVA_ML_WORKFLOW_URL\" in os.environ:\n            self.url = os.environ[\"DERIVA_ML_WORKFLOW_URL\"]\n            self.checksum = os.environ.get(\"DERIVA_ML_WORKFLOW_CHECKSUM\", \"\")\n            notebook_path = os.environ.get(\"DERIVA_ML_NOTEBOOK_PATH\")\n            if notebook_path:\n                self.git_root = Workflow._get_git_root(Path(notebook_path))\n            self.is_notebook = True\n            return self\n\n        # Standard git detection for local development\n        if not self.url:\n            path, self.is_notebook = Workflow._get_python_script()\n            self.url, self.checksum = Workflow.get_url_and_checksum(path)\n            self.git_root = Workflow._get_git_root(path)\n\n        self.version = self.version or Workflow.get_dynamic_version(root=str(self.git_root or Path.cwd()))\n        return self\n\n    @staticmethod\n    def get_url_and_checksum(executable_path: Path) -&gt; tuple[str, str]:\n        \"\"\"Determines the Git URL and checksum for a file.\n\n        Computes the Git repository URL and file checksum for the specified path.\n        For notebooks, strips cell outputs before computing the checksum.\n\n        Args:\n            executable_path: Path to the workflow file.\n\n        Returns:\n            tuple[str, str]: (GitHub URL, Git object hash)\n\n        Raises:\n            DerivaMLException: If not in a Git repository.\n\n        Example:\n            &gt;&gt;&gt; url, checksum = Workflow.get_url_and_checksum(Path(\"analysis.ipynb\"))\n            &gt;&gt;&gt; print(f\"URL: {url}\")\n            &gt;&gt;&gt; print(f\"Checksum: {checksum}\")\n        \"\"\"\n        try:\n            subprocess.run(\n                \"git rev-parse --is-inside-work-tree\",\n                capture_output=True,\n                text=True,\n                shell=True,\n                check=True,\n            )\n        except subprocess.CalledProcessError:\n            raise DerivaMLException(\"Not executing in a Git repository.\")\n\n        github_url, is_dirty = Workflow._github_url(executable_path)\n\n        if is_dirty:\n            logging.getLogger(\"deriva_ml\").warning(\n                f\"File {executable_path} has been modified since last commit. Consider commiting before executing\"\n            )\n\n        # If you are in a notebook, strip out the outputs before computing the checksum.\n        cmd = (\n            f\"nbstripout -t {executable_path} | git hash-object --stdin\"\n            if \"ipynb\" == executable_path.suffix\n            else f\"git hash-object {executable_path}\"\n        )\n        checksum = (\n            subprocess.run(\n                cmd,\n                capture_output=True,\n                text=True,\n                check=False,\n                shell=True,\n            ).stdout.strip()\n            if executable_path != \"REPL\"\n            else \"1\"\n        )\n        return github_url, checksum\n\n    @staticmethod\n    def _get_git_root(executable_path: Path) -&gt; str | None:\n        \"\"\"Gets the root directory of the Git repository.\n\n        Args:\n            executable_path: Path to check for Git repository.\n\n        Returns:\n            str | None: Absolute path to repository root, or None if not in repository.\n        \"\"\"\n        try:\n            result = subprocess.run(\n                [\"git\", \"rev-parse\", \"--show-toplevel\"],\n                cwd=executable_path.parent,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.DEVNULL,\n                text=True,\n                check=True,\n            )\n            return result.stdout.strip()\n        except subprocess.CalledProcessError:\n            return None  # Not in a git repository\n\n    @staticmethod\n    def _check_nbstrip_status() -&gt; None:\n        \"\"\"Checks if nbstripout is installed and configured.\n\n        Verifies that the nbstripout tool is available and properly installed in the\n        Git repository. Issues warnings if setup is incomplete.\n        \"\"\"\n        logger = logging.getLogger(\"deriva_ml\")\n        try:\n            if subprocess.run(\n                [\"nbstripout\", \"--is-installed\"],\n                check=False,\n                capture_output=True,\n            ).returncode:\n                logger.warning(\"nbstripout is not installed in repository. Please run nbstripout --install\")\n        except (subprocess.CalledProcessError, FileNotFoundError):\n            logger.warning(\"nbstripout is not found. Please install it with: pip install nbstripout\")\n\n    @staticmethod\n    def _get_notebook_path() -&gt; Path | None:\n        \"\"\"Gets the path of the currently executing notebook.\n\n        Returns:\n            Path | None: Absolute path to current notebook, or None if not in notebook.\n        \"\"\"\n\n        server, session = Workflow._get_notebook_session()\n\n        if server and session:\n            relative_path = session[\"notebook\"][\"path\"]\n            # Join the notebook directory with the relative path\n            return Path(server[\"root_dir\"]) / relative_path\n        else:\n            return None\n\n    @staticmethod\n    def _get_notebook_session() -&gt; tuple[dict[str, Any] | None, dict[str, Any] | None]:\n        \"\"\"Return the absolute path of the current notebook.\"\"\"\n        # Get the kernel's connection file and extract the kernel ID\n        try:\n            if not (connection_file := Path(get_kernel_connection()).name):\n                return None, None\n        except RuntimeError:\n            return None, None\n\n        # Extract kernel ID from connection filename.\n        # Standard Jupyter format: \"kernel-&lt;kernel_id&gt;.json\"\n        # PyCharm/other formats may vary: \"&lt;kernel_id&gt;.json\" or other patterns\n        kernel_id = None\n        if connection_file.startswith(\"kernel-\") and \"-\" in connection_file:\n            # Standard format: kernel-&lt;uuid&gt;.json\n            parts = connection_file.split(\"-\", 1)\n            if len(parts) &gt; 1:\n                kernel_id = parts[1].rsplit(\".\", 1)[0]\n        else:\n            # Fallback: assume filename (without extension) is the kernel ID\n            kernel_id = connection_file.rsplit(\".\", 1)[0]\n\n        if not kernel_id:\n            return None, None\n\n        # Look through the running server sessions to find the matching kernel ID\n        for server in get_servers():\n            try:\n                # If a token is required for authentication, include it in headers\n                token = server.get(\"token\", \"\")\n                headers = {}\n                if token:\n                    headers[\"Authorization\"] = f\"token {token}\"\n\n                try:\n                    sessions_url = server[\"url\"] + \"api/sessions\"\n                    response = requests.get(sessions_url, headers=headers)\n                    response.raise_for_status()\n                    sessions = response.json()\n                except RequestException as e:\n                    raise e\n                for sess in sessions:\n                    if sess[\"kernel\"][\"id\"] == kernel_id:\n                        return server, sess\n            except Exception as _e:\n                # Ignore servers we can't connect to.\n                pass\n        return None, None\n\n    @staticmethod\n    def _in_repl():\n        # Standard Python interactive mode\n        if hasattr(sys, \"ps1\"):\n            return True\n\n        # Interactive mode forced by -i\n        if sys.flags.interactive:\n            return True\n\n        # IPython / Jupyter detection\n        try:\n            from IPython import get_ipython\n\n            if get_ipython() is not None:\n                return True\n        except ImportError:\n            pass\n\n        return False\n\n    @staticmethod\n    def _get_python_script() -&gt; tuple[Path, bool]:\n        \"\"\"Return the path to the currently executing script\"\"\"\n        is_notebook = Workflow._get_notebook_path() is not None\n        return Path(_get_calling_module()), is_notebook\n\n    @staticmethod\n    def _github_url(executable_path: Path) -&gt; tuple[str, bool]:\n        \"\"\"Return a GitHub URL for the latest commit of the script from which this routine is called.\n\n        This routine is used to be called from a script or notebook (e.g., python -m file). It assumes that\n        the file is in a GitHub repository and committed.  It returns a URL to the last commited version of this\n        file in GitHub.\n\n        Returns: A tuple with the gethub_url and a boolean to indicate if uncommited changes\n            have been made to the file.\n\n        \"\"\"\n\n        # Get repo URL from local GitHub repo.\n        if executable_path == \"REPL\":\n            return \"REPL\", True\n        try:\n            result = subprocess.run(\n                [\"git\", \"remote\", \"get-url\", \"origin\"],\n                capture_output=True,\n                text=True,\n                cwd=executable_path.parent,\n            )\n            github_url = result.stdout.strip().removesuffix(\".git\")\n        except subprocess.CalledProcessError:\n            raise DerivaMLException(\"No GIT remote found\")\n\n        # Find the root directory for the repository\n        repo_root = Workflow._get_git_root(executable_path)\n\n        # Now check to see if a file has been modified since the last commit.\n        try:\n            result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"],\n                cwd=executable_path.parent,\n                capture_output=True,\n                text=True,\n                check=False,\n            )\n            is_dirty = bool(\"M \" in result.stdout.strip())  # Returns True if the output indicates a modified file\n        except subprocess.CalledProcessError:\n            is_dirty = False  # If the Git command fails, assume no changes\n\n        \"\"\"Get SHA-1 hash of latest commit of the file in the repository\"\"\"\n\n        result = subprocess.run(\n            [\"git\", \"log\", \"-n\", \"1\", \"--pretty=format:%H\", executable_path],\n            cwd=repo_root,\n            capture_output=True,\n            text=True,\n            check=False,\n        )\n        sha = result.stdout.strip()\n        url = f\"{github_url}/blob/{sha}/{executable_path.relative_to(repo_root)}\"\n        return url, is_dirty\n\n    @staticmethod\n    def get_dynamic_version(root: str | os.PathLike | None = None) -&gt; str:\n        \"\"\"\n        Return a dynamic version string based on VCS state (setuptools_scm),\n        including dirty/uncommitted changes if configured.\n\n        Works under uv / Python 3.10+ by forcing setuptools to use stdlib distutils.\n        \"\"\"\n        # 1) Tell setuptools to use stdlib distutils (or no override) to avoid\n        #    the '_distutils_hack' assertion you hit.\n        os.environ.setdefault(\"SETUPTOOLS_USE_DISTUTILS\", \"stdlib\")\n\n        warnings.filterwarnings(\n            \"ignore\",\n            category=UserWarning,\n            module=\"_distutils_hack\",\n        )\n        try:\n            from setuptools_scm import get_version\n        except Exception as e:  # ImportError or anything environment-specific\n            raise RuntimeError(f\"setuptools_scm is not available: {e}\") from e\n\n        if root is None:\n            # Adjust this to point at your repo root if needed\n            root = Path(__file__).resolve().parents[1]\n\n        return get_version(root=root)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Workflow.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(\n    name: str, value: Any\n) -&gt; None\n</code></pre> <p>Override setattr to intercept description and workflow_type updates.</p> <p>When the workflow is bound to a catalog (via lookup_workflow), setting the <code>description</code> or <code>workflow_type</code> properties will update the catalog record. If the catalog is read-only (a snapshot), a DerivaMLException is raised.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The attribute name being set.</p> required <code>value</code> <code>Any</code> <p>The value to set.</p> required <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If attempting to set properties on a read-only catalog (snapshot), or if workflow_type is not a valid vocabulary term.</p> <p>Examples:</p> <p>Update description::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.description = \"Updated description\"\n</code></pre> <p>Update workflow type::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.workflow_type = \"python_notebook\"\n</code></pre> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Override setattr to intercept description and workflow_type updates.\n\n    When the workflow is bound to a catalog (via lookup_workflow), setting\n    the ``description`` or ``workflow_type`` properties will update the catalog\n    record. If the catalog is read-only (a snapshot), a DerivaMLException is raised.\n\n    Args:\n        name: The attribute name being set.\n        value: The value to set.\n\n    Raises:\n        DerivaMLException: If attempting to set properties on a read-only\n            catalog (snapshot), or if workflow_type is not a valid vocabulary term.\n\n    Examples:\n        Update description::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.description = \"Updated description\"\n\n        Update workflow type::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.workflow_type = \"python_notebook\"\n    \"\"\"\n    # Only intercept updates after full initialization\n    # Use __dict__ check to avoid recursion during Pydantic model construction\n    if (\n        \"__pydantic_private__\" in self.__dict__\n        and self.__dict__.get(\"__pydantic_private__\", {}).get(\"_ml_instance\") is not None\n    ):\n        if name == \"description\":\n            self._update_description_in_catalog(value)\n        elif name == \"workflow_type\":\n            self._update_workflow_type_in_catalog(value)\n    super().__setattr__(name, value)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Workflow.get_dynamic_version","title":"get_dynamic_version  <code>staticmethod</code>","text":"<pre><code>get_dynamic_version(\n    root: str | PathLike | None = None,\n) -&gt; str\n</code></pre> <p>Return a dynamic version string based on VCS state (setuptools_scm), including dirty/uncommitted changes if configured.</p> <p>Works under uv / Python 3.10+ by forcing setuptools to use stdlib distutils.</p> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>@staticmethod\ndef get_dynamic_version(root: str | os.PathLike | None = None) -&gt; str:\n    \"\"\"\n    Return a dynamic version string based on VCS state (setuptools_scm),\n    including dirty/uncommitted changes if configured.\n\n    Works under uv / Python 3.10+ by forcing setuptools to use stdlib distutils.\n    \"\"\"\n    # 1) Tell setuptools to use stdlib distutils (or no override) to avoid\n    #    the '_distutils_hack' assertion you hit.\n    os.environ.setdefault(\"SETUPTOOLS_USE_DISTUTILS\", \"stdlib\")\n\n    warnings.filterwarnings(\n        \"ignore\",\n        category=UserWarning,\n        module=\"_distutils_hack\",\n    )\n    try:\n        from setuptools_scm import get_version\n    except Exception as e:  # ImportError or anything environment-specific\n        raise RuntimeError(f\"setuptools_scm is not available: {e}\") from e\n\n    if root is None:\n        # Adjust this to point at your repo root if needed\n        root = Path(__file__).resolve().parents[1]\n\n    return get_version(root=root)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Workflow.get_url_and_checksum","title":"get_url_and_checksum  <code>staticmethod</code>","text":"<pre><code>get_url_and_checksum(\n    executable_path: Path,\n) -&gt; tuple[str, str]\n</code></pre> <p>Determines the Git URL and checksum for a file.</p> <p>Computes the Git repository URL and file checksum for the specified path. For notebooks, strips cell outputs before computing the checksum.</p> <p>Parameters:</p> Name Type Description Default <code>executable_path</code> <code>Path</code> <p>Path to the workflow file.</p> required <p>Returns:</p> Type Description <code>tuple[str, str]</code> <p>tuple[str, str]: (GitHub URL, Git object hash)</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If not in a Git repository.</p> Example <p>url, checksum = Workflow.get_url_and_checksum(Path(\"analysis.ipynb\")) print(f\"URL: {url}\") print(f\"Checksum: {checksum}\")</p> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>@staticmethod\ndef get_url_and_checksum(executable_path: Path) -&gt; tuple[str, str]:\n    \"\"\"Determines the Git URL and checksum for a file.\n\n    Computes the Git repository URL and file checksum for the specified path.\n    For notebooks, strips cell outputs before computing the checksum.\n\n    Args:\n        executable_path: Path to the workflow file.\n\n    Returns:\n        tuple[str, str]: (GitHub URL, Git object hash)\n\n    Raises:\n        DerivaMLException: If not in a Git repository.\n\n    Example:\n        &gt;&gt;&gt; url, checksum = Workflow.get_url_and_checksum(Path(\"analysis.ipynb\"))\n        &gt;&gt;&gt; print(f\"URL: {url}\")\n        &gt;&gt;&gt; print(f\"Checksum: {checksum}\")\n    \"\"\"\n    try:\n        subprocess.run(\n            \"git rev-parse --is-inside-work-tree\",\n            capture_output=True,\n            text=True,\n            shell=True,\n            check=True,\n        )\n    except subprocess.CalledProcessError:\n        raise DerivaMLException(\"Not executing in a Git repository.\")\n\n    github_url, is_dirty = Workflow._github_url(executable_path)\n\n    if is_dirty:\n        logging.getLogger(\"deriva_ml\").warning(\n            f\"File {executable_path} has been modified since last commit. Consider commiting before executing\"\n        )\n\n    # If you are in a notebook, strip out the outputs before computing the checksum.\n    cmd = (\n        f\"nbstripout -t {executable_path} | git hash-object --stdin\"\n        if \"ipynb\" == executable_path.suffix\n        else f\"git hash-object {executable_path}\"\n    )\n    checksum = (\n        subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=False,\n            shell=True,\n        ).stdout.strip()\n        if executable_path != \"REPL\"\n        else \"1\"\n    )\n    return github_url, checksum\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.Workflow.setup_url_checksum","title":"setup_url_checksum","text":"<pre><code>setup_url_checksum() -&gt; 'Workflow'\n</code></pre> <p>Creates a workflow from the current execution context.</p> <p>Identifies the currently executing program (script or notebook) and creates a workflow definition. Automatically determines the Git repository information and source code checksum.</p> The behavior can be configured using environment variables <ul> <li>DERIVA_ML_WORKFLOW_URL: Override the detected workflow URL</li> <li>DERIVA_ML_WORKFLOW_CHECKSUM: Override the computed checksum</li> <li>DERIVA_MCP_IN_DOCKER: Set to \"true\" to use Docker metadata instead of git</li> </ul> <p>Docker environment variables (used when DERIVA_MCP_IN_DOCKER=true):     - DERIVA_MCP_VERSION: Semantic version of the Docker image     - DERIVA_MCP_GIT_COMMIT: Git commit hash at build time     - DERIVA_MCP_IMAGE_DIGEST: Docker image digest (unique identifier)     - DERIVA_MCP_IMAGE_NAME: Docker image name (e.g., ghcr.io/org/repo)</p> <p>Args:</p> <p>Returns:</p> Name Type Description <code>Workflow</code> <code>'Workflow'</code> <p>New workflow instance with detected Git information.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If not in a Git repository or detection fails (non-Docker).</p> Example <p>workflow = Workflow.create_workflow( ...     name=\"Sample Analysis\", ...     workflow_type=\"python_script\", ...     description=\"Process sample data\" ... )</p> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_url_checksum(self) -&gt; \"Workflow\":\n    \"\"\"Creates a workflow from the current execution context.\n\n    Identifies the currently executing program (script or notebook) and creates\n    a workflow definition. Automatically determines the Git repository information\n    and source code checksum.\n\n    The behavior can be configured using environment variables:\n        - DERIVA_ML_WORKFLOW_URL: Override the detected workflow URL\n        - DERIVA_ML_WORKFLOW_CHECKSUM: Override the computed checksum\n        - DERIVA_MCP_IN_DOCKER: Set to \"true\" to use Docker metadata instead of git\n\n    Docker environment variables (used when DERIVA_MCP_IN_DOCKER=true):\n        - DERIVA_MCP_VERSION: Semantic version of the Docker image\n        - DERIVA_MCP_GIT_COMMIT: Git commit hash at build time\n        - DERIVA_MCP_IMAGE_DIGEST: Docker image digest (unique identifier)\n        - DERIVA_MCP_IMAGE_NAME: Docker image name (e.g., ghcr.io/org/repo)\n\n    Args:\n\n    Returns:\n        Workflow: New workflow instance with detected Git information.\n\n    Raises:\n        DerivaMLException: If not in a Git repository or detection fails (non-Docker).\n\n    Example:\n        &gt;&gt;&gt; workflow = Workflow.create_workflow(\n        ...     name=\"Sample Analysis\",\n        ...     workflow_type=\"python_script\",\n        ...     description=\"Process sample data\"\n        ... )\n    \"\"\"\n    self._logger = logging.getLogger(\"deriva_ml\")\n\n    # Check if running in Docker container (no git repo available)\n    if os.environ.get(\"DERIVA_MCP_IN_DOCKER\", \"\").lower() == \"true\":\n        # Use Docker image metadata for provenance\n        self.version = self.version or os.environ.get(\"DERIVA_MCP_VERSION\", \"\")\n\n        # Use image digest as checksum (unique identifier for the container)\n        # Fall back to git commit if digest not available\n        self.checksum = self.checksum or (\n            os.environ.get(\"DERIVA_MCP_IMAGE_DIGEST\", \"\")\n            or os.environ.get(\"DERIVA_MCP_GIT_COMMIT\", \"\")\n        )\n\n        # Build URL pointing to the Docker image or source repo\n        if not self.url:\n            image_name = os.environ.get(\n                \"DERIVA_MCP_IMAGE_NAME\",\n                \"ghcr.io/informatics-isi-edu/deriva-ml-mcp\",\n            )\n            image_digest = os.environ.get(\"DERIVA_MCP_IMAGE_DIGEST\", \"\")\n            if image_digest:\n                # URL format: image@sha256:digest\n                self.url = f\"{image_name}@{image_digest}\"\n            else:\n                # Fall back to source repo with git commit\n                source_url = \"https://github.com/informatics-isi-edu/deriva-ml-mcp\"\n                git_commit = os.environ.get(\"DERIVA_MCP_GIT_COMMIT\", \"\")\n                self.url = f\"{source_url}/commit/{git_commit}\" if git_commit else source_url\n\n        return self\n\n    # Check to see if execution file info is being passed in by calling program (notebook runner)\n    if \"DERIVA_ML_WORKFLOW_URL\" in os.environ:\n        self.url = os.environ[\"DERIVA_ML_WORKFLOW_URL\"]\n        self.checksum = os.environ.get(\"DERIVA_ML_WORKFLOW_CHECKSUM\", \"\")\n        notebook_path = os.environ.get(\"DERIVA_ML_NOTEBOOK_PATH\")\n        if notebook_path:\n            self.git_root = Workflow._get_git_root(Path(notebook_path))\n        self.is_notebook = True\n        return self\n\n    # Standard git detection for local development\n    if not self.url:\n        path, self.is_notebook = Workflow._get_python_script()\n        self.url, self.checksum = Workflow.get_url_and_checksum(path)\n        self.git_root = Workflow._get_git_root(path)\n\n    self.version = self.version or Workflow.get_dynamic_version(root=str(self.git_root or Path.cwd()))\n    return self\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name)\n</code></pre> <p>Lazy import to avoid circular dependencies.</p> Source code in <code>src/deriva_ml/execution/__init__.py</code> <pre><code>def __getattr__(name):\n    \"\"\"Lazy import to avoid circular dependencies.\"\"\"\n    if name == \"Execution\":\n        from deriva_ml.execution.execution import Execution\n\n        return Execution\n    raise AttributeError(f\"module {__name__!r} has no attribute {name!r}\")\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.create_model_config","title":"create_model_config","text":"<pre><code>create_model_config(\n    ml_class: type[\"DerivaML\"]\n    | None = None,\n    description: str = \"Model execution\",\n    hydra_defaults: list | None = None,\n) -&gt; Any\n</code></pre> <p>Create a hydra-zen configuration for run_model.</p> <p>This helper creates a properly configured hydra-zen builds() for run_model with the specified DerivaML class bound via partial application.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.create_model_config--parameters","title":"Parameters","text":"<p>ml_class : type[DerivaML], optional     The DerivaML class (or subclass) to use. If None, uses the base DerivaML.</p> str, optional <p>Default description for executions. Can be overridden at runtime.</p> list, optional <p>Custom hydra defaults. If None, uses standard defaults for deriva_ml, datasets, assets, workflow, and model_config groups.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.create_model_config--returns","title":"Returns","text":"<p>Any     A hydra-zen builds() configuration ready to be registered with store().</p>"},{"location":"code-docs/execution/#deriva_ml.execution.create_model_config--examples","title":"Examples","text":"<p>Basic usage with DerivaML:</p> <pre><code>&gt;&gt;&gt; from deriva_ml.execution.runner import create_model_config\n&gt;&gt;&gt; model_config = create_model_config()\n&gt;&gt;&gt; store(model_config, name=\"deriva_model\")\n</code></pre> <p>With a custom subclass:</p> <pre><code>&gt;&gt;&gt; from eye_ai import EyeAI\n&gt;&gt;&gt; model_config = create_model_config(EyeAI, description=\"EyeAI analysis\")\n&gt;&gt;&gt; store(model_config, name=\"eyeai_model\")\n</code></pre> <p>With custom hydra defaults:</p> <pre><code>&gt;&gt;&gt; model_config = create_model_config(\n...     hydra_defaults=[\n...         \"_self_\",\n...         {\"deriva_ml\": \"production\"},\n...         {\"datasets\": \"full_dataset\"},\n...     ]\n... )\n</code></pre> Source code in <code>src/deriva_ml/execution/runner.py</code> <pre><code>def create_model_config(\n    ml_class: type[\"DerivaML\"] | None = None,\n    description: str = \"Model execution\",\n    hydra_defaults: list | None = None,\n) -&gt; Any:\n    \"\"\"Create a hydra-zen configuration for run_model.\n\n    This helper creates a properly configured hydra-zen builds() for run_model\n    with the specified DerivaML class bound via partial application.\n\n    Parameters\n    ----------\n    ml_class : type[DerivaML], optional\n        The DerivaML class (or subclass) to use. If None, uses the base DerivaML.\n\n    description : str, optional\n        Default description for executions. Can be overridden at runtime.\n\n    hydra_defaults : list, optional\n        Custom hydra defaults. If None, uses standard defaults for deriva_ml,\n        datasets, assets, workflow, and model_config groups.\n\n    Returns\n    -------\n    Any\n        A hydra-zen builds() configuration ready to be registered with store().\n\n    Examples\n    --------\n    Basic usage with DerivaML:\n\n        &gt;&gt;&gt; from deriva_ml.execution.runner import create_model_config\n        &gt;&gt;&gt; model_config = create_model_config()\n        &gt;&gt;&gt; store(model_config, name=\"deriva_model\")\n\n    With a custom subclass:\n\n        &gt;&gt;&gt; from eye_ai import EyeAI\n        &gt;&gt;&gt; model_config = create_model_config(EyeAI, description=\"EyeAI analysis\")\n        &gt;&gt;&gt; store(model_config, name=\"eyeai_model\")\n\n    With custom hydra defaults:\n\n        &gt;&gt;&gt; model_config = create_model_config(\n        ...     hydra_defaults=[\n        ...         \"_self_\",\n        ...         {\"deriva_ml\": \"production\"},\n        ...         {\"datasets\": \"full_dataset\"},\n        ...     ]\n        ... )\n    \"\"\"\n    from functools import partial\n\n    if hydra_defaults is None:\n        hydra_defaults = [\n            \"_self_\",\n            {\"deriva_ml\": \"default_deriva\"},\n            {\"datasets\": \"default_dataset\"},\n            {\"assets\": \"default_asset\"},\n            {\"workflow\": \"default_workflow\"},\n            {\"model_config\": \"default_model\"},\n        ]\n\n    # Create a partial function with ml_class bound\n    if ml_class is not None:\n        run_func = partial(run_model, ml_class=ml_class)\n    else:\n        run_func = run_model\n\n    return builds(\n        run_func,\n        description=description,\n        populate_full_signature=True,\n        hydra_defaults=hydra_defaults,\n    )\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.get_all_multirun_configs","title":"get_all_multirun_configs","text":"<pre><code>get_all_multirun_configs() -&gt; dict[\n    str, MultirunSpec\n]\n</code></pre> <p>Get all registered multirun configurations.</p> <p>Returns:</p> Type Description <code>dict[str, MultirunSpec]</code> <p>Dictionary mapping names to MultirunSpec instances.</p> Source code in <code>src/deriva_ml/execution/multirun_config.py</code> <pre><code>def get_all_multirun_configs() -&gt; dict[str, MultirunSpec]:\n    \"\"\"Get all registered multirun configurations.\n\n    Returns:\n        Dictionary mapping names to MultirunSpec instances.\n    \"\"\"\n    return dict(_multirun_registry)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.get_multirun_config","title":"get_multirun_config","text":"<pre><code>get_multirun_config(\n    name: str,\n) -&gt; MultirunSpec | None\n</code></pre> <p>Look up a registered multirun configuration by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the multirun configuration.</p> required <p>Returns:</p> Type Description <code>MultirunSpec | None</code> <p>The MultirunSpec if found, None otherwise.</p> Source code in <code>src/deriva_ml/execution/multirun_config.py</code> <pre><code>def get_multirun_config(name: str) -&gt; MultirunSpec | None:\n    \"\"\"Look up a registered multirun configuration by name.\n\n    Args:\n        name: The name of the multirun configuration.\n\n    Returns:\n        The MultirunSpec if found, None otherwise.\n    \"\"\"\n    return _multirun_registry.get(name)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.get_notebook_configuration","title":"get_notebook_configuration","text":"<pre><code>get_notebook_configuration(\n    config_class: type[T],\n    config_name: str,\n    overrides: list[str] | None = None,\n    job_name: str = \"notebook\",\n    version_base: str = \"1.3\",\n) -&gt; T\n</code></pre> <p>Load and return a hydra-zen configuration for use in notebooks.</p> <p>This function is the notebook equivalent of <code>run_model</code>. While <code>run_model</code> launches a full execution with model training, <code>get_notebook_configuration</code> simply resolves the configuration and returns it for interactive use.</p> <p>The function handles: - Adding configurations to the hydra store - Launching hydra-zen to resolve defaults and overrides - Returning the instantiated configuration object</p> <p>Parameters:</p> Name Type Description Default <code>config_class</code> <code>type[T]</code> <p>The hydra-zen builds() class for the configuration. This should be a class created with <code>builds(YourConfig, ...)</code>.</p> required <code>config_name</code> <code>str</code> <p>Name of the configuration in the hydra store. Must match the name used when calling <code>store(config_class, name=...)</code>.</p> required <code>overrides</code> <code>list[str] | None</code> <p>Optional list of Hydra override strings (e.g., [\"param=value\"]).</p> <code>None</code> <code>job_name</code> <code>str</code> <p>Name for the Hydra job (default: \"notebook\").</p> <code>'notebook'</code> <code>version_base</code> <code>str</code> <p>Hydra version base (default: \"1.3\").</p> <code>'1.3'</code> <p>Returns:</p> Type Description <code>T</code> <p>The instantiated configuration object with all defaults resolved.</p> Example <p>In your notebook's configuration module (e.g., <code>configs/roc_analysis.py</code>):</p> <p>from dataclasses import dataclass, field from hydra_zen import builds, store from deriva_ml.execution import BaseConfig</p> <p>@dataclass ... class ROCAnalysisConfig(BaseConfig): ...     execution_rids: list[str] = field(default_factory=list)</p> <p>ROCAnalysisConfigBuilds = builds( ...     ROCAnalysisConfig, ...     populate_full_signature=True, ...     hydra_defaults=[\"self\", {\"deriva_ml\": \"default_deriva\"}], ... ) store(ROCAnalysisConfigBuilds, name=\"roc_analysis\")</p> <p>In your notebook:</p> <p>from configs import load_all_configs from configs.roc_analysis import ROCAnalysisConfigBuilds from deriva_ml.execution import get_notebook_configuration</p> Environment Variables <p>DERIVA_ML_HYDRA_OVERRIDES: JSON-encoded list of override strings.     When running via <code>deriva-ml-run-notebook</code>, this is automatically     set from command-line arguments. Overrides from this environment     variable are applied first, then any overrides passed directly     to this function are applied (taking precedence).</p> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>def get_notebook_configuration(\n    config_class: type[T],\n    config_name: str,\n    overrides: list[str] | None = None,\n    job_name: str = \"notebook\",\n    version_base: str = \"1.3\",\n) -&gt; T:\n    \"\"\"Load and return a hydra-zen configuration for use in notebooks.\n\n    This function is the notebook equivalent of `run_model`. While `run_model`\n    launches a full execution with model training, `get_notebook_configuration`\n    simply resolves the configuration and returns it for interactive use.\n\n    The function handles:\n    - Adding configurations to the hydra store\n    - Launching hydra-zen to resolve defaults and overrides\n    - Returning the instantiated configuration object\n\n    Args:\n        config_class: The hydra-zen builds() class for the configuration.\n            This should be a class created with `builds(YourConfig, ...)`.\n        config_name: Name of the configuration in the hydra store.\n            Must match the name used when calling `store(config_class, name=...)`.\n        overrides: Optional list of Hydra override strings (e.g., [\"param=value\"]).\n        job_name: Name for the Hydra job (default: \"notebook\").\n        version_base: Hydra version base (default: \"1.3\").\n\n    Returns:\n        The instantiated configuration object with all defaults resolved.\n\n    Example:\n        In your notebook's configuration module (e.g., `configs/roc_analysis.py`):\n\n        &gt;&gt;&gt; from dataclasses import dataclass, field\n        &gt;&gt;&gt; from hydra_zen import builds, store\n        &gt;&gt;&gt; from deriva_ml.execution import BaseConfig\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; @dataclass\n        ... class ROCAnalysisConfig(BaseConfig):\n        ...     execution_rids: list[str] = field(default_factory=list)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; ROCAnalysisConfigBuilds = builds(\n        ...     ROCAnalysisConfig,\n        ...     populate_full_signature=True,\n        ...     hydra_defaults=[\"_self_\", {\"deriva_ml\": \"default_deriva\"}],\n        ... )\n        &gt;&gt;&gt; store(ROCAnalysisConfigBuilds, name=\"roc_analysis\")\n\n        In your notebook:\n\n        &gt;&gt;&gt; from configs import load_all_configs\n        &gt;&gt;&gt; from configs.roc_analysis import ROCAnalysisConfigBuilds\n        &gt;&gt;&gt; from deriva_ml.execution import get_notebook_configuration\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Load all project configs into hydra store\n        &gt;&gt;&gt; load_all_configs()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Get resolved configuration\n        &gt;&gt;&gt; config = get_notebook_configuration(\n        ...     ROCAnalysisConfigBuilds,\n        ...     config_name=\"roc_analysis\",\n        ...     overrides=[\"execution_rids=[3JRC,3KT0]\"],\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Use the configuration\n        &gt;&gt;&gt; print(config.execution_rids)  # ['3JRC', '3KT0']\n        &gt;&gt;&gt; print(config.deriva_ml.hostname)  # From default_deriva config\n\n    Environment Variables:\n        DERIVA_ML_HYDRA_OVERRIDES: JSON-encoded list of override strings.\n            When running via `deriva-ml-run-notebook`, this is automatically\n            set from command-line arguments. Overrides from this environment\n            variable are applied first, then any overrides passed directly\n            to this function are applied (taking precedence).\n    \"\"\"\n    # Ensure configs are in the hydra store\n    store.add_to_hydra_store(overwrite_ok=True)\n\n    # Collect overrides from environment variable (set by run_notebook CLI)\n    env_overrides_json = os.environ.get(\"DERIVA_ML_HYDRA_OVERRIDES\")\n    env_overrides = json.loads(env_overrides_json) if env_overrides_json else []\n\n    # Merge overrides: env overrides first, then explicit overrides (higher precedence)\n    all_overrides = env_overrides + (overrides or [])\n\n    # Variables to capture from within the task function\n    captured_choices: dict[str, str] = {}\n    captured_output_dir: str | None = None\n\n    # Define a task function that instantiates and returns the config\n    # The cfg from launch() is an OmegaConf DictConfig, so we need to\n    # use hydra_zen.instantiate() to convert it to actual Python objects\n    def return_instantiated_config(cfg: Any) -&gt; T:\n        nonlocal captured_choices, captured_output_dir\n        # Capture the Hydra runtime choices (which config names were selected)\n        # and runtime output directory (for uploading hydra config files)\n        # Filter out None values (some Hydra internal groups have None choices)\n        try:\n            from hydra.core.hydra_config import HydraConfig\n            hydra_cfg = HydraConfig.get()\n            choices = hydra_cfg.runtime.choices\n            captured_choices = {k: v for k, v in choices.items() if v is not None}\n            captured_output_dir = hydra_cfg.runtime.output_dir\n        except Exception:\n            # If HydraConfig is not available, leave choices empty\n            pass\n        return instantiate(cfg)\n\n    # Launch hydra-zen to resolve the configuration\n    result = launch(\n        config_class,\n        return_instantiated_config,\n        version_base=version_base,\n        config_name=config_name,\n        job_name=job_name,\n        overrides=all_overrides,\n    )\n\n    # Inject the captured choices into the config object\n    config = result.return_value\n    if hasattr(config, \"config_choices\"):\n        config.config_choices = captured_choices\n\n    # Store the hydra output dir in module-level variable for run_notebook() to use.\n    # This is NOT stored on the config because it's a runtime artifact, not a\n    # configuration parameter, and adding it to the structured config causes\n    # Hydra OmegaConf composition errors.\n    global _captured_hydra_output_dir\n    _captured_hydra_output_dir = captured_output_dir\n\n    return config\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.get_notebook_configuration--load-all-project-configs-into-hydra-store","title":"Load all project configs into hydra store","text":"<p>load_all_configs()</p>"},{"location":"code-docs/execution/#deriva_ml.execution.get_notebook_configuration--get-resolved-configuration","title":"Get resolved configuration","text":"<p>config = get_notebook_configuration( ...     ROCAnalysisConfigBuilds, ...     config_name=\"roc_analysis\", ...     overrides=[\"execution_rids=[3JRC,3KT0]\"], ... )</p>"},{"location":"code-docs/execution/#deriva_ml.execution.get_notebook_configuration--use-the-configuration","title":"Use the configuration","text":"<p>print(config.execution_rids)  # ['3JRC', '3KT0'] print(config.deriva_ml.hostname)  # From default_deriva config</p>"},{"location":"code-docs/execution/#deriva_ml.execution.list_multirun_configs","title":"list_multirun_configs","text":"<pre><code>list_multirun_configs() -&gt; list[str]\n</code></pre> <p>List all registered multirun configuration names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of registered multirun config names.</p> Source code in <code>src/deriva_ml/execution/multirun_config.py</code> <pre><code>def list_multirun_configs() -&gt; list[str]:\n    \"\"\"List all registered multirun configuration names.\n\n    Returns:\n        List of registered multirun config names.\n    \"\"\"\n    return list(_multirun_registry.keys())\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.load_configs","title":"load_configs","text":"<pre><code>load_configs(\n    package_name: str = \"configs\",\n) -&gt; list[str]\n</code></pre> <p>Dynamically import all configuration modules from a package.</p> <p>This function discovers and imports all Python modules in the specified package. Each module is expected to register its configurations with the hydra-zen store as a side effect of being imported.</p> <p>Parameters:</p> Name Type Description Default <code>package_name</code> <code>str</code> <p>Name of the package containing config modules. Default is \"configs\" which works for the standard project layout.</p> <code>'configs'</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of module names that were successfully loaded.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If a config module fails to import.</p> Example Note <p>The \"experiments\" module (if present) is loaded last because it typically depends on other configs being registered first.</p> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>def load_configs(package_name: str = \"configs\") -&gt; list[str]:\n    \"\"\"Dynamically import all configuration modules from a package.\n\n    This function discovers and imports all Python modules in the specified\n    package. Each module is expected to register its configurations with\n    the hydra-zen store as a side effect of being imported.\n\n    Args:\n        package_name: Name of the package containing config modules.\n            Default is \"configs\" which works for the standard project layout.\n\n    Returns:\n        List of module names that were successfully loaded.\n\n    Raises:\n        ImportError: If a config module fails to import.\n\n    Example:\n        # In your main script or notebook\n        from deriva_ml.execution import load_configs\n\n        load_configs()  # Loads from \"configs\" package\n        # or\n        load_configs(\"my_project.configs\")  # Custom package\n\n    Note:\n        The \"experiments\" module (if present) is loaded last because it\n        typically depends on other configs being registered first.\n    \"\"\"\n    loaded_modules = []\n\n    try:\n        package = importlib.import_module(package_name)\n    except ImportError:\n        # Package doesn't exist, return empty\n        return []\n\n    package_dir = Path(package.__file__).parent\n\n    # Collect module names, recursing into subpackages\n    modules_to_load = []\n    for module_info in pkgutil.iter_modules([str(package_dir)]):\n        if module_info.ispkg:\n            # Recurse into subpackages (e.g., configs/dev/)\n            sub_loaded = load_configs(f\"{package_name}.{module_info.name}\")\n            loaded_modules.extend(sub_loaded)\n        else:\n            modules_to_load.append(module_info.name)\n\n    # Sort modules but ensure 'experiments' is loaded last\n    modules_to_load.sort()\n    if \"experiments\" in modules_to_load:\n        modules_to_load.remove(\"experiments\")\n        modules_to_load.append(\"experiments\")\n\n    for module_name in modules_to_load:\n        full_name = f\"{package_name}.{module_name}\"\n        importlib.import_module(full_name)\n        loaded_modules.append(full_name)\n\n    return sorted(loaded_modules)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.load_configs--in-your-main-script-or-notebook","title":"In your main script or notebook","text":"<p>from deriva_ml.execution import load_configs</p> <p>load_configs()  # Loads from \"configs\" package</p>"},{"location":"code-docs/execution/#deriva_ml.execution.load_configs--or","title":"or","text":"<p>load_configs(\"my_project.configs\")  # Custom package</p>"},{"location":"code-docs/execution/#deriva_ml.execution.notebook_config","title":"notebook_config","text":"<pre><code>notebook_config(\n    name: str,\n    config_class: type[BaseConfig]\n    | None = None,\n    defaults: dict[str, str]\n    | None = None,\n    **field_defaults: Any,\n) -&gt; Any\n</code></pre> <p>Register a notebook configuration with simplified syntax.</p> <p>This is the recommended way to create notebook configurations. It handles all the hydra-zen boilerplate (builds, store, defaults) automatically.</p> <p>For simple notebooks that only use BaseConfig fields (deriva_ml, datasets, assets, etc.), just specify which defaults to use. For notebooks with custom parameters, provide a config_class that inherits from BaseConfig.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Configuration name. Used both as the hydra config name and to look up the config in run_notebook().</p> required <code>config_class</code> <code>type[BaseConfig] | None</code> <p>Optional dataclass inheriting from BaseConfig. If None, uses BaseConfig directly (suitable for notebooks that only need the standard fields).</p> <code>None</code> <code>defaults</code> <code>dict[str, str] | None</code> <p>Dict mapping config group names to config names. These override the base defaults. Common groups: - \"deriva_ml\": Connection config (e.g., \"default_deriva\", \"eye_ai\") - \"datasets\": Dataset config (e.g., \"cifar10_training\") - \"assets\": Asset config (e.g., \"model_weights\") - \"workflow\": Workflow config (e.g., \"default_workflow\")</p> <code>None</code> <code>**field_defaults</code> <code>Any</code> <p>Default values for fields in config_class.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The hydra-zen builds() class, in case you need to reference it directly.</p> <p>Examples:</p> <p>Simple notebook using only standard fields:</p> <pre><code># configs/roc_analysis.py\nfrom deriva_ml.execution import notebook_config\n\nnotebook_config(\n    \"roc_analysis\",\n    defaults={\"assets\": \"roc_comparison_probabilities\"},\n)\n</code></pre> <p>Notebook with custom parameters:</p> <pre><code># configs/training_analysis.py\nfrom dataclasses import dataclass\nfrom deriva_ml.execution import BaseConfig, notebook_config\n\n@dataclass\nclass TrainingAnalysisConfig(BaseConfig):\n    learning_rate: float = 0.001\n    batch_size: int = 32\n\nnotebook_config(\n    \"training_analysis\",\n    config_class=TrainingAnalysisConfig,\n    defaults={\"datasets\": \"cifar10_training\"},\n    learning_rate=0.01,  # Override default\n)\n</code></pre> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>def notebook_config(\n    name: str,\n    config_class: type[BaseConfig] | None = None,\n    defaults: dict[str, str] | None = None,\n    **field_defaults: Any,\n) -&gt; Any:\n    \"\"\"Register a notebook configuration with simplified syntax.\n\n    This is the recommended way to create notebook configurations. It handles\n    all the hydra-zen boilerplate (builds, store, defaults) automatically.\n\n    For simple notebooks that only use BaseConfig fields (deriva_ml, datasets,\n    assets, etc.), just specify which defaults to use. For notebooks with\n    custom parameters, provide a config_class that inherits from BaseConfig.\n\n    Args:\n        name: Configuration name. Used both as the hydra config name and\n            to look up the config in run_notebook().\n        config_class: Optional dataclass inheriting from BaseConfig. If None,\n            uses BaseConfig directly (suitable for notebooks that only need\n            the standard fields).\n        defaults: Dict mapping config group names to config names. These\n            override the base defaults. Common groups:\n            - \"deriva_ml\": Connection config (e.g., \"default_deriva\", \"eye_ai\")\n            - \"datasets\": Dataset config (e.g., \"cifar10_training\")\n            - \"assets\": Asset config (e.g., \"model_weights\")\n            - \"workflow\": Workflow config (e.g., \"default_workflow\")\n        **field_defaults: Default values for fields in config_class.\n\n    Returns:\n        The hydra-zen builds() class, in case you need to reference it directly.\n\n    Examples:\n        Simple notebook using only standard fields:\n\n            # configs/roc_analysis.py\n            from deriva_ml.execution import notebook_config\n\n            notebook_config(\n                \"roc_analysis\",\n                defaults={\"assets\": \"roc_comparison_probabilities\"},\n            )\n\n        Notebook with custom parameters:\n\n            # configs/training_analysis.py\n            from dataclasses import dataclass\n            from deriva_ml.execution import BaseConfig, notebook_config\n\n            @dataclass\n            class TrainingAnalysisConfig(BaseConfig):\n                learning_rate: float = 0.001\n                batch_size: int = 32\n\n            notebook_config(\n                \"training_analysis\",\n                config_class=TrainingAnalysisConfig,\n                defaults={\"datasets\": \"cifar10_training\"},\n                learning_rate=0.01,  # Override default\n            )\n    \"\"\"\n    # Use BaseConfig if no custom class provided\n    actual_class = config_class or BaseConfig\n\n    # Build the hydra defaults list\n    hydra_defaults = [\"_self_\"]\n\n    # Start with base defaults, then apply overrides\n    default_groups = {\n        \"deriva_ml\": \"default_deriva\",\n        \"datasets\": \"default_dataset\",\n        \"assets\": \"default_asset\",\n    }\n    if defaults:\n        default_groups.update(defaults)\n\n    for group, config_name in default_groups.items():\n        hydra_defaults.append({group: config_name})\n\n    # Create the hydra-zen builds() class\n    config_builds = builds(\n        actual_class,\n        populate_full_signature=True,\n        hydra_defaults=hydra_defaults,\n        **field_defaults,\n    )\n\n    # Register with hydra-zen store\n    store(config_builds, name=name)\n\n    # Also register in our internal registry for run_notebook()\n    _notebook_configs[name] = (config_builds, name)\n\n    return config_builds\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.reset_multirun_state","title":"reset_multirun_state","text":"<pre><code>reset_multirun_state() -&gt; None\n</code></pre> <p>Reset the global multirun state.</p> <p>This is primarily useful for testing to ensure clean state between tests.</p> Source code in <code>src/deriva_ml/execution/runner.py</code> <pre><code>def reset_multirun_state() -&gt; None:\n    \"\"\"Reset the global multirun state.\n\n    This is primarily useful for testing to ensure clean state between tests.\n    \"\"\"\n    global _multirun_state\n    _multirun_state.parent_execution_rid = None\n    _multirun_state.parent_execution = None\n    _multirun_state.ml_instance = None\n    _multirun_state.job_sequence = 0\n    _multirun_state.sweep_dir = None\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.run_model","title":"run_model","text":"<pre><code>run_model(\n    deriva_ml: \"DerivaMLConfig\",\n    datasets: list[\"DatasetSpec\"],\n    assets: list[\"RID\"],\n    description: str,\n    workflow: \"Workflow\",\n    model_config: Any,\n    dry_run: bool = False,\n    ml_class: type[\"DerivaML\"]\n    | None = None,\n    upload_timeout: int = 600,\n    upload_chunk_size: int = 50000000,\n) -&gt; None\n</code></pre> <p>Execute a machine learning model within a DerivaML execution context.</p> <p>This function serves as the main entry point called by hydra-zen after configuration resolution. It orchestrates the complete execution lifecycle: connecting to Deriva, creating an execution record, running the model, and uploading results.</p> <p>In multirun mode, this function also: - Creates a parent execution on the first job to group all sweep jobs - Links each child execution to the parent with sequence ordering</p>"},{"location":"code-docs/execution/#deriva_ml.execution.run_model--parameters","title":"Parameters","text":"<p>deriva_ml : DerivaMLConfig     Configuration for the DerivaML connection. Contains server URL,     catalog ID, credentials, and other connection parameters.</p> list[DatasetSpec] <p>Specifications for datasets to use in this execution. Each DatasetSpec identifies a dataset in the Deriva catalog to be made available to the model.</p> list[RID] <p>Resource IDs (RIDs) of assets to include in the execution. Typically used for model weight files, pretrained checkpoints, or other artifacts needed by the model.</p> str <p>Human-readable description of this execution run. Stored in the Deriva catalog for provenance tracking. In multirun mode, this is also used for the parent execution if running via multirun_config.</p> Workflow <p>The workflow definition to associate with this execution. Defines the computational pipeline and its metadata.</p> Any <p>A hydra-zen callable that wraps the actual model code. When called with <code>ml_instance</code> and <code>execution</code> arguments, it runs the model training or inference logic.</p> bool, optional <p>If True, create the execution record but skip actual model execution. Useful for testing configuration without running expensive computations. Default is False.</p> type[DerivaML], optional <p>The DerivaML class (or subclass) to instantiate. If None, uses the base DerivaML class. Use this to instantiate domain-specific classes like EyeAI or GUDMAP.</p> int, optional <p>Timeout in seconds for each chunk upload. Default is 600 (10 min). This value is used as both the connect and read timeout. Since urllib3 uses the connect timeout for socket writes, it must be large enough to send a full chunk over the network.</p> int, optional <p>Chunk size in bytes for hatrac uploads. Default is 50000000 (50 MB). Larger chunks reduce overhead but require more memory.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.run_model--returns","title":"Returns","text":"<p>None     Results are uploaded to the Deriva catalog as execution outputs.</p>"},{"location":"code-docs/execution/#deriva_ml.execution.run_model--examples","title":"Examples","text":"<p>This function is typically not called directly, but through hydra:</p> <pre><code># From command line:\npython deriva_run.py +experiment=cifar10_cnn dry_run=True\n\n# Multirun (creates parent + child executions):\npython deriva_run.py --multirun +experiment=cifar10_quick,cifar10_extended\n\n# With a custom DerivaML subclass (in your script):\nfrom functools import partial\nrun_model_eyeai = partial(run_model, ml_class=EyeAI)\n</code></pre> Source code in <code>src/deriva_ml/execution/runner.py</code> <pre><code>def run_model(\n    deriva_ml: \"DerivaMLConfig\",\n    datasets: list[\"DatasetSpec\"],\n    assets: list[\"RID\"],\n    description: str,\n    workflow: \"Workflow\",\n    model_config: Any,\n    dry_run: bool = False,\n    ml_class: type[\"DerivaML\"] | None = None,\n    upload_timeout: int = 600,\n    upload_chunk_size: int = 50_000_000,\n) -&gt; None:\n    \"\"\"\n    Execute a machine learning model within a DerivaML execution context.\n\n    This function serves as the main entry point called by hydra-zen after\n    configuration resolution. It orchestrates the complete execution lifecycle:\n    connecting to Deriva, creating an execution record, running the model,\n    and uploading results.\n\n    In multirun mode, this function also:\n    - Creates a parent execution on the first job to group all sweep jobs\n    - Links each child execution to the parent with sequence ordering\n\n    Parameters\n    ----------\n    deriva_ml : DerivaMLConfig\n        Configuration for the DerivaML connection. Contains server URL,\n        catalog ID, credentials, and other connection parameters.\n\n    datasets : list[DatasetSpec]\n        Specifications for datasets to use in this execution. Each DatasetSpec\n        identifies a dataset in the Deriva catalog to be made available to\n        the model.\n\n    assets : list[RID]\n        Resource IDs (RIDs) of assets to include in the execution. Typically\n        used for model weight files, pretrained checkpoints, or other\n        artifacts needed by the model.\n\n    description : str\n        Human-readable description of this execution run. Stored in the\n        Deriva catalog for provenance tracking. In multirun mode, this is\n        also used for the parent execution if running via multirun_config.\n\n    workflow : Workflow\n        The workflow definition to associate with this execution. Defines\n        the computational pipeline and its metadata.\n\n    model_config : Any\n        A hydra-zen callable that wraps the actual model code. When called\n        with `ml_instance` and `execution` arguments, it runs the model\n        training or inference logic.\n\n    dry_run : bool, optional\n        If True, create the execution record but skip actual model execution.\n        Useful for testing configuration without running expensive computations.\n        Default is False.\n\n    ml_class : type[DerivaML], optional\n        The DerivaML class (or subclass) to instantiate. If None, uses the\n        base DerivaML class. Use this to instantiate domain-specific classes\n        like EyeAI or GUDMAP.\n\n    upload_timeout : int, optional\n        Timeout in seconds for each chunk upload. Default is 600 (10 min).\n        This value is used as both the connect and read timeout. Since urllib3\n        uses the connect timeout for socket writes, it must be large enough\n        to send a full chunk over the network.\n\n    upload_chunk_size : int, optional\n        Chunk size in bytes for hatrac uploads. Default is 50000000 (50 MB).\n        Larger chunks reduce overhead but require more memory.\n\n    Returns\n    -------\n    None\n        Results are uploaded to the Deriva catalog as execution outputs.\n\n    Examples\n    --------\n    This function is typically not called directly, but through hydra:\n\n        # From command line:\n        python deriva_run.py +experiment=cifar10_cnn dry_run=True\n\n        # Multirun (creates parent + child executions):\n        python deriva_run.py --multirun +experiment=cifar10_quick,cifar10_extended\n\n        # With a custom DerivaML subclass (in your script):\n        from functools import partial\n        run_model_eyeai = partial(run_model, ml_class=EyeAI)\n    \"\"\"\n    global _multirun_state\n\n    # Import here to avoid circular imports\n    from deriva_ml import DerivaML\n    from deriva_ml.execution import ExecutionConfiguration\n\n    # ---------------------------------------------------------------------------\n    # Clear hydra's logging configuration\n    # ---------------------------------------------------------------------------\n    # Hydra sets up its own logging handlers which can interfere with DerivaML's\n    # logging. Remove them to ensure consistent log output.\n    root = logging.getLogger()\n    for handler in root.handlers[:]:\n        root.removeHandler(handler)\n\n    # ---------------------------------------------------------------------------\n    # Connect to the Deriva catalog\n    # ---------------------------------------------------------------------------\n    # Use the provided ml_class or default to DerivaML\n    if ml_class is None:\n        ml_class = DerivaML\n\n    ml_instance = ml_class.instantiate(deriva_ml)\n\n    # ---------------------------------------------------------------------------\n    # Handle multirun mode - create parent execution on first job\n    # ---------------------------------------------------------------------------\n    is_multirun = _is_multirun()\n    if is_multirun and _multirun_state.parent_execution is None:\n        _create_parent_execution(ml_instance, workflow, description, dry_run)\n\n    # ---------------------------------------------------------------------------\n    # Capture Hydra runtime choices for provenance\n    # ---------------------------------------------------------------------------\n    # The choices dict maps config group names to the selected config names\n    # e.g., {\"model_config\": \"cifar10_quick\", \"datasets\": \"cifar10_training\"}\n    # Filter out None values (some Hydra internal groups have None choices)\n    config_choices: dict[str, str] = {}\n    try:\n        hydra_cfg = HydraConfig.get()\n        config_choices = {k: v for k, v in hydra_cfg.runtime.choices.items() if v is not None}\n    except Exception:\n        pass  # HydraConfig not available outside Hydra context\n\n    # ---------------------------------------------------------------------------\n    # Create the execution context\n    # ---------------------------------------------------------------------------\n    # The ExecutionConfiguration bundles together all the inputs for this run:\n    # which datasets to use, which assets (model weights, etc.), and metadata.\n\n    # In multirun mode, enhance the description with job info\n    job_description = description\n    if is_multirun:\n        job_num = _get_job_num()\n        job_description = f\"[Job {job_num}] {description}\"\n\n    execution_config = ExecutionConfiguration(\n        datasets=datasets,\n        assets=assets,\n        description=job_description,\n        config_choices=config_choices,\n    )\n\n    # Create the execution record in the catalog. This generates a unique\n    # execution ID and sets up the working directories for this run.\n    execution = ml_instance.create_execution(\n        execution_config,\n        workflow=workflow,\n        dry_run=dry_run\n    )\n\n    # ---------------------------------------------------------------------------\n    # Link to parent execution in multirun mode\n    # ---------------------------------------------------------------------------\n    if is_multirun and _multirun_state.parent_execution is not None:\n        if not dry_run:\n            try:\n                # Get the current job sequence from the global state\n                job_sequence = _multirun_state.job_sequence\n                _multirun_state.parent_execution.add_nested_execution(\n                    execution,\n                    sequence=job_sequence\n                )\n                logging.info(\n                    f\"Linked execution {execution.execution_rid} to parent \"\n                    f\"{_multirun_state.parent_execution_rid} (sequence={job_sequence})\"\n                )\n                # Increment the sequence for the next job\n                _multirun_state.job_sequence += 1\n            except Exception as e:\n                logging.warning(f\"Failed to link execution to parent: {e}\")\n\n    # ---------------------------------------------------------------------------\n    # Run the model within the execution context\n    # ---------------------------------------------------------------------------\n    # The context manager handles setup (downloading datasets, creating output\n    # directories) and teardown (recording completion status, timing).\n    with execution.execute() as exec_context:\n        if dry_run:\n            # In dry run mode, skip model execution but still test the setup\n            logging.info(\"Dry run mode: skipping model execution\")\n        else:\n            # Invoke the model configuration callable. The model_config is a\n            # hydra-zen wrapped function that has been partially configured with\n            # all model-specific parameters (e.g., learning rate, batch size).\n            # We provide the runtime context here.\n            model_config(ml_instance=ml_instance, execution=exec_context)\n\n    # ---------------------------------------------------------------------------\n    # Upload results to the catalog\n    # ---------------------------------------------------------------------------\n    # After the model completes, upload any output files (metrics, predictions,\n    # model checkpoints) to the Deriva catalog for permanent storage.\n    if not dry_run:\n        uploaded_assets = execution.upload_execution_outputs(\n            timeout=(upload_timeout, upload_timeout),\n            chunk_size=upload_chunk_size,\n        )\n\n        # Print summary of uploaded assets\n        total_files = sum(len(files) for files in uploaded_assets.values())\n        if total_files &gt; 0:\n            print(f\"\\nUploaded {total_files} asset(s) to catalog:\")\n            for asset_type, files in uploaded_assets.items():\n                for f in files:\n                    print(f\"  - {asset_type}: {f}\")\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.run_notebook","title":"run_notebook","text":"<pre><code>run_notebook(\n    config_name: str,\n    overrides: list[str] | None = None,\n    workflow_name: str | None = None,\n    workflow_type: str = \"Analysis Notebook\",\n    ml_class: type[DerivaML]\n    | None = None,\n    config_package: str = \"configs\",\n) -&gt; tuple[\n    DerivaML, Execution, BaseConfig\n]\n</code></pre> <p>Initialize a notebook with DerivaML execution context.</p> <p>This is the main entry point for notebooks. It handles all the setup: 1. Loads all config modules from the config package 2. Resolves the hydra-zen configuration 3. Creates the DerivaML connection 4. Creates a workflow and execution context 5. Downloads any specified datasets and assets</p> <p>Parameters:</p> Name Type Description Default <code>config_name</code> <code>str</code> <p>Name of the notebook configuration (registered via notebook_config() or store()).</p> required <code>overrides</code> <code>list[str] | None</code> <p>Optional list of Hydra override strings (e.g., [\"assets=different_assets\"]).</p> <code>None</code> <code>workflow_name</code> <code>str | None</code> <p>Name for the workflow. Defaults to config_name.</p> <code>None</code> <code>workflow_type</code> <code>str</code> <p>Type of workflow (default: \"Analysis Notebook\").</p> <code>'Analysis Notebook'</code> <code>ml_class</code> <code>type[DerivaML] | None</code> <p>Optional DerivaML subclass to use. If None, uses DerivaML.</p> <code>None</code> <code>config_package</code> <code>str</code> <p>Package containing config modules (default: \"configs\").</p> <code>'configs'</code> <p>Returns:</p> Type Description <code>DerivaML</code> <p>Tuple of (ml_instance, execution, config):</p> <code>Execution</code> <ul> <li>ml_instance: Connected DerivaML (or subclass) instance</li> </ul> <code>BaseConfig</code> <ul> <li>execution: Execution context with downloaded inputs</li> </ul> <code>tuple[DerivaML, Execution, BaseConfig]</code> <ul> <li>config: Resolved configuration object</li> </ul> Example Example with overrides <p>ml, execution, config = run_notebook(     \"roc_analysis\",     overrides=[\"assets=roc_quick_probabilities\"], )</p> Example with custom ML class <p>from eye_ai import EyeAI</p> <p>ml, execution, config = run_notebook(     \"eye_analysis\",     ml_class=EyeAI, )</p> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>def run_notebook(\n    config_name: str,\n    overrides: list[str] | None = None,\n    workflow_name: str | None = None,\n    workflow_type: str = \"Analysis Notebook\",\n    ml_class: type[\"DerivaML\"] | None = None,\n    config_package: str = \"configs\",\n) -&gt; tuple[\"DerivaML\", \"Execution\", BaseConfig]:\n    \"\"\"Initialize a notebook with DerivaML execution context.\n\n    This is the main entry point for notebooks. It handles all the setup:\n    1. Loads all config modules from the config package\n    2. Resolves the hydra-zen configuration\n    3. Creates the DerivaML connection\n    4. Creates a workflow and execution context\n    5. Downloads any specified datasets and assets\n\n    Args:\n        config_name: Name of the notebook configuration (registered via\n            notebook_config() or store()).\n        overrides: Optional list of Hydra override strings\n            (e.g., [\"assets=different_assets\"]).\n        workflow_name: Name for the workflow. Defaults to config_name.\n        workflow_type: Type of workflow (default: \"Analysis Notebook\").\n        ml_class: Optional DerivaML subclass to use. If None, uses DerivaML.\n        config_package: Package containing config modules (default: \"configs\").\n\n    Returns:\n        Tuple of (ml_instance, execution, config):\n        - ml_instance: Connected DerivaML (or subclass) instance\n        - execution: Execution context with downloaded inputs\n        - config: Resolved configuration object\n\n    Example:\n        # Simple usage\n        from deriva_ml.execution import run_notebook\n\n        ml, execution, config = run_notebook(\"roc_analysis\")\n\n        # Access config values\n        print(config.assets)\n        print(config.deriva_ml.hostname)\n\n        # Use ml and execution\n        for asset_table, paths in execution.asset_paths.items():\n            for path in paths:\n                print(f\"Downloaded: {path.file_name}\")\n\n        # At the end of notebook\n        execution.upload_execution_outputs()\n\n    Example with overrides:\n        ml, execution, config = run_notebook(\n            \"roc_analysis\",\n            overrides=[\"assets=roc_quick_probabilities\"],\n        )\n\n    Example with custom ML class:\n        from eye_ai import EyeAI\n\n        ml, execution, config = run_notebook(\n            \"eye_analysis\",\n            ml_class=EyeAI,\n        )\n    \"\"\"\n    # Import here to avoid circular imports\n    from deriva_ml import DerivaML\n    from deriva_ml.execution import Execution, ExecutionConfiguration\n\n    # Load all config modules\n    load_configs(config_package)\n\n    # Get the config builds class from our registry or try the store\n    if config_name in _notebook_configs:\n        config_builds, _ = _notebook_configs[config_name]\n    else:\n        # Fall back to looking up in hydra store by building a simple config\n        # This handles configs registered the old way\n        config_builds = DerivaBaseConfig\n\n    # Resolve the configuration\n    config = get_notebook_configuration(\n        config_builds,\n        config_name=config_name,\n        overrides=overrides,\n    )\n\n    # Create DerivaML instance, passing the hydra output dir captured during\n    # config resolution so that hydra YAML configs get uploaded with the execution.\n    actual_ml_class = ml_class or DerivaML\n    hydra_output_dir = Path(_captured_hydra_output_dir) if _captured_hydra_output_dir else None\n    ml = actual_ml_class(\n        hostname=config.deriva_ml.hostname,\n        catalog_id=config.deriva_ml.catalog_id,\n        hydra_runtime_output_dir=hydra_output_dir,\n    )\n\n    # Create workflow\n    actual_workflow_name = workflow_name or config_name.replace(\"_\", \" \").title()\n    workflow = ml.create_workflow(\n        name=actual_workflow_name,\n        workflow_type=workflow_type,\n        description=config.description or f\"Running {config_name}\",\n    )\n\n    # Create execution configuration\n    exec_config = ExecutionConfiguration(\n        workflow=workflow,\n        datasets=config.datasets if config.datasets else [],\n        assets=config.assets if config.assets else [],\n        description=config.description or f\"Execution of {config_name}\",\n    )\n\n    # Create execution context (downloads inputs)\n    execution = Execution(configuration=exec_config, ml_object=ml, dry_run=config.dry_run)\n\n    return ml, execution, config\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.run_notebook--simple-usage","title":"Simple usage","text":"<p>from deriva_ml.execution import run_notebook</p> <p>ml, execution, config = run_notebook(\"roc_analysis\")</p>"},{"location":"code-docs/execution/#deriva_ml.execution.run_notebook--access-config-values","title":"Access config values","text":"<p>print(config.assets) print(config.deriva_ml.hostname)</p>"},{"location":"code-docs/execution/#deriva_ml.execution.run_notebook--use-ml-and-execution","title":"Use ml and execution","text":"<p>for asset_table, paths in execution.asset_paths.items():     for path in paths:         print(f\"Downloaded: {path.file_name}\")</p>"},{"location":"code-docs/execution/#deriva_ml.execution.run_notebook--at-the-end-of-notebook","title":"At the end of notebook","text":"<p>execution.upload_execution_outputs()</p>"},{"location":"code-docs/execution/#deriva_ml.execution.with_description","title":"with_description","text":"<pre><code>with_description(\n    items: list, description: str\n) -&gt; Any\n</code></pre> <p>Create a hydra-zen config for a list with an attached description.</p> <p>Use this to add descriptions to configuration values like asset RIDs or dataset specifications. The result is a hydra-zen config that, when instantiated, produces a DescribedList.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list</code> <p>List items (e.g., asset RIDs, dataset specs).</p> required <code>description</code> <code>str</code> <p>Human-readable description of this configuration.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>A hydra-zen config that instantiates to a DescribedList.</p> Example <p>from hydra_zen import store from deriva_ml.execution import with_description</p> Note <p>For model configs created with <code>builds()</code>, use the <code>zen_meta</code> parameter instead:</p> <p>model_store( ...     Cifar10CNNConfig, ...     name=\"cifar10_quick\", ...     epochs=3, ...     zen_meta={\"description\": \"Quick training - 3 epochs\"}, ... )</p> Source code in <code>src/deriva_ml/execution/base_config.py</code> <pre><code>def with_description(items: list, description: str) -&gt; Any:\n    \"\"\"Create a hydra-zen config for a list with an attached description.\n\n    Use this to add descriptions to configuration values like asset RIDs\n    or dataset specifications. The result is a hydra-zen config that, when\n    instantiated, produces a DescribedList.\n\n    Args:\n        items: List items (e.g., asset RIDs, dataset specs).\n        description: Human-readable description of this configuration.\n\n    Returns:\n        A hydra-zen config that instantiates to a DescribedList.\n\n    Example:\n        &gt;&gt;&gt; from hydra_zen import store\n        &gt;&gt;&gt; from deriva_ml.execution import with_description\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Assets with description\n        &gt;&gt;&gt; asset_store = store(group=\"assets\")\n        &gt;&gt;&gt; asset_store(\n        ...     with_description(\n        ...         [\"3WMG\", \"3XPA\"],\n        ...         \"Model weights from quick and extended training runs\",\n        ...     ),\n        ...     name=\"comparison_weights\",\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Datasets with description\n        &gt;&gt;&gt; from deriva_ml.dataset import DatasetSpecConfig\n        &gt;&gt;&gt; datasets_store = store(group=\"datasets\")\n        &gt;&gt;&gt; datasets_store(\n        ...     with_description(\n        ...         [DatasetSpecConfig(rid=\"28CT\", version=\"0.21.0\")],\n        ...         \"Complete CIFAR-10 dataset with 10,000 images\",\n        ...     ),\n        ...     name=\"cifar10_complete\",\n        ... )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # After instantiation:\n        &gt;&gt;&gt; # config.assets is a DescribedList\n        &gt;&gt;&gt; # config.assets[0]  # \"3WMG\"\n        &gt;&gt;&gt; # config.assets.description  # \"Model weights from...\"\n\n    Note:\n        For model configs created with `builds()`, use the `zen_meta` parameter\n        instead:\n\n        &gt;&gt;&gt; model_store(\n        ...     Cifar10CNNConfig,\n        ...     name=\"cifar10_quick\",\n        ...     epochs=3,\n        ...     zen_meta={\"description\": \"Quick training - 3 epochs\"},\n        ... )\n    \"\"\"\n    return _DescribedListConfig(items=items, description=description)\n</code></pre>"},{"location":"code-docs/execution/#deriva_ml.execution.with_description--assets-with-description","title":"Assets with description","text":"<p>asset_store = store(group=\"assets\") asset_store( ...     with_description( ...         [\"3WMG\", \"3XPA\"], ...         \"Model weights from quick and extended training runs\", ...     ), ...     name=\"comparison_weights\", ... )</p>"},{"location":"code-docs/execution/#deriva_ml.execution.with_description--datasets-with-description","title":"Datasets with description","text":"<p>from deriva_ml.dataset import DatasetSpecConfig datasets_store = store(group=\"datasets\") datasets_store( ...     with_description( ...         [DatasetSpecConfig(rid=\"28CT\", version=\"0.21.0\")], ...         \"Complete CIFAR-10 dataset with 10,000 images\", ...     ), ...     name=\"cifar10_complete\", ... )</p>"},{"location":"code-docs/execution/#deriva_ml.execution.with_description--after-instantiation","title":"After instantiation:","text":""},{"location":"code-docs/execution/#deriva_ml.execution.with_description--configassets-is-a-describedlist","title":"config.assets is a DescribedList","text":""},{"location":"code-docs/execution/#deriva_ml.execution.with_description--configassets0-3wmg","title":"config.assets[0]  # \"3WMG\"","text":""},{"location":"code-docs/execution/#deriva_ml.execution.with_description--configassetsdescription-model-weights-from","title":"config.assets.description  # \"Model weights from...\"","text":""},{"location":"code-docs/execution_configuration/","title":"ExecutionConfiguration class","text":"<p>Configuration management for DerivaML executions.</p> <p>This module provides functionality for configuring and managing execution parameters in DerivaML. It includes:</p> <ul> <li>ExecutionConfiguration class: Core class for execution settings</li> <li>Parameter validation: Handles JSON and file-based parameters</li> <li>Dataset specifications: Manages dataset versions and materialization</li> <li>Asset management: Tracks required input files with optional caching</li> </ul> <p>The module supports both direct parameter specification and JSON-based configuration files.</p> Typical usage example <p>workflow = ml.lookup_workflow_by_url(\"https://github.com/my-org/my-repo\") config = ExecutionConfiguration( ...     workflow=workflow, ...     datasets=[DatasetSpec(rid=\"1-abc123\", version=\"1.0.0\")], ...     description=\"Process sample data\" ... ) execution = ml.create_execution(config)</p>"},{"location":"code-docs/execution_configuration/#deriva_ml.execution.execution_configuration.AssetRID","title":"AssetRID  <code>dataclass</code>","text":"<p>               Bases: <code>str</code></p> <p>A string subclass representing an asset Resource ID with optional description.</p> <p>.. deprecated::     Use :class:<code>AssetSpec</code> instead for new code. <code>AssetRID</code> is retained     for backward compatibility.</p> <p>Attributes:</p> Name Type Description <code>rid</code> <code>str</code> <p>The Resource ID string identifying the asset in Deriva.</p> <code>description</code> <code>str</code> <p>Optional human-readable description of the asset.</p> Example <p>asset = AssetRID(\"3RA\", \"Pretrained model weights\") print(asset)  # \"3RA\" print(asset.description)  # \"Pretrained model weights\"</p> Source code in <code>src/deriva_ml/execution/execution_configuration.py</code> <pre><code>@dataclass\nclass AssetRID(str):\n    \"\"\"A string subclass representing an asset Resource ID with optional description.\n\n    .. deprecated::\n        Use :class:`AssetSpec` instead for new code. ``AssetRID`` is retained\n        for backward compatibility.\n\n    Attributes:\n        rid: The Resource ID string identifying the asset in Deriva.\n        description: Optional human-readable description of the asset.\n\n    Example:\n        &gt;&gt;&gt; asset = AssetRID(\"3RA\", \"Pretrained model weights\")\n        &gt;&gt;&gt; print(asset)  # \"3RA\"\n        &gt;&gt;&gt; print(asset.description)  # \"Pretrained model weights\"\n    \"\"\"\n\n    rid: str\n    description: str = \"\"\n\n    def __new__(cls, rid: str, description: str = \"\"):\n        obj = super().__new__(cls, rid)\n        obj.description = description\n        return obj\n</code></pre>"},{"location":"code-docs/execution_configuration/#deriva_ml.execution.execution_configuration.ExecutionConfiguration","title":"ExecutionConfiguration","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a DerivaML execution.</p> <p>Defines the complete configuration for a computational or manual process in DerivaML, including required datasets, input assets, workflow definition, and parameters.</p> <p>Attributes:</p> Name Type Description <code>datasets</code> <code>list[DatasetSpec]</code> <p>Dataset specifications, each containing: - rid: Dataset Resource Identifier - version: Version to use - materialize: Whether to extract dataset contents</p> <code>assets</code> <code>list[AssetSpec]</code> <p>Asset specifications. Each element can be: - A plain RID string (no caching) - An <code>AssetSpec(rid=..., cache=True)</code> for checksum-based caching</p> <code>workflow</code> <code>Workflow | None</code> <p>Workflow object defining the computational process. Use <code>ml.lookup_workflow(rid)</code> or <code>ml.lookup_workflow_by_url(url)</code> to get a Workflow object from a RID or URL. Defaults to <code>None</code>, which means the workflow must be provided via the <code>workflow</code> parameter of <code>ml.create_execution()</code> instead. If no workflow is specified in either place, a <code>DerivaMLException</code> is raised at execution creation time.</p> <code>description</code> <code>str</code> <p>Description of execution purpose (supports Markdown).</p> <code>argv</code> <code>list[str]</code> <p>Command line arguments used to start execution.</p> <code>config_choices</code> <code>dict[str, str]</code> <p>Hydra config group choices that were selected. Maps group names to selected config names (e.g., {\"model_config\": \"cifar10_quick\"}). Automatically populated by run_model() and get_notebook_configuration().</p> Example Source code in <code>src/deriva_ml/execution/execution_configuration.py</code> <pre><code>class ExecutionConfiguration(BaseModel):\n    \"\"\"Configuration for a DerivaML execution.\n\n    Defines the complete configuration for a computational or manual process in DerivaML,\n    including required datasets, input assets, workflow definition, and parameters.\n\n    Attributes:\n        datasets (list[DatasetSpec]): Dataset specifications, each containing:\n            - rid: Dataset Resource Identifier\n            - version: Version to use\n            - materialize: Whether to extract dataset contents\n        assets (list[AssetSpec]): Asset specifications. Each element can be:\n            - A plain RID string (no caching)\n            - An ``AssetSpec(rid=..., cache=True)`` for checksum-based caching\n        workflow (Workflow | None): Workflow object defining the computational process.\n            Use ``ml.lookup_workflow(rid)`` or ``ml.lookup_workflow_by_url(url)`` to get\n            a Workflow object from a RID or URL. Defaults to ``None``, which means the\n            workflow must be provided via the ``workflow`` parameter of\n            ``ml.create_execution()`` instead. If no workflow is specified in either\n            place, a ``DerivaMLException`` is raised at execution creation time.\n        description (str): Description of execution purpose (supports Markdown).\n        argv (list[str]): Command line arguments used to start execution.\n        config_choices (dict[str, str]): Hydra config group choices that were selected.\n            Maps group names to selected config names (e.g., {\"model_config\": \"cifar10_quick\"}).\n            Automatically populated by run_model() and get_notebook_configuration().\n\n    Example:\n        &gt;&gt;&gt; # Plain RIDs (backward compatible)\n        &gt;&gt;&gt; config = ExecutionConfiguration(assets=[\"6-EPNR\", \"6-EP56\"])\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Mixed: cached model weights + uncached embeddings\n        &gt;&gt;&gt; config = ExecutionConfiguration(\n        ...     assets=[\n        ...         AssetSpec(rid=\"6-EPNR\", cache=True),\n        ...         \"6-EP56\",\n        ...     ]\n        ... )\n    \"\"\"\n\n    datasets: list[DatasetSpec] = []\n    assets: list[AssetSpec] = []\n    workflow: Workflow | None = None\n    description: str = \"\"\n    argv: list[str] = Field(default_factory=lambda: sys.argv)\n    config_choices: dict[str, str] = Field(default_factory=dict)\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @field_validator(\"assets\", mode=\"before\")\n    @classmethod\n    def validate_assets(cls, value: Any) -&gt; Any:\n        \"\"\"Normalize asset entries to AssetSpec objects.\n\n        Accepts plain RID strings, AssetRID objects, DictConfig from Hydra,\n        AssetSpec objects, or dicts with 'rid' and optional 'cache' keys.\n        \"\"\"\n        result = []\n        for v in value:\n            if isinstance(v, AssetSpec):\n                result.append(v)\n            elif isinstance(v, dict):\n                # Dict with rid/cache keys (e.g., from JSON config)\n                result.append(AssetSpec(**v))\n            elif isinstance(v, DictConfig):\n                # OmegaConf DictConfig from Hydra \u2014 may have rid+cache or just rid\n                d = dict(v)\n                if \"rid\" in d:\n                    result.append(AssetSpec(**d))\n                else:\n                    # Legacy DictConfig with just .rid attribute (AssetRID-style)\n                    result.append(AssetSpec(rid=v.rid, cache=getattr(v, \"cache\", False)))\n            elif isinstance(v, AssetRID):\n                result.append(AssetSpec(rid=v.rid))\n            elif isinstance(v, str):\n                result.append(AssetSpec(rid=v))\n            else:\n                # Unknown type \u2014 try string coercion\n                result.append(AssetSpec(rid=str(v)))\n        return result\n\n    @staticmethod\n    def load_configuration(path: Path) -&gt; ExecutionConfiguration:\n        \"\"\"Creates an ExecutionConfiguration from a JSON file.\n\n        Loads and parses a JSON configuration file into an ExecutionConfiguration\n        instance. The file should contain a valid configuration specification.\n\n        Args:\n            path: Path to JSON configuration file.\n\n        Returns:\n            ExecutionConfiguration: Loaded configuration instance.\n\n        Raises:\n            ValueError: If JSON file is invalid or missing required fields.\n            FileNotFoundError: If configuration file doesn't exist.\n\n        Example:\n            &gt;&gt;&gt; config = ExecutionConfiguration.load_configuration(Path(\"config.json\"))\n            &gt;&gt;&gt; print(f\"Workflow: {config.workflow}\")\n            &gt;&gt;&gt; print(f\"Datasets: {len(config.datasets)}\")\n        \"\"\"\n        with Path(path).open() as fd:\n            config = json.load(fd)\n        return ExecutionConfiguration.model_validate(config)\n</code></pre>"},{"location":"code-docs/execution_configuration/#deriva_ml.execution.execution_configuration.ExecutionConfiguration--plain-rids-backward-compatible","title":"Plain RIDs (backward compatible)","text":"<p>config = ExecutionConfiguration(assets=[\"6-EPNR\", \"6-EP56\"])</p>"},{"location":"code-docs/execution_configuration/#deriva_ml.execution.execution_configuration.ExecutionConfiguration--mixed-cached-model-weights-uncached-embeddings","title":"Mixed: cached model weights + uncached embeddings","text":"<p>config = ExecutionConfiguration( ...     assets=[ ...         AssetSpec(rid=\"6-EPNR\", cache=True), ...         \"6-EP56\", ...     ] ... )</p>"},{"location":"code-docs/execution_configuration/#deriva_ml.execution.execution_configuration.ExecutionConfiguration.load_configuration","title":"load_configuration  <code>staticmethod</code>","text":"<pre><code>load_configuration(\n    path: Path,\n) -&gt; ExecutionConfiguration\n</code></pre> <p>Creates an ExecutionConfiguration from a JSON file.</p> <p>Loads and parses a JSON configuration file into an ExecutionConfiguration instance. The file should contain a valid configuration specification.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to JSON configuration file.</p> required <p>Returns:</p> Name Type Description <code>ExecutionConfiguration</code> <code>ExecutionConfiguration</code> <p>Loaded configuration instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If JSON file is invalid or missing required fields.</p> <code>FileNotFoundError</code> <p>If configuration file doesn't exist.</p> Example <p>config = ExecutionConfiguration.load_configuration(Path(\"config.json\")) print(f\"Workflow: {config.workflow}\") print(f\"Datasets: {len(config.datasets)}\")</p> Source code in <code>src/deriva_ml/execution/execution_configuration.py</code> <pre><code>@staticmethod\ndef load_configuration(path: Path) -&gt; ExecutionConfiguration:\n    \"\"\"Creates an ExecutionConfiguration from a JSON file.\n\n    Loads and parses a JSON configuration file into an ExecutionConfiguration\n    instance. The file should contain a valid configuration specification.\n\n    Args:\n        path: Path to JSON configuration file.\n\n    Returns:\n        ExecutionConfiguration: Loaded configuration instance.\n\n    Raises:\n        ValueError: If JSON file is invalid or missing required fields.\n        FileNotFoundError: If configuration file doesn't exist.\n\n    Example:\n        &gt;&gt;&gt; config = ExecutionConfiguration.load_configuration(Path(\"config.json\"))\n        &gt;&gt;&gt; print(f\"Workflow: {config.workflow}\")\n        &gt;&gt;&gt; print(f\"Datasets: {len(config.datasets)}\")\n    \"\"\"\n    with Path(path).open() as fd:\n        config = json.load(fd)\n    return ExecutionConfiguration.model_validate(config)\n</code></pre>"},{"location":"code-docs/execution_configuration/#deriva_ml.execution.execution_configuration.ExecutionConfiguration.validate_assets","title":"validate_assets  <code>classmethod</code>","text":"<pre><code>validate_assets(value: Any) -&gt; Any\n</code></pre> <p>Normalize asset entries to AssetSpec objects.</p> <p>Accepts plain RID strings, AssetRID objects, DictConfig from Hydra, AssetSpec objects, or dicts with 'rid' and optional 'cache' keys.</p> Source code in <code>src/deriva_ml/execution/execution_configuration.py</code> <pre><code>@field_validator(\"assets\", mode=\"before\")\n@classmethod\ndef validate_assets(cls, value: Any) -&gt; Any:\n    \"\"\"Normalize asset entries to AssetSpec objects.\n\n    Accepts plain RID strings, AssetRID objects, DictConfig from Hydra,\n    AssetSpec objects, or dicts with 'rid' and optional 'cache' keys.\n    \"\"\"\n    result = []\n    for v in value:\n        if isinstance(v, AssetSpec):\n            result.append(v)\n        elif isinstance(v, dict):\n            # Dict with rid/cache keys (e.g., from JSON config)\n            result.append(AssetSpec(**v))\n        elif isinstance(v, DictConfig):\n            # OmegaConf DictConfig from Hydra \u2014 may have rid+cache or just rid\n            d = dict(v)\n            if \"rid\" in d:\n                result.append(AssetSpec(**d))\n            else:\n                # Legacy DictConfig with just .rid attribute (AssetRID-style)\n                result.append(AssetSpec(rid=v.rid, cache=getattr(v, \"cache\", False)))\n        elif isinstance(v, AssetRID):\n            result.append(AssetSpec(rid=v.rid))\n        elif isinstance(v, str):\n            result.append(AssetSpec(rid=v))\n        else:\n            # Unknown type \u2014 try string coercion\n            result.append(AssetSpec(rid=str(v)))\n    return result\n</code></pre>"},{"location":"code-docs/feature/","title":"Feature Classes","text":"<p>Feature management for ML experiments. Features represent measurable properties or characteristics that can be attached to domain entities and tracked across executions.</p> <p>Feature implementation for deriva-ml.</p> <p>This module provides classes for defining and managing features in deriva-ml. Features represent measurable properties or characteristics that can be associated with records in a table. The module includes:</p> <ul> <li>Feature: Main class for defining and managing features</li> <li>FeatureRecord: Base class for feature records using pydantic models</li> </ul> Typical usage example <p>feature = Feature(association_result, model) FeatureClass = feature.feature_record_class() record = FeatureClass(value=\"high\", confidence=0.95)</p>"},{"location":"code-docs/feature/#deriva_ml.feature.Feature","title":"Feature","text":"<p>Manages feature definitions and their relationships in the catalog.</p> <p>A Feature represents a measurable property or characteristic that can be associated with records in a table. Features can include asset references, controlled vocabulary terms, and custom metadata fields.</p> <p>Attributes:</p> Name Type Description <code>feature_table</code> <p>Table containing the feature implementation.</p> <code>target_table</code> <p>Table that the feature is associated with.</p> <code>feature_name</code> <p>Name of the feature (from Feature_Name column default).</p> <code>feature_columns</code> <p>Set of columns specific to this feature.</p> <code>asset_columns</code> <p>Set of columns referencing asset tables.</p> <code>term_columns</code> <p>Set of columns referencing vocabulary tables.</p> <code>value_columns</code> <p>Set of columns containing direct values.</p> Example <p>feature = Feature(association_result, model) print(f\"Feature {feature.feature_name} on {feature.target_table.name}\") print(\"Asset columns:\", [c.name for c in feature.asset_columns])</p> Source code in <code>src/deriva_ml/feature.py</code> <pre><code>class Feature:\n    \"\"\"Manages feature definitions and their relationships in the catalog.\n\n    A Feature represents a measurable property or characteristic that can be associated with records in a table.\n    Features can include asset references, controlled vocabulary terms, and custom metadata fields.\n\n    Attributes:\n        feature_table: Table containing the feature implementation.\n        target_table: Table that the feature is associated with.\n        feature_name: Name of the feature (from Feature_Name column default).\n        feature_columns: Set of columns specific to this feature.\n        asset_columns: Set of columns referencing asset tables.\n        term_columns: Set of columns referencing vocabulary tables.\n        value_columns: Set of columns containing direct values.\n\n    Example:\n        &gt;&gt;&gt; feature = Feature(association_result, model)\n        &gt;&gt;&gt; print(f\"Feature {feature.feature_name} on {feature.target_table.name}\")\n        &gt;&gt;&gt; print(\"Asset columns:\", [c.name for c in feature.asset_columns])\n    \"\"\"\n\n    def __init__(self, atable: FindAssociationResult, model: \"DerivaModel\") -&gt; None:\n        self.feature_table = atable.table\n        self.target_table = atable.self_fkey.pk_table\n        self.feature_name = atable.table.columns[\"Feature_Name\"].default\n        self._model = model\n\n        skip_columns = {\n            \"RID\",\n            \"RMB\",\n            \"RCB\",\n            \"RCT\",\n            \"RMT\",\n            \"Feature_Name\",\n            self.target_table.name,\n            \"Execution\",\n        }\n        self.feature_columns = {c for c in self.feature_table.columns if c.name not in skip_columns}\n\n        assoc_fkeys = {atable.self_fkey} | atable.other_fkeys\n\n        # Determine the role of each column in the feature outside the FK columns.\n        self.asset_columns = {\n            fk.foreign_key_columns[0]\n            for fk in self.feature_table.foreign_keys\n            if fk not in assoc_fkeys and self._model.is_asset(fk.pk_table)\n        }\n\n        self.term_columns = {\n            fk.foreign_key_columns[0]\n            for fk in self.feature_table.foreign_keys\n            if fk not in assoc_fkeys and self._model.is_vocabulary(fk.pk_table)\n        }\n\n        self.value_columns = self.feature_columns - (self.asset_columns | self.term_columns)\n\n    def feature_record_class(self) -&gt; type[FeatureRecord]:\n        \"\"\"Create a pydantic model for entries into the specified feature table\n\n        Returns:\n            A Feature class that can be used to create instances of the feature.\n        \"\"\"\n\n        def map_type(c: Column) -&gt; UnionType | Type[str] | Type[int] | Type[float]:\n            \"\"\"Maps a Deriva column type to a Python/pydantic type.\n\n            Converts ERMrest column types to appropriate Python types for use in pydantic models.\n            Special handling is provided for asset columns which can accept either strings or Path objects.\n\n            Args:\n                c: ERMrest column to map to a Python type.\n\n            Returns:\n                UnionType | Type[str] | Type[int] | Type[float]: Appropriate Python type for the column:\n                    - str | Path for asset columns\n                    - str for text columns\n                    - int for integer columns\n                    - float for floating point columns\n                    - str for all other types\n\n            Example:\n                &gt;&gt;&gt; col = Column(name=\"score\", type=\"float4\")\n                &gt;&gt;&gt; typ = map_type(col)  # Returns float\n            \"\"\"\n            if c.name in {c.name for c in self.asset_columns}:\n                return str | Path\n\n            match c.type.typename:\n                case \"text\":\n                    return str\n                case \"int2\" | \"int4\" | \"int8\":\n                    return int\n                case \"float4\" | \"float8\":\n                    return float\n                case _:\n                    return str\n\n        featureclass_name = f\"{self.target_table.name}Feature{self.feature_name}\"\n\n        # Create feature class. To do this, we must determine the python type for each column and also if the\n        # column is optional or not based on its nullability.\n        feature_columns = {\n            c.name: (\n                Optional[map_type(c)] if c.nullok else map_type(c),\n                c.default or None,\n            )\n            for c in self.feature_columns\n        } | {\n            \"Feature_Name\": (\n                str,\n                self.feature_name,\n            ),  # Set default value for Feature_Name\n            self.target_table.name: (str, ...),\n        }\n        docstring = (\n            f\"Class to capture fields in a feature {self.feature_name} on table {self.target_table}. \"\n            \"Feature columns include:\\n\"\n        )\n        docstring += \"\\n\".join([f\"    {c.name}\" for c in self.feature_columns])\n\n        model = create_model(\n            featureclass_name,\n            __base__=FeatureRecord,\n            __doc__=docstring,\n            **feature_columns,\n        )\n        model.feature = self  # Set value of class variable within the feature class definition.\n\n        return model\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"Feature(target_table={self.target_table.name}, feature_name={self.feature_name}, \"\n            f\"feature_table={self.feature_table.name})\"\n        )\n</code></pre>"},{"location":"code-docs/feature/#deriva_ml.feature.Feature.feature_record_class","title":"feature_record_class","text":"<pre><code>feature_record_class() -&gt; type[\n    FeatureRecord\n]\n</code></pre> <p>Create a pydantic model for entries into the specified feature table</p> <p>Returns:</p> Type Description <code>type[FeatureRecord]</code> <p>A Feature class that can be used to create instances of the feature.</p> Source code in <code>src/deriva_ml/feature.py</code> <pre><code>def feature_record_class(self) -&gt; type[FeatureRecord]:\n    \"\"\"Create a pydantic model for entries into the specified feature table\n\n    Returns:\n        A Feature class that can be used to create instances of the feature.\n    \"\"\"\n\n    def map_type(c: Column) -&gt; UnionType | Type[str] | Type[int] | Type[float]:\n        \"\"\"Maps a Deriva column type to a Python/pydantic type.\n\n        Converts ERMrest column types to appropriate Python types for use in pydantic models.\n        Special handling is provided for asset columns which can accept either strings or Path objects.\n\n        Args:\n            c: ERMrest column to map to a Python type.\n\n        Returns:\n            UnionType | Type[str] | Type[int] | Type[float]: Appropriate Python type for the column:\n                - str | Path for asset columns\n                - str for text columns\n                - int for integer columns\n                - float for floating point columns\n                - str for all other types\n\n        Example:\n            &gt;&gt;&gt; col = Column(name=\"score\", type=\"float4\")\n            &gt;&gt;&gt; typ = map_type(col)  # Returns float\n        \"\"\"\n        if c.name in {c.name for c in self.asset_columns}:\n            return str | Path\n\n        match c.type.typename:\n            case \"text\":\n                return str\n            case \"int2\" | \"int4\" | \"int8\":\n                return int\n            case \"float4\" | \"float8\":\n                return float\n            case _:\n                return str\n\n    featureclass_name = f\"{self.target_table.name}Feature{self.feature_name}\"\n\n    # Create feature class. To do this, we must determine the python type for each column and also if the\n    # column is optional or not based on its nullability.\n    feature_columns = {\n        c.name: (\n            Optional[map_type(c)] if c.nullok else map_type(c),\n            c.default or None,\n        )\n        for c in self.feature_columns\n    } | {\n        \"Feature_Name\": (\n            str,\n            self.feature_name,\n        ),  # Set default value for Feature_Name\n        self.target_table.name: (str, ...),\n    }\n    docstring = (\n        f\"Class to capture fields in a feature {self.feature_name} on table {self.target_table}. \"\n        \"Feature columns include:\\n\"\n    )\n    docstring += \"\\n\".join([f\"    {c.name}\" for c in self.feature_columns])\n\n    model = create_model(\n        featureclass_name,\n        __base__=FeatureRecord,\n        __doc__=docstring,\n        **feature_columns,\n    )\n    model.feature = self  # Set value of class variable within the feature class definition.\n\n    return model\n</code></pre>"},{"location":"code-docs/feature/#deriva_ml.feature.FeatureRecord","title":"FeatureRecord","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for dynamically generated feature record models.</p> <p>This class serves as the base for pydantic models that represent feature records. Each feature record contains the values and metadata associated with a feature instance.</p> <p>Attributes:</p> Name Type Description <code>Execution</code> <code>Optional[str]</code> <p>RID of the execution that created this feature record.</p> <code>Feature_Name</code> <code>str</code> <p>Name of the feature this record belongs to.</p> <code>feature</code> <code>ClassVar[Optional[Feature]]</code> <p>Reference to the Feature object that created this record.</p> Example <p>class GeneFeature(FeatureRecord): ...     value: str ...     confidence: float record = GeneFeature( ...     Feature_Name=\"expression\", ...     value=\"high\", ...     confidence=0.95 ... )</p> Source code in <code>src/deriva_ml/feature.py</code> <pre><code>class FeatureRecord(BaseModel):\n    \"\"\"Base class for dynamically generated feature record models.\n\n    This class serves as the base for pydantic models that represent feature records. Each feature record\n    contains the values and metadata associated with a feature instance.\n\n    Attributes:\n        Execution (Optional[str]): RID of the execution that created this feature record.\n        Feature_Name (str): Name of the feature this record belongs to.\n        feature (ClassVar[Optional[Feature]]): Reference to the Feature object that created this record.\n\n    Example:\n        &gt;&gt;&gt; class GeneFeature(FeatureRecord):\n        ...     value: str\n        ...     confidence: float\n        &gt;&gt;&gt; record = GeneFeature(\n        ...     Feature_Name=\"expression\",\n        ...     value=\"high\",\n        ...     confidence=0.95\n        ... )\n    \"\"\"\n\n    # model_dump of this feature should be compatible with feature table columns.\n    Execution: Optional[str] = None\n    Feature_Name: str\n    feature: ClassVar[Optional[\"Feature\"]] = None\n\n    class Config:\n        arbitrary_types_allowed = True\n        extra = \"forbid\"\n\n    @classmethod\n    def feature_columns(cls) -&gt; set[Column]:\n        \"\"\"Returns all columns specific to this feature.\n\n        Returns:\n            set[Column]: Set of feature-specific columns, excluding system and relationship columns.\n        \"\"\"\n        return cls.feature.feature_columns\n\n    @classmethod\n    def asset_columns(cls) -&gt; set[Column]:\n        \"\"\"Returns columns that reference asset tables.\n\n        Returns:\n            set[Column]: Set of columns that contain references to asset tables.\n        \"\"\"\n        return cls.feature.asset_columns\n\n    @classmethod\n    def term_columns(cls) -&gt; set[Column]:\n        \"\"\"Returns columns that reference vocabulary terms.\n\n        Returns:\n            set[Column]: Set of columns that contain references to controlled vocabulary terms.\n        \"\"\"\n        return cls.feature.term_columns\n\n    @classmethod\n    def value_columns(cls) -&gt; set[Column]:\n        \"\"\"Returns columns that contain direct values.\n\n        Returns:\n            set[Column]: Set of columns containing direct values (not references to assets or terms).\n        \"\"\"\n        return cls.feature.value_columns\n</code></pre>"},{"location":"code-docs/feature/#deriva_ml.feature.FeatureRecord.asset_columns","title":"asset_columns  <code>classmethod</code>","text":"<pre><code>asset_columns() -&gt; set[Column]\n</code></pre> <p>Returns columns that reference asset tables.</p> <p>Returns:</p> Type Description <code>set[Column]</code> <p>set[Column]: Set of columns that contain references to asset tables.</p> Source code in <code>src/deriva_ml/feature.py</code> <pre><code>@classmethod\ndef asset_columns(cls) -&gt; set[Column]:\n    \"\"\"Returns columns that reference asset tables.\n\n    Returns:\n        set[Column]: Set of columns that contain references to asset tables.\n    \"\"\"\n    return cls.feature.asset_columns\n</code></pre>"},{"location":"code-docs/feature/#deriva_ml.feature.FeatureRecord.feature_columns","title":"feature_columns  <code>classmethod</code>","text":"<pre><code>feature_columns() -&gt; set[Column]\n</code></pre> <p>Returns all columns specific to this feature.</p> <p>Returns:</p> Type Description <code>set[Column]</code> <p>set[Column]: Set of feature-specific columns, excluding system and relationship columns.</p> Source code in <code>src/deriva_ml/feature.py</code> <pre><code>@classmethod\ndef feature_columns(cls) -&gt; set[Column]:\n    \"\"\"Returns all columns specific to this feature.\n\n    Returns:\n        set[Column]: Set of feature-specific columns, excluding system and relationship columns.\n    \"\"\"\n    return cls.feature.feature_columns\n</code></pre>"},{"location":"code-docs/feature/#deriva_ml.feature.FeatureRecord.term_columns","title":"term_columns  <code>classmethod</code>","text":"<pre><code>term_columns() -&gt; set[Column]\n</code></pre> <p>Returns columns that reference vocabulary terms.</p> <p>Returns:</p> Type Description <code>set[Column]</code> <p>set[Column]: Set of columns that contain references to controlled vocabulary terms.</p> Source code in <code>src/deriva_ml/feature.py</code> <pre><code>@classmethod\ndef term_columns(cls) -&gt; set[Column]:\n    \"\"\"Returns columns that reference vocabulary terms.\n\n    Returns:\n        set[Column]: Set of columns that contain references to controlled vocabulary terms.\n    \"\"\"\n    return cls.feature.term_columns\n</code></pre>"},{"location":"code-docs/feature/#deriva_ml.feature.FeatureRecord.value_columns","title":"value_columns  <code>classmethod</code>","text":"<pre><code>value_columns() -&gt; set[Column]\n</code></pre> <p>Returns columns that contain direct values.</p> <p>Returns:</p> Type Description <code>set[Column]</code> <p>set[Column]: Set of columns containing direct values (not references to assets or terms).</p> Source code in <code>src/deriva_ml/feature.py</code> <pre><code>@classmethod\ndef value_columns(cls) -&gt; set[Column]:\n    \"\"\"Returns columns that contain direct values.\n\n    Returns:\n        set[Column]: Set of columns containing direct values (not references to assets or terms).\n    \"\"\"\n    return cls.feature.value_columns\n</code></pre>"},{"location":"code-docs/upload/","title":"Upload Utilities","text":"<p>Utilities for uploading files and assets to a Deriva catalog's Hatrac object store.</p> <p>This module provides functions that help structure local directories for uploading to a DerivaML catalog, and generating an upload specification for those directories.</p> <p>Here is the directory layout we support:</p> <p>deriva-ml/        execution                            execution-asset                                            file1, file2, ....   &lt;- Need to update execution_asset association table.                execution-metadata                                    feature                                                         asset                                                                                    file1, file2, ...                            .jsonl    &lt;- needs to have asset_name column remapped before uploading                 table                                                record_table.csv                 asset                                                           file1, file2, ....                 asset-type                                              file1.jsonl, file2.jsonl"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.asset_file_path","title":"asset_file_path","text":"<pre><code>asset_file_path(\n    prefix: Path | str,\n    exec_rid: RID,\n    asset_table: Table,\n    file_name: str,\n    metadata: dict[str, Any],\n) -&gt; Path\n</code></pre> <p>Return the file in which to place  assets of a specified type are to be uploaded.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Path | str</code> <p>Path prefix to use.</p> required <code>exec_rid</code> <code>RID</code> <p>RID to use.</p> required <code>asset_table</code> <code>Table</code> <p>Table in which to place assets.</p> required <code>file_name</code> <code>str</code> <p>File name to use.</p> required <code>metadata</code> <code>dict[str, Any]</code> <p>Any additional metadata to add to the asset</p> required <p>Returns:     Path to directory in which to place assets of type asset_type.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def asset_file_path(\n    prefix: Path | str,\n    exec_rid: RID,\n    asset_table: Table,\n    file_name: str,\n    metadata: dict[str, Any],\n) -&gt; Path:\n    \"\"\"Return the file in which to place  assets of a specified type are to be uploaded.\n\n    Args:\n        prefix: Path prefix to use.\n        exec_rid: RID to use.\n        asset_table: Table in which to place assets.\n        file_name: File name to use.\n        metadata: Any additional metadata to add to the asset\n    Returns:\n        Path to directory in which to place assets of type asset_type.\n    \"\"\"\n    schema = asset_table.schema.name\n    asset_name = asset_table.name\n\n    path = execution_root(prefix, exec_rid) / \"asset\" / schema / asset_name\n    metadata = metadata or {}\n    asset_columns = {\n        \"Filename\",\n        \"URL\",\n        \"Length\",\n        \"MD5\",\n        \"Description\",\n    }.union(set(DerivaSystemColumns))\n    asset_metadata = {c.name for c in asset_table.columns} - asset_columns\n\n    if not (asset_metadata &gt;= set(metadata.keys())):\n        raise DerivaMLException(f\"Metadata {metadata} does not match asset metadata {asset_metadata}\")\n\n    for m in asset_metadata:\n        path = path / str(metadata.get(m, \"None\"))\n    path.mkdir(parents=True, exist_ok=True)\n    return path / file_name\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.asset_root","title":"asset_root","text":"<pre><code>asset_root(\n    prefix: Path | str, exec_rid: str\n) -&gt; Path\n</code></pre> <p>Return the path to the directory in which features for the specified execution should be placed.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def asset_root(prefix: Path | str, exec_rid: str) -&gt; Path:\n    \"\"\"Return the path to the directory in which features for the specified execution should be placed.\"\"\"\n    path = execution_root(prefix, exec_rid) / \"asset\"\n    path.mkdir(parents=True, exist_ok=True)\n    return path\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.asset_table_upload_spec","title":"asset_table_upload_spec","text":"<pre><code>asset_table_upload_spec(\n    model: DerivaModel,\n    asset_table: str | Table,\n    chunk_size: int | None = None,\n)\n</code></pre> <p>Generate upload specification for an asset table.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>DerivaModel</code> <p>The DerivaModel instance.</p> required <code>asset_table</code> <code>str | Table</code> <p>The asset table name or Table object.</p> required <code>chunk_size</code> <code>int | None</code> <p>Optional chunk size in bytes for hatrac uploads. If provided, large files will be uploaded in chunks of this size.</p> <code>None</code> <p>Returns:</p> Type Description <p>A dictionary containing the upload specification for the asset table.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def asset_table_upload_spec(\n    model: DerivaModel, asset_table: str | Table, chunk_size: int | None = None\n):\n    \"\"\"Generate upload specification for an asset table.\n\n    Args:\n        model: The DerivaModel instance.\n        asset_table: The asset table name or Table object.\n        chunk_size: Optional chunk size in bytes for hatrac uploads. If provided,\n            large files will be uploaded in chunks of this size.\n\n    Returns:\n        A dictionary containing the upload specification for the asset table.\n    \"\"\"\n    metadata_columns = model.asset_metadata(asset_table)\n    asset_table = model.name_to_table(asset_table)\n    schema = model.name_to_table(asset_table).schema.name\n\n    # Be careful here as a metadata value might be a string with can contain special characters.\n    metadata_path = \"/\".join([rf\"(?P&lt;{c}&gt;[-:._ \\w]+)\" for c in metadata_columns])\n    asset_path = f\"{exec_dir_regex}/asset/{schema}/{asset_table.name}/{metadata_path}/{asset_file_regex}\"\n    asset_table = model.name_to_table(asset_table)\n    schema = model.name_to_table(asset_table).schema.name\n\n    # Build hatrac_options with optional chunk_size\n    hatrac_options = {\"versioned_urls\": True}\n    if chunk_size is not None:\n        hatrac_options[\"chunk_size\"] = chunk_size\n\n    # Create upload specification\n    spec = {\n        # Upload assets into an asset table of an asset table.\n        \"column_map\": {\n            \"MD5\": \"{md5}\",\n            \"URL\": \"{URI}\",\n            \"Length\": \"{file_size}\",\n            \"Filename\": \"{file_name}\",\n        }\n        | {c: f\"{{{c}}}\" for c in metadata_columns},\n        \"file_pattern\": asset_path,  # Sets schema, asset_table, file\n        \"asset_type\": \"file\",\n        \"target_table\": [schema, asset_table.name],\n        \"checksum_types\": [\"sha256\", \"md5\"],\n        \"hatrac_options\": hatrac_options,\n        \"hatrac_templates\": {\n            \"hatrac_uri\": f\"/hatrac/{asset_table.name}/{{md5}}.{{file_name}}\",\n            \"content-disposition\": \"filename*=UTF-8''{file_name}\",\n        },\n        \"record_query_template\": \"/entity/{target_table}/MD5={md5}&amp;Filename={file_name}\",\n    }\n    return spec\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.asset_type_path","title":"asset_type_path","text":"<pre><code>asset_type_path(\n    prefix: Path | str,\n    exec_rid: RID,\n    asset_table: Table,\n) -&gt; Path\n</code></pre> <p>Return the path to a JSON line file in which to place asset_type information.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Path | str</code> <p>Location of upload root directory</p> required <code>exec_rid</code> <code>RID</code> <p>Execution RID</p> required <code>asset_table</code> <code>Table</code> <p>Table in which to place assets.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the file in which to place asset_type values for the named asset.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def asset_type_path(prefix: Path | str, exec_rid: RID, asset_table: Table) -&gt; Path:\n    \"\"\"Return the path to a JSON line file in which to place asset_type information.\n\n    Args:\n        prefix: Location of upload root directory\n        exec_rid: Execution RID\n        asset_table: Table in which to place assets.\n\n    Returns:\n        Path to the file in which to place asset_type values for the named asset.\n    \"\"\"\n    path = execution_root(prefix, exec_rid=exec_rid) / \"asset-type\" / asset_table.schema.name\n    path.mkdir(parents=True, exist_ok=True)\n    return path / f\"{asset_table.name}.jsonl\"\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.bulk_upload_configuration","title":"bulk_upload_configuration","text":"<pre><code>bulk_upload_configuration(\n    model: DerivaModel,\n    chunk_size: int | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Return an upload specification for deriva-ml</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>DerivaModel</code> <p>Model from which to generate the upload configuration.</p> required <code>chunk_size</code> <code>int | None</code> <p>Optional chunk size in bytes for hatrac uploads. If provided, large files will be uploaded in chunks of this size.</p> <code>None</code> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def bulk_upload_configuration(\n    model: DerivaModel, chunk_size: int | None = None\n) -&gt; dict[str, Any]:\n    \"\"\"Return an upload specification for deriva-ml\n\n    Args:\n        model: Model from which to generate the upload configuration.\n        chunk_size: Optional chunk size in bytes for hatrac uploads. If provided,\n            large files will be uploaded in chunks of this size.\n    \"\"\"\n    asset_tables_with_metadata = [\n        asset_table_upload_spec(model=model, asset_table=t, chunk_size=chunk_size)\n        for t in model.find_assets()\n        if model.asset_metadata(t)\n    ]\n\n    # Build hatrac_options with optional chunk_size for non-metadata assets\n    hatrac_options = {\"versioned_urls\": True}\n    if chunk_size is not None:\n        hatrac_options[\"chunk_size\"] = chunk_size\n\n    return {\n        \"asset_mappings\": asset_tables_with_metadata\n        + [\n            {\n                # Upload assets into an asset table of an asset table without any metadata\n                \"column_map\": {\n                    \"MD5\": \"{md5}\",\n                    \"URL\": \"{URI}\",\n                    \"Length\": \"{file_size}\",\n                    \"Filename\": \"{file_name}\",\n                },\n                \"asset_type\": \"file\",\n                \"target_table\": [\"{schema}\", \"{asset_table}\"],\n                \"file_pattern\": asset_path_regex + \"/\" + asset_file_regex,  # Sets schema, asset_table, name, ext\n                \"checksum_types\": [\"sha256\", \"md5\"],\n                \"hatrac_options\": hatrac_options,\n                \"hatrac_templates\": {\n                    \"hatrac_uri\": \"/hatrac/{asset_table}/{md5}.{file_name}\",\n                    \"content-disposition\": \"filename*=UTF-8''{file_name}\",\n                },\n                \"record_query_template\": \"/entity/{target_table}/MD5={md5}&amp;Filename={file_name}\",\n            },\n            # {\n            #  Upload the records into a  table\n            #   \"asset_type\": \"skip\",\n            ##   \"default_columns\": [\"RID\", \"RCB\", \"RMB\", \"RCT\", \"RMT\"],\n            #  \"file_pattern\": feature_value_regex,  # Sets schema, table,\n            #  \"ext_pattern\": \"^.*[.](?P&lt;file_ext&gt;json|csv)$\",\n            #  \"target_table\": [\"{schema}\", \"{table}\"],\n            # },\n            {\n                #  Upload the records into a  table\n                \"asset_type\": \"table\",\n                \"default_columns\": [\"RID\", \"RCB\", \"RMB\", \"RCT\", \"RMT\"],\n                \"file_pattern\": table_regex,  # Sets schema, table,\n                \"ext_pattern\": \"^.*[.](?P&lt;file_ext&gt;json|csv)$\",\n                \"target_table\": [\"{schema}\", \"{table}\"],\n            },\n        ],\n        \"version_update_url\": \"https://github.com/informatics-isi-edu/deriva-client\",\n        \"version_compatibility\": [[\"&gt;=1.4.0\", \"&lt;2.0.0\"]],\n    }\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.execution_rids","title":"execution_rids","text":"<pre><code>execution_rids(\n    prefix: Path | str,\n) -&gt; list[RID]\n</code></pre> <p>Return a list of all the execution RIDS that have files waiting to be uploaded.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def execution_rids(prefix: Path | str) -&gt; list[RID]:\n    \"\"\"Return a list of all the execution RIDS that have files waiting to be uploaded.\"\"\"\n    path = upload_root(prefix) / \"execution\"\n    return [d.name for d in path.iterdir()]\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.execution_root","title":"execution_root","text":"<pre><code>execution_root(\n    prefix: Path | str, exec_rid\n) -&gt; Path\n</code></pre> <p>Path to directory to place execution specific upload files.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def execution_root(prefix: Path | str, exec_rid) -&gt; Path:\n    \"\"\"Path to directory to place execution specific upload files.\"\"\"\n    path = upload_root(prefix) / \"execution\" / exec_rid\n    path.mkdir(exist_ok=True, parents=True)\n    return path\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.feature_dir","title":"feature_dir","text":"<pre><code>feature_dir(\n    prefix: Path | str,\n    exec_rid: str,\n    schema: str,\n    target_table: str,\n    feature_name: str,\n) -&gt; Path\n</code></pre> <p>Return the path to eht directory in which a named feature for an execution should be placed.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def feature_dir(prefix: Path | str, exec_rid: str, schema: str, target_table: str, feature_name: str) -&gt; Path:\n    \"\"\"Return the path to eht directory in which a named feature for an execution should be placed.\"\"\"\n    path = feature_root(prefix, exec_rid) / schema / target_table / feature_name\n    path.mkdir(parents=True, exist_ok=True)\n    return path\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.feature_root","title":"feature_root","text":"<pre><code>feature_root(\n    prefix: Path | str, exec_rid: str\n) -&gt; Path\n</code></pre> <p>Return the path to the directory in which features for the specified execution should be placed.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def feature_root(prefix: Path | str, exec_rid: str) -&gt; Path:\n    \"\"\"Return the path to the directory in which features for the specified execution should be placed.\"\"\"\n    path = execution_root(prefix, exec_rid) / \"feature\"\n    path.mkdir(parents=True, exist_ok=True)\n    return path\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.feature_value_path","title":"feature_value_path","text":"<pre><code>feature_value_path(\n    prefix: Path | str,\n    exec_rid: str,\n    schema: str,\n    target_table: str,\n    feature_name: str,\n) -&gt; Path\n</code></pre> <p>Return the path to a CSV file in which to place feature values that are to be uploaded.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Path | str</code> <p>Location of upload root directory</p> required <code>exec_rid</code> <code>str</code> <p>RID of the execution to be associated with this feature.</p> required <code>schema</code> <code>str</code> <p>Domain schema name</p> required <code>target_table</code> <code>str</code> <p>Target table name for the feature.</p> required <code>feature_name</code> <code>str</code> <p>Name of the feature.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to CSV file in which to place feature values</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def feature_value_path(prefix: Path | str, exec_rid: str, schema: str, target_table: str, feature_name: str) -&gt; Path:\n    \"\"\"Return the path to a CSV file in which to place feature values that are to be uploaded.\n\n    Args:\n        prefix: Location of upload root directory\n        exec_rid: RID of the execution to be associated with this feature.\n        schema: Domain schema name\n        target_table: Target table name for the feature.\n        feature_name: Name of the feature.\n\n    Returns:\n        Path to CSV file in which to place feature values\n    \"\"\"\n    return feature_dir(prefix, exec_rid, schema, target_table, feature_name) / f\"{feature_name}.jsonl\"\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.is_feature_dir","title":"is_feature_dir","text":"<pre><code>is_feature_dir(\n    path: Path,\n) -&gt; Optional[re.Match]\n</code></pre> <p>Path matches the pattern for where the table for a feature would go.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def is_feature_dir(path: Path) -&gt; Optional[re.Match]:\n    \"\"\"Path matches the pattern for where the table for a feature would go.\"\"\"\n    return re.match(feature_table_dir_regex + \"$\", path.as_posix())\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.normalize_asset_dir","title":"normalize_asset_dir","text":"<pre><code>normalize_asset_dir(\n    path: str | Path,\n) -&gt; Optional[tuple[str, str]]\n</code></pre> <p>Parse a path to an asset file and return the asset table name and file name.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the asset file</p> required <p>Returns:</p> Type Description <code>Optional[tuple[str, str]]</code> <p>Tuple of (schema/table, filename) or None if path doesn't match pattern</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def normalize_asset_dir(path: str | Path) -&gt; Optional[tuple[str, str]]:\n    \"\"\"Parse a path to an asset file and return the asset table name and file name.\n\n    Args:\n        path: Path to the asset file\n\n    Returns:\n        Tuple of (schema/table, filename) or None if path doesn't match pattern\n    \"\"\"\n    path = Path(path)\n    if not (m := re.match(asset_path_regex, str(path))):\n        return None\n    return f\"{m['schema']}/{m['asset_table']}\", path.name\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.table_path","title":"table_path","text":"<pre><code>table_path(\n    prefix: Path | str,\n    schema: str,\n    table: str,\n) -&gt; Path\n</code></pre> <p>Return the path to a CSV file in which to place table values that are to be uploaded.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>Path | str</code> <p>Location of upload root directory</p> required <code>schema</code> <code>str</code> <p>Domain schema</p> required <code>table</code> <code>str</code> <p>Name of the table to be uploaded.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the file in which to place table values that are to be uploaded.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def table_path(prefix: Path | str, schema: str, table: str) -&gt; Path:\n    \"\"\"Return the path to a CSV file in which to place table values that are to be uploaded.\n\n    Args:\n        prefix: Location of upload root directory\n        schema: Domain schema\n        table: Name of the table to be uploaded.\n\n    Returns:\n        Path to the file in which to place table values that are to be uploaded.\n    \"\"\"\n    path = upload_root(prefix) / \"table\" / schema / table\n    path.mkdir(parents=True, exist_ok=True)\n    return path / f\"{table}.csv\"\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.upload_asset","title":"upload_asset","text":"<pre><code>upload_asset(\n    model: DerivaModel,\n    file: Path | str,\n    table: Table,\n    **kwargs: Any,\n) -&gt; dict\n</code></pre> <p>Upload the specified file into Hatrac and update the associated asset table.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>Path | str</code> <p>path to the file to upload.</p> required <code>table</code> <code>Table</code> <p>Name of the asset table</p> required <code>model</code> <code>DerivaModel</code> <p>Model to upload assets to.</p> required <code>kwargs</code> <code>Any</code> <p>Keyword arguments for values of additional columns to be added to the asset table.</p> <code>{}</code> <p>Returns:</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef upload_asset(model: DerivaModel, file: Path | str, table: Table, **kwargs: Any) -&gt; dict:\n    \"\"\"Upload the specified file into Hatrac and update the associated asset table.\n\n    Args:\n        file: path to the file to upload.\n        table: Name of the asset table\n        model: Model to upload assets to.\n        kwargs: Keyword arguments for values of additional columns to be added to the asset table.\n\n    Returns:\n\n    \"\"\"\n    if not model.is_asset(table):\n        raise DerivaMLException(f\"Table {table} is not an asset table.\")\n\n    file_path = Path(file)\n    file_name = file_path.name\n    file_size = file_path.stat().st_size\n\n    hatrac_path = f\"/hatrac/{table.name}/\"\n    hs = HatracStore(\n        \"https\",\n        server=model.catalog.deriva_server.server,\n        credentials=model.catalog.deriva_server.credentials,\n    )\n    md5_hashes = hash_utils.compute_file_hashes(file, frozenset([\"md5\"]))[\"md5\"]\n    sanitized_filename = urlquote(re.sub(\"[^a-zA-Z0-9_.-]\", \"_\", md5_hashes[0] + \".\" + file_name))\n    hatrac_path = f\"{hatrac_path}{sanitized_filename}\"\n\n    try:\n        # Upload the file to hatrac.\n        hatrac_uri = hs.put_obj(\n            hatrac_path,\n            file,\n            md5=md5_hashes[1],\n            content_type=mime_utils.guess_content_type(file),\n            content_disposition=\"filename*=UTF-8''\" + file_name,\n        )\n    except Exception as e:\n        raise e\n    try:\n        # Now update the asset table.\n        ipath = model.catalog.getPathBuilder().schemas[table.schema.name].tables[table.name]\n        return list(\n            ipath.insert(\n                [\n                    {\n                        \"URL\": hatrac_uri,\n                        \"Filename\": file_name,\n                        \"Length\": file_size,\n                        \"MD5\": md5_hashes[0],\n                    }\n                    | kwargs\n                ]\n            )\n        )[0]\n    except Exception as e:\n        raise e\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.upload_directory","title":"upload_directory","text":"<pre><code>upload_directory(\n    model: DerivaModel,\n    directory: Path | str,\n    progress_callback: Callable[\n        [UploadProgress], None\n    ]\n    | None = None,\n    max_retries: int = 3,\n    retry_delay: float = 5.0,\n    timeout: tuple[int, int]\n    | None = None,\n    chunk_size: int | None = None,\n) -&gt; dict[Any, FileUploadState] | None\n</code></pre> <p>Upload assets from a directory. This routine assumes that the current upload specification includes a configuration for the specified directory.  Every asset in the specified directory is uploaded</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>DerivaModel</code> <p>Model to upload assets to.</p> required <code>directory</code> <code>Path | str</code> <p>Directory containing the assets and tables to upload.</p> required <code>progress_callback</code> <code>Callable[[UploadProgress], None] | None</code> <p>Optional callback function to receive upload progress updates. Called with UploadProgress objects containing file information and progress.</p> <code>None</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed uploads (default: 3).</p> <code>3</code> <code>retry_delay</code> <code>float</code> <p>Initial delay in seconds between retries, doubles with each attempt (default: 5.0).</p> <code>5.0</code> <code>timeout</code> <code>tuple[int, int] | None</code> <p>Tuple of (connect_timeout, read_timeout) in seconds. Default is (600, 600). Note: urllib3 uses connect_timeout as the socket timeout during request body writes, so it must be large enough for a full chunk upload. Both values should be set generously for large file uploads.</p> <code>None</code> <code>chunk_size</code> <code>int | None</code> <p>Optional chunk size in bytes for hatrac uploads. If provided, large files will be uploaded in chunks of this size.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[Any, FileUploadState] | None</code> <p>Results of the upload operation.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If there is an issue with uploading the assets.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>@validate_call(config=ConfigDict(arbitrary_types_allowed=True))\ndef upload_directory(\n    model: DerivaModel,\n    directory: Path | str,\n    progress_callback: Callable[[UploadProgress], None] | None = None,\n    max_retries: int = 3,\n    retry_delay: float = 5.0,\n    timeout: tuple[int, int] | None = None,\n    chunk_size: int | None = None,\n) -&gt; dict[Any, FileUploadState] | None:\n    \"\"\"Upload assets from a directory. This routine assumes that the current upload specification includes a\n    configuration for the specified directory.  Every asset in the specified directory is uploaded\n\n    Args:\n        model: Model to upload assets to.\n        directory: Directory containing the assets and tables to upload.\n        progress_callback: Optional callback function to receive upload progress updates.\n            Called with UploadProgress objects containing file information and progress.\n        max_retries: Maximum number of retry attempts for failed uploads (default: 3).\n        retry_delay: Initial delay in seconds between retries, doubles with each attempt (default: 5.0).\n        timeout: Tuple of (connect_timeout, read_timeout) in seconds. Default is (600, 600).\n            Note: urllib3 uses connect_timeout as the socket timeout during request body\n            writes, so it must be large enough for a full chunk upload. Both values should\n            be set generously for large file uploads.\n        chunk_size: Optional chunk size in bytes for hatrac uploads. If provided,\n            large files will be uploaded in chunks of this size.\n\n    Returns:\n        Results of the upload operation.\n\n    Raises:\n        DerivaMLException: If there is an issue with uploading the assets.\n    \"\"\"\n    import logging\n    import time\n\n    from deriva.core import DEFAULT_SESSION_CONFIG\n\n    logger = logging.getLogger(\"deriva_ml\")\n\n    directory = Path(directory)\n    if not directory.is_dir():\n        raise DerivaMLException(\"Directory does not exist\")\n\n    # Track upload progress across files\n    # status_callback is called twice per file: once before upload starts, once after it completes\n    upload_state = {\"completed_files\": 0, \"total_files\": 0, \"status_calls\": 0}\n\n    # Count total files to upload\n    for root, dirs, files in os.walk(directory):\n        upload_state[\"total_files\"] += len(files)\n\n    # Create wrapper callbacks for GenericUploader if a progress callback was provided\n    def file_callback(**kwargs) -&gt; bool:\n        \"\"\"Callback for per-chunk progress updates from GenericUploader.\n\n        The deriva GenericUploader passes kwargs with: completed, total, file_path, host, job_info.\n        Note: This callback is only invoked for large files (&gt; 25MB) that use chunked uploads.\n        Small files are uploaded in a single request and this callback won't be called.\n        \"\"\"\n        if progress_callback is not None:\n            file_path = kwargs.get(\"file_path\", \"\")\n            completed_chunks = kwargs.get(\"completed\", 0)\n            total_chunks = kwargs.get(\"total\", 0)\n\n            progress = UploadProgress(\n                file_path=file_path,\n                file_name=Path(file_path).name if file_path else \"\",\n                bytes_completed=completed_chunks,\n                bytes_total=total_chunks,\n                percent_complete=(completed_chunks / total_chunks * 100) if total_chunks &gt; 0 else 0,\n                phase=\"uploading_chunks\",\n                message=f\"Uploading large file: chunk {completed_chunks} of {total_chunks}\",\n            )\n            progress_callback(progress)\n        return True  # Continue upload\n\n    def status_callback() -&gt; None:\n        \"\"\"Callback for per-file status updates from GenericUploader.\n\n        GenericUploader calls this twice per file: once before upload starts (odd calls)\n        and once after upload completes (even calls). We use even calls to track completed files.\n        \"\"\"\n        if progress_callback is not None:\n            upload_state[\"status_calls\"] += 1\n\n            # Even calls indicate file completion (after upload)\n            if upload_state[\"status_calls\"] % 2 == 0:\n                upload_state[\"completed_files\"] += 1\n\n            # Report progress with current file count\n            current_file = (upload_state[\"status_calls\"] + 1) // 2  # 1-indexed current file\n            progress = UploadProgress(\n                phase=\"uploading\",\n                message=f\"Uploading file {current_file} of {upload_state['total_files']}\",\n                percent_complete=(upload_state[\"completed_files\"] / upload_state[\"total_files\"] * 100)\n                if upload_state[\"total_files\"] &gt; 0\n                else 0,\n            )\n            progress_callback(progress)\n\n    def do_upload(uploader) -&gt; dict[str, dict]:\n        \"\"\"Perform the upload and return raw results.\"\"\"\n        uploader.getUpdatedConfig()\n        uploader.scanDirectory(directory, purge_state=True)\n        return uploader.uploadFiles(\n            file_callback=file_callback if progress_callback else None,\n            status_callback=status_callback if progress_callback else None,\n        )\n\n    # Use provided timeout or default\n    upload_timeout = timeout if timeout is not None else DEFAULT_UPLOAD_TIMEOUT\n\n    # Now upload the files by creating an upload spec and then calling the uploader.\n    with TemporaryDirectory() as temp_dir:\n        spec_file = Path(temp_dir) / \"config.json\"\n        with spec_file.open(\"w+\") as cfile:\n            json.dump(bulk_upload_configuration(model, chunk_size=chunk_size), cfile)\n\n        # Create session config with longer timeout for large file uploads\n        session_config = DEFAULT_SESSION_CONFIG.copy()\n        session_config[\"timeout\"] = upload_timeout\n        logger.debug(f\"Upload session config timeout: {session_config['timeout']}\")\n\n        all_results = {}\n        attempt = 0\n        current_delay = retry_delay\n\n        while attempt &lt;= max_retries:\n            uploader = GenericUploader(\n                server={\n                    \"host\": model.hostname,\n                    \"protocol\": \"https\",\n                    \"catalog_id\": model.catalog.catalog_id,\n                    \"session\": session_config,\n                },\n                config_file=spec_file,\n            )\n            try:\n                raw_results = do_upload(uploader)\n\n                # Process results and check for failures\n                failed_files = []\n                for path, result in raw_results.items():\n                    state = UploadState(result[\"State\"])\n                    if state == UploadState.failed or result[\"Result\"] is None:\n                        failed_files.append((path, result[\"Status\"]))\n                    else:\n                        # Store successful results\n                        all_results[path] = FileUploadState(\n                            state=state,\n                            status=result[\"Status\"],\n                            result=result[\"Result\"],\n                        )\n\n                if not failed_files:\n                    # All uploads successful\n                    break\n\n                attempt += 1\n                if attempt &gt; max_retries:\n                    # Final attempt failed, raise error with details\n                    error_details = \"; \".join([f\"{path}: {msg}\" for path, msg in failed_files])\n                    raise DerivaMLException(\n                        f\"Failed to upload {len(failed_files)} file(s) after {max_retries} retries: {error_details}\"\n                    )\n\n                # Log retry attempt and wait before retrying\n                logger.warning(\n                    f\"Upload failed for {len(failed_files)} file(s), retrying in {current_delay:.1f}s \"\n                    f\"(attempt {attempt}/{max_retries}): {[p for p, _ in failed_files]}\"\n                )\n                if progress_callback:\n                    progress_callback(UploadProgress(\n                        phase=\"retrying\",\n                        message=f\"Retrying {len(failed_files)} failed upload(s) in {current_delay:.1f}s (attempt {attempt}/{max_retries})\",\n                        percent_complete=0,\n                    ))\n\n                time.sleep(current_delay)\n                current_delay *= 2  # Exponential backoff\n\n                # Reset upload state for retry\n                upload_state[\"status_calls\"] = 0\n\n            finally:\n                uploader.cleanup()\n\n        return all_results\n</code></pre>"},{"location":"code-docs/upload/#deriva_ml.dataset.upload.upload_root","title":"upload_root","text":"<pre><code>upload_root(prefix: Path | str) -&gt; Path\n</code></pre> <p>Return the top level directory of where to put files to be uploaded.</p> Source code in <code>src/deriva_ml/dataset/upload.py</code> <pre><code>def upload_root(prefix: Path | str) -&gt; Path:\n    \"\"\"Return the top level directory of where to put files to be uploaded.\"\"\"\n    path = Path(prefix) / \"deriva-ml\"\n    path.mkdir(exist_ok=True, parents=True)\n    return path\n</code></pre>"},{"location":"code-docs/workflow/","title":"Workflow Class","text":"<p>The Workflow class represents a computational workflow in DerivaML. Workflows define the steps and logic for ML experiments and can be associated with Python scripts, Jupyter notebooks, or programmatically defined processes.</p>"},{"location":"code-docs/workflow/#deriva_ml.execution.workflow.Workflow","title":"Workflow","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a computational workflow in DerivaML.</p> <p>A workflow defines a computational process or analysis pipeline. Each workflow has a unique identifier, source code location, and type. Workflows are typically associated with Git repositories for version control.</p> <p>When a Workflow is retrieved via <code>lookup_workflow(rid)</code> or <code>lookup_workflow_by_url()</code>, it is bound to a catalog and its <code>description</code> and <code>workflow_type</code> properties become writable. Setting these properties will update the catalog record. If the catalog is read-only (a snapshot), attempting to set them will raise a <code>DerivaMLException</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Human-readable name of the workflow.</p> <code>url</code> <code>str</code> <p>URI to the workflow source code (typically a GitHub URL).</p> <code>workflow_type</code> <code>str</code> <p>Type of workflow (must be a controlled vocabulary term). When the workflow is bound to a writable catalog, setting this property will update the catalog record. The new value must be a valid term from the Workflow_Type vocabulary.</p> <code>version</code> <code>str | None</code> <p>Version identifier (semantic versioning).</p> <code>description</code> <code>str | None</code> <p>Description of workflow purpose and behavior. When the workflow is bound to a writable catalog, setting this property will update the catalog record.</p> <code>rid</code> <code>RID | None</code> <p>Resource Identifier if registered in catalog.</p> <code>checksum</code> <code>str | None</code> <p>Git hash of workflow source code.</p> <code>is_notebook</code> <code>bool</code> <p>Whether workflow is a Jupyter notebook.</p> Note <p>The recommended way to create a Workflow is via :meth:<code>DerivaML.create_workflow() &lt;deriva_ml.DerivaML.create_workflow&gt;</code>, which validates the workflow type against the catalog vocabulary::</p> <pre><code>&gt;&gt;&gt; workflow = ml.create_workflow(\n...     name=\"RNA Analysis\",\n...     workflow_type=\"python_notebook\",\n...     description=\"RNA sequence analysis\"\n... )\n</code></pre> Example <p>Create a workflow directly (without catalog validation)::</p> <pre><code>&gt;&gt;&gt; workflow = Workflow(\n...     name=\"RNA Analysis\",\n...     url=\"https://github.com/org/repo/analysis.ipynb\",\n...     workflow_type=\"python_notebook\",\n...     version=\"1.0.0\",\n...     description=\"RNA sequence analysis\"\n... )\n</code></pre> <p>Look up an existing workflow by RID and update its properties::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.description = \"Updated description for RNA analysis\"\n&gt;&gt;&gt; workflow.workflow_type = \"python_script\"\n&gt;&gt;&gt; print(workflow.description)\nUpdated description for RNA analysis\n</code></pre> <p>Look up by URL and update::</p> <pre><code>&gt;&gt;&gt; url = \"https://github.com/org/repo/blob/abc123/analysis.py\"\n&gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(url)\n&gt;&gt;&gt; workflow.description = \"New description\"\n</code></pre> <p>Attempting to update on a read-only catalog raises an error::</p> <pre><code>&gt;&gt;&gt; snapshot_ml = ml.catalog_snapshot(\"2023-01-15T10:30:00\")\n&gt;&gt;&gt; workflow = snapshot_ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.description = \"New description\"  # Raises DerivaMLException\n</code></pre> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>class Workflow(BaseModel):\n    \"\"\"Represents a computational workflow in DerivaML.\n\n    A workflow defines a computational process or analysis pipeline. Each workflow has\n    a unique identifier, source code location, and type. Workflows are typically\n    associated with Git repositories for version control.\n\n    When a Workflow is retrieved via ``lookup_workflow(rid)`` or ``lookup_workflow_by_url()``,\n    it is bound to a catalog and its ``description`` and ``workflow_type`` properties become\n    writable. Setting these properties will update the catalog record. If the catalog is\n    read-only (a snapshot), attempting to set them will raise a ``DerivaMLException``.\n\n    Attributes:\n        name (str): Human-readable name of the workflow.\n        url (str): URI to the workflow source code (typically a GitHub URL).\n        workflow_type (str): Type of workflow (must be a controlled vocabulary term).\n            When the workflow is bound to a writable catalog, setting this property\n            will update the catalog record. The new value must be a valid term from\n            the Workflow_Type vocabulary.\n        version (str | None): Version identifier (semantic versioning).\n        description (str | None): Description of workflow purpose and behavior.\n            When the workflow is bound to a writable catalog, setting this property\n            will update the catalog record.\n        rid (RID | None): Resource Identifier if registered in catalog.\n        checksum (str | None): Git hash of workflow source code.\n        is_notebook (bool): Whether workflow is a Jupyter notebook.\n\n    Note:\n        The recommended way to create a Workflow is via :meth:`DerivaML.create_workflow()\n        &lt;deriva_ml.DerivaML.create_workflow&gt;`, which validates the workflow type against\n        the catalog vocabulary::\n\n            &gt;&gt;&gt; workflow = ml.create_workflow(\n            ...     name=\"RNA Analysis\",\n            ...     workflow_type=\"python_notebook\",\n            ...     description=\"RNA sequence analysis\"\n            ... )\n\n    Example:\n        Create a workflow directly (without catalog validation)::\n\n            &gt;&gt;&gt; workflow = Workflow(\n            ...     name=\"RNA Analysis\",\n            ...     url=\"https://github.com/org/repo/analysis.ipynb\",\n            ...     workflow_type=\"python_notebook\",\n            ...     version=\"1.0.0\",\n            ...     description=\"RNA sequence analysis\"\n            ... )\n\n        Look up an existing workflow by RID and update its properties::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.description = \"Updated description for RNA analysis\"\n            &gt;&gt;&gt; workflow.workflow_type = \"python_script\"\n            &gt;&gt;&gt; print(workflow.description)\n            Updated description for RNA analysis\n\n        Look up by URL and update::\n\n            &gt;&gt;&gt; url = \"https://github.com/org/repo/blob/abc123/analysis.py\"\n            &gt;&gt;&gt; workflow = ml.lookup_workflow_by_url(url)\n            &gt;&gt;&gt; workflow.description = \"New description\"\n\n        Attempting to update on a read-only catalog raises an error::\n\n            &gt;&gt;&gt; snapshot_ml = ml.catalog_snapshot(\"2023-01-15T10:30:00\")\n            &gt;&gt;&gt; workflow = snapshot_ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.description = \"New description\"  # Raises DerivaMLException\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str\n    workflow_type: str\n    description: str | None = None\n    url: str | None = None\n    version: str | None = None\n    rid: RID | None = None\n    checksum: str | None = None\n    is_notebook: bool = False\n    git_root: Path | None = None\n\n    _ml_instance: \"DerivaMLCatalog | None\" = PrivateAttr(default=None)\n    _logger: logging.Logger = PrivateAttr(default=10)\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Override setattr to intercept description and workflow_type updates.\n\n        When the workflow is bound to a catalog (via lookup_workflow), setting\n        the ``description`` or ``workflow_type`` properties will update the catalog\n        record. If the catalog is read-only (a snapshot), a DerivaMLException is raised.\n\n        Args:\n            name: The attribute name being set.\n            value: The value to set.\n\n        Raises:\n            DerivaMLException: If attempting to set properties on a read-only\n                catalog (snapshot), or if workflow_type is not a valid vocabulary term.\n\n        Examples:\n            Update description::\n\n                &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n                &gt;&gt;&gt; workflow.description = \"Updated description\"\n\n            Update workflow type::\n\n                &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n                &gt;&gt;&gt; workflow.workflow_type = \"python_notebook\"\n        \"\"\"\n        # Only intercept updates after full initialization\n        # Use __dict__ check to avoid recursion during Pydantic model construction\n        if (\n            \"__pydantic_private__\" in self.__dict__\n            and self.__dict__.get(\"__pydantic_private__\", {}).get(\"_ml_instance\") is not None\n        ):\n            if name == \"description\":\n                self._update_description_in_catalog(value)\n            elif name == \"workflow_type\":\n                self._update_workflow_type_in_catalog(value)\n        super().__setattr__(name, value)\n\n    def _check_writable_catalog(self, operation: str) -&gt; None:\n        \"\"\"Check that the catalog is writable and workflow is registered.\n\n        Args:\n            operation: Description of the operation being attempted.\n\n        Raises:\n            DerivaMLException: If the workflow is not registered (no RID),\n                or if the catalog is read-only (a snapshot).\n        \"\"\"\n        # Import here to avoid circular dependency at module load\n        import importlib\n        _deriva_core = importlib.import_module(\"deriva.core\")\n        ErmrestSnapshot = _deriva_core.ErmrestSnapshot\n\n        if self.rid is None:\n            raise DerivaMLException(\n                f\"Cannot {operation}: Workflow is not registered in the catalog (no RID)\"\n            )\n\n        if isinstance(self._ml_instance.catalog, ErmrestSnapshot):\n            raise DerivaMLException(\n                f\"Cannot {operation} on a read-only catalog snapshot. \"\n                \"Use a writable catalog connection instead.\"\n            )\n\n    def _update_description_in_catalog(self, new_description: str | None) -&gt; None:\n        \"\"\"Update the description field in the catalog.\n\n        This internal method is called when the description property is set\n        on a catalog-bound Workflow object.\n\n        Args:\n            new_description: The new description value.\n\n        Raises:\n            DerivaMLException: If the workflow is not registered (no RID),\n                or if the catalog is read-only (a snapshot).\n        \"\"\"\n        self._check_writable_catalog(\"update description\")\n\n        # Update the catalog record\n        pb = self._ml_instance.pathBuilder()\n        workflow_path = pb.schemas[self._ml_instance.ml_schema].Workflow\n        workflow_path.update([{\"RID\": self.rid, \"Description\": new_description}])\n\n    def _update_workflow_type_in_catalog(self, new_workflow_type: str) -&gt; None:\n        \"\"\"Update the workflow_type field in the catalog.\n\n        This internal method is called when the workflow_type property is set\n        on a catalog-bound Workflow object. The new workflow type must be a valid\n        term from the Workflow_Type vocabulary.\n\n        Args:\n            new_workflow_type: The new workflow type (must be a valid vocabulary term).\n\n        Raises:\n            DerivaMLException: If the workflow is not registered (no RID),\n                the catalog is read-only (a snapshot), or the workflow_type\n                is not a valid vocabulary term.\n        \"\"\"\n        self._check_writable_catalog(\"update workflow_type\")\n\n        # Validate that the new workflow type exists in vocabulary\n        from deriva_ml.core.definitions import MLVocab\n        self._ml_instance.lookup_term(MLVocab.workflow_type, new_workflow_type)\n\n        # Update the catalog record\n        pb = self._ml_instance.pathBuilder()\n        workflow_path = pb.schemas[self._ml_instance.ml_schema].Workflow\n        workflow_path.update([{\"RID\": self.rid, \"Workflow_Type\": new_workflow_type}])\n\n    @model_validator(mode=\"after\")\n    def setup_url_checksum(self) -&gt; \"Workflow\":\n        \"\"\"Creates a workflow from the current execution context.\n\n        Identifies the currently executing program (script or notebook) and creates\n        a workflow definition. Automatically determines the Git repository information\n        and source code checksum.\n\n        The behavior can be configured using environment variables:\n            - DERIVA_ML_WORKFLOW_URL: Override the detected workflow URL\n            - DERIVA_ML_WORKFLOW_CHECKSUM: Override the computed checksum\n            - DERIVA_MCP_IN_DOCKER: Set to \"true\" to use Docker metadata instead of git\n\n        Docker environment variables (used when DERIVA_MCP_IN_DOCKER=true):\n            - DERIVA_MCP_VERSION: Semantic version of the Docker image\n            - DERIVA_MCP_GIT_COMMIT: Git commit hash at build time\n            - DERIVA_MCP_IMAGE_DIGEST: Docker image digest (unique identifier)\n            - DERIVA_MCP_IMAGE_NAME: Docker image name (e.g., ghcr.io/org/repo)\n\n        Args:\n\n        Returns:\n            Workflow: New workflow instance with detected Git information.\n\n        Raises:\n            DerivaMLException: If not in a Git repository or detection fails (non-Docker).\n\n        Example:\n            &gt;&gt;&gt; workflow = Workflow.create_workflow(\n            ...     name=\"Sample Analysis\",\n            ...     workflow_type=\"python_script\",\n            ...     description=\"Process sample data\"\n            ... )\n        \"\"\"\n        self._logger = logging.getLogger(\"deriva_ml\")\n\n        # Check if running in Docker container (no git repo available)\n        if os.environ.get(\"DERIVA_MCP_IN_DOCKER\", \"\").lower() == \"true\":\n            # Use Docker image metadata for provenance\n            self.version = self.version or os.environ.get(\"DERIVA_MCP_VERSION\", \"\")\n\n            # Use image digest as checksum (unique identifier for the container)\n            # Fall back to git commit if digest not available\n            self.checksum = self.checksum or (\n                os.environ.get(\"DERIVA_MCP_IMAGE_DIGEST\", \"\")\n                or os.environ.get(\"DERIVA_MCP_GIT_COMMIT\", \"\")\n            )\n\n            # Build URL pointing to the Docker image or source repo\n            if not self.url:\n                image_name = os.environ.get(\n                    \"DERIVA_MCP_IMAGE_NAME\",\n                    \"ghcr.io/informatics-isi-edu/deriva-ml-mcp\",\n                )\n                image_digest = os.environ.get(\"DERIVA_MCP_IMAGE_DIGEST\", \"\")\n                if image_digest:\n                    # URL format: image@sha256:digest\n                    self.url = f\"{image_name}@{image_digest}\"\n                else:\n                    # Fall back to source repo with git commit\n                    source_url = \"https://github.com/informatics-isi-edu/deriva-ml-mcp\"\n                    git_commit = os.environ.get(\"DERIVA_MCP_GIT_COMMIT\", \"\")\n                    self.url = f\"{source_url}/commit/{git_commit}\" if git_commit else source_url\n\n            return self\n\n        # Check to see if execution file info is being passed in by calling program (notebook runner)\n        if \"DERIVA_ML_WORKFLOW_URL\" in os.environ:\n            self.url = os.environ[\"DERIVA_ML_WORKFLOW_URL\"]\n            self.checksum = os.environ.get(\"DERIVA_ML_WORKFLOW_CHECKSUM\", \"\")\n            notebook_path = os.environ.get(\"DERIVA_ML_NOTEBOOK_PATH\")\n            if notebook_path:\n                self.git_root = Workflow._get_git_root(Path(notebook_path))\n            self.is_notebook = True\n            return self\n\n        # Standard git detection for local development\n        if not self.url:\n            path, self.is_notebook = Workflow._get_python_script()\n            self.url, self.checksum = Workflow.get_url_and_checksum(path)\n            self.git_root = Workflow._get_git_root(path)\n\n        self.version = self.version or Workflow.get_dynamic_version(root=str(self.git_root or Path.cwd()))\n        return self\n\n    @staticmethod\n    def get_url_and_checksum(executable_path: Path) -&gt; tuple[str, str]:\n        \"\"\"Determines the Git URL and checksum for a file.\n\n        Computes the Git repository URL and file checksum for the specified path.\n        For notebooks, strips cell outputs before computing the checksum.\n\n        Args:\n            executable_path: Path to the workflow file.\n\n        Returns:\n            tuple[str, str]: (GitHub URL, Git object hash)\n\n        Raises:\n            DerivaMLException: If not in a Git repository.\n\n        Example:\n            &gt;&gt;&gt; url, checksum = Workflow.get_url_and_checksum(Path(\"analysis.ipynb\"))\n            &gt;&gt;&gt; print(f\"URL: {url}\")\n            &gt;&gt;&gt; print(f\"Checksum: {checksum}\")\n        \"\"\"\n        try:\n            subprocess.run(\n                \"git rev-parse --is-inside-work-tree\",\n                capture_output=True,\n                text=True,\n                shell=True,\n                check=True,\n            )\n        except subprocess.CalledProcessError:\n            raise DerivaMLException(\"Not executing in a Git repository.\")\n\n        github_url, is_dirty = Workflow._github_url(executable_path)\n\n        if is_dirty:\n            logging.getLogger(\"deriva_ml\").warning(\n                f\"File {executable_path} has been modified since last commit. Consider commiting before executing\"\n            )\n\n        # If you are in a notebook, strip out the outputs before computing the checksum.\n        cmd = (\n            f\"nbstripout -t {executable_path} | git hash-object --stdin\"\n            if \"ipynb\" == executable_path.suffix\n            else f\"git hash-object {executable_path}\"\n        )\n        checksum = (\n            subprocess.run(\n                cmd,\n                capture_output=True,\n                text=True,\n                check=False,\n                shell=True,\n            ).stdout.strip()\n            if executable_path != \"REPL\"\n            else \"1\"\n        )\n        return github_url, checksum\n\n    @staticmethod\n    def _get_git_root(executable_path: Path) -&gt; str | None:\n        \"\"\"Gets the root directory of the Git repository.\n\n        Args:\n            executable_path: Path to check for Git repository.\n\n        Returns:\n            str | None: Absolute path to repository root, or None if not in repository.\n        \"\"\"\n        try:\n            result = subprocess.run(\n                [\"git\", \"rev-parse\", \"--show-toplevel\"],\n                cwd=executable_path.parent,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.DEVNULL,\n                text=True,\n                check=True,\n            )\n            return result.stdout.strip()\n        except subprocess.CalledProcessError:\n            return None  # Not in a git repository\n\n    @staticmethod\n    def _check_nbstrip_status() -&gt; None:\n        \"\"\"Checks if nbstripout is installed and configured.\n\n        Verifies that the nbstripout tool is available and properly installed in the\n        Git repository. Issues warnings if setup is incomplete.\n        \"\"\"\n        logger = logging.getLogger(\"deriva_ml\")\n        try:\n            if subprocess.run(\n                [\"nbstripout\", \"--is-installed\"],\n                check=False,\n                capture_output=True,\n            ).returncode:\n                logger.warning(\"nbstripout is not installed in repository. Please run nbstripout --install\")\n        except (subprocess.CalledProcessError, FileNotFoundError):\n            logger.warning(\"nbstripout is not found. Please install it with: pip install nbstripout\")\n\n    @staticmethod\n    def _get_notebook_path() -&gt; Path | None:\n        \"\"\"Gets the path of the currently executing notebook.\n\n        Returns:\n            Path | None: Absolute path to current notebook, or None if not in notebook.\n        \"\"\"\n\n        server, session = Workflow._get_notebook_session()\n\n        if server and session:\n            relative_path = session[\"notebook\"][\"path\"]\n            # Join the notebook directory with the relative path\n            return Path(server[\"root_dir\"]) / relative_path\n        else:\n            return None\n\n    @staticmethod\n    def _get_notebook_session() -&gt; tuple[dict[str, Any] | None, dict[str, Any] | None]:\n        \"\"\"Return the absolute path of the current notebook.\"\"\"\n        # Get the kernel's connection file and extract the kernel ID\n        try:\n            if not (connection_file := Path(get_kernel_connection()).name):\n                return None, None\n        except RuntimeError:\n            return None, None\n\n        # Extract kernel ID from connection filename.\n        # Standard Jupyter format: \"kernel-&lt;kernel_id&gt;.json\"\n        # PyCharm/other formats may vary: \"&lt;kernel_id&gt;.json\" or other patterns\n        kernel_id = None\n        if connection_file.startswith(\"kernel-\") and \"-\" in connection_file:\n            # Standard format: kernel-&lt;uuid&gt;.json\n            parts = connection_file.split(\"-\", 1)\n            if len(parts) &gt; 1:\n                kernel_id = parts[1].rsplit(\".\", 1)[0]\n        else:\n            # Fallback: assume filename (without extension) is the kernel ID\n            kernel_id = connection_file.rsplit(\".\", 1)[0]\n\n        if not kernel_id:\n            return None, None\n\n        # Look through the running server sessions to find the matching kernel ID\n        for server in get_servers():\n            try:\n                # If a token is required for authentication, include it in headers\n                token = server.get(\"token\", \"\")\n                headers = {}\n                if token:\n                    headers[\"Authorization\"] = f\"token {token}\"\n\n                try:\n                    sessions_url = server[\"url\"] + \"api/sessions\"\n                    response = requests.get(sessions_url, headers=headers)\n                    response.raise_for_status()\n                    sessions = response.json()\n                except RequestException as e:\n                    raise e\n                for sess in sessions:\n                    if sess[\"kernel\"][\"id\"] == kernel_id:\n                        return server, sess\n            except Exception as _e:\n                # Ignore servers we can't connect to.\n                pass\n        return None, None\n\n    @staticmethod\n    def _in_repl():\n        # Standard Python interactive mode\n        if hasattr(sys, \"ps1\"):\n            return True\n\n        # Interactive mode forced by -i\n        if sys.flags.interactive:\n            return True\n\n        # IPython / Jupyter detection\n        try:\n            from IPython import get_ipython\n\n            if get_ipython() is not None:\n                return True\n        except ImportError:\n            pass\n\n        return False\n\n    @staticmethod\n    def _get_python_script() -&gt; tuple[Path, bool]:\n        \"\"\"Return the path to the currently executing script\"\"\"\n        is_notebook = Workflow._get_notebook_path() is not None\n        return Path(_get_calling_module()), is_notebook\n\n    @staticmethod\n    def _github_url(executable_path: Path) -&gt; tuple[str, bool]:\n        \"\"\"Return a GitHub URL for the latest commit of the script from which this routine is called.\n\n        This routine is used to be called from a script or notebook (e.g., python -m file). It assumes that\n        the file is in a GitHub repository and committed.  It returns a URL to the last commited version of this\n        file in GitHub.\n\n        Returns: A tuple with the gethub_url and a boolean to indicate if uncommited changes\n            have been made to the file.\n\n        \"\"\"\n\n        # Get repo URL from local GitHub repo.\n        if executable_path == \"REPL\":\n            return \"REPL\", True\n        try:\n            result = subprocess.run(\n                [\"git\", \"remote\", \"get-url\", \"origin\"],\n                capture_output=True,\n                text=True,\n                cwd=executable_path.parent,\n            )\n            github_url = result.stdout.strip().removesuffix(\".git\")\n        except subprocess.CalledProcessError:\n            raise DerivaMLException(\"No GIT remote found\")\n\n        # Find the root directory for the repository\n        repo_root = Workflow._get_git_root(executable_path)\n\n        # Now check to see if a file has been modified since the last commit.\n        try:\n            result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"],\n                cwd=executable_path.parent,\n                capture_output=True,\n                text=True,\n                check=False,\n            )\n            is_dirty = bool(\"M \" in result.stdout.strip())  # Returns True if the output indicates a modified file\n        except subprocess.CalledProcessError:\n            is_dirty = False  # If the Git command fails, assume no changes\n\n        \"\"\"Get SHA-1 hash of latest commit of the file in the repository\"\"\"\n\n        result = subprocess.run(\n            [\"git\", \"log\", \"-n\", \"1\", \"--pretty=format:%H\", executable_path],\n            cwd=repo_root,\n            capture_output=True,\n            text=True,\n            check=False,\n        )\n        sha = result.stdout.strip()\n        url = f\"{github_url}/blob/{sha}/{executable_path.relative_to(repo_root)}\"\n        return url, is_dirty\n\n    @staticmethod\n    def get_dynamic_version(root: str | os.PathLike | None = None) -&gt; str:\n        \"\"\"\n        Return a dynamic version string based on VCS state (setuptools_scm),\n        including dirty/uncommitted changes if configured.\n\n        Works under uv / Python 3.10+ by forcing setuptools to use stdlib distutils.\n        \"\"\"\n        # 1) Tell setuptools to use stdlib distutils (or no override) to avoid\n        #    the '_distutils_hack' assertion you hit.\n        os.environ.setdefault(\"SETUPTOOLS_USE_DISTUTILS\", \"stdlib\")\n\n        warnings.filterwarnings(\n            \"ignore\",\n            category=UserWarning,\n            module=\"_distutils_hack\",\n        )\n        try:\n            from setuptools_scm import get_version\n        except Exception as e:  # ImportError or anything environment-specific\n            raise RuntimeError(f\"setuptools_scm is not available: {e}\") from e\n\n        if root is None:\n            # Adjust this to point at your repo root if needed\n            root = Path(__file__).resolve().parents[1]\n\n        return get_version(root=root)\n</code></pre>"},{"location":"code-docs/workflow/#deriva_ml.execution.workflow.Workflow.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(\n    name: str, value: Any\n) -&gt; None\n</code></pre> <p>Override setattr to intercept description and workflow_type updates.</p> <p>When the workflow is bound to a catalog (via lookup_workflow), setting the <code>description</code> or <code>workflow_type</code> properties will update the catalog record. If the catalog is read-only (a snapshot), a DerivaMLException is raised.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The attribute name being set.</p> required <code>value</code> <code>Any</code> <p>The value to set.</p> required <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If attempting to set properties on a read-only catalog (snapshot), or if workflow_type is not a valid vocabulary term.</p> <p>Examples:</p> <p>Update description::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.description = \"Updated description\"\n</code></pre> <p>Update workflow type::</p> <pre><code>&gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n&gt;&gt;&gt; workflow.workflow_type = \"python_notebook\"\n</code></pre> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Override setattr to intercept description and workflow_type updates.\n\n    When the workflow is bound to a catalog (via lookup_workflow), setting\n    the ``description`` or ``workflow_type`` properties will update the catalog\n    record. If the catalog is read-only (a snapshot), a DerivaMLException is raised.\n\n    Args:\n        name: The attribute name being set.\n        value: The value to set.\n\n    Raises:\n        DerivaMLException: If attempting to set properties on a read-only\n            catalog (snapshot), or if workflow_type is not a valid vocabulary term.\n\n    Examples:\n        Update description::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.description = \"Updated description\"\n\n        Update workflow type::\n\n            &gt;&gt;&gt; workflow = ml.lookup_workflow(\"2-ABC1\")\n            &gt;&gt;&gt; workflow.workflow_type = \"python_notebook\"\n    \"\"\"\n    # Only intercept updates after full initialization\n    # Use __dict__ check to avoid recursion during Pydantic model construction\n    if (\n        \"__pydantic_private__\" in self.__dict__\n        and self.__dict__.get(\"__pydantic_private__\", {}).get(\"_ml_instance\") is not None\n    ):\n        if name == \"description\":\n            self._update_description_in_catalog(value)\n        elif name == \"workflow_type\":\n            self._update_workflow_type_in_catalog(value)\n    super().__setattr__(name, value)\n</code></pre>"},{"location":"code-docs/workflow/#deriva_ml.execution.workflow.Workflow.get_dynamic_version","title":"get_dynamic_version  <code>staticmethod</code>","text":"<pre><code>get_dynamic_version(\n    root: str | PathLike | None = None,\n) -&gt; str\n</code></pre> <p>Return a dynamic version string based on VCS state (setuptools_scm), including dirty/uncommitted changes if configured.</p> <p>Works under uv / Python 3.10+ by forcing setuptools to use stdlib distutils.</p> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>@staticmethod\ndef get_dynamic_version(root: str | os.PathLike | None = None) -&gt; str:\n    \"\"\"\n    Return a dynamic version string based on VCS state (setuptools_scm),\n    including dirty/uncommitted changes if configured.\n\n    Works under uv / Python 3.10+ by forcing setuptools to use stdlib distutils.\n    \"\"\"\n    # 1) Tell setuptools to use stdlib distutils (or no override) to avoid\n    #    the '_distutils_hack' assertion you hit.\n    os.environ.setdefault(\"SETUPTOOLS_USE_DISTUTILS\", \"stdlib\")\n\n    warnings.filterwarnings(\n        \"ignore\",\n        category=UserWarning,\n        module=\"_distutils_hack\",\n    )\n    try:\n        from setuptools_scm import get_version\n    except Exception as e:  # ImportError or anything environment-specific\n        raise RuntimeError(f\"setuptools_scm is not available: {e}\") from e\n\n    if root is None:\n        # Adjust this to point at your repo root if needed\n        root = Path(__file__).resolve().parents[1]\n\n    return get_version(root=root)\n</code></pre>"},{"location":"code-docs/workflow/#deriva_ml.execution.workflow.Workflow.get_url_and_checksum","title":"get_url_and_checksum  <code>staticmethod</code>","text":"<pre><code>get_url_and_checksum(\n    executable_path: Path,\n) -&gt; tuple[str, str]\n</code></pre> <p>Determines the Git URL and checksum for a file.</p> <p>Computes the Git repository URL and file checksum for the specified path. For notebooks, strips cell outputs before computing the checksum.</p> <p>Parameters:</p> Name Type Description Default <code>executable_path</code> <code>Path</code> <p>Path to the workflow file.</p> required <p>Returns:</p> Type Description <code>tuple[str, str]</code> <p>tuple[str, str]: (GitHub URL, Git object hash)</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If not in a Git repository.</p> Example <p>url, checksum = Workflow.get_url_and_checksum(Path(\"analysis.ipynb\")) print(f\"URL: {url}\") print(f\"Checksum: {checksum}\")</p> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>@staticmethod\ndef get_url_and_checksum(executable_path: Path) -&gt; tuple[str, str]:\n    \"\"\"Determines the Git URL and checksum for a file.\n\n    Computes the Git repository URL and file checksum for the specified path.\n    For notebooks, strips cell outputs before computing the checksum.\n\n    Args:\n        executable_path: Path to the workflow file.\n\n    Returns:\n        tuple[str, str]: (GitHub URL, Git object hash)\n\n    Raises:\n        DerivaMLException: If not in a Git repository.\n\n    Example:\n        &gt;&gt;&gt; url, checksum = Workflow.get_url_and_checksum(Path(\"analysis.ipynb\"))\n        &gt;&gt;&gt; print(f\"URL: {url}\")\n        &gt;&gt;&gt; print(f\"Checksum: {checksum}\")\n    \"\"\"\n    try:\n        subprocess.run(\n            \"git rev-parse --is-inside-work-tree\",\n            capture_output=True,\n            text=True,\n            shell=True,\n            check=True,\n        )\n    except subprocess.CalledProcessError:\n        raise DerivaMLException(\"Not executing in a Git repository.\")\n\n    github_url, is_dirty = Workflow._github_url(executable_path)\n\n    if is_dirty:\n        logging.getLogger(\"deriva_ml\").warning(\n            f\"File {executable_path} has been modified since last commit. Consider commiting before executing\"\n        )\n\n    # If you are in a notebook, strip out the outputs before computing the checksum.\n    cmd = (\n        f\"nbstripout -t {executable_path} | git hash-object --stdin\"\n        if \"ipynb\" == executable_path.suffix\n        else f\"git hash-object {executable_path}\"\n    )\n    checksum = (\n        subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=False,\n            shell=True,\n        ).stdout.strip()\n        if executable_path != \"REPL\"\n        else \"1\"\n    )\n    return github_url, checksum\n</code></pre>"},{"location":"code-docs/workflow/#deriva_ml.execution.workflow.Workflow.setup_url_checksum","title":"setup_url_checksum","text":"<pre><code>setup_url_checksum() -&gt; 'Workflow'\n</code></pre> <p>Creates a workflow from the current execution context.</p> <p>Identifies the currently executing program (script or notebook) and creates a workflow definition. Automatically determines the Git repository information and source code checksum.</p> The behavior can be configured using environment variables <ul> <li>DERIVA_ML_WORKFLOW_URL: Override the detected workflow URL</li> <li>DERIVA_ML_WORKFLOW_CHECKSUM: Override the computed checksum</li> <li>DERIVA_MCP_IN_DOCKER: Set to \"true\" to use Docker metadata instead of git</li> </ul> <p>Docker environment variables (used when DERIVA_MCP_IN_DOCKER=true):     - DERIVA_MCP_VERSION: Semantic version of the Docker image     - DERIVA_MCP_GIT_COMMIT: Git commit hash at build time     - DERIVA_MCP_IMAGE_DIGEST: Docker image digest (unique identifier)     - DERIVA_MCP_IMAGE_NAME: Docker image name (e.g., ghcr.io/org/repo)</p> <p>Args:</p> <p>Returns:</p> Name Type Description <code>Workflow</code> <code>'Workflow'</code> <p>New workflow instance with detected Git information.</p> <p>Raises:</p> Type Description <code>DerivaMLException</code> <p>If not in a Git repository or detection fails (non-Docker).</p> Example <p>workflow = Workflow.create_workflow( ...     name=\"Sample Analysis\", ...     workflow_type=\"python_script\", ...     description=\"Process sample data\" ... )</p> Source code in <code>src/deriva_ml/execution/workflow.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_url_checksum(self) -&gt; \"Workflow\":\n    \"\"\"Creates a workflow from the current execution context.\n\n    Identifies the currently executing program (script or notebook) and creates\n    a workflow definition. Automatically determines the Git repository information\n    and source code checksum.\n\n    The behavior can be configured using environment variables:\n        - DERIVA_ML_WORKFLOW_URL: Override the detected workflow URL\n        - DERIVA_ML_WORKFLOW_CHECKSUM: Override the computed checksum\n        - DERIVA_MCP_IN_DOCKER: Set to \"true\" to use Docker metadata instead of git\n\n    Docker environment variables (used when DERIVA_MCP_IN_DOCKER=true):\n        - DERIVA_MCP_VERSION: Semantic version of the Docker image\n        - DERIVA_MCP_GIT_COMMIT: Git commit hash at build time\n        - DERIVA_MCP_IMAGE_DIGEST: Docker image digest (unique identifier)\n        - DERIVA_MCP_IMAGE_NAME: Docker image name (e.g., ghcr.io/org/repo)\n\n    Args:\n\n    Returns:\n        Workflow: New workflow instance with detected Git information.\n\n    Raises:\n        DerivaMLException: If not in a Git repository or detection fails (non-Docker).\n\n    Example:\n        &gt;&gt;&gt; workflow = Workflow.create_workflow(\n        ...     name=\"Sample Analysis\",\n        ...     workflow_type=\"python_script\",\n        ...     description=\"Process sample data\"\n        ... )\n    \"\"\"\n    self._logger = logging.getLogger(\"deriva_ml\")\n\n    # Check if running in Docker container (no git repo available)\n    if os.environ.get(\"DERIVA_MCP_IN_DOCKER\", \"\").lower() == \"true\":\n        # Use Docker image metadata for provenance\n        self.version = self.version or os.environ.get(\"DERIVA_MCP_VERSION\", \"\")\n\n        # Use image digest as checksum (unique identifier for the container)\n        # Fall back to git commit if digest not available\n        self.checksum = self.checksum or (\n            os.environ.get(\"DERIVA_MCP_IMAGE_DIGEST\", \"\")\n            or os.environ.get(\"DERIVA_MCP_GIT_COMMIT\", \"\")\n        )\n\n        # Build URL pointing to the Docker image or source repo\n        if not self.url:\n            image_name = os.environ.get(\n                \"DERIVA_MCP_IMAGE_NAME\",\n                \"ghcr.io/informatics-isi-edu/deriva-ml-mcp\",\n            )\n            image_digest = os.environ.get(\"DERIVA_MCP_IMAGE_DIGEST\", \"\")\n            if image_digest:\n                # URL format: image@sha256:digest\n                self.url = f\"{image_name}@{image_digest}\"\n            else:\n                # Fall back to source repo with git commit\n                source_url = \"https://github.com/informatics-isi-edu/deriva-ml-mcp\"\n                git_commit = os.environ.get(\"DERIVA_MCP_GIT_COMMIT\", \"\")\n                self.url = f\"{source_url}/commit/{git_commit}\" if git_commit else source_url\n\n        return self\n\n    # Check to see if execution file info is being passed in by calling program (notebook runner)\n    if \"DERIVA_ML_WORKFLOW_URL\" in os.environ:\n        self.url = os.environ[\"DERIVA_ML_WORKFLOW_URL\"]\n        self.checksum = os.environ.get(\"DERIVA_ML_WORKFLOW_CHECKSUM\", \"\")\n        notebook_path = os.environ.get(\"DERIVA_ML_NOTEBOOK_PATH\")\n        if notebook_path:\n            self.git_root = Workflow._get_git_root(Path(notebook_path))\n        self.is_notebook = True\n        return self\n\n    # Standard git detection for local development\n    if not self.url:\n        path, self.is_notebook = Workflow._get_python_script()\n        self.url, self.checksum = Workflow.get_url_and_checksum(path)\n        self.git_root = Workflow._get_git_root(path)\n\n    self.version = self.version or Workflow.get_dynamic_version(root=str(self.git_root or Path.cwd()))\n    return self\n</code></pre>"},{"location":"user-guide/annotations/","title":"Catalog Annotations","text":"<p>Deriva catalogs use annotations to control how data is displayed in the Chaise web interface. Annotations configure things like:</p> <ul> <li>Display names for tables and columns</li> <li>Which columns appear in list vs. detail views</li> <li>How related tables are shown</li> <li>Row ordering and pagination</li> <li>Custom formatting and markdown templates</li> <li>Faceted search configuration</li> </ul> <p>DerivaML provides annotation builder classes that make it easier to create and manage annotations with IDE autocompletion, type safety, and validation.</p>"},{"location":"user-guide/annotations/#quick-start","title":"Quick Start","text":"<pre><code>from deriva_ml.model import (\n    TableHandle, Display, VisibleColumns, TableDisplay,\n    PseudoColumn, OutboundFK, fk_constraint, SortKey,\n    CONTEXT_COMPACT, CONTEXT_DETAILED\n)\n\n# Get a table handle\ntable = ml.model.name_to_table(\"Subject\")\nhandle = TableHandle(table)\n\n# Set display name and description\nhandle.set_annotation(Display(\n    name=\"Research Subjects\",\n    comment=\"Individuals enrolled in the study\"\n))\n\n# Configure visible columns\nvc = VisibleColumns()\nvc.compact([\"RID\", \"Name\", \"Species\", \"Age\"])\nvc.detailed([\"RID\", \"Name\", \"Species\", \"Age\", \"Enrollment_Date\", \"Notes\"])\nhandle.set_annotation(vc)\n\n# Set row name pattern (how rows appear in dropdowns)\ntd = TableDisplay()\ntd.row_name(\"{{{Name}}} ({{{Species}}})\")\nhandle.set_annotation(td)\n</code></pre>"},{"location":"user-guide/annotations/#understanding-contexts","title":"Understanding Contexts","text":"<p>Annotations often apply to specific contexts - different places where data appears in the UI:</p> Context Description Example Use <code>*</code> Default for all contexts Fallback settings <code>compact</code> Table/list views Search results, data browser <code>compact/brief</code> Abbreviated previews Tooltips, inline references <code>compact/select</code> Selection dropdowns Foreign key pickers <code>detailed</code> Full record view Single record page <code>entry</code> Create/edit forms Data entry <code>entry/create</code> Create form only New record form <code>entry/edit</code> Edit form only Existing record form <code>filter</code> Faceted search Search sidebar <p>DerivaML provides constants for common contexts:</p> <pre><code>from deriva_ml.model import (\n    CONTEXT_DEFAULT,    # \"*\"\n    CONTEXT_COMPACT,    # \"compact\"\n    CONTEXT_DETAILED,   # \"detailed\"\n    CONTEXT_ENTRY,      # \"entry\"\n    CONTEXT_FILTER,     # \"filter\"\n)\n</code></pre>"},{"location":"user-guide/annotations/#annotation-builders","title":"Annotation Builders","text":""},{"location":"user-guide/annotations/#display-annotation","title":"Display Annotation","text":"<p>Controls basic display properties for tables and columns.</p> <pre><code>from deriva_ml.model import Display, NameStyle\n\n# Simple display name\ndisplay = Display(name=\"Friendly Name\")\n\n# With markdown name (mutually exclusive with name)\ndisplay = Display(markdown_name=\"**Bold** Name\")\n\n# With description/tooltip\ndisplay = Display(\n    name=\"Subjects\",\n    comment=\"Research subjects enrolled in the study\"\n)\n\n# With name styling\ndisplay = Display(\n    name_style=NameStyle(\n        underline_space=True,  # Convert underscores to spaces\n        title_case=True        # Apply title case\n    )\n)\n\n# Context-specific options\ndisplay = Display(\n    name=\"Value\",\n    show_null={\n        CONTEXT_COMPACT: False,      # Hide nulls in lists\n        CONTEXT_DETAILED: '\"N/A\"'    # Show \"N/A\" in detail view\n    }\n)\n\n# Apply to table\nhandle.set_annotation(display)\n</code></pre>"},{"location":"user-guide/annotations/#visible-columns","title":"Visible Columns","text":"<p>Controls which columns appear in different UI contexts.</p> <pre><code>from deriva_ml.model import VisibleColumns, PseudoColumn, fk_constraint\n\nvc = VisibleColumns()\n\n# Simple column lists\nvc.compact([\"RID\", \"Name\", \"Status\"])\nvc.detailed([\"RID\", \"Name\", \"Status\", \"Description\", \"Created\"])\nvc.entry([\"Name\", \"Status\", \"Description\"])\n\n# Include foreign key references (shows related data)\nvc.compact([\n    \"RID\",\n    \"Name\",\n    fk_constraint(\"domain\", \"Subject_Species_fkey\"),  # FK reference\n])\n\n# Include pseudo-columns (computed/derived values)\nvc.detailed([\n    \"RID\",\n    \"Name\",\n    PseudoColumn(\n        source=\"Description\",\n        markdown_name=\"Notes\"  # Custom display name\n    ),\n])\n\n# Set default for all contexts\nvc.default([\"RID\", \"Name\"])\n\n# Reference another context (inherit its settings)\nvc.set_context(\"compact/brief\", \"compact\")\n\nhandle.set_annotation(vc)\n</code></pre>"},{"location":"user-guide/annotations/#visible-foreign-keys","title":"Visible Foreign Keys","text":"<p>Controls which related tables appear in the detail view.</p> <pre><code>from deriva_ml.model import VisibleForeignKeys, fk_constraint, PseudoColumn\n\nvfk = VisibleForeignKeys()\n\n# Show inbound foreign keys (tables that reference this one)\nvfk.detailed([\n    fk_constraint(\"domain\", \"Image_Subject_fkey\"),\n    fk_constraint(\"domain\", \"Diagnosis_Subject_fkey\"),\n])\n\n# Set for all contexts\nvfk.default([fk_constraint(\"domain\", \"Sample_Subject_fkey\")])\n\nhandle.set_annotation(vfk)\n</code></pre>"},{"location":"user-guide/annotations/#table-display","title":"Table Display","text":"<p>Controls table-level display options like row naming and ordering.</p> <pre><code>from deriva_ml.model import TableDisplay, TableDisplayOptions, SortKey, TemplateEngine\n\ntd = TableDisplay()\n\n# Row name pattern (used in dropdowns, references)\ntd.row_name(\"{{{Name}}}\")\n\n# More complex pattern with multiple columns\ntd.row_name(\"{{{Name}}} - {{{RID}}}\")\n\n# With explicit template engine\ntd.row_name(\n    \"{{{Name}}} ({{{Species}}})\",\n    template_engine=TemplateEngine.HANDLEBARS\n)\n\n# Configure compact view options\ntd.compact(TableDisplayOptions(\n    row_order=[\n        SortKey(\"Name\"),                      # Ascending\n        SortKey(\"Created\", descending=True),  # Descending\n    ],\n    page_size=50\n))\n\n# Configure detailed view options\ntd.detailed(TableDisplayOptions(\n    collapse_toc_panel=True,\n    hide_column_headers=False\n))\n\nhandle.set_annotation(td)\n</code></pre>"},{"location":"user-guide/annotations/#column-display","title":"Column Display","text":"<p>Controls how column values are rendered.</p> <pre><code>from deriva_ml.model import ColumnDisplay, ColumnDisplayOptions, PreFormat\n\ncd = ColumnDisplay()\n\n# Number formatting\ncd.default(ColumnDisplayOptions(\n    pre_format=PreFormat(format=\"%.2f\")  # Two decimal places\n))\n\n# Boolean formatting\ncd.default(ColumnDisplayOptions(\n    pre_format=PreFormat(\n        bool_true_value=\"Yes\",\n        bool_false_value=\"No\"\n    )\n))\n\n# Markdown pattern (make URLs clickable)\ncd.default(ColumnDisplayOptions(\n    markdown_pattern=\"[Link]({{{_value}}})\"\n))\n\n# Context-specific formatting\ncd.compact(ColumnDisplayOptions(\n    markdown_pattern=\"[{{{_value}}}]({{{_value}}})\"\n))\ncd.detailed(ColumnDisplayOptions(\n    markdown_pattern=\"**URL**: [{{{_value}}}]({{{_value}}})\"\n))\n\n# Apply to a column\ncol_handle = handle.column(\"URL\")\ncol_handle.annotations[ColumnDisplay.tag] = cd.to_dict()\ncol_handle.apply()\n</code></pre>"},{"location":"user-guide/annotations/#pseudo-columns","title":"Pseudo-Columns","text":"<p>Pseudo-columns display computed values, values from related tables, or custom markdown patterns.</p>"},{"location":"user-guide/annotations/#basic-pseudo-column","title":"Basic Pseudo-Column","text":"<pre><code>from deriva_ml.model import PseudoColumn\n\n# Simple column with custom name\npc = PseudoColumn(\n    source=\"Internal_ID\",\n    markdown_name=\"ID\"\n)\n</code></pre>"},{"location":"user-guide/annotations/#foreign-key-traversal","title":"Foreign Key Traversal","text":"<p>Display values from related tables by traversing foreign keys.</p> <pre><code>from deriva_ml.model import PseudoColumn, OutboundFK, InboundFK\n\n# Outbound: Follow FK from this table to another\n# Example: Image -&gt; Subject (get Subject name)\npc = PseudoColumn(\n    source=[\n        OutboundFK(\"domain\", \"Image_Subject_fkey\"),\n        \"Name\"  # Column in the referenced table\n    ],\n    markdown_name=\"Subject Name\"\n)\n\n# Inbound: Follow FK from another table to this one\n# Example: Subject &lt;- Images (count images)\npc = PseudoColumn(\n    source=[\n        InboundFK(\"domain\", \"Image_Subject_fkey\"),\n        \"RID\"\n    ],\n    aggregate=Aggregate.CNT,  # Count the related records\n    markdown_name=\"Image Count\"\n)\n\n# Multi-hop: Chain multiple FKs\n# Example: Image -&gt; Subject -&gt; Species\npc = PseudoColumn(\n    source=[\n        OutboundFK(\"domain\", \"Image_Subject_fkey\"),\n        OutboundFK(\"domain\", \"Subject_Species_fkey\"),\n        \"Name\"\n    ],\n    markdown_name=\"Species\"\n)\n</code></pre>"},{"location":"user-guide/annotations/#aggregates","title":"Aggregates","text":"<p>Aggregate values from related tables.</p> <pre><code>from deriva_ml.model import PseudoColumn, InboundFK, Aggregate\n\n# Count related records\npc = PseudoColumn(\n    source=[InboundFK(\"domain\", \"Sample_Subject_fkey\"), \"RID\"],\n    aggregate=Aggregate.CNT,\n    markdown_name=\"Sample Count\"\n)\n\n# Count distinct values\npc = PseudoColumn(\n    source=[InboundFK(\"domain\", \"Sample_Subject_fkey\"), \"Type\"],\n    aggregate=Aggregate.CNT_D,\n    markdown_name=\"Unique Types\"\n)\n\n# Min/max values\npc = PseudoColumn(\n    source=[InboundFK(\"domain\", \"Measurement_Subject_fkey\"), \"Value\"],\n    aggregate=Aggregate.MAX,\n    markdown_name=\"Max Value\"\n)\n\n# Array of values\npc = PseudoColumn(\n    source=[InboundFK(\"domain\", \"Tag_Subject_fkey\"), \"Name\"],\n    aggregate=Aggregate.ARRAY,\n    markdown_name=\"Tags\"\n)\n</code></pre>"},{"location":"user-guide/annotations/#display-options","title":"Display Options","text":"<pre><code>from deriva_ml.model import PseudoColumn, PseudoColumnDisplay, ArrayUxMode\n\npc = PseudoColumn(\n    source=\"URL\",\n    display=PseudoColumnDisplay(\n        markdown_pattern=\"[Download]({{{_value}}})\",\n        show_foreign_key_link=False\n    )\n)\n\n# Array display options\npc = PseudoColumn(\n    source=[InboundFK(\"domain\", \"Tag_Subject_fkey\"), \"Name\"],\n    aggregate=Aggregate.ARRAY,\n    display=PseudoColumnDisplay(\n        array_ux_mode=ArrayUxMode.CSV  # Show as comma-separated\n    )\n)\n</code></pre>"},{"location":"user-guide/annotations/#faceted-search","title":"Faceted Search","text":"<p>Configure the filter panel in the Chaise data browser.</p> <pre><code>from deriva_ml.model import (\n    VisibleColumns, Facet, FacetList, FacetRange,\n    FacetUxMode, OutboundFK\n)\n\n# Create facet list\nfacets = FacetList()\n\n# Simple choice facet\nfacets.add(Facet(\n    source=\"Status\",\n    open=True,  # Start expanded\n    markdown_name=\"Status\"\n))\n\n# FK-based facet\nfacets.add(Facet(\n    source=[OutboundFK(\"domain\", \"Subject_Species_fkey\"), \"Name\"],\n    markdown_name=\"Species\",\n    open=True\n))\n\n# Range facet for numeric values\nfacets.add(Facet(\n    source=\"Age\",\n    ux_mode=FacetUxMode.RANGES,\n    ranges=[\n        FacetRange(min=0, max=18),\n        FacetRange(min=18, max=65),\n        FacetRange(min=65)  # 65+\n    ],\n    markdown_name=\"Age Group\"\n))\n\n# Facet with preset choices\nfacets.add(Facet(\n    source=\"Priority\",\n    ux_mode=FacetUxMode.CHOICES,\n    choices=[\"High\", \"Medium\", \"Low\"],\n    hide_null_choice=True\n))\n\n# Check presence facet (has value / no value)\nfacets.add(Facet(\n    source=\"Notes\",\n    ux_mode=FacetUxMode.CHECK_PRESENCE,\n    markdown_name=\"Has Notes\"\n))\n\n# Apply to visible columns\nvc = VisibleColumns()\nvc.compact([\"RID\", \"Name\", \"Status\"])\nvc._contexts[\"filter\"] = facets.to_dict()\n\nhandle.set_annotation(vc)\n</code></pre>"},{"location":"user-guide/annotations/#handlebars-templates","title":"Handlebars Templates","text":"<p>Many annotations support Handlebars templates for custom formatting.</p>"},{"location":"user-guide/annotations/#available-variables","title":"Available Variables","text":"<pre><code># Get template variables for a table\nvars = ml.get_handlebars_template_variables(\"Subject\")\n\n# Direct column access\n# {{{ColumnName}}}\n\n# Row context (all columns)\n# {{{_row.ColumnName}}}\n\n# Current value (in column_display)\n# {{{_value}}}\n\n# Foreign key values\n# {{{$fkeys.schema.constraint_name.values.ColumnName}}}\n# {{{$fkeys.schema.constraint_name.rowName}}}\n\n# Catalog info\n# {{{$catalog.id}}}\n# {{{$catalog.snapshot}}}\n</code></pre>"},{"location":"user-guide/annotations/#template-examples","title":"Template Examples","text":"<pre><code># Row name with multiple fields\n\"{{{Name}}} ({{{Species}}})\"\n\n# Conditional display\n\"{{#if Notes}}{{{Notes}}}{{else}}No notes{{/if}}\"\n\n# URL link\n\"[{{{Filename}}}]({{{URL}}})\"\n\n# Image preview\n\"[![{{{Filename}}}]({{{URL}}})]({{{URL}}})\"\n\n# Formatted date\n\"{{formatDate RCT 'YYYY-MM-DD'}}\"\n\n# FK value\n\"{{{$fkeys.domain.Subject_Species_fkey.values.Name}}}\"\n</code></pre>"},{"location":"user-guide/annotations/#complete-example","title":"Complete Example","text":"<p>Here's a complete example configuring annotations for a Subject table:</p> <pre><code>from deriva_ml import DerivaML\nfrom deriva_ml.model import (\n    TableHandle, Display, VisibleColumns, VisibleForeignKeys,\n    TableDisplay, TableDisplayOptions, ColumnDisplay, ColumnDisplayOptions,\n    PseudoColumn, OutboundFK, InboundFK, Facet, FacetList,\n    fk_constraint, SortKey, Aggregate, FacetUxMode, PreFormat,\n    CONTEXT_COMPACT, CONTEXT_DETAILED\n)\n\n# Connect to catalog\nml = DerivaML(hostname=\"example.org\", catalog_id=\"1\")\n\n# Get table handle\ntable = ml.model.name_to_table(\"Subject\")\nhandle = TableHandle(table)\n\n# 1. Display annotation - friendly name and description\nhandle.set_annotation(Display(\n    name=\"Research Subjects\",\n    comment=\"Individuals enrolled in research studies\"\n))\n\n# 2. Table display - row naming and ordering\ntd = TableDisplay()\ntd.row_name(\"{{{Name}}} ({{{Subject_ID}}})\")\ntd.compact(TableDisplayOptions(\n    row_order=[SortKey(\"Name\")],\n    page_size=25\n))\nhandle.set_annotation(td)\n\n# 3. Visible columns - what appears in each view\nvc = VisibleColumns()\n\n# Compact view - essential columns\nvc.compact([\n    \"RID\",\n    \"Subject_ID\",\n    \"Name\",\n    fk_constraint(\"domain\", \"Subject_Species_fkey\"),\n    \"Age\",\n    PseudoColumn(\n        source=[InboundFK(\"domain\", \"Sample_Subject_fkey\"), \"RID\"],\n        aggregate=Aggregate.CNT,\n        markdown_name=\"Samples\"\n    ),\n])\n\n# Detailed view - all columns plus computed fields\nvc.detailed([\n    \"RID\",\n    \"Subject_ID\",\n    \"Name\",\n    fk_constraint(\"domain\", \"Subject_Species_fkey\"),\n    \"Age\",\n    \"Sex\",\n    \"Enrollment_Date\",\n    \"Notes\",\n    PseudoColumn(\n        source=[InboundFK(\"domain\", \"Sample_Subject_fkey\"), \"RID\"],\n        aggregate=Aggregate.CNT,\n        markdown_name=\"Sample Count\"\n    ),\n])\n\n# Entry view - editable fields\nvc.entry([\"Subject_ID\", \"Name\", \"Species\", \"Age\", \"Sex\", \"Notes\"])\n\n# Filter configuration\nfacets = FacetList()\nfacets.add(Facet(\n    source=[OutboundFK(\"domain\", \"Subject_Species_fkey\"), \"Name\"],\n    markdown_name=\"Species\",\n    open=True\n))\nfacets.add(Facet(\n    source=\"Sex\",\n    open=True\n))\nfacets.add(Facet(\n    source=\"Age\",\n    ux_mode=FacetUxMode.RANGES\n))\nvc._contexts[\"filter\"] = facets.to_dict()\n\nhandle.set_annotation(vc)\n\n# 4. Visible foreign keys - related tables in detail view\nvfk = VisibleForeignKeys()\nvfk.detailed([\n    fk_constraint(\"domain\", \"Sample_Subject_fkey\"),\n    fk_constraint(\"domain\", \"Diagnosis_Subject_fkey\"),\n    fk_constraint(\"domain\", \"Image_Subject_fkey\"),\n])\nhandle.set_annotation(vfk)\n\n# 5. Column-specific annotations\nage_col = handle.column(\"Age\")\nage_col.description = \"Age in years at enrollment\"\nage_col.set_display_name(\"Age (years)\")\n\nnotes_col = handle.column(\"Notes\")\nnotes_col.description = \"Additional observations or comments\"\n\nprint(\"Annotations configured successfully!\")\n</code></pre>"},{"location":"user-guide/annotations/#using-raw-dictionaries","title":"Using Raw Dictionaries","text":"<p>The annotation builders are optional. You can always use raw dictionaries for complex cases or when the builders don't cover your needs:</p> <pre><code># Raw dictionary approach\ntable.annotations[\"tag:isrd.isi.edu,2016:visible-columns\"] = {\n    \"compact\": [\"RID\", \"Name\", \"Description\"],\n    \"detailed\": [\"RID\", \"Name\", \"Description\", \"Created\"],\n    \"filter\": {\n        \"and\": [\n            {\"source\": \"Name\", \"open\": True},\n            {\"source\": \"Status\"}\n        ]\n    }\n}\ntable.apply()\n</code></pre>"},{"location":"user-guide/annotations/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Always provide descriptions - Use <code>comment</code> for tables and columns to make the catalog self-documenting.</p> </li> <li> <p>Set row name patterns - Makes foreign key dropdowns and references readable.</p> </li> <li> <p>Configure visible columns - Show relevant columns in compact view, more detail in detailed view.</p> </li> <li> <p>Use faceted search - Configure filters for commonly-searched fields.</p> </li> <li> <p>Order columns logically - Put identifiers first, then key attributes, then metadata.</p> </li> <li> <p>Test in Chaise - Use <code>ml.get_chaise_url(\"TableName\")</code> to view your changes.</p> </li> </ol>"},{"location":"user-guide/annotations/#api-reference","title":"API Reference","text":"<p>For complete API documentation, see:</p> <ul> <li><code>deriva_ml.model.annotations</code> - Annotation builder classes</li> <li><code>TableHandle</code> - Table wrapper with annotation methods</li> <li><code>ColumnHandle</code> - Column wrapper with annotation methods</li> </ul>"},{"location":"user-guide/cli-reference/","title":"CLI Reference","text":"<p>DerivaML provides several command-line tools for running ML workflows, managing versions, and administering catalogs. All commands are installed as console scripts when you install the <code>deriva-ml</code> package.</p> <p>When using a project managed with <code>uv</code>, prefix commands with <code>uv run</code>:</p> <pre><code>uv run deriva-ml-run +experiment=my_experiment\n</code></pre>"},{"location":"user-guide/cli-reference/#command-overview","title":"Command Overview","text":"Command Description <code>deriva-ml-run</code> Execute ML models with Hydra configuration and execution tracking <code>deriva-ml-run-notebook</code> Execute Jupyter notebooks with parameter injection and tracking <code>bump-version</code> Bump semantic version tags and push to remote <code>deriva-ml-install-kernel</code> Install a Jupyter kernel for the current virtual environment <code>deriva-ml-split-dataset</code> Split a dataset into training and testing subsets <code>deriva-ml-create-schema</code> Create the DerivaML schema in a catalog <code>deriva-ml-check-catalog-schema</code> Validate a catalog's schema against DerivaML requirements <code>deriva-ml-table-comments-utils</code> Update table and column comments from documentation files <code>create-demo-catalog</code> Create a demo catalog with sample data for testing"},{"location":"user-guide/cli-reference/#model-and-notebook-execution","title":"Model and Notebook Execution","text":""},{"location":"user-guide/cli-reference/#deriva-ml-run","title":"deriva-ml-run","text":"<p>Execute ML models with Hydra-zen configuration composition and automatic execution tracking in a Deriva catalog.</p> <p>Synopsis:</p> <pre><code>deriva-ml-run [--host HOST] [--catalog CATALOG] [--config-dir DIR]\n              [--config-name NAME] [--info] [--multirun|-m] [OVERRIDES...]\n</code></pre> <p>Arguments:</p> Argument Default Description <code>--host HOST</code> (from config) Deriva server hostname <code>--catalog CATALOG</code> (from config) Catalog ID or identifier <code>--config-dir DIR</code>, <code>-c</code> <code>src/configs</code> Path to the configs directory <code>--config-name NAME</code> <code>deriva_model</code> Name of the main Hydra-zen config <code>--info</code> Display available configuration groups and options <code>--multirun</code>, <code>-m</code> Enable Hydra multirun mode for parameter sweeps <code>OVERRIDES</code> Hydra-zen configuration overrides (positional) <p>Examples:</p> <pre><code># Run with default configuration\nuv run deriva-ml-run\n\n# Override a config group\nuv run deriva-ml-run model_config=my_model datasets=full_training\n\n# Override individual parameters\nuv run deriva-ml-run model_config.epochs=50 model_config.learning_rate=0.001\n\n# Use an experiment preset\nuv run deriva-ml-run +experiment=cifar10_quick\n\n# Dry run (download inputs, skip catalog writes)\nuv run deriva-ml-run dry_run=true\n\n# Show all available configs\nuv run deriva-ml-run --info\n\n# Override host and catalog from command line\nuv run deriva-ml-run --host prod.example.org --catalog 100\n\n# Multirun with comma-separated values\nuv run deriva-ml-run --multirun model_config.learning_rate=0.0001,0.001,0.01\n\n# Named multirun configuration\nuv run deriva-ml-run +multirun=lr_sweep\n\n# Named multirun with additional overrides\nuv run deriva-ml-run +multirun=lr_sweep model_config.epochs=5\n</code></pre> <p>See also: Running Models and Notebooks</p>"},{"location":"user-guide/cli-reference/#deriva-ml-run-notebook","title":"deriva-ml-run-notebook","text":"<p>Execute Jupyter notebooks with parameter injection, automatic kernel detection, and execution tracking. The executed notebook and a Markdown conversion are uploaded to the catalog as execution assets.</p> <p>Synopsis:</p> <pre><code>deriva-ml-run-notebook NOTEBOOK [--host HOST] [--catalog CATALOG]\n                       [--file FILE] [--parameter KEY VALUE]\n                       [--kernel KERNEL] [--inspect] [--info]\n                       [--log-output] [OVERRIDES...]\n</code></pre> <p>Arguments:</p> Argument Default Description <code>NOTEBOOK</code> (required) Path to the <code>.ipynb</code> notebook file <code>--host HOST</code> (from config) Deriva server hostname <code>--catalog CATALOG</code> (from config) Catalog ID or identifier <code>--file FILE</code>, <code>-f</code> JSON or YAML file with parameter values <code>--parameter KEY VALUE</code>, <code>-p</code> Parameter name and value to inject (repeatable) <code>--kernel KERNEL</code>, <code>-k</code> (auto-detected) Jupyter kernel name <code>--inspect</code> Display notebook parameters and exit <code>--info</code> Display available Hydra configuration groups <code>--log-output</code> Stream cell outputs during execution <code>OVERRIDES</code> Hydra-zen configuration overrides (positional) <p>Environment Variables Set During Execution:</p> Variable Purpose <code>DERIVA_ML_WORKFLOW_URL</code> Git URL or local path to the notebook source <code>DERIVA_ML_WORKFLOW_CHECKSUM</code> MD5 checksum of the notebook file <code>DERIVA_ML_NOTEBOOK_PATH</code> Absolute filesystem path to the notebook <code>DERIVA_ML_SAVE_EXECUTION_RID</code> Path where the notebook saves execution metadata <code>DERIVA_ML_HYDRA_OVERRIDES</code> JSON-encoded list of Hydra overrides <p>Examples:</p> <pre><code># Run a notebook with default configuration\nuv run deriva-ml-run-notebook notebooks/analyze_results.ipynb\n\n# Override Hydra config groups (positional overrides)\nuv run deriva-ml-run-notebook notebooks/analysis.ipynb \\\n    assets=my_assets deriva_ml=production\n\n# Inject parameters into the notebook's parameter cell\nuv run deriva-ml-run-notebook notebooks/train.ipynb \\\n    -p learning_rate 0.001 -p epochs 50\n\n# Load parameters from a YAML file\nuv run deriva-ml-run-notebook notebooks/train.ipynb --file params.yaml\n\n# Inspect available notebook parameters without running\nuv run deriva-ml-run-notebook notebooks/train.ipynb --inspect\n\n# Show available Hydra config groups\nuv run deriva-ml-run-notebook notebooks/analysis.ipynb --info\n\n# Stream notebook output to terminal\nuv run deriva-ml-run-notebook notebooks/train.ipynb --log-output\n\n# Override host and catalog\nuv run deriva-ml-run-notebook notebooks/analysis.ipynb \\\n    --host prod.example.org --catalog 100\n</code></pre> <p>See also: Running Models and Notebooks, Using Jupyter Notebooks</p>"},{"location":"user-guide/cli-reference/#development-tools","title":"Development Tools","text":""},{"location":"user-guide/cli-reference/#bump-version","title":"bump-version","text":"<p>Manage semantic version tags for your project. Creates an initial tag if none exists, or bumps the existing version using bump-my-version.</p> <p>This tool works with setuptools_scm for dynamic version derivation from git tags \u2014 there is no hardcoded version string in the source code.</p> <p>Synopsis:</p> <pre><code>bump-version [patch|minor|major]\n</code></pre> <p>Arguments:</p> Argument Default Description <code>patch\\|minor\\|major</code> <code>patch</code> Which semantic version component to increment <p>Environment Variables:</p> Variable Default Description <code>START</code> <code>0.1.0</code> Initial version if no tag exists <code>PREFIX</code> <code>v</code> Tag prefix (e.g., <code>v</code> for tags like <code>v1.2.3</code>) <p>How Versioning Works:</p> <ul> <li>At a tag: Version is clean, e.g., <code>1.2.3</code></li> <li>After a tag: Includes distance and commit hash, e.g., <code>1.2.3.post2+g1234abc</code></li> <li>Dirty working tree: Adds <code>.dirty</code> suffix</li> </ul> <p>Examples:</p> <pre><code># Bump patch version (1.2.3 -&gt; 1.2.4)\nuv run bump-version\n\n# Bump minor version (1.2.3 -&gt; 1.3.0)\nuv run bump-version minor\n\n# Bump major version (1.2.3 -&gt; 2.0.0)\nuv run bump-version major\n\n# Check current version\nuv run python -m setuptools_scm\n</code></pre> <p>Requirements: <code>git</code>, <code>uv</code>, and <code>bump-my-version</code> configured in <code>pyproject.toml</code>.</p>"},{"location":"user-guide/cli-reference/#deriva-ml-install-kernel","title":"deriva-ml-install-kernel","text":"<p>Install a Jupyter kernel for the current virtual environment. This allows Jupyter notebooks to use the DerivaML environment with all its dependencies.</p> <p>Synopsis:</p> <pre><code>deriva-ml-install-kernel [--install-local]\n</code></pre> <p>Arguments:</p> Argument Description <code>--install-local</code> Install kernel to the venv's prefix directory instead of the user's Jupyter data directory <p>The kernel name and display name are derived from the virtual environment's <code>prompt</code> setting in <code>pyvenv.cfg</code>.</p> <p>Example Workflow:</p> <pre><code># Create virtual environment with a name\nuv venv --prompt my-ml-project\n\n# Activate it\nsource .venv/bin/activate\n\n# Install the Jupyter kernel\nuv run deriva-ml-install-kernel\n# Output: Installed Jupyter kernel 'my-ml-project' with display name 'Python (my-ml-project)'\n\n# The kernel now appears in Jupyter's kernel selector\njupyter lab\n</code></pre> <p>Kernel location: <code>~/.local/share/jupyter/kernels/</code> (Linux/macOS) or <code>%APPDATA%\\jupyter\\kernels\\</code> (Windows).</p>"},{"location":"user-guide/cli-reference/#data-operations","title":"Data Operations","text":""},{"location":"user-guide/cli-reference/#deriva-ml-split-dataset","title":"deriva-ml-split-dataset","text":"<p>Split a DerivaML dataset into training and testing subsets. Follows scikit-learn conventions for split parameters and supports stratified splitting.</p> <p>Synopsis:</p> <pre><code>deriva-ml-split-dataset --hostname HOST --catalog-id ID --dataset-rid RID\n                        [--test-size SIZE] [--train-size SIZE] [--seed SEED]\n                        [--stratify-by-column COL] [--element-table TABLE]\n                        [--include-tables TABLES] [--training-types TYPES]\n                        [--testing-types TYPES] [--description DESC]\n                        [--workflow-type TYPE] [--dry-run] [--show-urls]\n                        [--no-shuffle]\n</code></pre> <p>Arguments:</p> Argument Default Description <code>--hostname</code> (required) Deriva server hostname <code>--catalog-id</code> (required) Catalog ID to connect to <code>--dataset-rid</code> (required) RID of the source dataset to split <code>--domain-schema</code> (auto-detected) Domain schema name <code>--test-size</code> <code>0.2</code> Test set size as fraction (0-1) or absolute count <code>--train-size</code> (complement) Train set size as fraction (0-1) or absolute count <code>--seed</code> <code>42</code> Random seed for reproducibility <code>--no-shuffle</code> Do not shuffle before splitting <code>--stratify-by-column</code> Column name for stratified splitting (requires <code>--include-tables</code>) <code>--element-table</code> (auto-detected) Element table to split (e.g., <code>Image</code>) <code>--include-tables</code> Comma-separated tables for denormalization (required for stratified splitting) <code>--training-types</code> <code>Labeled</code> Comma-separated dataset types for the training set <code>--testing-types</code> <code>Labeled</code> Comma-separated dataset types for the testing set <code>--description</code> Description for the parent split dataset <code>--workflow-type</code> <code>Dataset_Split</code> Workflow type vocabulary term <code>--dry-run</code> Print the split plan without modifying the catalog <code>--show-urls</code> Show Chaise web interface URLs for created datasets <p>Examples:</p> <pre><code># Simple random 80/20 split\nuv run deriva-ml-split-dataset --hostname localhost --catalog-id 9 \\\n    --dataset-rid 28D0\n\n# Stratified split by class label\nuv run deriva-ml-split-dataset --hostname localhost --catalog-id 9 \\\n    --dataset-rid 28D0 \\\n    --stratify-by-column Image_Classification_Image_Class \\\n    --include-tables Image,Image_Classification\n\n# Fixed-count split\nuv run deriva-ml-split-dataset --hostname localhost --catalog-id 9 \\\n    --dataset-rid 28D0 --train-size 400 --test-size 100\n\n# Dry run (show plan without modifying catalog)\nuv run deriva-ml-split-dataset --hostname localhost --catalog-id 9 \\\n    --dataset-rid 28D0 --dry-run\n</code></pre>"},{"location":"user-guide/cli-reference/#create-demo-catalog","title":"create-demo-catalog","text":"<p>Create a demonstration catalog with sample data for testing and development.</p> <p>Synopsis:</p> <pre><code>create-demo-catalog --host HOST [--domain-schema SCHEMA]\n</code></pre> <p>Arguments:</p> Argument Default Description <code>--host</code> (required) Deriva server hostname <code>--domain-schema</code> <code>demo-schema</code> Name for the domain schema <p>This command is primarily used for development and testing of DerivaML itself.</p>"},{"location":"user-guide/cli-reference/#catalog-administration","title":"Catalog Administration","text":""},{"location":"user-guide/cli-reference/#deriva-ml-create-schema","title":"deriva-ml-create-schema","text":"<p>Create the DerivaML schema in a Deriva catalog. This is typically run once when setting up a new catalog for ML workflows.</p> <p>Synopsis:</p> <pre><code>deriva-ml-create-schema HOSTNAME PROJECT_NAME SCHEMA_NAME --curie_prefix PREFIX\n</code></pre> <p>Arguments:</p> Argument Default Description <code>HOSTNAME</code> (required) Deriva server hostname <code>PROJECT_NAME</code> (required) Project name for the catalog <code>SCHEMA_NAME</code> <code>deriva-ml</code> Schema name <code>--curie_prefix</code> (required) CURIE prefix for identifiers"},{"location":"user-guide/cli-reference/#deriva-ml-check-catalog-schema","title":"deriva-ml-check-catalog-schema","text":"<p>Validate a catalog's schema against the DerivaML reference schema. Reports any missing tables, columns, or configuration issues.</p> <p>Synopsis:</p> <pre><code>deriva-ml-check-catalog-schema --host HOST [--catalog CATALOG] [--dump]\n</code></pre> <p>Arguments:</p> Argument Default Description <code>--host</code> (required) Deriva server hostname <code>--catalog</code> <code>1</code> Catalog number <code>--dump</code> Dump schema details"},{"location":"user-guide/cli-reference/#deriva-ml-table-comments-utils","title":"deriva-ml-table-comments-utils","text":"<p>Update table and column comments in a catalog from file-based documentation. This is an administrative utility for maintaining schema documentation.</p> <p>Synopsis:</p> <pre><code>deriva-ml-table-comments-utils --host HOST [--catalog CATALOG]\n</code></pre> <p>This command uses Deriva's <code>BaseCLI</code> for standard host/catalog arguments.</p>"},{"location":"user-guide/datasets/","title":"Datasets","text":"<p>When working with ML models, it is often convenient to collect various input data into named, identifiable collections called datasets. DerivaML provides a flexible set of mechanisms for creating and manipulating datasets.</p> <p>A dataset is a versioned collection of objects within a DerivaML catalog. Datasets can be heterogeneous, containing sets of different object types. It's possible to have an object referenced in multiple ways - for example, a collection of subjects and a collection of observations that reference those subjects. DerivaML manages these relationships and makes it possible to view them from all paths.</p> <p>As with any other object in DerivaML, each dataset is identified by its Resource Identifier (RID). In addition, a dataset may have one or more dataset types and a version.</p>"},{"location":"user-guide/datasets/#dataset-types","title":"Dataset Types","text":"<p>Dataset types are assigned from a controlled vocabulary called <code>Dataset_Type</code>. You can define new dataset types as needed:</p> <pre><code>from deriva_ml import MLVocab\n\nml.add_term(MLVocab.dataset_type, \"TrainingSet\", description=\"Dataset for model training\")\nml.add_term(MLVocab.dataset_type, \"ValidationSet\", description=\"Dataset for model validation\")\n</code></pre> <p>When you create a dataset, you can provide as many dataset types as required to streamline organizing and discovering them in your code.</p>"},{"location":"user-guide/datasets/#creating-datasets","title":"Creating Datasets","text":"<p>The most common way to create a dataset is within an execution, which provides provenance tracking:</p> <pre><code>from deriva_ml import DerivaML\nfrom deriva_ml.execution import ExecutionConfiguration\n\n# Connect to the catalog\nml = DerivaML(\"deriva.example.org\", \"my_catalog\")\n\n# Create a workflow\nworkflow = ml.create_workflow(\n    name=\"Data Preparation Workflow\",\n    workflow_type=\"Data Processing\",\n    description=\"Prepares training and validation datasets\"\n)\n\n# Create an execution configuration\nconfig = ExecutionConfiguration(\n    workflow=workflow,\n    description=\"Create datasets for experiment\"\n)\n\n# Create datasets within the execution context\nwith ml.create_execution(config) as exe:\n    training_dataset = exe.create_dataset(\n        dataset_types=[\"TrainingSet\", \"Image\"],\n        description=\"Training images for classification model\"\n    )\n\n    validation_dataset = exe.create_dataset(\n        dataset_types=[\"ValidationSet\", \"Image\"],\n        description=\"Validation images for model evaluation\"\n    )\n\n# Upload any outputs after context exits\nexe.upload_execution_outputs()\n</code></pre> <p>You can also create datasets directly through the DerivaML instance:</p> <pre><code>dataset = ml.create_dataset(\n    dataset_types=[\"ExperimentData\"],\n    description=\"Raw experimental data\"\n)\n</code></pre>"},{"location":"user-guide/datasets/#dataset-element-types","title":"Dataset Element Types","text":"<p>A dataset may consist of many different types of objects. In general, any element from the domain model may be included in a dataset. To see what element types are available:</p> <pre><code># List available element types\nelement_types = dataset.list_dataset_element_types()\nfor table in element_types:\n    print(table.name)\n</code></pre> <p>To add a new element type that can be included in datasets:</p> <pre><code># Add Subject table as a valid dataset element type\nml.add_dataset_element_type(\"Subject\")\n</code></pre>"},{"location":"user-guide/datasets/#adding-members-to-a-dataset","title":"Adding Members to a Dataset","text":"<p>Once you have a dataset, you can add members using their RIDs:</p> <pre><code># Add individual members by RID\ndataset.add_dataset_members(members=[\"1-abc123\", \"1-def456\", \"1-ghi789\"])\n\n# Add members with execution tracking\ndataset.add_dataset_members(\n    members=subject_rids,\n    execution_rid=execution.execution_rid\n)\n</code></pre>"},{"location":"user-guide/datasets/#listing-dataset-members","title":"Listing Dataset Members","text":"<p>To see what's in a dataset:</p> <pre><code># List all members of current version\nmembers = dataset.list_dataset_members()\nfor member in members:\n    print(f\"Table: {member['table']}, RID: {member['rid']}\")\n\n# List members of a specific version\nmembers_v1 = dataset.list_dataset_members(version=\"1.0.0\")\n</code></pre>"},{"location":"user-guide/datasets/#nested-datasets","title":"Nested Datasets","text":"<p>Datasets can contain other datasets, forming hierarchies:</p> <pre><code># Create a parent dataset\nparent_dataset = ml.create_dataset(\n    dataset_types=[\"ExperimentCollection\"],\n    description=\"Collection of experiment datasets\"\n)\n\n# Add child datasets as members\nparent_dataset.add_dataset_members(\n    members=[training_dataset.dataset_rid, validation_dataset.dataset_rid]\n)\n\n# List child datasets\nchildren = parent_dataset.list_dataset_children()\n\n# List parent datasets\nparents = training_dataset.list_dataset_parents()\n</code></pre>"},{"location":"user-guide/datasets/#splitting-datasets","title":"Splitting Datasets","text":"<p>A common ML workflow is splitting a dataset into training and testing subsets. DerivaML provides the <code>split_dataset</code> function for this, with full provenance tracking. The API follows scikit-learn conventions (<code>test_size</code>, <code>train_size</code>, <code>shuffle</code>, <code>seed</code>, <code>stratify</code>) while creating a proper dataset hierarchy in the catalog.</p>"},{"location":"user-guide/datasets/#how-splitting-works","title":"How Splitting Works","text":"<p><code>split_dataset</code> creates a three-level dataset hierarchy:</p> <pre><code>Split (parent, type: \"Split\")\n\u251c\u2500\u2500 Training (child, type: \"Training\")\n\u2514\u2500\u2500 Testing (child, type: \"Testing\")\n</code></pre> <p>The entire operation is performed within an execution context, so the split is fully traceable back to the source dataset, the parameters used, and the code that ran it.</p>"},{"location":"user-guide/datasets/#simple-random-split","title":"Simple Random Split","text":"<p>The simplest case splits a dataset into training and testing subsets by randomly shuffling members:</p> <pre><code>from deriva_ml.dataset.split import split_dataset\n\n# 80/20 random split (default)\nresult = split_dataset(ml, source_dataset_rid, test_size=0.2, seed=42)\n\nprint(f\"Split:    {result['split']}\")\nprint(f\"Training: {result['training']} ({result['train_count']} samples)\")\nprint(f\"Testing:  {result['testing']} ({result['test_count']} samples)\")\n</code></pre> <p>You can also specify absolute counts instead of fractions:</p> <pre><code># Fixed-count split\nresult = split_dataset(\n    ml, source_dataset_rid,\n    train_size=400,\n    test_size=100,\n    seed=42,\n)\n</code></pre>"},{"location":"user-guide/datasets/#labeled-splits","title":"Labeled Splits","text":"<p>When your experiment needs ground truth labels in both training and testing sets (for evaluation, ROC curves, etc.), add the <code>\"Labeled\"</code> dataset type:</p> <pre><code>result = split_dataset(\n    ml, source_dataset_rid,\n    test_size=0.2,\n    seed=42,\n    training_types=[\"Labeled\"],\n    testing_types=[\"Labeled\"],\n)\n</code></pre> <p>This creates Training and Testing datasets with both their default type and the additional <code>\"Labeled\"</code> type, making them easy to discover and distinguish from unlabeled splits.</p>"},{"location":"user-guide/datasets/#stratified-splitting","title":"Stratified Splitting","text":"<p>Stratified splitting maintains the class distribution of a column across both splits. This requires denormalizing the dataset to access the column values:</p> <pre><code>result = split_dataset(\n    ml, source_dataset_rid,\n    test_size=0.2,\n    seed=42,\n    stratify_by_column=\"Image_Classification_Image_Class\",\n    include_tables=[\"Image\", \"Image_Classification\"],\n)\n</code></pre> <p>The <code>stratify_by_column</code> uses the denormalized column name format: <code>{TableName}_{ColumnName}</code>. The <code>include_tables</code> parameter specifies which tables to join during denormalization.</p> <p>!!! note     Stratified splitting requires scikit-learn to be installed. It is imported lazily, so the base <code>split_dataset</code> function works without it for random splits.</p>"},{"location":"user-guide/datasets/#custom-selection-functions","title":"Custom Selection Functions","text":"<p>For advanced splitting logic (balanced sampling, filtered subsets, etc.), provide a custom selection function:</p> <pre><code>import numpy as np\n\ndef balanced_selector(df, train_size, test_size, seed):\n    \"\"\"Select equal numbers from each class.\"\"\"\n    rng = np.random.default_rng(seed)\n    label_col = \"Image_Classification_Image_Class\"\n    classes = df[label_col].unique()\n    train_idx, test_idx = [], []\n    for cls in classes:\n        cls_indices = df.index[df[label_col] == cls].to_numpy()\n        rng.shuffle(cls_indices)\n        per_class_train = train_size // len(classes)\n        per_class_test = test_size // len(classes)\n        train_idx.extend(cls_indices[:per_class_train])\n        test_idx.extend(cls_indices[per_class_train:per_class_train + per_class_test])\n    return np.array(train_idx), np.array(test_idx)\n\nresult = split_dataset(\n    ml, source_dataset_rid,\n    test_size=100,\n    selection_fn=balanced_selector,\n    include_tables=[\"Image\", \"Image_Classification\"],\n)\n</code></pre> <p>A selection function must conform to the <code>SelectionFunction</code> protocol: it receives a DataFrame, train/test sizes, and a seed, and returns <code>(train_indices, test_indices)</code> as numpy arrays.</p>"},{"location":"user-guide/datasets/#dry-run","title":"Dry Run","text":"<p>Use <code>dry_run=True</code> to preview what would happen without modifying the catalog:</p> <pre><code>result = split_dataset(\n    ml, source_dataset_rid,\n    test_size=0.2,\n    dry_run=True,\n)\nprint(f\"Would create: {result['train_count']} train, {result['test_count']} test\")\nprint(f\"Strategy: {result['strategy']}\")\n</code></pre>"},{"location":"user-guide/datasets/#command-line-interface","title":"Command-Line Interface","text":"<p>The <code>deriva-ml-split-dataset</code> CLI provides the same functionality from the command line:</p> <pre><code># Simple random split\nderiva-ml-split-dataset --hostname localhost --catalog-id 9 \\\n    --dataset-rid 28D0 --test-size 0.2\n\n# Stratified split\nderiva-ml-split-dataset --hostname localhost --catalog-id 9 \\\n    --dataset-rid 28D0 --test-size 0.2 \\\n    --stratify-by-column Image_Classification_Image_Class \\\n    --include-tables Image,Image_Classification\n\n# Dry run\nderiva-ml-split-dataset --hostname localhost --catalog-id 9 \\\n    --dataset-rid 28D0 --dry-run\n</code></pre>"},{"location":"user-guide/datasets/#auto-detection","title":"Auto-Detection","text":"<p>When the source dataset has members in only one element table, <code>split_dataset</code> auto-detects which table to split. If the dataset has members in multiple tables, you must specify <code>element_table</code>:</p> <pre><code>result = split_dataset(\n    ml, source_dataset_rid,\n    test_size=0.2,\n    element_table=\"Image\",  # Required when dataset has multiple element types\n)\n</code></pre>"},{"location":"user-guide/datasets/#dataset-versioning","title":"Dataset Versioning","text":"<p>Every dataset is assigned a version number using semantic versioning (<code>major.minor.patch</code>):</p> <ul> <li>Major: Changes when there is a schema change to any object in the dataset</li> <li>Minor: Changes when new elements are added to a dataset</li> <li>Patch: Changes for minor alterations, such as adding comments or data cleaning</li> </ul> <p>DerivaML automatically assigns version <code>0.1.0</code> when a dataset is first created and increments the minor part whenever new elements are added.</p>"},{"location":"user-guide/datasets/#working-with-versions","title":"Working with Versions","text":"<pre><code># Get current version\ncurrent = dataset.current_version\nprint(f\"Current version: {current}\")  # e.g., \"1.2.3\"\n\n# Get version history\nhistory = dataset.dataset_history()\nfor entry in history:\n    print(f\"Version {entry.version}: {entry.description} at {entry.timestamp}\")\n\n# Increment version\nfrom deriva_ml.dataset.aux_classes import VersionPart\n\nnew_version = dataset.increment_dataset_version(\n    component=VersionPart.minor,\n    description=\"Added new training samples\"\n)\n</code></pre>"},{"location":"user-guide/datasets/#version-snapshots","title":"Version Snapshots","text":"<p>Each version is tied to a catalog snapshot, ensuring that the values in the dataset are the values that were present when the version was created. This provides reproducibility for ML experiments.</p> <pre><code># Get a dataset bound to a specific version\nversioned_dataset = dataset.set_version(\"1.0.0\")\n\n# Access members at that version\nmembers = versioned_dataset.list_dataset_members()\n</code></pre>"},{"location":"user-guide/datasets/#downloading-datasets","title":"Downloading Datasets","text":"<p>Datasets can be downloaded as BDBag archives for offline use or sharing:</p> <pre><code>from deriva_ml.dataset.aux_classes import DatasetSpec\n\n# Download the current version\nbag = dataset.download_dataset_bag()\n\n# Download a specific version\nbag = dataset.download_dataset_bag(version=\"1.0.0\")\n\n# Download with materialization (fetches all referenced files)\nbag = dataset.download_dataset_bag(materialize=True)\n</code></pre>"},{"location":"user-guide/datasets/#how-bag-export-traverses-related-tables","title":"How Bag Export Traverses Related Tables","text":"<p>When exporting a dataset as a BDBag, DerivaML follows foreign key relationships from each member table to include related data (e.g., vocabulary terms, device records). However, it stops traversing when it reaches another dataset element type \u2014 a table that has its own <code>Dataset_X</code> association table \u2014 if that element type has no members in this dataset.</p> <p>For example, consider a catalog where <code>CGM_Blood_Glucose</code> has a foreign key to <code>Observation</code>, which is referenced by <code>Image</code>, which links to <code>Image_Diagnosis</code>. If a dataset contains only <code>CGM_Blood_Glucose</code> records, the export will not follow the path through <code>Observation \u2192 Image \u2192 Image_Diagnosis</code>, because <code>Observation</code> is itself a dataset element type with no members in this dataset. If <code>Observation</code> records were needed, they would be included as explicit dataset members and reached through their own <code>Dataset_Observation</code> association path.</p> <p>Non-element-type tables (tables without a <code>Dataset_X</code> association, such as <code>Device</code>) are traversed normally regardless of dataset membership.</p> <p>This boundary-aware traversal ensures that bag exports include only the data relevant to the dataset's actual members, avoiding expensive multi-table joins that would return empty results.</p>"},{"location":"user-guide/datasets/#automatic-download-in-executions","title":"Automatic Download in Executions","text":"<p>When creating an execution with dataset specifications, you can download datasets within the execution context:</p> <pre><code>from deriva_ml.dataset import DatasetSpec\n\nconfig = ExecutionConfiguration(\n    datasets=[\n        DatasetSpec(rid=\"1-abc123\", version=\"1.0.0\"),\n        DatasetSpec(rid=\"1-def456\", materialize=True),\n    ],\n    workflow=workflow,\n    description=\"Process datasets\"\n)\n\nwith ml.create_execution(config) as exe:\n    # Download datasets as needed\n    bag = exe.download_dataset_bag(DatasetSpec(rid=\"1-abc123\"))\n    print(f\"Dataset available at {bag.bag_path}\")\n</code></pre>"},{"location":"user-guide/datasets/#working-with-datasetbag","title":"Working with DatasetBag","text":"<p>Once downloaded, a dataset is represented as a <code>DatasetBag</code> object:</p> <pre><code># Access dataset metadata\nprint(f\"RID: {bag.dataset_rid}\")\nprint(f\"Version: {bag.version}\")\n\n# Get tables as DataFrames\nsubjects_df = bag.get_table_as_dataframe(\"Subject\")\nimages_df = bag.get_table_as_dataframe(\"Image\")\n\n# Access the local path\nprint(f\"Dataset path: {bag.path}\")\n</code></pre>"},{"location":"user-guide/datasets/#assets-in-datasets","title":"Assets in Datasets","text":"<p>Assets are files stored in the DerivaML object store (Hatrac). Each asset is characterized by:</p> <ul> <li>A versioned URL</li> <li>Length (file size)</li> <li>MD5 checksum</li> <li>Asset type (from the <code>Asset_Type</code> vocabulary)</li> </ul>"},{"location":"user-guide/datasets/#accessing-assets","title":"Accessing Assets","text":"<pre><code># Get asset table from a downloaded dataset bag\nassets = bag.get_table_as_dataframe(\"Image\")\n\n# Assets have a local path after materialization\nfor _, asset in assets.iterrows():\n    local_path = asset[\"Filename\"]\n    print(f\"Asset: {local_path}\")\n</code></pre>"},{"location":"user-guide/datasets/#asset-organization","title":"Asset Organization","text":"<p>When datasets are materialized:</p> <ul> <li>All assets of the same type are placed in the same directory</li> <li>The directory is named by the asset type</li> <li>Use metadata to identify specific assets rather than relying on filenames</li> </ul> <p>If you need to reorganize assets for your application, using symbolic links is efficient for both time and disk space.</p>"},{"location":"user-guide/datasets/#restructuring-assets-for-ml-workflows","title":"Restructuring Assets for ML Workflows","text":"<p>Many ML frameworks expect training data organized in a specific directory structure (e.g., <code>train/class1/</code>, <code>train/class2/</code>). The <code>restructure_assets()</code> method reorganizes downloaded assets into a hierarchical directory structure based on dataset types and metadata or feature values.</p> <pre><code>from pathlib import Path\n\n# Download a dataset with nested structure\nbag = dataset.download_dataset_bag()\n\n# Restructure images by dataset type and a label column/feature\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./ml_data\"),\n    group_by=[\"label\"],\n)\n</code></pre> <p>This creates a directory structure like:</p> <pre><code>ml_data/\n  Complete/           # Parent dataset type\n    Training/         # Nested dataset type\n      positive/       # Label value\n        image1.jpg\n        image2.jpg\n      negative/\n        image3.jpg\n    Testing/\n      positive/\n        image4.jpg\n      negative/\n        image5.jpg\n</code></pre>"},{"location":"user-guide/datasets/#grouping-options","title":"Grouping Options","text":"<p>The <code>group_by</code> parameter accepts column names from the asset table or feature names:</p> <pre><code># Group by a column in the asset table\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./by_subject\"),\n    group_by=[\"Subject\"],  # Foreign key column\n)\n\n# Group by a feature attached to the asset\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./by_quality\"),\n    group_by=[\"Quality\"],  # Feature name\n)\n\n# Multiple grouping levels\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./multi_level\"),\n    group_by=[\"Subject\", \"Quality\"],  # Creates Subject/Quality/file structure\n)\n</code></pre>"},{"location":"user-guide/datasets/#symlinks-vs-copies","title":"Symlinks vs Copies","text":"<p>By default, <code>restructure_assets()</code> creates symbolic links to save disk space:</p> <pre><code># Default: create symlinks (efficient, but requires original bag to remain)\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./linked\"),\n    use_symlinks=True,  # Default\n)\n\n# Create copies instead (uses more disk space, but independent of original)\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./copied\"),\n    use_symlinks=False,\n)\n</code></pre>"},{"location":"user-guide/datasets/#custom-type-selection","title":"Custom Type Selection","text":"<p>When a dataset has multiple types, you can control which type is used for the directory name:</p> <pre><code># Use a custom function to select the type\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./custom\"),\n    group_by=[\"label\"],\n    type_selector=lambda types: types[-1] if types else \"unknown\",\n)\n</code></pre>"},{"location":"user-guide/datasets/#handling-missing-values","title":"Handling Missing Values","text":"<p>When a grouping value is missing or <code>None</code>, assets are placed in an <code>Unknown</code> folder:</p> <pre><code>ml_data/\n  Training/\n    positive/\n      image1.jpg\n    Unknown/          # Assets with missing label values\n      image2.jpg\n</code></pre>"},{"location":"user-guide/datasets/#prediction-scenarios-datasets-without-types","title":"Prediction Scenarios (Datasets Without Types)","text":"<p>When a dataset has no type defined (empty <code>dataset_types</code> list), it is treated as a Testing dataset. This is common for prediction/inference scenarios where you want to apply a trained model to new unlabeled data:</p> <pre><code># Create a dataset for prediction (no type)\nprediction_dataset = ml.create_dataset(\n    dataset_types=[],  # No type - will be treated as Testing\n    description=\"Unlabeled images for prediction\"\n)\n\n# Add images and download\nprediction_dataset.add_dataset_members({\"Image\": image_rids})\nbag = prediction_dataset.download_dataset_bag()\n\n# Restructure for prediction - ends up in testing/Unknown/\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./prediction_data\"),\n    group_by=[\"Diagnosis\"],  # No labels assigned yet\n)\n</code></pre> <p>This creates:</p> <pre><code>prediction_data/\n  testing/            # Dataset without type treated as Testing\n    Unknown/          # No labels assigned\n      image1.jpg\n      image2.jpg\n</code></pre>"},{"location":"user-guide/datasets/#finding-assets-through-foreign-key-paths","title":"Finding Assets Through Foreign Key Paths","text":"<p>Assets are found by traversing all foreign key paths from the dataset, not just direct associations. For example, if a dataset contains Subjects and the schema has Subject \u2192 Encounter \u2192 Image relationships, <code>restructure_assets()</code> will find all Images reachable through those paths even though they are not directly in a Dataset_Image association table:</p> <pre><code># Dataset contains only Subjects\nsubject_dataset = ml.create_dataset(\n    dataset_types=[\"Training\"],\n    description=\"Training subjects\"\n)\nsubject_dataset.add_dataset_members({\"Subject\": subject_rids})\n\n# But we want to restructure Images connected via FK path\nbag = subject_dataset.download_dataset_bag()\nbag.restructure_assets(\n    asset_table=\"Image\",  # Finds Images via Subject -&gt; Encounter -&gt; Image\n    output_dir=Path(\"./ml_data\"),\n    group_by=[\"Quality\"],\n)\n</code></pre>"},{"location":"user-guide/datasets/#handling-multiple-feature-values","title":"Handling Multiple Feature Values","text":"<p>When an asset has multiple values for the same feature (e.g., labeled by different annotators or different model runs), you can provide a <code>value_selector</code> function to choose which value to use:</p> <pre><code>from deriva_ml.dataset.dataset_bag import FeatureValueRecord\n\ndef select_latest_execution(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n    \"\"\"Select the feature value from the most recent execution.\"\"\"\n    return max(records, key=lambda r: r.execution_rid or \"\")\n\ndef select_by_confidence(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n    \"\"\"Select the feature value with highest confidence from raw record.\"\"\"\n    return max(records, key=lambda r: r.raw_record.get(\"Confidence\", 0))\n\n# Use value_selector to resolve multiple values\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./ml_data\"),\n    group_by=[\"Diagnosis\"],\n    value_selector=select_latest_execution,\n)\n</code></pre> <p>The <code>FeatureValueRecord</code> contains: - <code>target_rid</code>: RID of the asset this feature value applies to - <code>feature_name</code>: Name of the feature - <code>value</code>: The feature value (typically a vocabulary term name) - <code>execution_rid</code>: RID of the execution that created this value (for provenance) - <code>raw_record</code>: The complete feature table row as a dictionary</p> <p>If no <code>value_selector</code> is provided and an asset has multiple different values for the same feature, an error is raised when <code>enforce_vocabulary=True</code> (the default). Set <code>enforce_vocabulary=False</code> to use the first value found instead.</p>"},{"location":"user-guide/datasets/#enforcing-vocabulary-based-grouping","title":"Enforcing Vocabulary-Based Grouping","text":"<p>By default, <code>enforce_vocabulary=True</code> ensures that feature-based grouping only uses vocabulary-controlled features. This prevents accidental grouping by asset-based features (which would create cryptic directory names):</p> <pre><code># This will raise an error if BoundingBox is an asset-based feature\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./ml_data\"),\n    group_by=[\"BoundingBox\"],  # Asset-based feature\n    enforce_vocabulary=True,   # Default - will error\n)\n\n# Allow non-vocabulary features\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./ml_data\"),\n    group_by=[\"BoundingBox\"],\n    enforce_vocabulary=False,  # Allows asset-based features\n)\n</code></pre>"},{"location":"user-guide/datasets/#finding-datasets","title":"Finding Datasets","text":"<p>To discover datasets in the catalog:</p> <pre><code># List all datasets\nall_datasets = ml.find_datasets()\nfor ds in all_datasets:\n    print(f\"{ds.dataset_rid}: {ds.description} (v{ds.current_version})\")\n\n# Look up a specific dataset\ndataset = ml.lookup_dataset(\"1-abc123\")\n</code></pre>"},{"location":"user-guide/datasets/#deleting-datasets","title":"Deleting Datasets","text":"<p>Datasets can be soft-deleted (marked as deleted but retained in the catalog):</p> <pre><code># Delete a single dataset\nml.delete_dataset(dataset)\n\n# Delete a dataset and all nested datasets\nml.delete_dataset(dataset, recurse=True)\n</code></pre>"},{"location":"user-guide/deriva_ml_structure/","title":"Using the Deriva-ML library","text":"<p>While the deriva-ml library is quite flexible, its use can be simplified if a few basic guidelines are followed when structuring an ML project.</p> <p>When creating a new project, we suggest that you create two new GitHub repositories.  If your project is named \"foo,\" create GitHub repositories <code>foo-ml</code> and <code>foo-exec</code>.  GitHub templates for these repositories can be found here.</p> <p><code>foo-ml</code> will contain all of the code related to the actual ML models. We can split this code into two classes.  The first is code, which needs to understand the structure of the data model of the deriva catalog. These functions are best implemented by creating a derived class using DerivaML as a base class.  Any catalog-specific code or utility functions that might be useful to any ML model should be placed here.</p> <p>Code that implements a specific model should be implemented as a module in the models' directory. YOu can make these stand-alone functions or make them derived classes from the class implemented above.  Templates for a model module are provided.  In general, best practice suggests that these modules should be able to execute stand-alone (i.e., have a </p> <pre><code>def main():\n  ...\n\nif __file__ == \"main\":\n  main()\n</code></pre> <p>conditional at the bottom) and provide a single entry point for the model function.  Python prototype definitions are provided  for common ML functions in the library. We also recommend that you avoid the temptation to hardcode model parameters and paths but rather pass everything in as an argument to the entry points, as indicated by the prototypes. Finally, we advocate the liberal use of Python-type hints and the use of either Python data classes or pedantic class descriptions.  Pytantic is included as a standard part of the base Conda environment.</p> <p>The last piece of this puzzle is the <code>foo-exec</code> repository. This repository will house the code required to execute a specific instance of a model with a specific dataset. This repository is organized into notebook code or scripts, with corresponding subdirectories.</p> <p>Before running a model in production, we recommend that you commit all of your code in the <code>foo-ml</code> and <code>foo-exec</code> repositories and optionally provide a GitHub tag for your workflow. At that point, you can update your workflow specification [link] and run your code using the workflow_term component of the specification to differentiate the current execution from others.</p>"},{"location":"user-guide/execution-configuration/","title":"Configuring and Running Executions","text":"<p>Executions are how DerivaML tracks ML workflow runs with full provenance. Every execution records:</p> <ul> <li>Inputs: Which datasets and assets were used</li> <li>Outputs: Which files and datasets were produced</li> <li>Timing: When the workflow started and stopped</li> <li>Status: Progress updates and completion state</li> </ul>"},{"location":"user-guide/execution-configuration/#workflows","title":"Workflows","text":"<p>A Workflow represents a reusable computational process or analysis pipeline. Workflows are a key part of DerivaML's provenance model \u2014 every execution is linked to exactly one workflow, which records what code was run. Understanding workflows is essential before creating executions.</p>"},{"location":"user-guide/execution-configuration/#workflow-execution-and-workflow-type","title":"Workflow, Execution, and Workflow Type","text":"<p>These three concepts form a hierarchy:</p> <ul> <li>Workflow Type \u2014 A controlled vocabulary term that categorizes workflows (e.g., \"Training\",   \"Inference\"). Managed in the <code>Workflow_Type</code> vocabulary table.</li> <li>Workflow \u2014 A reusable definition of a computational process. It records the source code   location (URL), Git checksum, version, and type. A single workflow can be used by many   executions.</li> <li>Execution \u2014 A specific run of a workflow at a particular time, with particular inputs   and outputs. Each execution references exactly one workflow.</li> </ul> <pre><code>Workflow_Type (vocabulary)\n  \u2514\u2500\u2500 Workflow (reusable definition)\n        \u2514\u2500\u2500 Execution (one specific run)\n        \u2514\u2500\u2500 Execution (another run)\n        \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"user-guide/execution-configuration/#creating-a-workflow","title":"Creating a Workflow","text":"<p>Use <code>ml.create_workflow()</code> to create a new workflow. This validates the workflow type against the catalog vocabulary and returns a <code>Workflow</code> object:</p> <pre><code>workflow = ml.create_workflow(\n    name=\"ResNet50 Training\",\n    workflow_type=\"Training\",\n    description=\"Fine-tune ResNet50 on medical images\"\n)\n</code></pre> <p>You can call <code>create_workflow()</code> from any Python script, notebook, or interactive session. Because DerivaML automatically detects the calling source code (see Automatic Source Code Detection below), the same <code>create_workflow()</code> call in the same committed script always produces a Workflow with the same URL and checksum.</p> <p>The returned <code>Workflow</code> object is not yet registered in the catalog. Registration happens automatically when you pass it to <code>ml.create_execution()</code>, or you can register it explicitly with <code>ml.add_workflow(workflow)</code>. In either case, if a workflow with the same URL or checksum already exists in the catalog, the existing record is reused rather than creating a duplicate. This means you can place <code>create_workflow()</code> at the top of every script or notebook without worrying about duplicate records \u2014 running the same committed code repeatedly reuses the same workflow.</p>"},{"location":"user-guide/execution-configuration/#implicit-workflow-creation","title":"Implicit Workflow Creation","text":"<p>When using the hydra-zen configuration system (via <code>deriva-ml-run</code> or <code>deriva-ml-run-notebook</code>), you typically do not call <code>create_workflow()</code> at all. Instead, you define a workflow configuration and the framework handles the rest. See Running Models and Notebooks for the complete guide to setting up and running with these tools.</p> <pre><code># In your configs/workflow.py\nfrom hydra_zen import builds, store\nfrom deriva_ml.execution import Workflow\n\nworkflow_store = store(group=\"workflow\")\n\nworkflow_store(\n    builds(\n        Workflow,\n        name=\"ResNet50 Training\",\n        workflow_type=\"Training\",\n        description=\"Fine-tune ResNet50 on medical images\",\n        populate_full_signature=True,\n    ),\n    name=\"resnet_training\",\n)\n</code></pre> <p>At runtime, hydra-zen instantiates the <code>Workflow</code> object from this configuration, and <code>run_model()</code> passes it to <code>create_execution()</code> automatically. The source code detection, catalog registration, and deduplication all happen behind the scenes.</p> <p>From the command line, you select the workflow by name:</p> <pre><code># Use a named workflow configuration\nuv run deriva-ml-run workflow=resnet_training\n\n# Or as part of an experiment preset that bundles workflow + model + data\nuv run deriva-ml-run +experiment=resnet_imagenet\n</code></pre>"},{"location":"user-guide/execution-configuration/#automatic-source-code-detection","title":"Automatic Source Code Detection","text":"<p>When a <code>Workflow</code> object is created (either via <code>ml.create_workflow()</code> or the <code>Workflow</code> constructor), DerivaML automatically detects the source code that is creating the workflow and records it for provenance. The detection works differently depending on the execution environment.</p>"},{"location":"user-guide/execution-configuration/#python-scripts","title":"Python Scripts","text":"<p>When running from a Python script (e.g., <code>python train.py</code> or <code>uv run deriva-ml-run</code>), DerivaML identifies the script file, constructs a GitHub blob URL that includes the current commit hash, and computes a Git object hash of the file content:</p> <pre><code>URL:      https://github.com/org/repo/blob/a1b2c3d/src/models/train.py\nChecksum: e5f6a7b8c9d0...  (git hash-object of file content)\nVersion:  0.3.1             (from setuptools-scm or pyproject.toml)\n</code></pre> <p>If the script has uncommitted changes, DerivaML issues a warning. The URL still points to the last committed version, so the checksum may not match the code that actually ran. Committing before running ensures reproducibility.</p>"},{"location":"user-guide/execution-configuration/#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>When running inside a Jupyter notebook, DerivaML identifies the notebook file by querying the running Jupyter server for the current kernel's notebook path. The checksum is computed after stripping cell outputs with <code>nbstripout</code>, so re-running a notebook without code changes produces the same checksum regardless of output differences.</p> <p>For notebooks launched via <code>deriva-ml-run-notebook</code>, the notebook path and URL are passed through environment variables (<code>DERIVA_ML_WORKFLOW_URL</code>, <code>DERIVA_ML_WORKFLOW_CHECKSUM</code>) so that detection works even when the notebook is executed by a separate process.</p> <p>To ensure clean checksums, install <code>nbstripout</code> in your repository:</p> <pre><code>pip install nbstripout\nnbstripout --install\n</code></pre>"},{"location":"user-guide/execution-configuration/#docker-containers","title":"Docker Containers","text":"<p>When running inside a Docker container (with <code>DERIVA_MCP_IN_DOCKER=true</code>), there is no local Git repository. Instead, DerivaML reads provenance from environment variables set at image build time:</p> Variable Purpose <code>DERIVA_MCP_IMAGE_NAME</code> Docker image name (e.g., <code>ghcr.io/org/repo</code>) <code>DERIVA_MCP_IMAGE_DIGEST</code> Image digest (<code>sha256:...</code>) used as checksum <code>DERIVA_MCP_GIT_COMMIT</code> Git commit hash at build time (fallback checksum) <code>DERIVA_MCP_VERSION</code> Semantic version of the image"},{"location":"user-guide/execution-configuration/#overriding-detection","title":"Overriding Detection","text":"<p>You can bypass automatic detection by setting the <code>url</code> and <code>checksum</code> fields explicitly when constructing a <code>Workflow</code>:</p> <pre><code>workflow = Workflow(\n    name=\"Custom Pipeline\",\n    workflow_type=\"Training\",\n    url=\"https://github.com/org/repo/blob/main/pipeline.py\",\n    checksum=\"abc123def456\",\n)\n</code></pre> <p>Or by setting environment variables before the workflow is created:</p> <pre><code>export DERIVA_ML_WORKFLOW_URL=\"https://github.com/org/repo/blob/main/pipeline.py\"\nexport DERIVA_ML_WORKFLOW_CHECKSUM=\"abc123def456\"\n</code></pre>"},{"location":"user-guide/execution-configuration/#reusing-existing-workflows","title":"Reusing Existing Workflows","text":"<p>If a workflow with the same URL or checksum already exists in the catalog, <code>ml.add_workflow()</code> returns the existing workflow's RID rather than creating a duplicate. This means running the same committed script multiple times reuses the same workflow record.</p> <p>You can also look up existing workflows directly:</p> <pre><code># Look up by RID\nworkflow = ml.lookup_workflow(\"2-ABC1\")\n\n# Look up by URL or Git checksum\nworkflow = ml.lookup_workflow_by_url(\"https://github.com/org/repo/blob/abc123/train.py\")\n\n# List all workflows in the catalog\nall_workflows = ml.find_workflows()\nfor w in all_workflows:\n    print(f\"{w.name} ({w.workflow_type}): {w.url}\")\n</code></pre>"},{"location":"user-guide/execution-configuration/#updating-workflow-properties","title":"Updating Workflow Properties","text":"<p>Workflows retrieved from the catalog (via <code>lookup_workflow</code>, <code>lookup_workflow_by_url</code>, or <code>find_workflows</code>) are bound to the catalog. You can update their <code>description</code> and <code>workflow_type</code> properties, and the changes are written to the catalog immediately:</p> <pre><code>workflow = ml.lookup_workflow(\"2-ABC1\")\nworkflow.description = \"Updated: now includes data augmentation\"\nworkflow.workflow_type = \"Training\"  # Must be a valid Workflow_Type term\n</code></pre>"},{"location":"user-guide/execution-configuration/#workflow-types","title":"Workflow Types","text":"<p>Workflow types are controlled vocabulary terms that categorize workflows. Common types include:</p> Type Description Training Model training workflows Inference Running predictions on new data Preprocessing Data cleaning and transformation Evaluation Model evaluation and metrics Annotation Adding labels or features <p>These are not fixed \u2014 add custom types for your project:</p> <pre><code>ml.add_term(\n    table=\"Workflow_Type\",\n    term_name=\"Data_Augmentation\",\n    description=\"Workflows that augment training data\"\n)\n</code></pre> <p>The workflow type must exist in the catalog before creating a workflow that uses it. <code>ml.create_workflow()</code> validates this and raises a <code>DerivaMLException</code> if the type is not found.</p>"},{"location":"user-guide/execution-configuration/#providing-the-workflow-to-an-execution","title":"Providing the Workflow to an Execution","text":"<p>A workflow must be provided when creating an execution. There are two ways:</p> <pre><code># Option 1: In the ExecutionConfiguration\nconfig = ExecutionConfiguration(\n    workflow=workflow,\n    description=\"Training run\",\n    datasets=[DatasetSpec(rid=\"1-ABC\")],\n)\nexe = ml.create_execution(config)\n\n# Option 2: As a separate argument to create_execution\nconfig = ExecutionConfiguration(\n    description=\"Training run\",\n    datasets=[DatasetSpec(rid=\"1-ABC\")],\n)\nexe = ml.create_execution(config, workflow=workflow)\n</code></pre> <p>If no workflow is provided in either place, a <code>DerivaMLException</code> is raised.</p>"},{"location":"user-guide/execution-configuration/#execution-lifecycle","title":"Execution Lifecycle","text":"<p>The execution workflow follows these steps:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  1. Create Execution Configuration                              \u2502\n\u2502     - Specify workflow                                          \u2502\n\u2502     - Declare input datasets and assets                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  2. Create and Start Execution                                  \u2502\n\u2502     - Context manager handles timing automatically              \u2502\n\u2502     - Input datasets/assets are recorded                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  3. Run ML Workflow                                             \u2502\n\u2502     - Download datasets as needed                               \u2502\n\u2502     - Process data, train models, run inference                 \u2502\n\u2502     - Register output files with asset_file_path()              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  4. Upload Outputs                                              \u2502\n\u2502     - Call upload_execution_outputs() after context exits       \u2502\n\u2502     - Files are uploaded to Hatrac object store                 \u2502\n\u2502     - Provenance links are created                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/execution-configuration/#creating-an-execution-configuration","title":"Creating an Execution Configuration","text":"<p>The <code>ExecutionConfiguration</code> specifies what inputs your workflow will use:</p> <pre><code>from deriva_ml import DerivaML\nfrom deriva_ml.execution import ExecutionConfiguration\nfrom deriva_ml.dataset.aux_classes import DatasetSpec\n\nml = DerivaML(hostname, catalog_id)\n\n# Create a workflow definition\nworkflow = ml.create_workflow(\n    name=\"ResNet50 Training\",\n    workflow_type=\"Training\",\n    description=\"Train ResNet50 on image classification task\"\n)\n\n# Configure the execution\nconfig = ExecutionConfiguration(\n    workflow=workflow,\n    description=\"Training run with augmented data\",\n    datasets=[\n        DatasetSpec(rid=\"1-ABC\"),                    # Use current version\n        DatasetSpec(rid=\"1-DEF\", version=\"1.2.0\"),  # Use specific version\n    ],\n    assets=[\"2-GHI\", \"2-JKL\"],  # Additional input asset RIDs\n)\n</code></pre>"},{"location":"user-guide/execution-configuration/#datasetspec-options","title":"DatasetSpec Options","text":"Parameter Type Default Description <code>rid</code> str required Dataset RID <code>version</code> str None Specific version (default: current) <code>materialize</code> bool True Download asset files (False = metadata only) <pre><code># Download with all files\nDatasetSpec(rid=\"1-ABC\", materialize=True)\n\n# Download metadata only (faster for large datasets)\nDatasetSpec(rid=\"1-ABC\", materialize=False)\n\n# Use specific version\nDatasetSpec(rid=\"1-ABC\", version=\"2.1.0\")\n</code></pre>"},{"location":"user-guide/execution-configuration/#running-an-execution","title":"Running an Execution","text":"<p>Use the context manager pattern for automatic timing:</p> <pre><code># Create execution with context manager\nwith ml.create_execution(config) as exe:\n    print(f\"Execution RID: {exe.execution_rid}\")\n    print(f\"Working directory: {exe.working_dir}\")\n\n    # Download input datasets\n    bag = exe.download_dataset_bag(DatasetSpec(rid=\"1-ABC\"))\n\n    # Access dataset elements\n    images = bag.list_dataset_members()[\"Image\"]\n    for img in images:\n        # img[\"Filename\"] contains local path to the file\n        process_image(img[\"Filename\"])\n\n    # Train your model\n    model = train_model(images)\n\n    # Register output files\n    model_path = exe.asset_file_path(\"Model\", \"best_model.pt\")\n    torch.save(model.state_dict(), model_path)\n\n    metrics_path = exe.asset_file_path(\"Execution_Metadata\", \"metrics.json\")\n    with open(metrics_path, 'w') as f:\n        json.dump({\"accuracy\": 0.95}, f)\n\n# IMPORTANT: Upload after context exits\nexe.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/execution-configuration/#what-the-context-manager-does","title":"What the Context Manager Does","text":"<ul> <li>On entry: Records start time, sets status to \"running\"</li> <li>On exit: Records stop time, calculates duration</li> <li>Exception handling: If an exception occurs, status is set to \"failed\"</li> </ul>"},{"location":"user-guide/execution-configuration/#why-upload-is-separate","title":"Why Upload is Separate","text":"<p><code>upload_execution_outputs()</code> is called outside the context manager because:</p> <ol> <li>Upload can be done asynchronously for large files</li> <li>You can inspect outputs before uploading</li> <li>Partial uploads can be retried if they fail</li> <li>Even failed executions should upload partial results</li> </ol>"},{"location":"user-guide/execution-configuration/#tuning-uploads-for-large-files","title":"Tuning Uploads for Large Files","text":"<p>When uploading large files (e.g., model checkpoints &gt; 1 GB), the default timeouts may not be sufficient. <code>upload_execution_outputs()</code> accepts parameters to control upload behavior:</p> <pre><code># Default behavior (50 MB chunks, 10 min timeout per chunk, 3 retries)\nexe.upload_execution_outputs()\n\n# Increase timeout for large files on slow connections (30 min per chunk)\nexe.upload_execution_outputs(timeout=(1800, 1800))\n\n# Use smaller chunks if timeouts persist (25 MB chunks)\nexe.upload_execution_outputs(chunk_size=25 * 1024 * 1024)\n\n# More retries with longer initial delay\nexe.upload_execution_outputs(max_retries=5, retry_delay=10.0)\n\n# Combined: large file on slow connection\nexe.upload_execution_outputs(\n    timeout=(1800, 1800),        # 30 min per chunk (both write and read)\n    chunk_size=25 * 1024 * 1024, # 25 MB chunks (smaller = faster per chunk)\n    max_retries=5,               # 5 retry attempts\n    retry_delay=10.0,            # 10s initial delay (doubles each retry)\n)\n</code></pre> <p>!!! note     The timeout tuple is <code>(connect_timeout, read_timeout)</code>. However, urllib3 uses     <code>connect_timeout</code> as the socket timeout when writing the request body (uploading     chunk data). Both values should be set large enough for a full chunk to be     transferred over your network.</p> Parameter Default Description <code>timeout</code> <code>(600, 600)</code> <code>(connect_timeout, read_timeout)</code> in seconds per chunk <code>chunk_size</code> 50 MB Chunk size in bytes for hatrac uploads <code>max_retries</code> <code>3</code> Maximum retry attempts for failed uploads <code>retry_delay</code> <code>5.0</code> Initial delay between retries (doubles each attempt)"},{"location":"user-guide/execution-configuration/#registering-output-files","title":"Registering Output Files","text":"<p>Use <code>asset_file_path()</code> to register files for upload:</p> <pre><code>with ml.create_execution(config) as exe:\n    # Method 1: Get a path for a new file\n    output_path = exe.asset_file_path(\n        asset_name=\"Model\",        # Target asset table\n        file_name=\"model.pt\"       # Filename to create\n    )\n    torch.save(model, output_path)  # Write to the returned path\n\n    # Method 2: Stage an existing file\n    exe.asset_file_path(\n        asset_name=\"Image\",\n        file_name=\"/path/to/existing/file.png\",  # Existing file\n        copy_file=True                           # Copy (default: symlink)\n    )\n\n    # Method 3: Rename during upload\n    exe.asset_file_path(\n        asset_name=\"Image\",\n        file_name=\"/path/to/temp.png\",\n        rename_file=\"processed_image.png\"\n    )\n\n    # Method 4: Apply asset types\n    exe.asset_file_path(\n        asset_name=\"Image\",\n        file_name=\"mask.png\",\n        asset_types=[\"Segmentation_Mask\", \"Derived\"]\n    )\n</code></pre>"},{"location":"user-guide/execution-configuration/#updating-status","title":"Updating Status","text":"<p>Report progress during long-running workflows:</p> <pre><code>from deriva_ml.core.definitions import Status\n\nwith ml.create_execution(config) as exe:\n    exe.update_status(Status.running, \"Loading data...\")\n\n    data = load_data()\n    exe.update_status(Status.running, \"Training model...\")\n\n    for epoch in range(100):\n        train_epoch(model, data)\n        exe.update_status(Status.running, f\"Epoch {epoch+1}/100 complete\")\n\n    exe.update_status(Status.running, \"Saving model...\")\n</code></pre>"},{"location":"user-guide/execution-configuration/#creating-output-datasets","title":"Creating Output Datasets","text":"<p>If your workflow produces a new curated dataset:</p> <pre><code>with ml.create_execution(config) as exe:\n    # Process data and generate outputs\n    processed_rids = process_data(input_data)\n\n    # Create a new dataset linked to this execution\n    output_dataset = exe.create_dataset(\n        description=\"Augmented training images\",\n        dataset_types=[\"Training\", \"Augmented\"]\n    )\n\n    # Add processed items to the output dataset\n    output_dataset.add_dataset_members(processed_rids)\n\nexe.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/execution-configuration/#restoring-executions","title":"Restoring Executions","text":"<p>Resume working with a previous execution:</p> <pre><code># Restore by RID\nexe = ml.restore_execution(\"1-XYZ\")\n\n# Continue working\nexe.asset_file_path(\"Model\", \"continued_model.pt\")\nexe.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/execution-configuration/#complete-example","title":"Complete Example","text":"<pre><code>from deriva_ml import DerivaML\nfrom deriva_ml.execution import ExecutionConfiguration\nfrom deriva_ml.dataset.aux_classes import DatasetSpec\nimport torch\nimport json\n\n# Connect to catalog\nml = DerivaML(\"your-server.org\", \"1\")\n\n# Define workflow\nworkflow = ml.create_workflow(\n    name=\"Image Classifier Training v3\",\n    workflow_type=\"Training\",\n    description=\"Train CNN classifier on medical images\"\n)\n\n# Configure execution\nconfig = ExecutionConfiguration(\n    workflow=workflow,\n    description=\"Training with learning rate 0.001\",\n    datasets=[DatasetSpec(rid=\"1-ABC\")],\n)\n\n# Run execution\nwith ml.create_execution(config) as exe:\n    # Download training data\n    bag = exe.download_dataset_bag(DatasetSpec(rid=\"1-ABC\"))\n    train_loader = create_dataloader(bag)\n\n    # Train model\n    model = ResNet50()\n    for epoch in range(50):\n        loss = train_epoch(model, train_loader)\n        exe.update_status(Status.running, f\"Epoch {epoch}: loss={loss:.4f}\")\n\n    # Save model\n    model_path = exe.asset_file_path(\"Model\", \"classifier.pt\")\n    torch.save(model.state_dict(), model_path)\n\n    # Save metrics\n    metrics_path = exe.asset_file_path(\"Execution_Metadata\", \"training_metrics.json\")\n    with open(metrics_path, 'w') as f:\n        json.dump({\"final_loss\": loss, \"epochs\": 50}, f)\n\n# Upload all outputs\nexe.upload_execution_outputs()\n\nprint(f\"Execution complete: {exe.execution_rid}\")\n</code></pre>"},{"location":"user-guide/features/","title":"Features","text":"<p>Features are a core concept in DerivaML for ML data engineering. They enable you to associate metadata with domain objects (like Images, Subjects, or any table in your schema) to support machine learning workflows.</p>"},{"location":"user-guide/features/#what-is-a-feature","title":"What is a Feature?","text":"<p>A feature associates metadata values with records in your domain tables. Unlike regular table columns, features:</p> <ol> <li>Track Provenance: Every feature value records which Execution produced it</li> <li>Use Controlled Vocabularies: Categorical features use vocabulary terms for consistency</li> <li>Support Multiple Values: An object can have multiple values for the same feature</li> <li>Are Versioned: Feature values are included in dataset versions for reproducibility</li> </ol>"},{"location":"user-guide/features/#common-use-cases","title":"Common Use Cases","text":"Use Case Example Feature Type Ground truth labels \"Normal\" vs \"Abnormal\" classification Term-based Model predictions Inference results from a classifier Term-based Quality scores Image quality ratings (1-5) Term-based Derived measurements Computed metrics from analysis Value-based Related assets Segmentation masks, embeddings Asset-based"},{"location":"user-guide/features/#feature-types","title":"Feature Types","text":"<p>Features can reference different types of values:</p>"},{"location":"user-guide/features/#term-based-features","title":"Term-Based Features","text":"<p>The most common type. Values come from controlled vocabulary tables, ensuring consistency and enabling queries across the vocabulary hierarchy.</p> <pre><code># Create a vocabulary for diagnosis labels\nml.create_vocabulary(\"Diagnosis_Type\", \"Clinical diagnosis categories\")\nml.add_term(\"Diagnosis_Type\", \"Normal\", \"No abnormality detected\")\nml.add_term(\"Diagnosis_Type\", \"Abnormal\", \"Abnormality present\")\n\n# Create a feature that uses this vocabulary\nml.create_feature(\n    target_table=\"Image\",\n    feature_name=\"Diagnosis\",\n    terms=[\"Diagnosis_Type\"],\n    comment=\"Clinical diagnosis for this image\"\n)\n</code></pre>"},{"location":"user-guide/features/#asset-based-features","title":"Asset-Based Features","text":"<p>Link derived assets (files) to domain objects. Useful for segmentation masks, embeddings, or any computed files.</p> <pre><code># Create an asset table for segmentation masks\nml.create_asset(\"Segmentation_Mask\", comment=\"Binary segmentation mask images\")\n\n# Create a feature linking masks to images\nml.create_feature(\n    target_table=\"Image\",\n    feature_name=\"Segmentation\",\n    assets=[\"Segmentation_Mask\"],\n    comment=\"Segmentation mask for this image\"\n)\n</code></pre> <p>When you create an asset-based feature, the generated <code>FeatureRecord</code> class accepts either a file path or an asset RID for the asset column. During execution upload, file paths are automatically replaced with the RIDs of the uploaded assets.</p>"},{"location":"user-guide/features/#mixed-features","title":"Mixed Features","text":"<p>Features can reference both terms and assets for complex annotations.</p>"},{"location":"user-guide/features/#creating-feature-values","title":"Creating Feature Values","text":"<p>Feature values are created during Executions to maintain provenance. Every value knows which workflow produced it.</p> <p>The workflow for adding feature values is: 1. Get the FeatureRecord class for your feature (via <code>create_feature()</code> or <code>feature_record_class()</code>) 2. Create instances of the FeatureRecord with your data 3. Add the records within an execution using <code>execution.add_features()</code></p> <pre><code>from deriva_ml import DerivaML\nfrom deriva_ml.execution import ExecutionConfiguration\nfrom deriva_ml.dataset import DatasetSpec\n\nml = DerivaML(hostname, catalog_id)\n\n# Get the FeatureRecord class for the Diagnosis feature\nDiagnosisFeature = ml.feature_record_class(\"Image\", \"Diagnosis\")\n\n# Set up execution\nconfig = ExecutionConfiguration(\n    workflow=ml.create_workflow(\"Labeling\", \"Annotation\"),\n    datasets=[DatasetSpec(rid=dataset_rid)],\n)\n\nwith ml.create_execution(config) as exe:\n    # Get images to label\n    bag = exe.download_dataset_bag(DatasetSpec(rid=dataset_rid))\n\n    # Create feature records (provenance tracked automatically)\n    feature_records = []\n    for image in bag.list_dataset_members()[\"Image\"]:\n        record = DiagnosisFeature(\n            Image=image[\"RID\"],       # Target record RID\n            Diagnosis_Type=\"Normal\",  # Vocabulary term name\n        )\n        feature_records.append(record)\n\n    # Add all feature records to the execution\n    exe.add_features(feature_records)\n\n# Upload after execution context exits\nexe.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/features/#asset-based-feature-values","title":"Asset-Based Feature Values","text":"<p>For asset-based features, you provide file paths instead of vocabulary terms. The execution handles uploading the asset files and linking them to the feature records.</p> <pre><code># Get the FeatureRecord class for an asset-based feature\nSegmentationFeature = ml.feature_record_class(\"Image\", \"Segmentation\")\n\nconfig = ExecutionConfiguration(\n    workflow=ml.create_workflow(\"Segmentation\", \"Model_Inference\"),\n    datasets=[DatasetSpec(rid=dataset_rid)],\n)\n\nwith ml.create_execution(config) as exe:\n    bag = exe.download_dataset_bag(DatasetSpec(rid=dataset_rid))\n\n    feature_records = []\n    for image in bag.list_dataset_members()[\"Image\"]:\n        # Create the asset file using asset_file_path\n        mask_path = exe.asset_file_path(\n            \"Segmentation_Mask\",\n            f\"mask_{image['RID']}.png\",\n        )\n\n        # Write the asset file (e.g., a segmentation mask)\n        generate_segmentation_mask(image, output_path=mask_path)\n\n        # Reference the file path in the feature record\n        record = SegmentationFeature(\n            Image=image[\"RID\"],\n            Segmentation_Mask=mask_path,  # File path, not an RID\n        )\n        feature_records.append(record)\n\n    exe.add_features(feature_records)\n\n# Upload assets and feature values\nexe.upload_execution_outputs()\n</code></pre> <p>During upload, the execution automatically:</p> <ol> <li>Uploads each asset file to the catalog's object store</li> <li>Replaces the file paths in the feature records with the RIDs of the uploaded assets</li> <li>Inserts the feature records into the catalog</li> </ol> <p>After upload, querying the feature values returns asset RIDs rather than file paths.</p>"},{"location":"user-guide/features/#querying-feature-values","title":"Querying Feature Values","text":""},{"location":"user-guide/features/#list-all-values-for-a-feature","title":"List All Values for a Feature","text":"<pre><code># Get all diagnosis values across all images\nvalues = ml.list_feature_values(\"Image\", \"Diagnosis\")\nfor v in values:\n    print(f\"Image {v['Image']}: {v['Diagnosis']} (by Execution {v['Execution']})\")\n</code></pre>"},{"location":"user-guide/features/#find-features-on-a-table","title":"Find Features on a Table","text":"<pre><code># What features are defined for images?\nfeatures = ml.find_features(\"Image\")\nfor f in features:\n    print(f\"  {f.feature_name}: {f.feature_table.name}\")\n\n# List all features in the catalog\nall_features = ml.find_features()\n</code></pre>"},{"location":"user-guide/features/#get-feature-structure","title":"Get Feature Structure","text":"<pre><code># Examine a specific feature's structure\nfeature = ml.lookup_feature(\"Image\", \"Diagnosis\")\nprint(f\"Target: {feature.target_table.name}\")\nprint(f\"Feature table: {feature.feature_table.name}\")\nprint(f\"Columns: {[c.name for c in feature.feature_table.columns]}\")\n</code></pre>"},{"location":"user-guide/features/#feature-tables","title":"Feature Tables","text":"<p>When you create a feature, DerivaML creates an association table with:</p> Column Purpose <code>{TargetTable}</code> RID of the domain object (e.g., Image RID) <code>Feature_Name</code> The feature name (from Feature_Name vocabulary) <code>Execution</code> RID of the execution that produced this value <code>{VocabTable}</code> RID of the vocabulary term (for term-based features) <code>{AssetTable}</code> RID of the asset (for asset-based features) <p>This structure enables: - Querying all values for a feature - Finding which execution produced a value - Joining with vocabulary tables for term labels - Multiple values per object (many-to-many relationship)</p>"},{"location":"user-guide/features/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/features/#feature-naming","title":"Feature Naming","text":"<ul> <li>Use descriptive names: <code>Diagnosis</code>, <code>Quality_Score</code>, <code>Predicted_Class</code></li> <li>Feature names are controlled vocabulary terms in <code>Feature_Name</code> table</li> <li>Same feature name can be used across different tables</li> </ul>"},{"location":"user-guide/features/#vocabulary-design","title":"Vocabulary Design","text":"<ul> <li>Create vocabularies before features that use them</li> <li>Include synonyms for flexible matching</li> <li>Add descriptions to help users understand term meanings</li> </ul>"},{"location":"user-guide/features/#provenance","title":"Provenance","text":"<ul> <li>Always create feature values within an Execution context</li> <li>Use meaningful workflow types: \"Manual_Annotation\", \"Model_Inference\", etc.</li> <li>Include dataset versions for reproducibility</li> </ul>"},{"location":"user-guide/features/#working-with-multiple-values","title":"Working with Multiple Values","text":"<p>A single object can have multiple values for the same feature. This is common when:</p> <ul> <li>Multiple annotators label the same image</li> <li>A model produces predictions at different times</li> <li>Different versions of analysis are run</li> </ul>"},{"location":"user-guide/features/#querying-multiple-values","title":"Querying Multiple Values","text":"<pre><code># Get all values for a specific image\nvalues = ml.list_feature_values(\"Image\", \"Diagnosis\")\nimage_values = [v for v in values if v[\"Image\"] == image_rid]\n\nfor v in image_values:\n    print(f\"Value: {v['Diagnosis_Type']} from Execution {v['Execution']}\")\n</code></pre>"},{"location":"user-guide/features/#resolving-multiple-values-in-restructure_assets","title":"Resolving Multiple Values in restructure_assets","text":"<p>When restructuring assets by a feature that has multiple values, you can provide a <code>value_selector</code> function to choose which value to use:</p> <pre><code>from deriva_ml.dataset.dataset_bag import FeatureValueRecord\n\ndef select_latest(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n    \"\"\"Select the value from the most recent execution.\"\"\"\n    return max(records, key=lambda r: r.execution_rid or \"\")\n\nbag.restructure_assets(\n    asset_table=\"Image\",\n    output_dir=Path(\"./ml_data\"),\n    group_by=[\"Diagnosis\"],\n    value_selector=select_latest,\n)\n</code></pre> <p>The <code>FeatureValueRecord</code> provides:</p> Attribute Description <code>target_rid</code> RID of the object this value applies to <code>feature_name</code> Name of the feature <code>value</code> The feature value (e.g., vocabulary term name) <code>execution_rid</code> RID of the execution that created this value <code>raw_record</code> Complete feature table row as a dictionary"},{"location":"user-guide/features/#consensus-or-aggregation","title":"Consensus or Aggregation","text":"<p>For more complex scenarios, you might aggregate multiple values:</p> <pre><code>from collections import Counter\n\ndef select_majority_vote(records: list[FeatureValueRecord]) -&gt; FeatureValueRecord:\n    \"\"\"Select the most common value (majority vote).\"\"\"\n    counts = Counter(r.value for r in records)\n    most_common_value = counts.most_common(1)[0][0]\n    return next(r for r in records if r.value == most_common_value)\n</code></pre>"},{"location":"user-guide/features/#deleting-features","title":"Deleting Features","text":"<pre><code># WARNING: This permanently removes the feature and all its values\nml.delete_feature(\"Image\", \"Diagnosis\")\n</code></pre> <p>Deletion removes: - The feature table - All feature values - All provenance information for this feature</p>"},{"location":"user-guide/features/#features-in-datasets","title":"Features in Datasets","text":"<p>Feature values are included when you:</p> <ol> <li>Export a dataset: Feature tables are exported as CSVs in the BDBag</li> <li>Download a dataset bag: Feature values are loaded into the local SQLite database</li> <li>Version a dataset: Feature values at that version are preserved via catalog snapshots</li> </ol> <p>This ensures ML workflows have access to the labels and annotations associated with dataset elements.</p>"},{"location":"user-guide/file-assets/","title":"File Assets","text":"<p>File assets are tables that manage files (images, models, data files, etc.) in DerivaML. They provide automatic tracking of file metadata, integration with the Hatrac object store, and provenance linking through executions.</p>"},{"location":"user-guide/file-assets/#what-is-an-asset-table","title":"What is an Asset Table?","text":"<p>An asset table is a special table type that includes standard columns for file management:</p> Column Type Purpose <code>URL</code> text Hatrac object store URL for the file <code>Filename</code> text Original filename <code>Length</code> int8 File size in bytes <code>MD5</code> text MD5 checksum for integrity verification <code>Description</code> text Optional description <p>You can add additional columns for domain-specific metadata (e.g., <code>Width</code>, <code>Height</code> for images).</p>"},{"location":"user-guide/file-assets/#asset-types","title":"Asset Types","text":"<p>Assets are categorized using the <code>Asset_Type</code> controlled vocabulary. This enables:</p> <ul> <li>Filtering assets by type in queries</li> <li>Organizing assets in the Chaise UI</li> <li>Consistent categorization across the catalog</li> </ul> <pre><code># List available asset types\ntypes = ml.list_vocabulary_terms(\"Asset_Type\")\nfor t in types:\n    print(f\"{t.name}: {t.description}\")\n\n# Add a new asset type\nml.add_term(\n    table=\"Asset_Type\",\n    term_name=\"Segmentation_Mask\",\n    description=\"Binary mask images for segmentation tasks\"\n)\n</code></pre>"},{"location":"user-guide/file-assets/#creating-asset-tables","title":"Creating Asset Tables","text":""},{"location":"user-guide/file-assets/#basic-asset-table","title":"Basic Asset Table","text":"<pre><code>from deriva_ml import DerivaML\n\nml = DerivaML(hostname, catalog_id)\n\n# Create a simple asset table\nml.create_asset(\n    asset_name=\"Model\",\n    comment=\"Trained ML model files\"\n)\n</code></pre>"},{"location":"user-guide/file-assets/#asset-table-with-metadata-columns","title":"Asset Table with Metadata Columns","text":"<pre><code>from deriva_ml import ColumnDefinition, BuiltinTypes\n\n# Create an image asset table with additional metadata\nml.create_asset(\n    asset_name=\"Image\",\n    column_defs=[\n        ColumnDefinition(name=\"Width\", type=BuiltinTypes.int4, comment=\"Image width in pixels\"),\n        ColumnDefinition(name=\"Height\", type=BuiltinTypes.int4, comment=\"Image height in pixels\"),\n        ColumnDefinition(name=\"Format\", type=BuiltinTypes.text, comment=\"Image format (PNG, JPEG, etc.)\"),\n    ],\n    comment=\"Training and evaluation images\"\n)\n</code></pre>"},{"location":"user-guide/file-assets/#asset-table-with-references","title":"Asset Table with References","text":"<p>Link assets to other domain tables:</p> <pre><code># Create image asset that references Subject\nml.create_asset(\n    asset_name=\"Image\",\n    referenced_tables=[\"Subject\"],  # Creates foreign key to Subject table\n    comment=\"Medical images linked to subjects\"\n)\n</code></pre>"},{"location":"user-guide/file-assets/#uploading-assets-in-executions","title":"Uploading Assets in Executions","text":"<p>Assets are uploaded through the execution workflow using <code>asset_file_path()</code>. This:</p> <ol> <li>Stages files in a local working directory</li> <li>Associates files with the correct asset table</li> <li>Applies asset type labels</li> <li>Links files to the execution for provenance</li> </ol>"},{"location":"user-guide/file-assets/#basic-upload-pattern","title":"Basic Upload Pattern","text":"<pre><code>from deriva_ml.execution import ExecutionConfiguration\n\nconfig = ExecutionConfiguration(\n    workflow=ml.create_workflow(\"Training\", \"Training\"),\n    datasets=[DatasetSpec(rid=dataset_rid)],\n)\n\nwith ml.create_execution(config) as exe:\n    # Train your model...\n    model = train_model(data)\n\n    # Register the model file for upload\n    model_path = exe.asset_file_path(\n        asset_name=\"Model\",           # Target asset table\n        file_name=\"best_model.pt\"     # Filename to use\n    )\n\n    # Save the model to the registered path\n    torch.save(model.state_dict(), model_path)\n\n# Upload all registered assets to the catalog\nexe.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/file-assets/#registering-existing-files","title":"Registering Existing Files","text":"<pre><code>with ml.create_execution(config) as exe:\n    # Stage an existing file for upload\n    exe.asset_file_path(\n        asset_name=\"Image\",\n        file_name=\"/path/to/existing/image.png\",  # Source file path\n        copy_file=True,                           # Copy instead of symlink\n        rename_file=\"processed_image.png\"         # Optional: rename during upload\n    )\n\nexe.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/file-assets/#applying-asset-types","title":"Applying Asset Types","text":"<pre><code>with ml.create_execution(config) as exe:\n    # Register with specific asset types\n    exe.asset_file_path(\n        asset_name=\"Image\",\n        file_name=\"mask.png\",\n        asset_types=[\"Segmentation_Mask\", \"Derived\"]  # Multiple types\n    )\n\nexe.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/file-assets/#listing-assets","title":"Listing Assets","text":"<pre><code># List all assets in a table\nassets = ml.list_assets(\"Image\")\nfor asset in assets:\n    print(f\"RID: {asset['RID']}\")\n    print(f\"  Filename: {asset['Filename']}\")\n    print(f\"  URL: {asset['URL']}\")\n    print(f\"  Size: {asset['Length']} bytes\")\n    print(f\"  MD5: {asset['MD5']}\")\n    print(f\"  Types: {asset.get('Asset_Type', [])}\")\n</code></pre>"},{"location":"user-guide/file-assets/#assets-and-provenance","title":"Assets and Provenance","text":"<p>Every asset uploaded through an execution is linked via an association table:</p> Table Purpose <code>{Asset}_Execution</code> Links assets to executions with role (Input/Output) <p>This enables: - Finding which execution produced an asset - Tracking which assets were used as inputs - Full lineage from raw data to final outputs</p> <pre><code># Query assets produced by an execution\npb = ml.pathBuilder()\nasset_execution = pb.schemas[ml.ml_schema].Image_Execution\nresults = asset_execution.filter(\n    asset_execution.Execution == execution_rid\n).filter(\n    asset_execution.Asset_Role == \"Output\"\n).entities().fetch()\n</code></pre>"},{"location":"user-guide/file-assets/#assets-in-datasets","title":"Assets in Datasets","text":"<p>Assets can be included in datasets as dataset elements:</p> <pre><code># Enable Image table as dataset element type\nml.add_dataset_element_type(\"Image\")\n\n# Add images to a dataset\ndataset = ml.lookup_dataset(dataset_rid)\ndataset.add_dataset_members(image_rids)\n</code></pre> <p>When you download a dataset bag, asset files are fetched based on the <code>materialize</code> option:</p> <pre><code># Download with all asset files\nbag = exe.download_dataset_bag(\n    DatasetSpec(rid=dataset_rid, materialize=True)\n)\n\n# Download metadata only (faster, smaller)\nbag = exe.download_dataset_bag(\n    DatasetSpec(rid=dataset_rid, materialize=False)\n)\n</code></pre>"},{"location":"user-guide/file-assets/#working-directory","title":"Working Directory","text":"<p>Each execution has a temporary working directory for staging files:</p> <pre><code>with ml.create_execution(config) as exe:\n    # Get the working directory path\n    work_dir = exe.working_dir\n    print(f\"Working directory: {work_dir}\")\n\n    # Files registered with asset_file_path are staged here\n    # They're uploaded when upload_execution_outputs() is called\n</code></pre> <p>The working directory is cleaned up after <code>upload_execution_outputs(clean_folder=True)</code> (default).</p>"},{"location":"user-guide/file-assets/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/file-assets/#file-organization","title":"File Organization","text":"<ul> <li>Use descriptive filenames that include relevant identifiers</li> <li>Apply consistent asset types for filtering</li> <li>Include meaningful descriptions in asset records</li> </ul>"},{"location":"user-guide/file-assets/#large-files","title":"Large Files","text":"<ul> <li>Consider compression for large files</li> <li>Use <code>materialize=False</code> when you only need metadata</li> <li>Monitor disk space in working directories</li> </ul>"},{"location":"user-guide/file-assets/#provenance","title":"Provenance","text":"<ul> <li>Always upload assets through executions for provenance</li> <li>Use meaningful workflow types and descriptions</li> <li>Include input datasets for complete lineage</li> </ul>"},{"location":"user-guide/hydra-zen-configuration/","title":"Hydra-zen Configuration","text":"<p>DerivaML integrates with hydra-zen for configuration management, enabling reproducible ML workflows with structured, composable configurations.</p>"},{"location":"user-guide/hydra-zen-configuration/#overview","title":"Overview","text":"<p>Hydra-zen provides a Pythonic way to configure applications using dataclasses and structured configs. DerivaML leverages this for:</p> <ul> <li>Environment Configuration: Different settings for dev/staging/production</li> <li>Dataset Collections: Named groups of datasets for experiments</li> <li>Execution Parameters: Reproducible execution configurations</li> <li>Working Directory Management: Automatic Hydra output organization</li> </ul>"},{"location":"user-guide/hydra-zen-configuration/#quick-start","title":"Quick Start","text":"<pre><code>from hydra_zen import builds, instantiate, store\nfrom deriva_ml import DerivaML, DerivaMLConfig\n\n# Create a structured config for DerivaML\nDerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\n\n# Configure for your environment\nconf = DerivaMLConf(\n    hostname='deriva.example.org',\n    catalog_id='42',\n    domain_schema='my_domain',\n)\n\n# Instantiate to get a DerivaMLConfig, then create DerivaML\nconfig = instantiate(conf)\nml = DerivaML.instantiate(config)\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#configuration-classes","title":"Configuration Classes","text":""},{"location":"user-guide/hydra-zen-configuration/#derivamlconfig","title":"DerivaMLConfig","text":"<p>The main configuration class for DerivaML instances:</p> <pre><code>from deriva_ml import DerivaMLConfig\nfrom hydra_zen import builds\n\nDerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\n\nconf = DerivaMLConf(\n    hostname='example.org',           # Deriva server hostname\n    catalog_id='1',                   # Catalog ID or name\n    domain_schema='my_project',       # Domain schema name\n    working_dir='/shared/workspace',  # Base working directory\n    use_minid=True,                   # Use MINID for dataset bags\n    check_auth=True,                  # Verify authentication\n)\n</code></pre> Parameter Type Default Description <code>hostname</code> str required Deriva server hostname <code>catalog_id</code> str/int 1 Catalog identifier <code>domain_schema</code> str None Domain schema (auto-detected if None) <code>working_dir</code> str/Path None Base directory for outputs <code>ml_schema</code> str \"deriva-ml\" ML schema name <code>use_minid</code> bool True Use MINID service for datasets <code>check_auth</code> bool True Verify authentication on connect"},{"location":"user-guide/hydra-zen-configuration/#datasetspecconfig","title":"DatasetSpecConfig","text":"<p>For configuring dataset specifications in execution configurations:</p> <pre><code>from deriva_ml.dataset import DatasetSpecConfig\n\n# Create dataset specs for an experiment\ntraining_data = DatasetSpecConfig(\n    rid=\"1ABC\",\n    version=\"1.0.0\",\n    materialize=True,      # Download asset files\n    description=\"Training images\"\n)\n\nmetadata_only = DatasetSpecConfig(\n    rid=\"2DEF\",\n    version=\"2.0.0\",\n    materialize=False,     # Only download table data\n)\n</code></pre> Parameter Type Default Description <code>rid</code> str required Dataset RID <code>version</code> str required Semantic version (e.g., \"1.2.0\") <code>materialize</code> bool True Download asset files <code>description</code> str \"\" Description for logging"},{"location":"user-guide/hydra-zen-configuration/#assetridconfig","title":"AssetRIDConfig","text":"<p>For configuring input assets (model weights, config files, etc.):</p> <pre><code>from deriva_ml.execution import AssetRIDConfig\n\n# Define input assets\nmodel_weights = AssetRIDConfig(rid=\"WXYZ\", description=\"Pretrained model\")\nconfig_file = AssetRIDConfig(rid=\"ABCD\", description=\"Hyperparameters\")\n\nassets = [model_weights, config_file]\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#working-directory-configuration","title":"Working Directory Configuration","text":"<p>DerivaML automatically configures Hydra's output directory based on your <code>working_dir</code> setting:</p> <pre><code>conf = DerivaMLConf(\n    hostname='deriva.example.org',\n    working_dir='/shared/ml_workspace',  # Custom working directory\n)\n</code></pre> <p>The output structure is:</p> <pre><code>{working_dir}/{username}/deriva-ml/hydra/{timestamp}/\n</code></pre> <p>For example:</p> <pre><code>/shared/ml_workspace/jsmith/deriva-ml/hydra/2024-01-15_10-30-45/\n</code></pre> <p>This ensures: - Each user has isolated workspace - Outputs are organized by timestamp - Hydra config files are preserved for reproducibility</p>"},{"location":"user-guide/hydra-zen-configuration/#using-the-hydra-store","title":"Using the Hydra Store","text":"<p>The hydra-zen store allows you to register named configurations:</p>"},{"location":"user-guide/hydra-zen-configuration/#environment-configurations","title":"Environment Configurations","text":"<pre><code>from hydra_zen import store\nfrom deriva_ml import DerivaMLConfig\n\nDerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\n\n# Register different environments\nderiva_store = store(group=\"deriva_ml\")\n\nderiva_store(DerivaMLConf(\n    hostname='dev.example.org',\n    catalog_id='1',\n    use_minid=False,\n), name='dev')\n\nderiva_store(DerivaMLConf(\n    hostname='prod.example.org',\n    catalog_id='100',\n    use_minid=True,\n), name='prod')\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#dataset-collections","title":"Dataset Collections","text":"<pre><code>from hydra_zen import store\nfrom deriva_ml.dataset import DatasetSpecConfig\n\n# Define dataset collections\ntraining_v1 = [\n    DatasetSpecConfig(rid=\"TRNA\", version=\"1.0.0\"),\n    DatasetSpecConfig(rid=\"TRNB\", version=\"1.0.0\"),\n]\n\ntraining_v2 = [\n    DatasetSpecConfig(rid=\"TRNA\", version=\"2.0.0\"),\n    DatasetSpecConfig(rid=\"TRNB\", version=\"2.0.0\"),\n    DatasetSpecConfig(rid=\"TRNC\", version=\"1.0.0\"),\n]\n\n# Store them\ndatasets_store = store(group=\"datasets\")\ndatasets_store(training_v1, name=\"training_v1\")\ndatasets_store(training_v2, name=\"training_v2\")\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#asset-collections","title":"Asset Collections","text":"<pre><code>from hydra_zen import store\nfrom deriva_ml.execution import AssetRIDConfig\n\n# Define asset collections\nresnet_weights = [\n    AssetRIDConfig(rid=\"RSN1\", description=\"ResNet50 pretrained\"),\n]\n\nvit_weights = [\n    AssetRIDConfig(rid=\"VIT1\", description=\"ViT-B/16 pretrained\"),\n    AssetRIDConfig(rid=\"VIT2\", description=\"ViT fine-tuned\"),\n]\n\n# Store them\nassets_store = store(group=\"assets\")\nassets_store(resnet_weights, name=\"resnet\")\nassets_store(vit_weights, name=\"vit\")\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#complete-execution-configuration","title":"Complete Execution Configuration","text":"<p>Combine all components for a full execution configuration:</p> <pre><code>from hydra_zen import builds, instantiate, make_config, store\nfrom deriva_ml import DerivaML, DerivaMLConfig\nfrom deriva_ml.execution import ExecutionConfiguration, Workflow\nfrom deriva_ml.dataset import DatasetSpecConfig\n\n# Build configs\nDerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\nExecConf = builds(ExecutionConfiguration, populate_full_signature=True)\nWorkflowConf = builds(\n    Workflow,\n    name=\"Image Classification\",\n    workflow_type=\"Training\",\n    description=\"Train CNN classifier\",\n    populate_full_signature=True\n)\n\n# Create combined application config\nAppConfig = make_config(\n    deriva_ml=DerivaMLConf(hostname=\"example.org\", catalog_id=\"1\"),\n    execution=ExecConf(\n        description=\"Training run\",\n        datasets=[\n            DatasetSpecConfig(rid=\"DATA\", version=\"1.0.0\"),\n        ],\n        assets=[\"WGTS\"],\n    ),\n    workflow=WorkflowConf,\n)\n\n# Use in your application\ndef train(cfg: AppConfig):\n    # Instantiate configs\n    ml_config = instantiate(cfg.deriva_ml)\n    exec_config = instantiate(cfg.execution)\n\n    # Create DerivaML instance\n    ml = DerivaML.instantiate(ml_config)\n\n    # Run execution\n    with ml.create_execution(exec_config) as exe:\n        # ... training code ...\n        pass\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#using-with-hydra-cli","title":"Using with Hydra CLI","text":"<p>DerivaML provides <code>deriva-ml-run</code> which handles Hydra configuration composition, config module loading, and execution tracking automatically. See Running Models and Notebooks for the recommended workflow.</p> <p>The examples below show the underlying Hydra CLI patterns for reference:</p> <pre><code># Use default config\npython train.py\n\n# Override hostname\npython train.py deriva_ml.hostname=staging.example.org\n\n# Use different dataset collection\npython train.py +datasets=training_v2\n\n# Multi-run with different configs\npython train.py --multirun +datasets=training_v1,training_v2\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#example-complete-ml-script","title":"Example: Complete ML Script","text":"<p>!!! note     In practice, <code>create_model_config()</code> and <code>deriva-ml-run</code> handle the     boilerplate shown below automatically. See     Running Models and Notebooks for the     recommended approach.</p> <pre><code>\"\"\"train.py - Example training script with hydra-zen configuration.\"\"\"\nfrom hydra_zen import builds, instantiate, store, zen\nfrom deriva_ml import DerivaML, DerivaMLConfig\nfrom deriva_ml.execution import ExecutionConfiguration\nfrom deriva_ml.dataset import DatasetSpecConfig\n\n# Define configs\nDerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\nExecConf = builds(ExecutionConfiguration, populate_full_signature=True)\n\n# Store environment configs\nstore(DerivaMLConf(hostname=\"localhost\", catalog_id=1), group=\"deriva_ml\", name=\"local\")\nstore(DerivaMLConf(hostname=\"prod.org\", catalog_id=100), group=\"deriva_ml\", name=\"prod\")\n\n# Store dataset configs\nstore([DatasetSpecConfig(rid=\"DATA\", version=\"1.0.0\")], group=\"datasets\", name=\"default\")\n\n# Main config combining all groups\nConfig = make_config(\n    defaults=[\n        \"_self_\",\n        {\"deriva_ml\": \"local\"},\n        {\"datasets\": \"default\"},\n    ],\n    deriva_ml=DerivaMLConf,\n    datasets=list,\n    description=\"Training run\",\n)\n\n@zen(Config)\ndef main(cfg):\n    # Instantiate DerivaML\n    ml_config = instantiate(cfg.deriva_ml)\n    ml = DerivaML.instantiate(ml_config)\n\n    # Create execution config\n    exec_config = ExecutionConfiguration(\n        description=cfg.description,\n        datasets=[instantiate(d) for d in cfg.datasets],\n    )\n\n    # Run\n    with ml.create_execution(exec_config) as exe:\n        for ds in exe.datasets:\n            bag = exe.download_dataset_bag(ds)\n            # Process data...\n\n    exe.upload_execution_outputs()\n\nif __name__ == \"__main__\":\n    store.add_to_hydra_store()\n    main()\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#configuring-ml-models-with-derivaml","title":"Configuring ML Models with DerivaML","text":"<p>A powerful pattern is to use <code>zen_partial=True</code> to create partially configured model functions that receive the DerivaML <code>Execution</code> object at runtime. This allows you to:</p> <ul> <li>Configure model hyperparameters via Hydra</li> <li>Access datasets and assets through the execution object</li> <li>Keep model code separate from configuration</li> </ul>"},{"location":"user-guide/hydra-zen-configuration/#model-protocol","title":"Model Protocol","text":"<p>Define a protocol for models that integrate with DerivaML:</p> <pre><code># models/model_protocol.py\nfrom typing import Protocol, Any, runtime_checkable\nfrom deriva_ml.execution import Execution\nfrom deriva_ml import DerivaML\n\n@runtime_checkable\nclass DerivaMLModel(Protocol):\n    def __call__(self,\n                 *args: Any,\n                 ml_instance: DerivaML,\n                 execution: Execution,\n                 **kwargs: Any) -&gt; None:\n        \"\"\"Interface for functions that integrate DerivaML with ML frameworks.\"\"\"\n        ...\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#model-implementation","title":"Model Implementation","text":"<p>Create model functions that follow the protocol:</p> <pre><code># models/my_model.py\nfrom deriva_ml.execution import Execution\nfrom deriva_ml import DerivaML, MLAsset, ExecAssetType\n\ndef train_classifier(\n    learning_rate: float,\n    epochs: int,\n    batch_size: int,\n    ml_instance: DerivaML,\n    execution: Execution | None = None,\n) -&gt; None:\n    \"\"\"Train a classifier using DerivaML execution context.\n\n    Args:\n        learning_rate: Learning rate for optimizer\n        epochs: Number of training epochs\n        batch_size: Training batch size\n        ml_instance: DerivaML instance for catalog access\n        execution: Execution object with datasets, assets, and working directory\n    \"\"\"\n    # Access input assets (e.g., pretrained weights)\n    for table, assets in execution.asset_paths.items():\n        print(f\"Loading assets from {table}:\")\n        for asset in assets:\n            print(f\"  {asset}\")\n\n    # Access datasets\n    for dataset in execution.datasets:\n        bag = execution.download_dataset_bag(dataset)\n        # Process dataset...\n\n    # Your training code here\n    print(f\"Training with lr={learning_rate}, epochs={epochs}, batch={batch_size}\")\n\n    # Register output files for upload\n    model_path = execution.asset_file_path(\n        MLAsset.execution_asset,\n        \"trained_model.pt\",\n        ExecAssetType.output_file\n    )\n    # Save model to model_path...\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#model-configuration-with-zen_partial","title":"Model Configuration with zen_partial","text":"<p>Use <code>zen_partial=True</code> to create a partially applied function:</p> <pre><code># configs/model.py\nfrom hydra_zen import builds, store\nfrom models.my_model import train_classifier\n\n# Build the base configuration with zen_partial=True\n# This creates a callable that waits for ml_instance and execution\nModelConfig = builds(\n    train_classifier,\n    learning_rate=1e-3,\n    epochs=10,\n    batch_size=32,\n    populate_full_signature=True,\n    zen_partial=True,  # Key: creates partial function\n)\n\n# Register configurations\nmodel_store = store(group=\"model_config\")\nmodel_store(ModelConfig, name=\"default\")\n\n# Create variants by overriding specific parameters\nmodel_store(ModelConfig, name=\"fast_training\", epochs=5, learning_rate=1e-2)\nmodel_store(ModelConfig, name=\"long_training\", epochs=100, learning_rate=1e-4)\nmodel_store(ModelConfig, name=\"large_batch\", batch_size=128, epochs=50)\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#model-runner","title":"Model Runner","text":"<p>Create a runner that instantiates the partial config with execution context:</p> <pre><code># model_runner.py\nimport logging\nfrom typing import Any\nfrom deriva_ml import DerivaML, DerivaMLConfig, RID\nfrom deriva_ml.dataset import DatasetSpec\nfrom deriva_ml.execution import ExecutionConfiguration, Workflow\n\ndef run_model(\n    deriva_ml: DerivaMLConfig,\n    datasets: list[DatasetSpec],\n    assets: list[RID],\n    description: str,\n    workflow: Workflow,\n    model_config: Any,  # Partially configured model callable\n    dry_run: bool = False,\n) -&gt; None:\n    \"\"\"Execute a configured model with DerivaML.\n\n    Args:\n        deriva_ml: DerivaML connection configuration\n        datasets: List of dataset specifications\n        assets: List of input asset RIDs\n        description: Execution description\n        workflow: Workflow definition\n        model_config: Partially configured model (from zen_partial)\n        dry_run: If True, don't record execution in catalog\n    \"\"\"\n    # Connect to catalog\n    ml_instance = DerivaML.instantiate(deriva_ml)\n\n    # Create execution configuration\n    execution_config = ExecutionConfiguration(\n        datasets=datasets,\n        assets=assets,\n        description=description\n    )\n\n    execution = ml_instance.create_execution(\n        execution_config,\n        workflow=workflow,\n        dry_run=dry_run\n    )\n\n    with execution.execute() as exe:\n        # Complete the partial function with runtime arguments\n        model_config(ml_instance=ml_instance, execution=exe)\n\n    # Upload outputs after execution completes\n    execution.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#main-script","title":"Main Script","text":"<p>Tie everything together with a Hydra entry point:</p> <pre><code># train.py\nfrom hydra_zen import store, zen, builds\n\nfrom model_runner import run_model\n\n# Build main application config with defaults\napp_config = builds(\n    run_model,\n    description=\"Model training run\",\n    populate_full_signature=True,\n    hydra_defaults=[\n        \"_self_\",\n        {\"deriva_ml\": \"default\"},\n        {\"datasets\": \"training\"},\n        {\"assets\": \"weights\"},\n        {\"workflow\": \"training_workflow\"},\n        {\"model_config\": \"default\"},\n    ],\n)\nstore(app_config, name=\"train_app\")\n\n# Import config modules to register them\nimport configs.deriva      # noqa: F401\nimport configs.datasets    # noqa: F401\nimport configs.assets      # noqa: F401\nimport configs.workflow    # noqa: F401\nimport configs.model       # noqa: F401\n\nif __name__ == \"__main__\":\n    store.add_to_hydra_store()\n    zen(run_model).hydra_main(\n        config_name=\"train_app\",\n        version_base=\"1.3\",\n        config_path=None,\n    )\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#running-the-model","title":"Running the Model","text":"<pre><code># Run with defaults\npython train.py\n\n# Override model config\npython train.py model_config=long_training\n\n# Override multiple parameters\npython train.py model_config=fast_training datasets=validation\n\n# Override individual hyperparameters\npython train.py model_config.epochs=25 model_config.learning_rate=0.001\n\n# Multi-run experiments\npython train.py --multirun model_config=default,fast_training,long_training\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#key-benefits-of-zen_partial","title":"Key Benefits of zen_partial","text":"<ol> <li>Separation of concerns: Model hyperparameters are configured separately from runtime context</li> <li>Deferred execution: The model function isn't called until <code>ml_instance</code> and <code>execution</code> are available</li> <li>Config variants: Easy to create model variants by overriding specific parameters</li> <li>CLI flexibility: All hyperparameters are exposed to Hydra's CLI</li> <li>Reproducibility: Full configuration is logged by Hydra</li> </ol>"},{"location":"user-guide/hydra-zen-configuration/#configuration-descriptions","title":"Configuration Descriptions","text":"<p>Adding descriptions to configurations helps users and AI assistants understand and discover the right configurations. DerivaML provides two mechanisms depending on the configuration type:</p>"},{"location":"user-guide/hydra-zen-configuration/#for-list-based-configs-assets-datasets","title":"For List-Based Configs (Assets, Datasets)","text":"<p>Use <code>with_description()</code> to wrap lists of RIDs or <code>DatasetSpecConfig</code> objects:</p> <pre><code>from hydra_zen import store\nfrom deriva_ml.dataset import DatasetSpecConfig\nfrom deriva_ml.execution import with_description\n\n# Datasets with descriptions\ndatasets_store = store(group=\"datasets\")\ndatasets_store(\n    with_description(\n        [DatasetSpecConfig(rid=\"28D4\", version=\"0.22.0\")],\n        \"Split dataset with 10,000 images (5,000 train + 5,000 test). \"\n        \"Testing images are unlabeled. Use for standard train/test workflows.\"\n    ),\n    name=\"cifar10_split\",\n)\n\n# Assets with descriptions\nasset_store = store(group=\"assets\")\nasset_store(\n    with_description(\n        [\"3WMG\", \"3XPA\"],\n        \"Model weights from quick (3WMG) and extended (3XPA) training runs. \"\n        \"Use for comparison experiments.\"\n    ),\n    name=\"comparison_weights\",\n)\n\n# Empty default\nasset_store(\n    with_description([], \"No assets - empty default configuration\"),\n    name=\"default_asset\",\n)\n</code></pre> <p>After instantiation, <code>config.datasets</code> and <code>config.assets</code> behave like regular lists but have a <code>.description</code> attribute:</p> <pre><code># Normal list operations work\nfor dataset in config.datasets:\n    print(dataset.rid)\n\n# Access description\nprint(config.assets.description)  # \"Model weights from quick...\"\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#for-model-configs-builds","title":"For Model Configs (builds())","text":"<p>Use <code>zen_meta</code> parameter when storing <code>builds()</code> configs:</p> <pre><code>from hydra_zen import builds, store\nfrom models.my_model import train_classifier\n\nmodel_store = store(group=\"model_config\")\n\nModelConfig = builds(\n    train_classifier,\n    learning_rate=1e-3,\n    epochs=10,\n    populate_full_signature=True,\n    zen_partial=True,\n)\n\n# Add description via zen_meta\nmodel_store(\n    ModelConfig,\n    name=\"default_model\",\n    zen_meta={\n        \"description\": (\n            \"Default training config: 10 epochs, lr=1e-3. \"\n            \"Balanced for standard training runs.\"\n        )\n    },\n)\n\n# Variant with description\nmodel_store(\n    ModelConfig,\n    name=\"quick\",\n    epochs=3,\n    batch_size=128,\n    zen_meta={\n        \"description\": (\n            \"Quick validation: 3 epochs, batch 128. \"\n            \"Use for rapid iteration and debugging.\"\n        )\n    },\n)\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#summary-when-to-use-each-mechanism","title":"Summary: When to Use Each Mechanism","text":"Config Type Storage Pattern Description Mechanism Assets (RID lists) <code>store([\"RID1\", \"RID2\"], ...)</code> <code>with_description(items, desc)</code> Datasets (DatasetSpecConfig lists) <code>store([DatasetSpecConfig(...)], ...)</code> <code>with_description(items, desc)</code> Model configs <code>store(builds(...), ...)</code> <code>zen_meta={\"description\": desc}</code> Workflow configs <code>store(builds(Workflow, ...), ...)</code> <code>zen_meta={\"description\": desc}</code>"},{"location":"user-guide/hydra-zen-configuration/#writing-good-descriptions","title":"Writing Good Descriptions","text":"<p>Include: - What it contains: Size, types, key parameters - Where it came from: Source execution, version - When to use it: Training, testing, debugging, production</p> <p>Examples:</p> <pre><code># \u2713 Good dataset description\n\"Training dataset with 5,000 labeled CIFAR-10 images (32x32 RGB). \"\n\"All images have ground truth classifications.\"\n\n# \u2713 Good asset description\n\"Model weights (model.pt) from extended training: 50 epochs, \"\n\"64\u2192128 channels, dropout 0.25. Use for inference or fine-tuning.\"\n\n# \u2713 Good model config description\n\"Quick training: 3 epochs, batch 128. Use for rapid iteration \"\n\"and verifying the training pipeline works.\"\n\n# \u2717 Bad (too vague)\n\"Training dataset\"\n\"Model weights\"\n\"Quick config\"\n</code></pre>"},{"location":"user-guide/hydra-zen-configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Use <code>builds()</code> with <code>populate_full_signature=True</code> to expose all parameters</li> <li>Use <code>zen_partial=True</code> for model functions that need runtime context</li> <li>Store related configs in the same group for easy composition</li> <li>Use descriptive names for stored configurations</li> <li>Set <code>working_dir</code> for reproducible output locations</li> <li>Use <code>DatasetSpecConfig</code> instead of building <code>DatasetSpec</code> directly for cleaner configs</li> <li>Use <code>AssetRIDConfig</code> for consistent asset specification</li> <li>Define a model protocol for consistent model interfaces across your project</li> <li>Always add descriptions using <code>with_description()</code> for lists or <code>zen_meta</code> for builds</li> </ol>"},{"location":"user-guide/hydra-zen-configuration/#related-documentation","title":"Related Documentation","text":"<ul> <li>Running Models and Notebooks \u2014 Practical guide for project setup and CLI usage</li> <li>CLI Reference \u2014 All DerivaML command-line tools</li> <li>Execution Configuration \u2014 Execution lifecycle and workflows</li> <li>Using Jupyter Notebooks \u2014 Notebook reproducibility guidelines</li> <li>Datasets</li> <li>Hydra-zen Documentation</li> <li>Hydra Documentation</li> </ul>"},{"location":"user-guide/identifiers/","title":"Identifiers in Deriva-ML","text":"<p>Having global unique identifiers is a critical aspect of data that is FAIR.  Within DerivaML every object is given a unique name wich we call a Resource Identifier or RID. The RID itself takes the from of a string with a dash seperated set of four character blocks. Unqualified, the RID refers to the current values in the catalog, for example <code>1-000C</code></p> <p>A RID may also specify a catalog snapshot ID, in which case it refers to a value at a specific point in time. Here is an example of a fully qualified RID: <code>1-000C@32S-W6DS-GAMG</code> which specifies an the same object as above but with a prior value. </p> <p>Within a catalog, we can just use the RID, with or without the snapshot ID. However, if we want to refer to a RID outside the catalog, we can use a URI form:</p> <pre><code>https://www.eye-ai.org/id/1-000C@32S-W6DS-GAMG\n</code></pre> <p>We obtained this RID using the Cite button on the user interface.   </p> <p>Within the DerivaML class, a URI version of a RID can be obtained using the DerivaML.cite method.</p>"},{"location":"user-guide/install/","title":"Installing deriva-ml","text":"<p>Deriva ML is a python package that consists of the deriva ML libary  along with a number of Jupyter notebooks that demonstrate how to use various deriva-ml features.</p> <p>The latest working version of deriva-ml can be found on pypy, can can be installed using pip:</p> <pre><code>`pip install deriva-ml`\n</code></pre> <p><code>deriva-ml</code> uses semantic versioning.  The <code>pip</code> command</p> <pre><code>pip show deriva-ml\n</code></pre> <p>can be used to find the current installed version of <code>deriva-ml</code>.  The installed version can be updated to the latest version using the command</p> <pre><code>pip install --upgrade deriva-ml\n</code></pre> <p>Once deriva-ml is installed, it can be imported into your Python ennvironment.  The library is orginized into a single package with all of the essential routines directly accessable from the top level package. A typical import statement would be</p> <pre><code>from deriva_ml import DerivaML, MLVocab, DatasetBag, ExecutionConfiguration, Workflow, DerivaSystemColumns\n</code></pre> <p>We note that in most situations, you will not use the DerivaML class directly, but rather it will be the base class for a derived class that has domain specific functions in it. For example:</p> <pre><code>from eye-ai-ml import EyeAI\nfrom deriva_ml import MLVocab, DatasetBag, ExecutionConfiguration, Workflow, DerivaSystemColumns\n</code></pre>"},{"location":"user-guide/notebooks/","title":"Using Jupyter Notebooks With DerivaML","text":"<p>DerivaML can be used to execute Jupyter notebooks in a reproducible and structured manner. Although DerivaML provides numerous tools to support reproducible machine learning, users must adopt and maintain standardized development practices to fully benefit from these tools.</p> <p>In general, achieving reproducibility with Jupyter notebooks will require some discipline on the part of the developer. For an amusing take on some of the challenges associated with Jupyter notebooks, the following presentation is very helpful: I Don't Like Notebooks</p> <p>To ensure that your Jupyter notebooks are reproducible, follow these recommended guidelines:</p>"},{"location":"user-guide/notebooks/#version-control-and-semantic-versioning","title":"Version Control and Semantic Versioning","text":"<p>Always store your notebook in a GitHub repository. A repository template for DerivaML projects can be found at DerivaML Repository Template. To use a GitHub template select the Use This Template dropdown from the GitHub user interface, rather than clone. The template contains examples of both a DerivaML Python script and Jupyter notebook.</p> <p>Adopt semantic versioning for your notebooks. In addition to semantic versions, Git tags are also quite helpful. The repository template provides a command to simplify managing version numbers and tags:</p> <pre><code>uv run bump-version major|minor|patch\n</code></pre> <p>See <code>bump-version</code> for details.</p>"},{"location":"user-guide/notebooks/#clearing-notebook-outputs","title":"Clearing Notebook Outputs","text":"<p>Normal operation of a Jupyter notebook puts results in output cells in the notebook, modifying the notebook file and complicating reproducibility. For this reason, we recommend that before committing a notebook to Git, to clear all output cells, ensuring that only code and markdown cells are version-controlled.</p> <p>While you can always clear output cells manually from the notebook, DerivaML includes a script which automatically strips output cells upon commit. To set this up, execute the following command once in your repository:</p> <pre><code>nbstripout --install\n</code></pre> <p>You only need to perform the install once per repository, and after that, the notebook output will be stripped before every commit.</p>"},{"location":"user-guide/notebooks/#setting-notebook-parameters","title":"Setting Notebook Parameters","text":"<p>Another challenge for reproducibility is that the behavior of cells in a notebook is often modified by changing the values of global variables assigned in a code cell. In order to impose some order on this potentially chaotic process, DerivaML adopts the use of Papermill to help manage configuring notebooks prior to execution. The basic idea behind Papermill is to place all of the configuration variables for a notebook in a single cell, and then provide an interface that will substitute values in for those variables and run the notebook in its entirety.</p> <p>To use Papermill in DerivaML: - Define all configurable variables in a single \"parameters\" cell located immediately after your imports at the top of your notebook. The contents of this cell can be automatically updated when the notebook is executed. For Papermill to work, you must have a Jupyter cell tagged with <code>parameters</code> to indicate which cell contains parameter values. The DerivaML template already has this cell tagged. See Papermill for instructions on how to do this. - The parameters cell should contain only comments and variable assignments. It is recommended to include type hints for clarity and usability. - Avoid setting configuration variables elsewhere in your notebook.</p>"},{"location":"user-guide/notebooks/#notebook-structure-and-execution-flow","title":"Notebook Structure and Execution Flow","text":"<p>The overall workflow supported by DerivaML is a phase in which notebooks are developed and debugged, followed by an experimental phase in which multiple model parameters might be evaluated, or alternative approaches explored. The boundary between debugging and experimentation can be fuzzy; in general it is better to err on the side of considering a run of a notebook to be an experiment rather than debugging.</p> <p>The following guidelines can help facilitate notebook reproducibility: - Structure your notebook so that it runs sequentially, from the first to the last cell. - Regularly restart the kernel, clear outputs, and execute all cells sequentially to confirm reproducibility. - Keep each notebook focused on a single task; avoid combining multiple tasks within one notebook. - Utilize the <code>dry_run</code> mode during debugging to avoid cluttering the catalog with unnecessary execution records.</p> <p>Use <code>dry_run</code> only for debugging, not during model tuning, as recording all tuning attempts is crucial for transparency and reproducibility.</p>"},{"location":"user-guide/notebooks/#commit-and-tagging-procedures","title":"Commit and Tagging Procedures","text":"<p>After validating your notebook, commit it and generate a corresponding version tag:</p> <pre><code>git add -A &amp;&amp; git commit -m \"Notebook ready for execution\"\nuv run bump-version patch\n</code></pre>"},{"location":"user-guide/notebooks/#configuring-notebooks-with-hydra","title":"Configuring Notebooks with Hydra","text":"<p>DerivaML provides <code>notebook_config()</code> and <code>run_notebook()</code> for integrating notebooks with the hydra-zen configuration system. This allows notebooks to use the same configuration groups (datasets, assets, etc.) as model scripts.</p> <p>For the full guide on setting up notebook configurations and running them with <code>deriva-ml-run-notebook</code>, see Running Models and Notebooks.</p>"},{"location":"user-guide/notebooks/#quick-example","title":"Quick Example","text":"<p>In <code>src/configs/my_analysis.py</code>:</p> <pre><code>from deriva_ml.execution import notebook_config\n\nnotebook_config(\n    \"my_analysis\",\n    defaults={\"assets\": \"comparison_weights\", \"datasets\": \"training_data\"},\n)\n</code></pre> <p>In the first code cell of <code>notebooks/my_analysis.ipynb</code>:</p> <pre><code>from deriva_ml.execution import run_notebook\n\nml, execution, config = run_notebook(\"my_analysis\")\n</code></pre> <p>Running the notebook:</p> <pre><code># With default configuration\nuv run deriva-ml-run-notebook notebooks/my_analysis.ipynb\n\n# With Hydra overrides\nuv run deriva-ml-run-notebook notebooks/my_analysis.ipynb \\\n    assets=different_weights deriva_ml=production\n</code></pre>"},{"location":"user-guide/notebooks/#executing-notebooks-with-derivaml","title":"Executing Notebooks with DerivaML","text":"<p>A reproducible notebook execution has these components:</p> <ol> <li>A committed notebook file is specified.</li> <li>Per-execution specific values for variables in the <code>parameters</code> cell are specified and a new cell with the specified parameter values is injected into the notebook.</li> <li>The modified notebook is executed in its entirety, including the uploading of any notebook-generated assets.</li> <li>On conclusion of the notebook execution, the resulting notebook file (including output cells) and a Markdown conversion are uploaded into the DerivaML catalog as execution assets.</li> </ol> <p>DerivaML includes the <code>deriva-ml-run-notebook</code> command to conveniently execute notebooks, substitute parameters dynamically, and store the execution results as assets:</p> <pre><code># Parameter injection\nuv run deriva-ml-run-notebook notebooks/my-notebook.ipynb \\\n    -p parameter1 value1 -p parameter2 value2\n\n# Hydra config overrides\nuv run deriva-ml-run-notebook notebooks/my-notebook.ipynb \\\n    assets=my_assets deriva_ml=production\n\n# Inspect available parameters\nuv run deriva-ml-run-notebook notebooks/my-notebook.ipynb --inspect\n</code></pre> <p>Parameters can also be specified via a JSON or YAML configuration file using the <code>--file filename</code> option.</p> <p>For the complete CLI reference, see <code>deriva-ml-run-notebook</code>.</p>"},{"location":"user-guide/overview/","title":"Overview of DerivaML","text":""},{"location":"user-guide/overview/#overview","title":"Overview","text":"<p>Deriva-ML is a Python utility designed to streamline end-to-end machine learning (ML) experiments by integrating data  and metadata stored on the Deriva platform. It facilitates a seamless workflow for managing data catalogs, preprocessing,  model execution, and result documentation.</p> <p>Key components for Deriva-ML:</p> <ol> <li>Data Catalog: The catalog must include both the domain schema and a standard ML schema for effective data management.   </li> <li>Domain schema: The domain schema includes the data collected or generated by domain-specific experiments or systems.</li> <li> <p>ML schema: Each entity in the ML schema is designed to capture details of the ML development process. It including the following tables</p> <ul> <li>A Dataset represents a data collection, such as aggregation identified for training, validation, and testing purposes.</li> <li>A Workflow represents a specific sequence of computational steps or human interactions.</li> <li>An Execution is an instance of a workflow that a user instantiates at a specific time. </li> <li>An Execution Asset is an output file that results from the execution of a workflow.</li> <li>An Execution Metadata is an asset entity for saving metadata files referencing a given execution.</li> </ul> </li> <li> <p>Deriva-ML library: including the following process</p> </li> <li>Execution initiate</li> <li>ML execution context manager</li> <li> <p>Execution upload</p> </li> <li> <p>Catalog-ML library: A tool derived from Deriva-ML for configuring data curation tasks tailored to specific data catalogs. The method including the following categories:</p> </li> <li>Data pre-processing</li> <li>Data Analysis </li> </ol>"},{"location":"user-guide/overview/#installation","title":"Installation","text":"<p>To install Deriva-ML and its dependencies, use the following commands:</p> <pre><code>$ pip install deriva\n$ pip install deriva-ml\n$ pip install &lt;catalog-ML&gt;\n</code></pre>"},{"location":"user-guide/overview/#a-notebook-workflow","title":"A Notebook workflow","text":"<p>The Deriva-ML notebook workflow consists of an end-to-end process that includes: - Data migration from the catalog to the runtime environment.  - Data preprocessing.  - Execution of ML experiments.  - Storing outputs and metadata back into the catalog.</p>"},{"location":"user-guide/overview/#step-1-setup-the-environment","title":"Step 1: Setup the environment","text":""},{"location":"user-guide/overview/#load-prerequisite-packages","title":"Load prerequisite packages","text":"<pre><code># Prerequisites\nfrom pathlib import Path, PurePath\nimport logging\n\nfrom deriva_ml import DatasetBag, Workflow, ExecutionConfiguration\nfrom deriva_ml import MLVocab as vc\nimport &lt;catalog-ml&gt;\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n</code></pre>"},{"location":"user-guide/overview/#login-to-the-deriva-catalog","title":"Login to the Deriva catalog","text":"<pre><code>from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\nhost = 'www.***'\ncatalog_id = \"***\"\n\ngnl = GlobusNativeLogin(host=host)\nif gnl.is_logged_in([host]):\n    print(\"You are already logged in.\")\nelse:\n    gnl.login([host], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n    print(\"Login Successful\")\n</code></pre>"},{"location":"user-guide/overview/#set-working-and-caching-directories","title":"Set working and caching directories","text":"<ul> <li>Cache Directory: Used for saving materialized dataset bags. </li> <li>Working Directory: Stores temporary files for the execution, such as metadata and features, which are uploaded to the catalog.   (The content under this directory may be deleted after successfully upload to catalog by default.)</li> </ul> <pre><code>cache_dir = Path.home() / 'data'\nworking_dir = Path.home() / 'data'\nml_instance = catalogML(hostname = host, catalog_id = catalog_id, cache_dir= cache_dir, working_dir=working_dir)\n</code></pre>"},{"location":"user-guide/overview/#step2-execution-configuration","title":"Step2: Execution Configuration","text":"<p>Before starting execution: - Define the workflow and related objects (datasets, models). - Cache all required files in the caching directory.</p> <ul> <li>Configuration Parameters</li> <li>datasets: List of dictionary that contains dataset rids found in the catalog's Dataset table, and a flag to    indicate whether download the assets or not.</li> <li>assets: List of execution asset rids from the Execution_Assets table.</li> <li>execution: A descriptive Execution object.</li> <li>workflow: A Workflow object, including its type and associated code scripts.</li> <li>Instanciate the workflow by <code>Workflow()</code></li> <li>The workflow type is a controlled vocabulary term. Make sure the term is already existed in the catalog,    or create the new term before use. To create a new workflow_term, you can use    <code>ml_instance.add_term(vc.workflow_type, &lt;term_name&gt;, description=\"***\")</code>. Detailed description of how to add a new control   vocabulary term in the catalog see ##ToDo</li> <li>description: A textual summary of the current execution.</li> </ul> <p>Initialize the execution by <code>ml_instance.initialize_execution(config)</code>. A full record of directory of cached data and files, and rids of current execution will be returned.\\ Example:</p> <pre><code># RID of source dataset_table, if any.\nsource_dataset = &lt;dataset_rid&gt;\n\n# Add Workflow Vocab terms\nml_instance.add_term(vc.workflow_type, \"Test Workflow\", description=\"A test Workflow for new DM\")\n\n# Workflow instance\ntest_workflow = Workflow(\n    name=\"Test Sample Workflow\",\n    url=\"https://github.com/***\",\n    workflow_type=\"Test Workflow\"\n)\n\n# Configuration instance.\nconfig = ExecutionConfiguration(\n    # Comment out the following line if you don't need the assets.\n    # Materialize set to False if you only need the metadata from the bag, and not the assets.\n    datasets= [{'rid':source_dataset, 'materialize':True}],\n    assets=[asset_rid1, asset_rid2, ...],\n    workflow=test_workflow,\n    description=\"Our Test Workflow instance\")\n\n# Initialize execution\nexecution = ml_instance.create_execution(config)\nprint(execution)\n</code></pre> <p>Sample return:</p> <pre><code>caching_dir: /data\nworking_dir: /data/&lt;username&gt;/&lt;catalog&gt;_working\nexecution_rid: 5-SJ9Y\nworkflow_rid: 5-SG9W\ndataset_paths: [PosixPath('/data/2-AGAW_c3a8bcbd37b4c454471d0e057c550312719006f76604db0e7f65d4a539974b12/Dataset_2-AGAW')]\nasset_paths: [PosixPath('/data/.../EyeAI_working/5-SJ9Y/asset/optic_disk_crop_model.hdf5')]\nconfiguration: datasets=['2-AGAW'] \n               assets=['2-4JR6'] \n               workflow=Workflow(name='Test New Workflow-multimodal', \n                                 url='https://github.com/.../.../template.ipynb', \n                                 workflow_type='Test Workflow', \n                                 version=None, \n                                 description=None) \n               description='Template instance of a feature creation workflow'\n</code></pre>"},{"location":"user-guide/overview/#step3-access-datasets","title":"Step3: Access Datasets","text":"<p>In the notebook environment, you can save the downloaded dataset in to a <code>DatasetBag</code>. It is built on top of an <code>sqLite</code> database, enabling easy access to the tables by table name and datasets curation. - Build DatasetBag from downloaded data: <code>ds_bag = DatasetBag(configuration_record.bag_paths[i])</code> - Find all the tables in the database by <code>ds_bag.list_tables()</code> - Load the data in a table to pandas.DataFrame by <code>ds_bag.get_table_as_dataframe(table_name)</code></p>"},{"location":"user-guide/overview/#step4-ml-execution","title":"Step4: ML Execution","text":"<p>Run ML algorithms within a managed context. This ensures execution status is logged back to the catalog.</p> <pre><code>with ml_instance.create_execution(config) as exe:\n    # Run machine learning algorithms here ...\n    pass\n\n# Upload after context exits\nexe.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/overview/#step5-upload-results","title":"Step5: Upload results","text":"<p>Save and upload outputs to the catalog. Use <code>asset_file_path()</code> to register files for upload.</p> <p>Ensure that the asset types exist in the catalog before uploading.</p> <pre><code># Add controlled vocabulary terms for asset types\nml_instance.add_term(\"Asset_Type\", \"Example_Asset_Type\", description=\"Asset Type description\")\n\nwith ml_instance.create_execution(config) as exe:\n    # Get paths for output files\n    metadata_path = exe.asset_file_path(\"Execution_Metadata\", \"metrics.json\")\n    asset_path = exe.asset_file_path(\"Execution_Asset\", \"model.pt\", asset_types=[\"Example_Asset_Type\"])\n\n    # Save files to the registered paths\n    # ...\n\n# Upload files to the catalog after context exits\nexe.upload_execution_outputs(clean_folder=True)\n</code></pre> <p>Upon completion, all files can be accessed in the Execution Assets, Execution Metadata, and Features tables,  or through the current execution in the Execution table.</p>"},{"location":"user-guide/running-models-and-notebooks/","title":"Running Models and Notebooks","text":"<p>DerivaML provides two command-line tools for executing reproducible ML workflows:</p> <ul> <li><code>deriva-ml-run</code> \u2014 runs Python model functions</li> <li><code>deriva-ml-run-notebook</code> \u2014 runs Jupyter notebooks</li> </ul> <p>Both tools use hydra-zen for composable configuration and automatically track executions in the Deriva catalog. This guide walks through setting up a project, writing configuration, and running workflows.</p> <p>For detailed configuration class documentation, see Hydra-zen Configuration. For execution lifecycle details, see Configuring and Running Executions.</p>"},{"location":"user-guide/running-models-and-notebooks/#project-layout","title":"Project Layout","text":"<p>A DerivaML project follows this standard directory structure:</p> <pre><code>my-project/\n  pyproject.toml\n  src/\n    configs/             # Hydra-zen configuration modules (Python, no YAML)\n      __init__.py\n      base.py            # create_model_config() + store registration\n      deriva.py          # Connection settings (deriva_ml group)\n      datasets.py        # Dataset specifications (datasets group)\n      assets.py          # Input asset RIDs (assets group)\n      workflow.py        # Workflow definitions (workflow group)\n      my_model.py        # Model configs (model_config group)\n      my_notebook.py     # Notebook configs (notebook_config())\n      experiments.py     # Experiment presets (loaded last)\n      multiruns.py       # Named multirun/sweep configs\n    models/\n      my_model.py        # Model function implementations\n  notebooks/\n    my_notebook.ipynb\n</code></pre> <p>A repository template is available at DerivaML Repository Template.</p>"},{"location":"user-guide/running-models-and-notebooks/#how-configuration-discovery-works","title":"How Configuration Discovery Works","text":"<p>When you run <code>deriva-ml-run</code> or <code>deriva-ml-run-notebook</code>, the tool calls <code>load_configs()</code> which uses <code>pkgutil.iter_modules()</code> to discover and import all Python modules in the <code>configs/</code> package. Each module registers its configurations with the hydra-zen store as a side effect of being imported.</p> <p>Modules are loaded in alphabetical order, with one exception: <code>experiments.py</code> is always loaded last because experiments typically reference configurations from other modules.</p>"},{"location":"user-guide/running-models-and-notebooks/#setting-up-configuration-groups","title":"Setting Up Configuration Groups","text":"<p>DerivaML uses five standard configuration groups. Each group needs at least a default entry.</p>"},{"location":"user-guide/running-models-and-notebooks/#connection-settings-deriva_ml","title":"Connection Settings (<code>deriva_ml</code>)","text":"<p>Define how to connect to Deriva catalogs:</p> <pre><code># configs/deriva.py\nfrom hydra_zen import builds, store\nfrom deriva_ml import DerivaMLConfig\n\nDerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\nderiva_store = store(group=\"deriva_ml\")\n\n# Development catalog\nderiva_store(\n    DerivaMLConf(hostname=\"dev.example.org\", catalog_id=\"1\"),\n    name=\"default_deriva\",\n)\n\n# Production catalog\nderiva_store(\n    DerivaMLConf(hostname=\"prod.example.org\", catalog_id=\"100\"),\n    name=\"production\",\n)\n</code></pre> <p>See DerivaMLConfig for all parameters.</p>"},{"location":"user-guide/running-models-and-notebooks/#datasets-datasets","title":"Datasets (<code>datasets</code>)","text":"<p>Specify which datasets to download for each workflow:</p> <pre><code># configs/datasets.py\nfrom hydra_zen import store\nfrom deriva_ml.dataset import DatasetSpecConfig\nfrom deriva_ml.execution import with_description\n\ndatasets_store = store(group=\"datasets\")\n\n# Required: default (used when no override is specified)\ndatasets_store([], name=\"default_dataset\")\n\n# A named dataset collection\ndatasets_store(\n    with_description(\n        [DatasetSpecConfig(rid=\"1-ABC\", version=\"1.0.0\")],\n        \"Training dataset with 1000 labeled images.\",\n    ),\n    name=\"training_data\",\n)\n</code></pre> <p>See DatasetSpecConfig for options.</p>"},{"location":"user-guide/running-models-and-notebooks/#assets-assets","title":"Assets (<code>assets</code>)","text":"<p>List input asset RIDs (model weights, configuration files, etc.):</p> <pre><code># configs/assets.py\nfrom hydra_zen import store\nfrom deriva_ml.execution import with_description\n\nasset_store = store(group=\"assets\")\n\n# Required: default\nasset_store([], name=\"default_asset\")\n\n# Model weights\nasset_store(\n    with_description(\n        [\"6-EPNR\"],\n        \"ResNet50 pretrained weights from MAE pre-training.\",\n    ),\n    name=\"resnet_weights\",\n)\n</code></pre> <p>For caching support, use <code>AssetSpecConfig</code> instead of plain RID strings. See Configuration Descriptions for details on <code>with_description()</code>.</p>"},{"location":"user-guide/running-models-and-notebooks/#workflows-workflow","title":"Workflows (<code>workflow</code>)","text":"<p>Define the computational process being tracked:</p> <pre><code># configs/workflow.py\nfrom hydra_zen import builds, store\nfrom deriva_ml.execution import Workflow\n\nworkflow_store = store(group=\"workflow\")\n\nworkflow_store(\n    builds(Workflow, name=\"default\", workflow_type=\"Training\",\n           populate_full_signature=True),\n    name=\"default_workflow\",\n)\n\nworkflow_store(\n    builds(Workflow, name=\"Feature Extraction\", workflow_type=\"Preprocessing\",\n           description=\"Extract features from raw data\",\n           populate_full_signature=True),\n    name=\"feature_extraction\",\n)\n</code></pre> <p>See Workflows for how workflows track source code provenance.</p>"},{"location":"user-guide/running-models-and-notebooks/#model-configuration-model_config","title":"Model Configuration (<code>model_config</code>)","text":"<p>Configure model hyperparameters. This is where <code>zen_partial=True</code> is essential:</p> <pre><code># configs/my_model.py\nfrom hydra_zen import builds, store\nfrom models.my_model import train_classifier\n\nmodel_store = store(group=\"model_config\")\n\n# Base config: partially applied, waits for ml_instance and execution\nModelConfig = builds(\n    train_classifier,\n    learning_rate=1e-3,\n    epochs=10,\n    batch_size=32,\n    populate_full_signature=True,\n    zen_partial=True,\n)\n\nmodel_store(ModelConfig, name=\"default_model\")\nmodel_store(ModelConfig, name=\"quick\", epochs=3, learning_rate=1e-2)\nmodel_store(ModelConfig, name=\"long_training\", epochs=100, learning_rate=1e-4)\n</code></pre> <p>See Model Configuration with zen_partial for the full pattern.</p>"},{"location":"user-guide/running-models-and-notebooks/#writing-a-model-function","title":"Writing a Model Function","text":"<p>Model functions follow a simple protocol: they accept any number of configurable parameters plus two keyword arguments injected at runtime:</p> <pre><code># models/my_model.py\nfrom deriva_ml import DerivaML\nfrom deriva_ml.execution import Execution\n\ndef train_classifier(\n    learning_rate: float,\n    epochs: int,\n    batch_size: int,\n    ml_instance: DerivaML,\n    execution: Execution | None = None,\n) -&gt; None:\n    \"\"\"Train a classifier using DerivaML execution context.\"\"\"\n    # Access downloaded datasets\n    for dataset in execution.datasets:\n        bag = execution.download_dataset_bag(dataset)\n        # Process data from the bag...\n\n    # Access downloaded input assets (model weights, etc.)\n    for table_name, asset_paths in execution.asset_paths.items():\n        for asset_path in asset_paths:\n            print(f\"Loaded {table_name}: {asset_path}\")\n\n    # Your training code here\n    model = build_model()\n    for epoch in range(epochs):\n        train_epoch(model, learning_rate, batch_size)\n\n    # Register output files for upload\n    model_path = execution.asset_file_path(\"Model\", \"best_model.pt\")\n    save_model(model, model_path)\n\n    metrics_path = execution.asset_file_path(\"Execution_Metadata\", \"metrics.json\")\n    save_metrics(metrics_path)\n</code></pre> <p>The <code>ml_instance</code> and <code>execution</code> parameters are injected by <code>run_model()</code> at runtime. Hydra configures the remaining parameters (<code>learning_rate</code>, <code>epochs</code>, <code>batch_size</code>) from the config store.</p>"},{"location":"user-guide/running-models-and-notebooks/#the-base-configuration-basepy","title":"The Base Configuration (<code>base.py</code>)","text":"<p>The <code>base.py</code> module ties everything together using <code>create_model_config()</code>:</p> <pre><code># configs/base.py\nfrom hydra_zen import store\nfrom deriva_ml import DerivaML\nfrom deriva_ml.execution import create_model_config\n\nDerivaModelConfig = create_model_config(\n    DerivaML,                         # or your DerivaML subclass\n    description=\"My project model run\",\n    hydra_defaults=[\n        \"_self_\",\n        {\"deriva_ml\": \"default_deriva\"},\n        {\"datasets\": \"default_dataset\"},\n        {\"assets\": \"default_asset\"},\n        {\"workflow\": \"default_workflow\"},\n        {\"model_config\": \"default_model\"},\n    ],\n)\n\nstore(DerivaModelConfig, name=\"deriva_model\")\n</code></pre> <p><code>create_model_config()</code> creates a hydra-zen <code>builds()</code> of the <code>run_model()</code> function with all the standard groups wired up. The <code>deriva_model</code> name must match the <code>--config-name</code> argument (the default).</p> <p>If your project uses a DerivaML subclass (e.g., <code>EyeAI</code>), pass it as the first argument so that the correct class is instantiated at runtime.</p>"},{"location":"user-guide/running-models-and-notebooks/#running-with-deriva-ml-run","title":"Running with <code>deriva-ml-run</code>","text":""},{"location":"user-guide/running-models-and-notebooks/#basic-usage","title":"Basic Usage","text":"<pre><code># Run with all defaults from base.py\nuv run deriva-ml-run\n\n# Override a config group\nuv run deriva-ml-run model_config=quick datasets=training_data\n\n# Override individual parameters\nuv run deriva-ml-run model_config.epochs=50 model_config.learning_rate=0.001\n\n# Dry run: download inputs but skip catalog writes\nuv run deriva-ml-run dry_run=true\n\n# Show all available configuration groups and options\nuv run deriva-ml-run --info\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#overriding-host-and-catalog","title":"Overriding Host and Catalog","text":"<p>You can override the Deriva connection from the command line without changing configs:</p> <pre><code>uv run deriva-ml-run --host prod.example.org --catalog 100\n</code></pre> <p>Or using Hydra override syntax:</p> <pre><code>uv run deriva-ml-run deriva_ml=production\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#experiments","title":"Experiments","text":"<p>Experiments are preset configurations that bundle specific model, dataset, asset, and workflow choices. Define them in <code>configs/experiments.py</code>:</p> <pre><code># configs/experiments.py\nfrom hydra_zen import make_config, store\nfrom configs.base import DerivaModelConfig\n\nexperiment_store = store(group=\"experiment\", package=\"_global_\")\n\nexperiment_store(\n    make_config(\n        hydra_defaults=[\n            \"_self_\",\n            {\"override /model_config\": \"quick\"},\n            {\"override /datasets\": \"training_data\"},\n            {\"override /assets\": \"resnet_weights\"},\n            {\"override /workflow\": \"default_workflow\"},\n        ],\n        description=\"Quick training with ResNet weights on training data.\",\n        bases=(DerivaModelConfig,),\n    ),\n    name=\"quick_training\",\n)\n</code></pre> <p>Run an experiment:</p> <pre><code>uv run deriva-ml-run +experiment=quick_training\n\n# Override an experiment parameter\nuv run deriva-ml-run +experiment=quick_training model_config.epochs=25\n</code></pre> <p>Note the <code>+</code> prefix: this adds the experiment group, which is not in the default config. The <code>override /</code> prefix in <code>hydra_defaults</code> ensures the experiment's choices replace (rather than conflict with) the base defaults.</p>"},{"location":"user-guide/running-models-and-notebooks/#multiruns-and-sweeps","title":"Multiruns and Sweeps","text":"<p>For parameter sweeps, use Hydra's multirun mode:</p> <pre><code># Sweep a parameter\nuv run deriva-ml-run --multirun model_config.learning_rate=0.0001,0.001,0.01\n\n# Sweep across experiments\nuv run deriva-ml-run --multirun +experiment=quick_training,long_training\n</code></pre> <p>For complex sweeps, define named multirun configurations in <code>configs/multiruns.py</code>:</p> <pre><code># configs/multiruns.py\nfrom deriva_ml.execution import multirun_config\n\nmultirun_config(\n    \"lr_sweep\",\n    overrides=[\n        \"+experiment=quick_training\",\n        \"model_config.learning_rate=0.0001,0.001,0.01,0.1\",\n    ],\n    description='''## Learning Rate Sweep\n\n    Exploring optimal learning rates for quick training config.\n\n    | Learning Rate | Expected Behavior |\n    |--------------|-------------------|\n    | 0.0001 | Slow convergence |\n    | 0.001 | Standard baseline |\n    | 0.01 | Fast, may overshoot |\n    | 0.1 | Likely unstable |\n    ''',\n)\n</code></pre> <p>Run a named multirun:</p> <pre><code># Use the named multirun config (automatically enables multirun mode)\nuv run deriva-ml-run +multirun=lr_sweep\n\n# Override parameters from the multirun config\nuv run deriva-ml-run +multirun=lr_sweep model_config.epochs=5\n</code></pre> <p>Named multiruns create a parent-child execution structure in the catalog:</p> <ul> <li>Parent execution: Contains the markdown description and links to all children</li> <li>Child executions: One per parameter combination, each with full provenance</li> </ul> <p>Use <code>list_parent_executions()</code> and <code>list_nested_executions()</code> to navigate this hierarchy.</p>"},{"location":"user-guide/running-models-and-notebooks/#code-provenance","title":"Code Provenance","text":"<p>DerivaML records the Git commit hash and source URL for each execution. Always commit your code before running models:</p> <pre><code>git add -A &amp;&amp; git commit -m \"Ready for training run\"\nuv run bump-version patch  # Optional: create a release tag\nuv run deriva-ml-run +experiment=quick_training\n</code></pre> <p>If the working tree has uncommitted changes, DerivaML issues a warning and the execution record may not have a valid code reference.</p> <p>See Automatic Source Code Detection for details on how provenance works in scripts, notebooks, and Docker containers.</p>"},{"location":"user-guide/running-models-and-notebooks/#notebook-configuration","title":"Notebook Configuration","text":"<p>Notebooks use a slightly different pattern: instead of <code>zen_partial</code> model functions, they use <code>notebook_config()</code> and <code>run_notebook()</code>.</p>"},{"location":"user-guide/running-models-and-notebooks/#defining-a-notebook-configuration","title":"Defining a Notebook Configuration","text":"<p>For simple notebooks that only use the standard fields (datasets, assets, etc.):</p> <pre><code># configs/my_analysis.py\nfrom deriva_ml.execution import notebook_config\n\nnotebook_config(\n    \"my_analysis\",\n    defaults={\"assets\": \"comparison_weights\", \"datasets\": \"training_data\"},\n)\n</code></pre> <p>For notebooks with custom parameters:</p> <pre><code># configs/my_analysis.py\nfrom dataclasses import dataclass\nfrom deriva_ml.execution import BaseConfig, notebook_config\n\n@dataclass\nclass MyAnalysisConfig(BaseConfig):\n    threshold: float = 0.5\n    num_samples: int = 100\n\nnotebook_config(\n    \"my_analysis\",\n    config_class=MyAnalysisConfig,\n    defaults={\"assets\": \"comparison_weights\"},\n)\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#using-run_notebook-in-the-notebook","title":"Using <code>run_notebook()</code> in the Notebook","text":"<p>In the first code cell of your notebook:</p> <pre><code>from deriva_ml.execution import run_notebook\n\nml, execution, config = run_notebook(\"my_analysis\")\n</code></pre> <p>This single call:</p> <ol> <li>Loads all config modules from <code>src/configs/</code></li> <li>Resolves the hydra-zen configuration (including any CLI overrides)</li> <li>Connects to the Deriva catalog</li> <li>Creates a workflow and execution record</li> <li>Downloads any specified datasets and assets</li> </ol> <p>After that, you can use <code>ml</code>, <code>execution</code>, and <code>config</code> throughout the notebook:</p> <pre><code># Access resolved config values\nprint(config.threshold)  # 0.5\n\n# Access downloaded assets\nfor table, paths in execution.asset_paths.items():\n    for path in paths:\n        print(f\"Asset: {path}\")\n\n# At the end of the notebook\nexecution.upload_execution_outputs()\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#running-with-deriva-ml-run-notebook","title":"Running with <code>deriva-ml-run-notebook</code>","text":""},{"location":"user-guide/running-models-and-notebooks/#basic-usage_1","title":"Basic Usage","text":"<pre><code># Run with default configuration\nuv run deriva-ml-run-notebook notebooks/my_analysis.ipynb\n\n# Override Hydra config groups (positional overrides)\nuv run deriva-ml-run-notebook notebooks/my_analysis.ipynb \\\n    assets=different_weights deriva_ml=production\n</code></pre> <p>Hydra overrides are passed as positional arguments after the notebook path. These are forwarded to the notebook via the <code>DERIVA_ML_HYDRA_OVERRIDES</code> environment variable, where <code>run_notebook()</code> picks them up automatically.</p>"},{"location":"user-guide/running-models-and-notebooks/#parameter-injection","title":"Parameter Injection","text":"<p>You can also inject values directly into a notebook's parameter cell (tagged with <code>parameters</code> in Jupyter) using papermill:</p> <pre><code># Inject individual parameters\nuv run deriva-ml-run-notebook notebooks/train.ipynb \\\n    -p learning_rate 0.001 -p epochs 50\n\n# Load parameters from a file\nuv run deriva-ml-run-notebook notebooks/train.ipynb --file params.yaml\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#inspecting-available-options","title":"Inspecting Available Options","text":"<pre><code># Show notebook parameters (from the papermill parameters cell)\nuv run deriva-ml-run-notebook notebooks/train.ipynb --inspect\n\n# Show available Hydra config groups\nuv run deriva-ml-run-notebook notebooks/my_analysis.ipynb --info\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#kernel-selection","title":"Kernel Selection","text":"<p>The CLI automatically detects the Jupyter kernel for the current virtual environment. If auto-detection fails or you want to use a different kernel:</p> <pre><code>uv run deriva-ml-run-notebook notebooks/train.ipynb --kernel my-ml-project\n</code></pre> <p>If no kernel is installed for your environment, use <code>deriva-ml-install-kernel</code>.</p>"},{"location":"user-guide/running-models-and-notebooks/#output-handling","title":"Output Handling","text":"<p>After execution, <code>deriva-ml-run-notebook</code>:</p> <ol> <li>Converts the executed notebook to Markdown (with images embedded as base64    data URIs and DataFrame tables converted to Markdown format)</li> <li>Uploads both the <code>.ipynb</code> and <code>.md</code> files to the catalog as execution assets    with type <code>notebook_output</code></li> <li>Prints the execution URL for easy access</li> </ol>"},{"location":"user-guide/running-models-and-notebooks/#streaming-output","title":"Streaming Output","text":"<p>To see cell outputs in your terminal as the notebook runs:</p> <pre><code>uv run deriva-ml-run-notebook notebooks/train.ipynb --log-output\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#complete-walkthrough","title":"Complete Walkthrough","text":"<p>Here is a minimal end-to-end example showing how to set up a new DerivaML project and run a model.</p>"},{"location":"user-guide/running-models-and-notebooks/#1-project-setup","title":"1. Project Setup","text":"<pre><code># Create project from template\ngh repo create my-ml-project --template informatics-isi-edu/deriva-ml-model-template\n\n# Set up environment\ncd my-ml-project\nuv sync\nuv run deriva-ml-install-kernel  # If using notebooks\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#2-define-configurations","title":"2. Define Configurations","text":"<p>Create <code>src/configs/deriva.py</code>:</p> <pre><code>from hydra_zen import builds, store\nfrom deriva_ml import DerivaMLConfig\n\nDerivaMLConf = builds(DerivaMLConfig, populate_full_signature=True)\nstore(DerivaMLConf(hostname=\"dev.example.org\", catalog_id=\"1\"),\n      group=\"deriva_ml\", name=\"default_deriva\")\n</code></pre> <p>Create <code>src/configs/datasets.py</code>:</p> <pre><code>from hydra_zen import store\nfrom deriva_ml.dataset import DatasetSpecConfig\n\nstore([], group=\"datasets\", name=\"default_dataset\")\nstore([DatasetSpecConfig(rid=\"1-ABC\", version=\"1.0.0\")],\n      group=\"datasets\", name=\"training\")\n</code></pre> <p>Create <code>src/configs/assets.py</code>:</p> <pre><code>from hydra_zen import store\nstore([], group=\"assets\", name=\"default_asset\")\n</code></pre> <p>Create <code>src/configs/workflow.py</code>:</p> <pre><code>from hydra_zen import builds, store\nfrom deriva_ml.execution import Workflow\n\nstore(builds(Workflow, name=\"default\", workflow_type=\"Training\",\n             populate_full_signature=True),\n      group=\"workflow\", name=\"default_workflow\")\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#3-write-a-model-function","title":"3. Write a Model Function","text":"<p>Create <code>src/models/classifier.py</code>:</p> <pre><code>from deriva_ml import DerivaML\nfrom deriva_ml.execution import Execution\n\ndef train(\n    learning_rate: float = 0.001,\n    epochs: int = 10,\n    ml_instance: DerivaML = None,\n    execution: Execution | None = None,\n) -&gt; None:\n    print(f\"Training for {epochs} epochs at lr={learning_rate}\")\n    # Your training code here...\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#4-register-the-model-config","title":"4. Register the Model Config","text":"<p>Create <code>src/configs/classifier.py</code>:</p> <pre><code>from hydra_zen import builds, store\nfrom models.classifier import train\n\nstore(builds(train, populate_full_signature=True, zen_partial=True),\n      group=\"model_config\", name=\"default_model\")\nstore(builds(train, epochs=3, populate_full_signature=True, zen_partial=True),\n      group=\"model_config\", name=\"quick\")\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#5-create-the-base-config","title":"5. Create the Base Config","text":"<p>Create <code>src/configs/base.py</code>:</p> <pre><code>from hydra_zen import store\nfrom deriva_ml import DerivaML\nfrom deriva_ml.execution import create_model_config\n\nstore(create_model_config(DerivaML), name=\"deriva_model\")\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#6-run","title":"6. Run","text":"<pre><code># Authenticate\nuv run deriva-globus-auth-utils login --host dev.example.org\n\n# Verify configs\nuv run deriva-ml-run --info\n\n# Dry run\nuv run deriva-ml-run dry_run=true\n\n# Commit and run for real\ngit add -A &amp;&amp; git commit -m \"Initial model setup\"\nuv run deriva-ml-run model_config=quick datasets=training\n</code></pre>"},{"location":"user-guide/running-models-and-notebooks/#troubleshooting","title":"Troubleshooting","text":"<p>\"Config directory not found\" \u2014 Ensure <code>src/configs/</code> exists and contains an <code>__init__.py</code>. The <code>--config-dir</code> flag defaults to <code>src/configs</code>.</p> <p>\"Uncommitted changes\" warning \u2014 Commit your code before running. DerivaML tracks the Git commit hash for code provenance.</p> <p>\"Kernel not found\" \u2014 Run <code>uv run deriva-ml-install-kernel</code> to install a Jupyter kernel for the current environment. Verify with <code>jupyter kernelspec list</code>.</p> <p>Override syntax errors \u2014 Remember: <code>group=option</code> overrides a group in the defaults list, <code>group.param=value</code> overrides a specific parameter, <code>+group=option</code> adds a group not in the defaults (like <code>+experiment=...</code>).</p> <p>Notebook ignores Hydra overrides \u2014 Make sure the notebook calls <code>run_notebook(\"config_name\")</code> (not <code>get_notebook_configuration()</code> directly). Hydra overrides are passed via the <code>DERIVA_ML_HYDRA_OVERRIDES</code> environment variable, which <code>run_notebook()</code> reads automatically.</p>"}]}